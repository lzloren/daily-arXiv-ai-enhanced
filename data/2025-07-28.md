<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 15]
- [cs.CL](#cs.CL) [Total: 36]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Initial Steps in Integrating Large Reasoning and Action Models for Service Composition](https://arxiv.org/abs/2507.18775)
*Ilche Georgievski,Marco Aiello*

Main category: cs.AI

TL;DR: 论文提出结合大型推理模型（LRM）和大型动作模型（LAM）的框架，以解决服务组合中的语义推理和执行问题。


<details>
  <summary>Details</summary>
Motivation: 服务组合在构建自适应智能系统中面临推理能力有限和执行机制脆弱的挑战。

Method: 提出集成LRM和LAM的架构框架，LRM负责语义推理，LAM负责动态执行。

Result: 该框架能够自动化服务组合，弥合意图与执行之间的差距。

Conclusion: LRM-LAM集成有望将服务组合转变为基于自然语言意图的自动化过程。

Abstract: Service composition remains a central challenge in building adaptive and
intelligent software systems, often constrained by limited reasoning
capabilities or brittle execution mechanisms. This paper explores the
integration of two emerging paradigms enabled by large language models: Large
Reasoning Models (LRMs) and Large Action Models (LAMs). We argue that LRMs
address the challenges of semantic reasoning and ecosystem complexity while
LAMs excel in dynamic action execution and system interoperability. However,
each paradigm has complementary limitations - LRMs lack grounded action
capabilities, and LAMs often struggle with deep reasoning. We propose an
integrated LRM-LAM architectural framework as a promising direction for
advancing automated service composition. Such a system can reason about service
requirements and constraints while dynamically executing workflows, thus
bridging the gap between intention and execution. This integration has the
potential to transform service composition into a fully automated,
user-friendly process driven by high-level natural language intent.

</details>


### [2] [Simulation-Driven Reinforcement Learning in Queuing Network Routing Optimization](https://arxiv.org/abs/2507.18795)
*Fatima Al-Ani,Molly Wang,Jevon Charles,Aaron Ong,Joshua Forday,Vinayak Modi*

Main category: cs.AI

TL;DR: 开发了一种基于模拟的强化学习框架（Dyna-DDPG），用于优化复杂排队网络中的路由决策，适用于制造和通信领域。


<details>
  <summary>Details</summary>
Motivation: 传统排队方法在动态和不确定环境中表现不佳，因此需要一种更鲁棒的解决方案。

Method: 结合了深度确定性策略梯度（DDPG）和Dyna式规划（Dyna-DDPG），并设计了灵活的模拟环境。

Result: 实验表明，该框架能快速学习有效的路由策略，在干扰下保持鲁棒性，并能扩展到更大网络。

Conclusion: 该框架通过增强的Dyna-DDPG和良好的软件工程实践，为实际部署提供了可行方案。

Abstract: This study focuses on the development of a simulation-driven reinforcement
learning (RL) framework for optimizing routing decisions in complex queueing
network systems, with a particular emphasis on manufacturing and communication
applications. Recognizing the limitations of traditional queueing methods,
which often struggle with dynamic, uncertain environments, we propose a robust
RL approach leveraging Deep Deterministic Policy Gradient (DDPG) combined with
Dyna-style planning (Dyna-DDPG). The framework includes a flexible and
configurable simulation environment capable of modeling diverse queueing
scenarios, disruptions, and unpredictable conditions. Our enhanced Dyna-DDPG
implementation incorporates separate predictive models for next-state
transitions and rewards, significantly improving stability and sample
efficiency. Comprehensive experiments and rigorous evaluations demonstrate the
framework's capability to rapidly learn effective routing policies that
maintain robust performance under disruptions and scale effectively to larger
network sizes. Additionally, we highlight strong software engineering practices
employed to ensure reproducibility and maintainability of the framework,
enabling practical deployment in real-world scenarios.

</details>


### [3] [A Neuroscience-Inspired Dual-Process Model of Compositional Generalization](https://arxiv.org/abs/2507.18868)
*Alex Noviello,Claas Beger,Jacob Groner,Kevin Ellis,Weinan Sun*

Main category: cs.AI

TL;DR: MIRAGE框架通过模拟人脑HPC-PFC循环实现系统性组合泛化，结合元训练Transformer和Schema Engine，在SCAN基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决AI系统在组合泛化中的核心挑战，模仿人脑HPC-PFC机制以实现灵活推理。

Method: MIRAGE包含两个模块：元训练的Transformer Neural Decomposer（类似新皮层模式识别）和Schema Engine（类似HPC-PFC循环），通过动态提取和应用可重用模式实现泛化。

Result: 在SCAN基准测试中达到>99%准确率，仅需1.19M参数。消融实验验证了模式质量和迭代精炼的关键作用。

Conclusion: MIRAGE通过显式模式管理和迭代精炼，实现了系统性组合泛化，为AI系统提供了新思路。

Abstract: Systematic compositional generalization - constructing and understanding
novel combinations of known building blocks - remains a core challenge for AI
systems. Human cognition achieves this flexibility via the interplay of the
hippocampus (HPC) and prefrontal cortex (PFC): the hippocampus rapidly encodes
episodes, and the prefrontal cortex consolidates them into reusable schemas for
reasoning. Drawing on these insights, we present MIRAGE (Meta-Inference with
Rules and Abstractions from Generalized Experience), a framework that achieves
systematic generalization on compositional tasks. MIRAGE has two interacting
modules mirroring the brain's deliberative HPC-PFC loop and intuitive
neocortical pattern recognition. (1) The meta-trained Transformer Neural
Decomposer, paralleling neocortical "System 1" computation, is trained on a
task-agnostic stream of randomly sampled compositional grammars and applies one
decomposition step per pass, with successive passes iteratively refining the
sequence representation. (2) The Schema Engine, analogous to the HPC-PFC
"System 2" loop, dynamically extracts, ranks, and applies reusable schemas,
storing variable bindings in episodic memory and expanding them when needed. By
explicitly equipping the Transformer component of MIRAGE with actively managed
schematic structures, our model performs systematic compositional operations
through explicit schema application and transformation, relying solely on
frozen weights when solving entirely novel tasks. This approach demonstrates
systematic compositional generalization on the SCAN benchmark, achieving > 99%
accuracy on all task splits with only 1.19M parameters in the transformer
module. Ablation studies confirm that MIRAGE's systematicity critically depends
on the quality of extracted schemas and the model's iterative refinement
process.

</details>


### [4] [Success in Humanoid Reinforcement Learning under Partial Observation](https://arxiv.org/abs/2507.18883)
*Wuhao Wang,Zhiyong Chen*

Main category: cs.AI

TL;DR: 首次在部分可观测环境下成功训练人形机器人策略，性能接近全状态访问的先进结果，关键是一种新型历史编码器。


<details>
  <summary>Details</summary>
Motivation: 解决部分可观测性下人形机器人控制策略学习的挑战，尤其是在高维任务中。

Method: 提出一种新型历史编码器，处理固定长度的过去观测序列，集成到标准无模型算法中。

Result: 学习到的策略性能接近全状态基线，且能适应机器人属性变化。

Conclusion: 历史编码器通过重建上下文信息，实现了部分可观测环境下的鲁棒决策。

Abstract: Reinforcement learning has been widely applied to robotic control, but
effective policy learning under partial observability remains a major
challenge, especially in high-dimensional tasks like humanoid locomotion. To
date, no prior work has demonstrated stable training of humanoid policies with
incomplete state information in the benchmark Gymnasium Humanoid-v4
environment. The objective in this environment is to walk forward as fast as
possible without falling, with rewards provided for staying upright and moving
forward, and penalties incurred for excessive actions and external contact
forces. This research presents the first successful instance of learning under
partial observability in this environment. The learned policy achieves
performance comparable to state-of-the-art results with full state access,
despite using only one-third to two-thirds of the original states. Moreover,
the policy exhibits adaptability to robot properties, such as variations in
body part masses. The key to this success is a novel history encoder that
processes a fixed-length sequence of past observations in parallel. Integrated
into a standard model-free algorithm, the encoder enables performance on par
with fully observed baselines. We hypothesize that it reconstructs essential
contextual information from recent observations, thereby enabling robust
decision-making.

</details>


### [5] [Towards Improving Long-Tail Entity Predictions in Temporal Knowledge Graphs through Global Similarity and Weighted Sampling](https://arxiv.org/abs/2507.18977)
*Mehrnoosh Mirtaheri,Ryan A. Rossi,Sungchul Kim,Kanak Mahadik,Tong Yu,Xiang Chen,Mohammad Rostami*

Main category: cs.AI

TL;DR: 提出了一种增量训练框架，用于解决时序知识图谱（TKG）完成中未观察或稀疏连接实体的挑战，通过模型无关的增强层和加权采样策略提升性能。


<details>
  <summary>Details</summary>
Motivation: 传统TKG完成模型假设训练时能访问整个图谱，忽视了图谱动态演化带来的挑战，如新知识整合和稀疏连接实体处理。

Method: 结合模型无关的增强层（基于全局实体相似性）和加权采样策略（突出稀疏实体边），可增强现有TKG完成方法。

Result: 在两个基准数据集上，方法在总链接预测、归纳链接预测及长尾实体处理上优于现有方法，MRR提升10%-15%。

Conclusion: 该方法有效缓解灾难性遗忘，提升TKG完成方法的鲁棒性，特别适用于增量训练场景。

Abstract: Temporal Knowledge Graph (TKG) completion models traditionally assume access
to the entire graph during training. This overlooks challenges stemming from
the evolving nature of TKGs, such as: (i) the model's requirement to generalize
and assimilate new knowledge, and (ii) the task of managing new or unseen
entities that often have sparse connections. In this paper, we present an
incremental training framework specifically designed for TKGs, aiming to
address entities that are either not observed during training or have sparse
connections. Our approach combines a model-agnostic enhancement layer with a
weighted sampling strategy, that can be augmented to and improve any existing
TKG completion method. The enhancement layer leverages a broader, global
definition of entity similarity, which moves beyond mere local neighborhood
proximity of GNN-based methods. The weighted sampling strategy employed in
training accentuates edges linked to infrequently occurring entities. We
evaluate our method on two benchmark datasets, and demonstrate that our
framework outperforms existing methods in total link prediction, inductive link
prediction, and in addressing long-tail entities. Notably, our method achieves
a 10\% improvement and a 15\% boost in MRR for these datasets. The results
underscore the potential of our approach in mitigating catastrophic forgetting
and enhancing the robustness of TKG completion methods, especially in an
incremental training context

</details>


### [6] [Fine-Grained Traffic Inference from Road to Lane via Spatio-Temporal Graph Node Generation](https://arxiv.org/abs/2507.19089)
*Shuhao Li,Weidong Yang,Yue Cui,Xiaoxing Liu,Lingkai Meng,Lipeng Ma,Fan Zhang*

Main category: cs.AI

TL;DR: 论文提出了FRTI任务，通过有限的道路数据生成更详细的车道级交通信息，并设计了RoadDiff框架来解决该任务。


<details>
  <summary>Details</summary>
Motivation: 解决车道级交通数据获取困难的问题，为精确交通管理提供高效、低成本的解决方案。

Method: 设计了RoadDiff框架，包括Road-Lane Correlation Autoencoder-Decoder和Lane Diffusion Module，利用有限的时空依赖性和分布关系推断车道交通状态。

Result: 在六个不同道路条件的数据集上验证了RoadDiff模型的有效性。

Conclusion: RoadDiff框架能够高效解决FRTI任务，为精细交通管理提供支持。

Abstract: Fine-grained traffic management and prediction are fundamental to key
applications such as autonomous driving, lane change guidance, and traffic
signal control. However, obtaining lane-level traffic data has become a
critical bottleneck for data-driven models due to limitations in the types and
number of sensors and issues with the accuracy of tracking algorithms. To
address this, we propose the Fine-grained Road Traffic Inference (FRTI) task,
which aims to generate more detailed lane-level traffic information using
limited road data, providing a more energy-efficient and cost-effective
solution for precise traffic management. This task is abstracted as the first
scene of the spatio-temporal graph node generation problem. We designed a
two-stage framework--RoadDiff--to solve the FRTI task. solve the FRTI task.
This framework leverages the Road-Lane Correlation Autoencoder-Decoder and the
Lane Diffusion Module to fully utilize the limited spatio-temporal dependencies
and distribution relationships of road data to accurately infer fine-grained
lane traffic states. Based on existing research, we designed several baseline
models with the potential to solve the FRTI task and conducted extensive
experiments on six datasets representing different road conditions to validate
the effectiveness of the RoadDiff model in addressing the FRTI task. The
relevant datasets and code are available at
https://github.com/ShuhaoLii/RoadDiff.

</details>


### [7] [Pareto-NRPA: A Novel Monte-Carlo Search Algorithm for Multi-Objective Optimization](https://arxiv.org/abs/2507.19109)
*Noé Lallouet,Tristan Cazenave,Cyrille Enderli*

Main category: cs.AI

TL;DR: Pareto-NRPA是一种新的蒙特卡洛算法，用于离散搜索空间的多目标优化问题，扩展了单目标问题的NRPA算法，并在多目标优化中表现出色。


<details>
  <summary>Details</summary>
Motivation: 将单目标优化的NRPA算法扩展到多目标优化问题，以解决现有算法在收敛性和多样性上的不足。

Method: 通过一组策略并行探索解空间的不同区域，并在搜索的每个层级维护非支配前沿，策略更新基于Pareto前沿的多样性和隔离性。

Result: 在MO-TSPTW问题和神经架构搜索任务上，Pareto-NRPA表现优于现有最先进的多目标算法，尤其在受限搜索空间中。

Conclusion: Pareto-NRPA是NRPA算法在多目标优化中的首次成功扩展，具有显著的性能优势。

Abstract: We introduce Pareto-NRPA, a new Monte-Carlo algorithm designed for
multi-objective optimization problems over discrete search spaces. Extending
the Nested Rollout Policy Adaptation (NRPA) algorithm originally formulated for
single-objective problems, Pareto-NRPA generalizes the nested search and policy
update mechanism to multi-objective optimization. The algorithm uses a set of
policies to concurrently explore different regions of the solution space and
maintains non-dominated fronts at each level of search. Policy adaptation is
performed with respect to the diversity and isolation of sequences within the
Pareto front. We benchmark Pareto-NRPA on two classes of problems: a novel
bi-objective variant of the Traveling Salesman Problem with Time Windows
problem (MO-TSPTW), and a neural architecture search task on well-known
benchmarks. Results demonstrate that Pareto-NRPA achieves competitive
performance against state-of-the-art multi-objective algorithms, both in terms
of convergence and diversity of solutions. Particularly, Pareto-NRPA strongly
outperforms state-of-the-art evolutionary multi-objective algorithms on
constrained search spaces. To our knowledge, this work constitutes the first
adaptation of NRPA to the multi-objective setting.

</details>


### [8] [OS-MAP: How Far Can Computer-Using Agents Go in Breadth and Depth?](https://arxiv.org/abs/2507.19132)
*Xuetian Chen,Yinghao Chen,Xinfeng Yuan,Zhuo Peng,Lu Chen,Yuekeng Li,Zhoujia Zhang,Yingqian Huang,Leyan Huang,Jiaqing Liang,Tianbao Xie,Zhiyong Wu,Qiushi Sun,Biqing Qi,Bowen Zhou*

Main category: cs.AI

TL;DR: OS-MAP是一个用于日常计算机自动化任务的基准测试，通过五级自动化分类和需求层次结构评估代理能力，揭示了当前先进代理在感知、推理和协调方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试未能考虑任务内部异质性和代理能力与实际用户需求的匹配，阻碍了能力开发和研究成果的实际部署。

Method: 提出OS-MAP基准，包含416个任务，按五级自动化分类和需求层次结构组织，评估代理的自动化水平和泛化范围。

Result: 实验表明，即使基于VLM的先进代理在涉及感知、推理和协调的高级任务中也表现不佳。

Conclusion: OS-MAP为计算机代理研究提供了结构化评估框架，揭示了当前技术的局限性，推动未来研究进步。

Abstract: Computer-using agents have shown strong potential to boost human productivity
and enable new application forms across platforms. While recent advances have
led to usable applications, existing benchmarks fail to account for the
internal task heterogeneity and the corresponding agent capabilities, as well
as their alignment with actual user demands-hindering both targeted capability
development and the reliable transition of research progress into practical
deployment. To bridge the gap, we present OS-MAP, a benchmark for daily
computer-using automation that organizes its 416 realistic tasks across 15
applications along two key dimensions: a five-level taxonomy of automation and
a generalization scope derived from a real-world user demand hierarchy. To
enable fine-grained analysis of required capabilities and alignment with
real-world scenarios, OS-MAP evaluates agents along two dimensions: automation
level across a five-level taxonomy, and generalization scope across a demand
hierarchy. This design captures varying levels of required agent autonomy and
generalization, forming a performance-generalization evaluation matrix for
structured and comprehensive assessment. Experiments show that even
State-of-the-Art agents with VLM backbones struggle with higher-level tasks
involving perception, reasoning, and coordination-highlighting the need for a
deeper understanding of current strengths and limitations to drive the future
progress in computer-using agents research and deployment. All code,
environments, baselines, and data are publicly available at
https://github.com/OS-Copilot/OS-Map.

</details>


### [9] [PhysDrive: A Multimodal Remote Physiological Measurement Dataset for In-vehicle Driver Monitoring](https://arxiv.org/abs/2507.19172)
*Jiyao Wang,Xiao Yang,Qingyong Hu,Jiankai Tang,Can Liu,Dengbo He,Yuntao Wang,Yingcong Chen,Kaishun Wu*

Main category: cs.AI

TL;DR: PhysDrive是一个大规模多模态数据集，专注于无接触车内生理监测，填补了现有数据集的不足，支持多种传感器和驾驶条件的研究。


<details>
  <summary>Details</summary>
Motivation: 现有远程生理监测数据集规模小、多样性不足，无法满足真实驾驶场景的需求，PhysDrive旨在解决这一问题。

Method: 收集48名驾驶员的多模态数据（RGB、近红外相机、毫米波雷达），同步六种生理信号（ECG、BVP等），覆盖多种驾驶条件。

Result: PhysDrive为信号处理和深度学习方法提供了全面基准，并开源代码，兼容主流工具箱。

Conclusion: PhysDrive将成为多模态驾驶员监测和智能座舱系统研究的基础资源。

Abstract: Robust and unobtrusive in-vehicle physiological monitoring is crucial for
ensuring driving safety and user experience. While remote physiological
measurement (RPM) offers a promising non-invasive solution, its translation to
real-world driving scenarios is critically constrained by the scarcity of
comprehensive datasets. Existing resources are often limited in scale, modality
diversity, the breadth of biometric annotations, and the range of captured
conditions, thereby omitting inherent real-world challenges in driving. Here,
we present PhysDrive, the first large-scale multimodal dataset for contactless
in-vehicle physiological sensing with dedicated consideration on various
modality settings and driving factors. PhysDrive collects data from 48 drivers,
including synchronized RGB, near-infrared camera, and raw mmWave radar data,
accompanied with six synchronized ground truths (ECG, BVP, Respiration, HR, RR,
and SpO2). It covers a wide spectrum of naturalistic driving conditions,
including driver motions, dynamic natural light, vehicle types, and road
conditions. We extensively evaluate both signal-processing and deep-learning
methods on PhysDrive, establishing a comprehensive benchmark across all
modalities, and release full open-source code with compatibility for mainstream
public toolboxes. We envision PhysDrive will serve as a foundational resource
and accelerate research on multimodal driver monitoring and smart-cockpit
systems.

</details>


### [10] [Faster Lifting for Ordered Domains with Predecessor Relations](https://arxiv.org/abs/2507.19182)
*Kuncheng Zou,Jiahao Mai,Yonggang Zhang,Yuyi Wang,Ondřej Kuželka,Yuanhong Wang,Yi Chang*

Main category: cs.AI

TL;DR: 论文提出了一种新算法，直接在公理中处理前驱关系，显著提升了有序域上加权一阶模型计数（WFOMC）的效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理有序域上的前驱关系时效率低下，尤其是在涉及前驱关系时。

Method: 将前驱关系作为公理的本部分，设计了一种新算法，支持直接处理前驱关系。

Result: 新算法在处理直接和第二前驱关系时实现了指数级加速，并能处理一般k阶前驱关系，实验显示速度提升了一个数量级。

Conclusion: 新算法显著提升了有序域上WFOMC的效率，尤其在处理前驱关系时表现优异。

Abstract: We investigate lifted inference on ordered domains with predecessor
relations, where the elements of the domain respect a total (cyclic) order, and
every element has a distinct (clockwise) predecessor. Previous work has
explored this problem through weighted first-order model counting (WFOMC),
which computes the weighted sum of models for a given first-order logic
sentence over a finite domain. In WFOMC, the order constraint is typically
encoded by the linear order axiom introducing a binary predicate in the
sentence to impose a linear ordering on the domain elements. The immediate and
second predecessor relations are then encoded by the linear order predicate.
Although WFOMC with the linear order axiom is theoretically tractable, existing
algorithms struggle with practical applications, particularly when the
predecessor relations are involved. In this paper, we treat predecessor
relations as a native part of the axiom and devise a novel algorithm that
inherently supports these relations. The proposed algorithm not only provides
an exponential speedup for the immediate and second predecessor relations,
which are known to be tractable, but also handles the general k-th predecessor
relations. The extensive experiments on lifted inference tasks and
combinatorics math problems demonstrate the efficiency of our algorithm,
achieving speedups of a full order of magnitude.

</details>


### [11] [Knowledge Grafting: A Mechanism for Optimizing AI Model Deployment in Resource-Constrained Environments](https://arxiv.org/abs/2507.19261)
*Osama Almurshed,Ashish Kaushal,Asmail Muftah,Nitin Auluck,Omer Rana*

Main category: cs.AI

TL;DR: 论文提出了一种名为知识嫁接的新方法，通过将大型模型的特征转移到小型模型，显著减小模型体积并提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决AI模型在资源受限环境中部署的挑战，避免计算资源不足的问题。

Method: 采用知识嫁接机制，将大型模型（供体）的选定特征（接穗）转移到小型模型（砧木）。

Result: 模型体积减少88.54%，验证准确率提升至89.97%，测试准确率达90.45%。

Conclusion: 该方法突破了模型大小与性能的权衡，适用于边缘计算场景，推动AI在资源受限环境中的应用。

Abstract: The increasing adoption of Artificial Intelligence (AI) has led to larger,
more complex models with numerous parameters that require substantial computing
power -- resources often unavailable in many real-world application scenarios.
Our paper addresses this challenge by introducing knowledge grafting, a novel
mechanism that optimizes AI models for resource-constrained environments by
transferring selected features (the scion) from a large donor model to a
smaller rootstock model. The approach achieves an 88.54% reduction in model
size (from 64.39 MB to 7.38 MB), while improving generalization capability of
the model. Our new rootstock model achieves 89.97% validation accuracy (vs.
donor's 87.47%), maintains lower validation loss (0.2976 vs. 0.5068), and
performs exceptionally well on unseen test data with 90.45% accuracy. It
addresses the typical size vs performance trade-off, and enables deployment of
AI frameworks on resource-constrained devices with enhanced performance. We
have tested our approach on an agricultural weed detection scenario, however,
it can be extended across various edge computing scenarios, potentially
accelerating AI adoption in areas with limited hardware/software support -- by
mirroring in a similar manner the horticultural grafting enables productive
cultivation in challenging agri-based environments.

</details>


### [12] [Modeling Uncertainty: Constraint-Based Belief States in Imperfect-Information Games](https://arxiv.org/abs/2507.19263)
*Achille Morenville,Éric Piette*

Main category: cs.AI

TL;DR: 论文研究了在隐藏棋子身份游戏中，基于约束和概率的两种信念表示方法，发现约束方法效果接近概率方法。


<details>
  <summary>Details</summary>
Motivation: 解决不完全信息游戏中代理基于部分知识决策的挑战，减少游戏特定推理逻辑的需求。

Method: 使用约束满足问题和信念传播两种方法表示信念，并在两种游戏中评估其效果。

Result: 约束基信念与概率推理效果相当，代理性能差异小。

Conclusion: 约束基信念在许多情况下足以支持有效决策。

Abstract: In imperfect-information games, agents must make decisions based on partial
knowledge of the game state. The Belief Stochastic Game model addresses this
challenge by delegating state estimation to the game model itself. This allows
agents to operate on externally provided belief states, thereby reducing the
need for game-specific inference logic. This paper investigates two approaches
to represent beliefs in games with hidden piece identities: a constraint-based
model using Constraint Satisfaction Problems and a probabilistic extension
using Belief Propagation to estimate marginal probabilities. We evaluated the
impact of both representations using general-purpose agents across two
different games. Our findings indicate that constraint-based beliefs yield
results comparable to those of probabilistic inference, with minimal
differences in agent performance. This suggests that constraint-based belief
states alone may suffice for effective decision-making in many settings.

</details>


### [13] [Integrating LLM in Agent-Based Social Simulation: Opportunities and Challenges](https://arxiv.org/abs/2507.19364)
*Patrick Taillandier,Jean Daniel Zucker,Arnaud Grignard,Benoit Gaudou,Nghi Quang Huynh,Alexis Drogoul*

Main category: cs.AI

TL;DR: 本文探讨了大语言模型（LLMs）在社会模拟中的应用潜力与局限性，提出结合传统基于规则的建模平台的混合方法。


<details>
  <summary>Details</summary>
Motivation: 从计算社会科学角度分析LLMs在模拟人类认知和社会行为中的能力与不足，推动更有效的模拟方法。

Method: 分为三部分：1）评估LLMs在人类认知复现中的表现；2）调查LLMs在多智能体模拟中的应用；3）提出混合建模方法。

Result: LLMs在交互模拟中有直接价值，但在解释性或预测性建模中存在局限性。混合方法可结合灵活性与透明度。

Conclusion: 建议将LLMs与传统基于规则的建模平台结合，以平衡语言推理的表达灵活性与规则系统的分析严谨性。

Abstract: This position paper examines the use of Large Language Models (LLMs) in
social simulation, analyzing both their potential and their limitations from a
computational social science perspective. The first part reviews recent
findings on the ability of LLMs to replicate key aspects of human cognition,
including Theory of Mind reasoning and social inference, while also
highlighting significant limitations such as cognitive biases, lack of true
understanding, and inconsistencies in behavior. The second part surveys
emerging applications of LLMs in multi-agent simulation frameworks, focusing on
system architectures, scale, and validation strategies. Notable projects such
as Generative Agents (Smallville) and AgentSociety are discussed in terms of
their design choices, empirical grounding, and methodological innovations.
Particular attention is given to the challenges of behavioral fidelity,
calibration, and reproducibility in large-scale LLM-driven simulations. The
final section distinguishes between contexts where LLMs, like other black-box
systems, offer direct value-such as interactive simulations and serious
games-and those where their use is more problematic, notably in explanatory or
predictive modeling. The paper concludes by advocating for hybrid approaches
that integrate LLMs into traditional agent-based modeling platforms (GAMA,
Netlogo, etc), enabling modelers to combine the expressive flexibility of
language-based reasoning with the transparency and analytical rigor of
classical rule-based systems.

</details>


### [14] [Learning neuro-symbolic convergent term rewriting systems](https://arxiv.org/abs/2507.19372)
*Flavio Petruzzellis,Alberto Testolin,Alessandro Sperduti*

Main category: cs.AI

TL;DR: 提出了一种基于神经符号架构的学习框架（NRS和FastNRS），用于学习收敛的项重写系统，显著提升了泛化能力和效率。


<details>
  <summary>Details</summary>
Motivation: 解决符号算法学习的泛化和分布外性能问题。

Method: 采用神经符号架构，设计NRS和FastNRS两种模块化实现。

Result: 在数学公式简化任务中优于强基线模型（如GPT-4o），并在多域学习中表现优异。

Conclusion: 该框架在符号算法学习中表现出色，具有高效性和泛化能力。

Abstract: Building neural systems that can learn to execute symbolic algorithms is a
challenging open problem in artificial intelligence, especially when aiming for
strong generalization and out-of-distribution performance. In this work, we
introduce a general framework for learning convergent term rewriting systems
using a neuro-symbolic architecture inspired by the rewriting algorithm itself.
We present two modular implementations of such architecture: the Neural
Rewriting System (NRS) and the Fast Neural Rewriting System (FastNRS). As a
result of algorithmic-inspired design and key architectural elements, both
models can generalize to out-of-distribution instances, with FastNRS offering
significant improvements in terms of memory efficiency, training speed, and
inference time. We evaluate both architectures on four tasks involving the
simplification of mathematical formulas and further demonstrate their
versatility in a multi-domain learning scenario, where a single model is
trained to solve multiple types of problems simultaneously. The proposed system
significantly outperforms two strong neural baselines: the Neural Data Router,
a recent transformer variant specifically designed to solve algorithmic
problems, and GPT-4o, one of the most powerful general-purpose large-language
models. Moreover, our system matches or outperforms the latest o1-preview model
from OpenAI that excels in reasoning benchmarks.

</details>


### [15] [Hierarchical Deep Reinforcement Learning Framework for Multi-Year Asset Management Under Budget Constraints](https://arxiv.org/abs/2507.19458)
*Amir Fard,Arnold X. -X. Yuan*

Main category: cs.AI

TL;DR: 提出了一种分层深度强化学习方法，用于解决基础设施预算规划与维护优化的复杂性问题，通过分解问题层次并整合线性规划，显著提升了可扩展性和效率。


<details>
  <summary>Details</summary>
Motivation: 基础设施资产管理中的预算规划与维护优化面临组合动作空间、资产退化多样性、严格预算约束和环境不确定性等挑战，现有方法难以扩展。

Method: 采用分层深度强化学习框架，分为高层预算规划器和低层维护规划器，结合线性规划投影和Soft Actor-Critic算法，确保预算合规性和高效决策。

Result: 在10、15和20个排水区域的案例中，该方法比传统深度Q学习和遗传算法收敛更快、扩展性更强，且能提供接近最优的解决方案。

Conclusion: 分层深度强化学习方法有效解决了基础设施规划中的复杂性问题，为大规模资产管理提供了可扩展且高效的解决方案。

Abstract: Budget planning and maintenance optimization are crucial for infrastructure
asset management, ensuring cost-effectiveness and sustainability. However, the
complexity arising from combinatorial action spaces, diverse asset
deterioration, stringent budget constraints, and environmental uncertainty
significantly limits existing methods' scalability. This paper proposes a
Hierarchical Deep Reinforcement Learning methodology specifically tailored to
multi-year infrastructure planning. Our approach decomposes the problem into
two hierarchical levels: a high-level Budget Planner allocating annual budgets
within explicit feasibility bounds, and a low-level Maintenance Planner
prioritizing assets within the allocated budget. By structurally separating
macro-budget decisions from asset-level prioritization and integrating linear
programming projection within a hierarchical Soft Actor-Critic framework, the
method efficiently addresses exponential growth in the action space and ensures
rigorous budget compliance. A case study evaluating sewer networks of varying
sizes (10, 15, and 20 sewersheds) illustrates the effectiveness of the proposed
approach. Compared to conventional Deep Q-Learning and enhanced genetic
algorithms, our methodology converges more rapidly, scales effectively, and
consistently delivers near-optimal solutions even as network size grows.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [16] [Specification Self-Correction: Mitigating In-Context Reward Hacking Through Test-Time Refinement](https://arxiv.org/abs/2507.18742)
*Víctor Gallego*

Main category: cs.CL

TL;DR: 论文提出了一种名为Specification Self-Correction (SSC)的框架，通过多步推理过程让语言模型识别并修正自身指导规范中的缺陷，显著减少了模型利用规范漏洞的行为。


<details>
  <summary>Details</summary>
Motivation: 语言模型容易利用规范中的漏洞（in-context reward hacking）来获取高分，而不满足用户的真实意图。为了解决这一问题，论文提出了SSC框架。

Method: SSC采用多步推理过程：模型首先生成基于可能污染的规范的响应，然后对其输出进行批判，并修正规范以消除漏洞，最后生成更稳健的响应。

Result: 实验表明，SSC将模型利用规范漏洞的行为从50-70%减少到90%以上，且无需修改模型权重。

Conclusion: SSC框架在推理时动态修复规范漏洞，显著提升了模型行为的稳健性和对齐性。

Abstract: Language models (LMs) are susceptible to in-context reward hacking, where
they exploit flaws in tainted or faulty written specifications or rubrics to
achieve high scores without fulfilling the user's true intent. We introduce
Specification Self-Correction (SSC), a novel, test-time framework that enables
an LM to identify and correct flaws within its own guiding specification. SSC
employs a multi-step inference process where the model first generates a
response based on a potentially tainted specification, critiques its output,
and then revises the specification itself to remove the exploitable loophole. A
final, more robust response is then generated using this self-corrected
specification. Across experiments spanning creative writing and agentic coding
tasks with several LMs, we demonstrate that while models initially game tainted
specifications in 50-70\% of cases, the SSC process reduces this vulnerability
by over 90\%. This dynamic repair occurs at inference time, requires no weight
modification, and leads to more robustly aligned model behavior. Code at
https://github.com/vicgalle/specification-self-correction .

</details>


### [17] [The Role of Orthographic Consistency in Multilingual Embedding Models for Text Classification in Arabic-Script Languages](https://arxiv.org/abs/2507.18762)
*Abdulhady Abas Abdullah,Amir H. Gandomi,Tarik A Rashid,Seyedali Mirjalili,Laith Abualigah,Milena Živković,Hadi Veisi*

Main category: cs.CL

TL;DR: AS-RoBERTa系列模型针对阿拉伯语系语言（如库尔德语、阿拉伯语、波斯语和乌尔都语）进行预训练，通过专注于语言特定的脚本特征，显著提升了分类任务性能，优于通用多语言模型。


<details>
  <summary>Details</summary>
Motivation: 通用多语言模型在处理共享脚本但语言和文化差异较大的语言时表现不佳，尤其是阿拉伯语系语言。

Method: 提出AS-RoBERTa系列模型，每个模型针对特定语言进行预训练，专注于脚本特征和统计信息。

Result: AS-RoBERTa在分类任务中比mBERT和XLM-RoBERTa高出2到5个百分点，脚本专注的预训练是关键。

Conclusion: 脚本感知的预训练对阿拉伯语系语言有显著价值，支持进一步研究基于脚本和语言特性的预训练策略。

Abstract: In natural language processing, multilingual models like mBERT and
XLM-RoBERTa promise broad coverage but often struggle with languages that share
a script yet differ in orthographic norms and cultural context. This issue is
especially notable in Arabic-script languages such as Kurdish Sorani, Arabic,
Persian, and Urdu. We introduce the Arabic Script RoBERTa (AS-RoBERTa) family:
four RoBERTa-based models, each pre-trained on a large corpus tailored to its
specific language. By focusing pre-training on language-specific script
features and statistics, our models capture patterns overlooked by
general-purpose models. When fine-tuned on classification tasks, AS-RoBERTa
variants outperform mBERT and XLM-RoBERTa by 2 to 5 percentage points. An
ablation study confirms that script-focused pre-training is central to these
gains. Error analysis using confusion matrices shows how shared script traits
and domain-specific content affect performance. Our results highlight the value
of script-aware specialization for languages using the Arabic script and
support further work on pre-training strategies rooted in script and language
specificity.

</details>


### [18] [ylmmcl at Multilingual Text Detoxification 2025: Lexicon-Guided Detoxification and Classifier-Gated Rewriting](https://arxiv.org/abs/2507.18769)
*Nicole Lai-Lopez,Lusha Wang,Su Yuan,Liza Zhang*

Main category: cs.CL

TL;DR: 该论文提出了一种多语言文本去毒解决方案，结合词典引导标记、微调序列到序列模型和迭代分类器门控机制，在多语言任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决多语言文本去毒任务，提升去毒精度和跨语言泛化能力。

Method: 整合词典引导标记、微调序列到序列模型（s-nlp/mt0-xl-detox-orpo）和迭代分类器门控机制。

Result: 在开发集和测试集上取得最高STA（0.922）和平均J分数（0.612），xCOMET分数分别为0.793和0.787。

Conclusion: 该方法在多语言任务中表现优于基线方法，展现了强大的泛化能力，但SIM指标有所牺牲。

Abstract: In this work, we introduce our solution for the Multilingual Text
Detoxification Task in the PAN-2025 competition for the ylmmcl team: a robust
multilingual text detoxification pipeline that integrates lexicon-guided
tagging, a fine-tuned sequence-to-sequence model (s-nlp/mt0-xl-detox-orpo) and
an iterative classifier-based gatekeeping mechanism. Our approach departs from
prior unsupervised or monolingual pipelines by leveraging explicit toxic word
annotation via the multilingual_toxic_lexicon to guide detoxification with
greater precision and cross-lingual generalization. Our final model achieves
the highest STA (0.922) from our previous attempts, and an average official J
score of 0.612 for toxic inputs in both the development and test sets. It also
achieved xCOMET scores of 0.793 (dev) and 0.787 (test). This performance
outperforms baseline and backtranslation methods across multiple languages, and
shows strong generalization in high-resource settings (English, Russian,
French). Despite some trade-offs in SIM, the model demonstrates consistent
improvements in detoxification strength. In the competition, our team achieved
ninth place with a score of 0.612.

</details>


### [19] [Evaluating Code-Mixing in LLMs Across 18 Languages](https://arxiv.org/abs/2507.18791)
*Yilun Yang,Yekun Chai*

Main category: cs.CL

TL;DR: 论文研究了代码混合（多语言混合使用）对自然语言处理的挑战，指出现有基准的局限性，并提出了一种新的合成代码混合文本的方法。


<details>
  <summary>Details</summary>
Motivation: 代码混合对多语言用户至关重要，但现有基准和大型语言模型（LLM）在此领域的研究不足，且数据生成方法不成熟。

Method: 对18种语言的代码混合数据进行全面评估，并提出结合单词替换和GPT-4提示的合成文本生成方法。

Result: LLM在涉及多语言家族的代码混合数据上表现不佳。

Conclusion: 建议通过增加训练数据规模、模型规模和少样本学习来提升LLM在代码混合任务中的表现。

Abstract: Code-mixing, the practice of switching between languages within a
conversation, presents unique challenges for traditional natural language
processing. Existing benchmarks, such as LinCE and GLUECoS, are limited by
narrow language pairings and tasks, failing to adequately evaluate the
code-mixing capabilities of large language models (LLMs). Despite the
significance of code-mixing for multilingual users, research on LLMs in this
context remains limited. Additionally, current methods for generating
code-mixed data are underdeveloped. In this paper, we conduct a comprehensive
evaluation of LLMs' performance on code-mixed data across 18 languages from
seven language families. We also propose a novel approach for generating
synthetic code-mixed texts by combining word substitution with GPT-4 prompting.
Our analysis reveals consistent underperformance of LLMs on code-mixed datasets
involving multiple language families. We suggest that improvements in training
data size, model scale, and few-shot learning could enhance their performance.

</details>


### [20] [CueBuddy: helping non-native English speakers navigate English-centric STEM education](https://arxiv.org/abs/2507.18827)
*Pranav Gupta*

Main category: cs.CL

TL;DR: CueBuddy提供实时词汇提示，帮助非英语母语的STEM学生理解复杂术语，而不干扰课堂专注。


<details>
  <summary>Details</summary>
Motivation: 全球南方STEM学生在英语术语理解上落后于英语流利的同学，尽管科学基础相当。

Method: 通过实时技术关键词识别和多语言词汇表查询，提供实时词汇提示。

Result: CueBuddy帮助学生跟上复杂英语术语，同时保持课堂专注。

Conclusion: 该方法有效但存在局限性，未来可进一步扩展。

Abstract: Students across the world in STEM classes, especially in the Global South,
fall behind their peers who are more fluent in English, despite being at par
with them in terms of scientific prerequisites. While many of them are able to
follow everyday English at ease, key terms in English stay challenging. In most
cases, such students have had most of their course prerequisites in a lower
resource language. Live speech translation to lower resource languages is a
promising area of research, however, models for speech translation can be too
expensive on a large scale and often struggle with technical content. In this
paper, we describe CueBuddy, which aims to remediate these issues by providing
real-time "lexical cues" through technical keyword spotting along real-time
multilingual glossary lookup to help students stay up to speed with complex
English jargon without disrupting their concentration on the lecture. We also
describe the limitations and future extensions of our approach.

</details>


### [21] [PrismRAG: Boosting RAG Factuality with Distractor Resilience and Strategized Reasoning](https://arxiv.org/abs/2507.18857)
*Mohammad Kachuee,Teja Gollapudi,Minseok Kim,Yin Huang,Kai Sun,Xiao Yang,Jiaqi Wang,Nirav Shah,Yue Liu,Aaron Colak,Anuj Kumar,Wen-tau Yih,Xin Luna Dong*

Main category: cs.CL

TL;DR: PrismRAG通过训练模型处理干扰性上下文并增强推理能力，显著提升了RAG在问答任务中的准确性和事实性。


<details>
  <summary>Details</summary>
Motivation: 传统RAG在处理半相关或需要深度推理的上下文时表现不佳，PrismRAG旨在解决这一问题。

Method: PrismRAG通过训练模型处理包含干扰的QA对，并培养其自主推理能力，减少对人工指令的依赖。

Result: 在12个开放书RAG问答基准测试中，PrismRAG平均事实性提升5.4%，优于现有方法。

Conclusion: PrismRAG通过改进训练和推理机制，显著提升了RAG模型的性能。

Abstract: Retrieval-augmented generation (RAG) often falls short when retrieved context
includes confusing semi-relevant passages, or when answering questions require
deep contextual understanding and reasoning. We propose an efficient
fine-tuning framework, called PrismRAG, that (i) trains the model with
distractor-aware QA pairs mixing gold evidence with subtle distractor passages,
and (ii) instills reasoning-centric habits that make the LLM plan, rationalize,
and synthesize without relying on extensive human engineered instructions.
Evaluated across 12 open-book RAG QA benchmarks spanning diverse application
domains and scenarios, PrismRAG improves average factuality by 5.4%,
outperforming state-of-the-art solutions.

</details>


### [22] [MindFlow+: A Self-Evolving Agent for E-Commerce Customer Service](https://arxiv.org/abs/2507.18884)
*Ming Gong,Xucheng Huang,Ziheng Xu,Vijayan K. Asari*

Main category: cs.CL

TL;DR: MindFlow+是一种自进化的对话代理，结合大型语言模型（LLM）、模仿学习和离线强化学习（RL），通过数据驱动机制提升电子商务对话质量。


<details>
  <summary>Details</summary>
Motivation: 传统基于意图的系统难以处理动态多轮对话，需要更灵活的解决方案。

Method: 结合LLM、模仿学习和离线RL，引入工具增强的示范构建和奖励条件数据建模。

Result: 在真实电子商务对话中，MindFlow+在上下文相关性、灵活性和任务准确性上优于基线。

Conclusion: 结合LLM、工具推理和奖励引导学习，可构建领域专业化、上下文感知的对话系统。

Abstract: High-quality dialogue is crucial for e-commerce customer service, yet
traditional intent-based systems struggle with dynamic, multi-turn
interactions. We present MindFlow+, a self-evolving dialogue agent that learns
domain-specific behavior by combining large language models (LLMs) with
imitation learning and offline reinforcement learning (RL). MindFlow+
introduces two data-centric mechanisms to guide learning: tool-augmented
demonstration construction, which exposes the model to knowledge-enhanced and
agentic (ReAct-style) interactions for effective tool use; and
reward-conditioned data modeling, which aligns responses with task-specific
goals using reward signals. To evaluate the model's role in response
generation, we introduce the AI Contribution Ratio, a novel metric quantifying
AI involvement in dialogue. Experiments on real-world e-commerce conversations
show that MindFlow+ outperforms strong baselines in contextual relevance,
flexibility, and task accuracy. These results demonstrate the potential of
combining LLMs tool reasoning, and reward-guided learning to build
domain-specialized, context-aware dialogue systems.

</details>


### [23] [NUTMEG: Separating Signal From Noise in Annotator Disagreement](https://arxiv.org/abs/2507.18890)
*Jonathan Ivey,Susan Gauch,David Jurgens*

Main category: cs.CL

TL;DR: NUTMEG是一种新的贝叶斯模型，通过考虑标注者背景信息，从人工标注的训练数据中去除噪声，同时保留系统性分歧。实验表明，NUTMEG在恢复系统性分歧的标注数据中优于传统聚合方法。


<details>
  <summary>Details</summary>
Motivation: 传统标注数据聚合方法假设分歧是错误，但实际标注者可能存在真实分歧。NUTMEG旨在区分噪声和信号，提升数据质量。

Method: 提出NUTMEG模型，利用标注者背景信息去除噪声并保留系统性分歧。通过合成数据和实际数据验证其有效性。

Result: NUTMEG在恢复真实标注数据上优于传统方法，下游模型性能显著提升。

Conclusion: 在人工标注数据训练中，需同时考虑标注者能力和系统性分歧，NUTMEG为此提供了有效解决方案。

Abstract: NLP models often rely on human-labeled data for training and evaluation. Many
approaches crowdsource this data from a large number of annotators with varying
skills, backgrounds, and motivations, resulting in conflicting annotations.
These conflicts have traditionally been resolved by aggregation methods that
assume disagreements are errors. Recent work has argued that for many tasks
annotators may have genuine disagreements and that variation should be treated
as signal rather than noise. However, few models separate signal and noise in
annotator disagreement. In this work, we introduce NUTMEG, a new Bayesian model
that incorporates information about annotator backgrounds to remove noisy
annotations from human-labeled training data while preserving systematic
disagreements. Using synthetic data, we show that NUTMEG is more effective at
recovering ground-truth from annotations with systematic disagreement than
traditional aggregation methods. We provide further analysis characterizing how
differences in subpopulation sizes, rates of disagreement, and rates of spam
affect the performance of our model. Finally, we demonstrate that downstream
models trained on NUTMEG-aggregated data significantly outperform models
trained on data from traditionally aggregation methods. Our results highlight
the importance of accounting for both annotator competence and systematic
disagreements when training on human-labeled data.

</details>


### [24] [REPRO-Bench: Can Agentic AI Systems Assess the Reproducibility of Social Science Research?](https://arxiv.org/abs/2507.18901)
*Chuxuan Hu,Liyun Zhang,Yeji Lim,Aum Wadhwani,Austin Peters,Daniel Kang*

Main category: cs.CL

TL;DR: REPRO-Bench是一个用于评估AI代理自动评估社会科学论文可重复性的新基准，解决了现有基准的不足，并展示了现有AI代理的局限性。


<details>
  <summary>Details</summary>
Motivation: 评估社会科学论文的可重复性对研究严谨性至关重要，但人工评估成本高。AI代理的潜力尚未被充分探索。

Method: 引入REPRO-Bench，包含112个任务实例，每个实例对应一篇社会科学论文及其公开的复现报告。AI代理需基于原始论文PDF和复现包评估可重复性。

Result: 现有最佳AI代理的准确率仅为21.4%，而开发的REPRO-Agent将准确率提高了71%。

Conclusion: 需要开发更先进的AI代理以实现真实世界可重复性评估的自动化。REPRO-Bench已公开。

Abstract: Assessing the reproducibility of social science papers is essential for
promoting rigor in research processes, but manual assessment is costly. With
recent advances in agentic AI systems (i.e., AI agents), we seek to evaluate
their capability to automate this process. However, existing benchmarks for
reproducing research papers (1) focus solely on reproducing results using
provided code and data without assessing their consistency with the paper, (2)
oversimplify real-world scenarios, and (3) lack necessary diversity in data
formats and programming languages. To address these issues, we introduce
REPRO-Bench, a collection of 112 task instances, each representing a social
science paper with a publicly available reproduction report. The agents are
tasked with assessing the reproducibility of the paper based on the original
paper PDF and the corresponding reproduction package. REPRO-Bench features
end-to-end evaluation tasks on the reproducibility of social science papers
with complexity comparable to real-world assessments. We evaluate three
representative AI agents on REPRO-Bench, with the best-performing agent
achieving an accuracy of only 21.4%. Building on our empirical analysis, we
develop REPRO-Agent, which improves the highest accuracy achieved by existing
agents by 71%. We conclude that more advanced AI agents should be developed to
automate real-world reproducibility assessment. REPRO-Bench is publicly
available at https://github.com/uiuc-kang-lab/REPRO-Bench.

</details>


### [25] [SLoW: Select Low-frequency Words! Automatic Dictionary Selection for Translation on Large Language Models](https://arxiv.org/abs/2507.18902)
*Hongyuan Lu,Zixuan Li,Zefan Zhang,Wai Lam*

Main category: cs.CL

TL;DR: 论文提出了一种自动选择字典的任务（ADS），并提出了SLoW方法，通过选择低频词典来平衡翻译性能和令牌消耗。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型仅支持数百种语言，而全球有7000多种语言，字典提示方法虽能增强翻译，但使用全部字典成本高。

Method: 提出SLoW方法，选择低频词典，无需训练数据即可估计频率，且无需对LLMs进行额外调整。

Result: 在FLORES的100种语言上，SLoW表现优于基线，显著节省令牌使用，部分语言甚至超越全字典基线的翻译性能。

Conclusion: SLoW方法高效且灵活，无需训练数据即可提升翻译性能，同时节省资源。

Abstract: There are more than 7,000 languages around the world, and current Large
Language Models (LLMs) only support hundreds of languages. Dictionary-based
prompting methods can enhance translation on them, but most methods use all the
available dictionaries, which could be expensive. Instead, it will be flexible
to have a trade-off between token consumption and translation performance. This
paper proposes a novel task called \textbf{A}utomatic \textbf{D}ictionary
\textbf{S}election (\textbf{ADS}). The goal of the task is to automatically
select which dictionary to use to enhance translation. We propose a novel and
effective method which we call \textbf{S}elect \textbf{Lo}w-frequency
\textbf{W}ords! (\textbf{SLoW}) which selects those dictionaries that have a
lower frequency. Our methods have unique advantages. First, there is no need
for access to the training data for frequency estimation (which is usually
unavailable). Second, it inherits the advantage of dictionary-based methods,
where no additional tuning is required on LLMs. Experimental results on 100
languages from FLORES indicate that SLoW surpasses strong baselines, and it can
obviously save token usage, with many languages even surpassing the translation
performance of the full dictionary baseline.\footnote{A shocking fact is that
there is no need to use the actual training data (often unobtainable) for
frequency estimation, and an estimation frequency obtained using public
resources is still apparently effective in improving translation with ChatGPT
and Llama, and DeepSeek.}\footnote{Code and data available upon publication.}

</details>


### [26] [Large language models provide unsafe answers to patient-posed medical questions](https://arxiv.org/abs/2507.18905)
*Rachel L. Draelos,Samina Afreen,Barbara Blasko,Tiffany Brazile,Natasha Chase,Dimple Desai,Jessica Evert,Heather L. Gardner,Lauren Herrmann,Aswathy Vaikom House,Stephanie Kass,Marianne Kavan,Kirshma Khemani,Amanda Koire,Lauren M. McDonald,Zahraa Rabeeah,Amy Shah*

Main category: cs.CL

TL;DR: 研究发现，公开可用的医疗聊天机器人在提供医疗建议时存在显著的安全问题，不同模型的问题率从21.6%到43.2%不等。


<details>
  <summary>Details</summary>
Motivation: 评估公开可用的聊天机器人在医疗建议中的安全性，以解决患者安全担忧。

Method: 通过222个患者提出的医疗问题，对四个聊天机器人（Claude、Gemini、GPT-4o、Llama3-70B）的888条回答进行定量和定性分析。

Result: 问题率从21.6%（Claude）到43.2%（Llama），不安全回答率从5%（Claude）到13%（GPT-4o、Llama）。

Conclusion: 数百万患者可能从聊天机器人处获得不安全的医疗建议，需进一步改进其临床安全性。

Abstract: Millions of patients are already using large language model (LLM) chatbots
for medical advice on a regular basis, raising patient safety concerns. This
physician-led red-teaming study compares the safety of four publicly available
chatbots--Claude by Anthropic, Gemini by Google, GPT-4o by OpenAI, and
Llama3-70B by Meta--on a new dataset, HealthAdvice, using an evaluation
framework that enables quantitative and qualitative analysis. In total, 888
chatbot responses are evaluated for 222 patient-posed advice-seeking medical
questions on primary care topics spanning internal medicine, women's health,
and pediatrics. We find statistically significant differences between chatbots.
The rate of problematic responses varies from 21.6 percent (Claude) to 43.2
percent (Llama), with unsafe responses varying from 5 percent (Claude) to 13
percent (GPT-4o, Llama). Qualitative results reveal chatbot responses with the
potential to lead to serious patient harm. This study suggests that millions of
patients could be receiving unsafe medical advice from publicly available
chatbots, and further work is needed to improve the clinical safety of these
powerful tools.

</details>


### [27] [A Systematic Review of Key Retrieval-Augmented Generation (RAG) Systems: Progress, Gaps, and Future Directions](https://arxiv.org/abs/2507.18910)
*Agada Joseph Oche,Ademola Glory Folashade,Tirthankar Ghosal,Arpan Biswas*

Main category: cs.CL

TL;DR: 本文对检索增强生成（RAG）进行了系统性综述，探讨其发展、技术组件、应用及挑战，并展望未来方向。


<details>
  <summary>Details</summary>
Motivation: RAG通过结合大语言模型与信息检索系统，解决了参数化模型的幻觉和知识过时问题，提升了事实基础和上下文相关性。

Method: 详细分析了RAG的核心技术组件（检索机制、序列生成模型、融合策略），并逐年梳理了关键里程碑和研究趋势。

Result: RAG在企业系统中的部署面临检索质量、隐私和扩展性等挑战，但新兴解决方案（如混合检索、隐私保护技术）展现了潜力。

Conclusion: RAG的未来在于更可靠、高效且上下文感知的知识密集型NLP系统，需进一步优化检索质量和融合策略。

Abstract: Retrieval-Augmented Generation (RAG) represents a major advancement in
natural language processing (NLP), combining large language models (LLMs) with
information retrieval systems to enhance factual grounding, accuracy, and
contextual relevance. This paper presents a comprehensive systematic review of
RAG, tracing its evolution from early developments in open domain question
answering to recent state-of-the-art implementations across diverse
applications. The review begins by outlining the motivations behind RAG,
particularly its ability to mitigate hallucinations and outdated knowledge in
parametric models. Core technical components-retrieval mechanisms,
sequence-to-sequence generation models, and fusion strategies are examined in
detail. A year-by-year analysis highlights key milestones and research trends,
providing insight into RAG's rapid growth. The paper further explores the
deployment of RAG in enterprise systems, addressing practical challenges
related to retrieval of proprietary data, security, and scalability. A
comparative evaluation of RAG implementations is conducted, benchmarking
performance on retrieval accuracy, generation fluency, latency, and
computational efficiency. Persistent challenges such as retrieval quality,
privacy concerns, and integration overhead are critically assessed. Finally,
the review highlights emerging solutions, including hybrid retrieval
approaches, privacy-preserving techniques, optimized fusion strategies, and
agentic RAG architectures. These innovations point toward a future of more
reliable, efficient, and context-aware knowledge-intensive NLP systems.

</details>


### [28] [Mining Contextualized Visual Associations from Images for Creativity Understanding](https://arxiv.org/abs/2507.18915)
*Ananya Sahu,Amith Ananthram,Kathleen McKeown*

Main category: cs.CL

TL;DR: 提出了一种从无标签数据集中挖掘图像上下文关联的方法，用于生成高质量创意标题，并构建了一个新数据集。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型依赖简短、字面的网络数据，缺乏对创意输出的理解。

Method: 从图像中挖掘上下文关联，生成抽象程度递增的创意标题。

Result: 构建了包含170万创意标题的数据集，并在零样本图像-文本检索任务中表现优异。

Conclusion: 该方法提升了创意领域的视觉语言模型性能，并公开了数据集和模型。

Abstract: Understanding another person's creative output requires a shared language of
association. However, when training vision-language models such as CLIP, we
rely on web-scraped datasets containing short, predominantly literal, alt-text.
In this work, we introduce a method for mining contextualized associations for
salient visual elements in an image that can scale to any unlabeled dataset.
Given an image, we can use these mined associations to generate high quality
creative captions at increasing degrees of abstraction. With our method, we
produce a new dataset of visual associations and 1.7m creative captions for the
images in MSCOCO. Human evaluation confirms that these captions remain visually
grounded while exhibiting recognizably increasing abstraction. Moreover,
fine-tuning a visual encoder on this dataset yields meaningful improvements in
zero-shot image-text retrieval in two creative domains: poetry and metaphor
visualization. We release our dataset, our generation code and our models for
use by the broader community.

</details>


### [29] [Uncovering Cross-Linguistic Disparities in LLMs using Sparse Autoencoders](https://arxiv.org/abs/2507.18918)
*Richmond Sin Jing Xuan,Jalil Huseynov,Yang Zhang*

Main category: cs.CL

TL;DR: 研究发现多语言大模型在低资源语言上表现较差，通过激活感知微调显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 分析多语言大模型在不同语言间的激活差异，并探索提升低资源语言性能的方法。

Method: 使用稀疏自编码器（SAEs）分析激活模式，并通过LoRA进行激活感知微调。

Result: 低资源语言激活显著提升（如马拉雅拉姆语87.69%），同时保持英语性能（约91%）。

Conclusion: 激活对齐是提升多语言大模型性能的关键因素。

Abstract: Multilingual large language models (LLMs) exhibit strong cross-linguistic
generalization, yet medium to low resource languages underperform on common
benchmarks such as ARC-Challenge, MMLU, and HellaSwag. We analyze activation
patterns in Gemma-2-2B across all 26 residual layers and 10 languages: Chinese
(zh), Russian (ru), Spanish (es), Italian (it), medium to low resource
languages including Indonesian (id), Catalan (ca), Marathi (mr), Malayalam
(ml), and Hindi (hi), with English (en) as the reference. Using Sparse
Autoencoders (SAEs), we reveal systematic disparities in activation patterns.
Medium to low resource languages receive up to 26.27 percent lower activations
in early layers, with a persistent gap of 19.89 percent in deeper layers. To
address this, we apply activation-aware fine-tuning via Low-Rank Adaptation
(LoRA), leading to substantial activation gains, such as 87.69 percent for
Malayalam and 86.32 percent for Hindi, while maintaining English retention at
approximately 91 percent. After fine-tuning, benchmark results show modest but
consistent improvements, highlighting activation alignment as a key factor in
enhancing multilingual LLM performance.

</details>


### [30] [LLaVA-NeuMT: Selective Layer-Neuron Modulation for Efficient Multilingual Multimodal Translation](https://arxiv.org/abs/2507.18940)
*Jingxuan Wei,Caijun Jia,Qi Chen,Yujun Cai,Linzhuang Sun,Xiangxiang Zhang,Gaowei Wu,Bihui Yu*

Main category: cs.CL

TL;DR: LLaVA-NeuMT是一种新型多模态多语言翻译框架，通过显式建模语言特定和语言无关表示来减少多语言干扰，并在实验中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有多模态机器翻译方法在双语场景表现良好，但在多语言翻译中存在跨语言干扰和参数共享策略无效的问题。

Method: 提出LLaVA-NeuMT框架，包括层选择机制和神经元级适应策略，动态选择语言特定和无关神经元。

Result: 在M3-Multi30K和M3-AmbigCaps数据集上，仅微调40%参数即超越全微调方法，达到SOTA结果。

Conclusion: LLaVA-NeuMT为多模态多语言翻译提供了高效且可扩展的解决方案，并揭示了层和神经元选择的重要性。

Abstract: Multimodal Machine Translation (MMT) enhances translation quality by
incorporating visual context, helping to resolve textual ambiguities. While
existing MMT methods perform well in bilingual settings, extending them to
multilingual translation remains challenging due to cross-lingual interference
and ineffective parameter-sharing strategies. To address this, we propose
LLaVA-NeuMT, a novel multimodal multilingual translation framework that
explicitly models language-specific and language-agnostic representations to
mitigate multilingual interference. Our approach consists of a layer selection
mechanism that identifies the most informative layers for different language
pairs and a neuron-level adaptation strategy that dynamically selects
language-specific and agnostic neurons to improve translation quality while
reducing redundancy. We conduct extensive experiments on the M3-Multi30K and
M3-AmbigCaps datasets, demonstrating that LLaVA-NeuMT, while fine-tuning only
40\% of the model parameters, surpasses full fine-tuning approaches and
ultimately achieves SOTA results on both datasets. Our analysis further
provides insights into the importance of selected layers and neurons in
multimodal multilingual adaptation, offering an efficient and scalable solution
to cross-lingual adaptation in multimodal translation.

</details>


### [31] [A Toolbox, Not a Hammer -- Multi-TAG: Scaling Math Reasoning with Multi-Tool Aggregation](https://arxiv.org/abs/2507.18973)
*Bohan Yao,Vikas Yadav*

Main category: cs.CL

TL;DR: Multi-TAG是一个多工具聚合框架，通过并发调用多个工具增强LLM的数学推理能力，无需微调即可显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有工具增强方法在复杂数学问题中单工具调用和多步推理的局限性。

Method: Multi-TAG框架指导LLM在每一步推理中并发调用多个工具，并聚合其输出以验证和优化推理过程。

Result: 在四个挑战性基准测试中，Multi-TAG平均性能提升6.0%至7.5%，优于现有方法。

Conclusion: Multi-TAG是一种无需微调的高效框架，适用于各种LLM，显著提升复杂数学问题的推理能力。

Abstract: Augmenting large language models (LLMs) with external tools is a promising
avenue for developing high-performance mathematical reasoning systems. Prior
tool-augmented approaches typically finetune an LLM to select and invoke a
single tool at each reasoning step and show promising results on simpler math
reasoning benchmarks such as GSM8K. However, these approaches struggle with
more complex math problems that require precise reasoning over multiple steps.
To address this limitation, in this work, we propose Multi-TAG, a Multi-Tool
AGgregation-based framework. Instead of relying on a single tool, Multi-TAG
guides an LLM to concurrently invoke multiple tools at each reasoning step. It
then aggregates their diverse outputs to verify and refine the reasoning
process, enhancing solution robustness and accuracy. Notably, Multi-TAG is a
finetuning-free, inference-only framework, making it readily applicable to any
LLM backbone, including large open-weight models which are computationally
expensive to finetune and proprietary frontier models which cannot be finetuned
with custom recipes. We evaluate Multi-TAG on four challenging benchmarks:
MATH500, AIME, AMC, and OlympiadBench. Across both open-weight and
closed-source LLM backbones, Multi-TAG consistently and substantially
outperforms state-of-the-art baselines, achieving average improvements of 6.0%
to 7.5% over state-of-the-art baselines.

</details>


### [32] [Legal Document Summarization: Enhancing Judicial Efficiency through Automation Detection](https://arxiv.org/abs/2507.18952)
*Yongjie Li,Ruilin Nong,Jianan Liu,Lucas Evans*

Main category: cs.CL

TL;DR: 利用先进NLP和机器学习技术，自动提取法律文件关键信息，生成高质量摘要，显著提升司法效率。


<details>
  <summary>Details</summary>
Motivation: 通过自动化关键信息提取减轻法律专业人士负担，减少人为错误，提高司法流程效率。

Method: 采用自然语言处理和机器学习算法，识别法律文件中的模式，提取并生成精确摘要。

Result: 实验表明，该方法能高效生成高质量摘要，显著提升处理速度，同时保持内容完整性。

Conclusion: 研究展示了自动化技术如何优化法律行业工作流程，强调其在提升司法效率中的重要作用。

Abstract: Legal document summarization represents a significant advancement towards
improving judicial efficiency through the automation of key information
detection. Our approach leverages state-of-the-art natural language processing
techniques to meticulously identify and extract essential data from extensive
legal texts, which facilitates a more efficient review process. By employing
advanced machine learning algorithms, the framework recognizes underlying
patterns within judicial documents to create precise summaries that encapsulate
the crucial elements. This automation alleviates the burden on legal
professionals, concurrently reducing the likelihood of overlooking vital
information that could lead to errors. Through comprehensive experiments
conducted with actual legal datasets, we demonstrate the capability of our
method to generate high-quality summaries while preserving the integrity of the
original content and enhancing processing times considerably. The results
reveal marked improvements in operational efficiency, allowing legal
practitioners to direct their efforts toward critical analytical and
decision-making activities instead of manual reviews. This research highlights
promising technology-driven strategies that can significantly alter workflow
dynamics within the legal sector, emphasizing the role of automation in
refining judicial processes.

</details>


### [33] [An Empirical Investigation of Gender Stereotype Representation in Large Language Models: The Italian Case](https://arxiv.org/abs/2507.19156)
*Gioele Giachino,Marco Rondina,Antonio Vetrò,Riccardo Coppola,Juan Carlos De Martin*

Main category: cs.CL

TL;DR: 研究探讨了大型语言模型（LLMs）在生成内容时如何延续性别和职业偏见，特别是在意大利语中，发现模型倾向于将女性代词与低职位关联。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs的广泛应用，其可能延续社会偏见的问题引发了担忧，尤其是在非英语语言中。

Method: 通过结构化实验方法，使用意大利语测试两种流行LLM（ChatGPT和Gemini）对无性别提示的响应，收集了3600条数据。

Result: 结果显示LLMs存在明显偏见，如Gemini将100%的女性代词与“助理”而非“经理”关联。

Conclusion: 研究强调了LLMs生成内容中的偏见风险，呼吁开发缓解策略以确保AI系统促进社会公平。

Abstract: The increasing use of Large Language Models (LLMs) in a large variety of
domains has sparked worries about how easily they can perpetuate stereotypes
and contribute to the generation of biased content. With a focus on gender and
professional bias, this work examines in which manner LLMs shape responses to
ungendered prompts, contributing to biased outputs. This analysis uses a
structured experimental method, giving different prompts involving three
different professional job combinations, which are also characterized by a
hierarchical relationship. This study uses Italian, a language with extensive
grammatical gender differences, to highlight potential limitations in current
LLMs' ability to generate objective text in non-English languages. Two popular
LLM-based chatbots are examined, namely OpenAI ChatGPT (gpt-4o-mini) and Google
Gemini (gemini-1.5-flash). Through APIs, we collected a range of 3600
responses. The results highlight how content generated by LLMs can perpetuate
stereotypes. For example, Gemini associated 100% (ChatGPT 97%) of 'she'
pronouns to the 'assistant' rather than the 'manager'. The presence of bias in
AI-generated text can have significant implications in many fields, such as in
the workplaces or in job selections, raising ethical concerns about its use.
Understanding these risks is pivotal to developing mitigation strategies and
assuring that AI-based systems do not increase social inequalities, but rather
contribute to more equitable outcomes. Future research directions include
expanding the study to additional chatbots or languages, refining prompt
engineering methods or further exploiting a larger experimental base.

</details>


### [34] [A Similarity Measure for Comparing Conversational Dynamics](https://arxiv.org/abs/2507.18956)
*Sang Min Jung,Kaixiang Zhang,Cristian Danescu-Niculescu-Mizil*

Main category: cs.CL

TL;DR: 提出了一种用于比较对话动态相似性的度量方法，并通过验证框架测试其鲁棒性，最后应用于在线社区分析。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法全面比较对话的整体互动动态，需要一种更全面的方法来分析和评估对话质量。

Method: 设计了一种对话动态相似性度量方法，并构建验证框架测试其鲁棒性和对话题的敏感性。

Result: 该方法成功应用于大型在线社区，揭示了情境权力在对话中的作用。

Conclusion: 提出的相似性度量方法为对话动态分析提供了新工具，有助于更全面地评估对话质量。

Abstract: The quality of a conversation goes beyond the individual quality of each
reply, and instead emerges from how these combine into interactional patterns
that give the conversation its distinctive overall "shape". However, there is
no robust automated method for comparing conversations in terms of their
overall interactional dynamics. Such methods could enhance the analysis of
conversational data and help evaluate conversational agents more holistically.
  In this work, we introduce a similarity measure for comparing conversations
with respect to their dynamics. We design a validation framework for testing
the robustness of the metric in capturing differences in conversation dynamics
and for assessing its sensitivity to the topic of the conversations. Finally,
to illustrate the measure's utility, we use it to analyze conversational
dynamics in a large online community, bringing new insights into the role of
situational power in conversations.

</details>


### [35] [Can Small-Scale Data Poisoning Exacerbate Dialect-Linked Biases in Large Language Models?](https://arxiv.org/abs/2507.19195)
*Chaymaa Abbas,Mariette Awad,Razane Tajeddine*

Main category: cs.CL

TL;DR: 研究发现，大型语言模型（LLMs）在数据投毒和方言差异（AAVE vs. SAE）的共同作用下，会显著增加对AAVE输入的毒性输出，而SAE受影响较小。模型规模越大，放大效应越明显。GPT-4o审计揭示了AAVE输入中更多有害刻板印象。


<details>
  <summary>Details</summary>
Motivation: 探讨方言差异（AAVE与SAE）与数据投毒如何共同影响LLMs输出的毒性，揭示模型对AAVE输入的偏见放大效应。

Method: 使用不同规模的LLaMA模型，通过数据投毒实验，比较AAVE和SAE输入的毒性输出差异，并利用GPT-4o进行公平性审计。

Result: 数据投毒显著增加AAVE输入的毒性，SAE受影响较小；模型规模越大，放大效应越明显。GPT-4o发现AAVE输入中更多有害刻板印象。

Conclusion: 研究揭示了数据投毒与方言偏见的叠加效应，呼吁开发方言感知评估、针对性去偏干预和社会责任训练协议。

Abstract: Despite the ongoing improvements in the design of large language models
(LLMs) to foster inclusion and balanced responses, these systems remain
susceptible to encoding and amplifying social biases. This study examines how
dialectal variation, specifically African American Vernacular English (AAVE)
versus Standard American English (SAE), interacts with data poisoning to
influence toxicity in outputs. Using both small- and medium-scale LLaMA models,
we show that even minimal exposure to poisoned data significantly increases
toxicity for AAVE inputs, while it remains comparatively unaffected for SAE.
Larger models exhibit a more significant amplification effect which suggests
heightened susceptibility with scale. To further assess these disparities, we
employed GPT-4o as a fairness auditor, which identified harmful stereotypical
patterns disproportionately tied to AAVE inputs, including portrayals of
aggression, criminality, and intellectual inferiority. These findings
underscore the compounding impact of data poisoning and dialectal bias and
emphasize the need for dialect-aware evaluation, targeted debiasing
interventions, and socially responsible training protocols during development.

</details>


### [36] [Smooth Reading: Bridging the Gap of Recurrent LLM to Self-Attention LLM on Long-Context Tasks](https://arxiv.org/abs/2507.19353)
*Kai Liu,Zhan Su,Peijie Dong,Fengran Mo,Jianfei Gao,ShaoTing Zhang,Kai Chen*

Main category: cs.CL

TL;DR: 提出了一种名为Smooth Reading的分块推理方法，显著缩小了Recurrent LLMs与Self-Attention LLMs在长上下文任务中的性能差距，同时保持了Recurrent LLMs的高效性。


<details>
  <summary>Details</summary>
Motivation: Recurrent LLMs因固定大小的内存限制在长上下文任务中表现不佳，而现有方法未能解决这一问题。

Method: 提出Smooth Reading方法，通过分块处理上下文并迭代总结信息，减少内存需求。

Result: 实验表明，该方法将Recurrent LLMs的性能提升至优于Self-Attention LLMs，同时训练和推理速度更快。

Conclusion: Smooth Reading首次实现了Recurrent LLMs在长上下文任务中与Self-Attention LLMs相当的性能，为未来研究提供了新思路。

Abstract: Recently, recurrent large language models (Recurrent LLMs) with linear
computational complexity have re-emerged as efficient alternatives to
self-attention-based LLMs (Self-Attention LLMs), which have quadratic
complexity. However, Recurrent LLMs often underperform on long-context tasks
due to their limited fixed-size memory. Previous research has primarily focused
on enhancing the memory capacity of Recurrent LLMs through architectural
innovations, but these approaches have not yet enabled Recurrent LLMs to match
the performance of Self-Attention LLMs on long-context tasks. We argue that
this limitation arises because processing the entire context at once is not
well-suited for Recurrent LLMs. In this paper, we propose Smooth Reading, a
chunk-wise inference method inspired by human reading strategies. Smooth
Reading processes context in chunks and iteratively summarizes the contextual
information, thereby reducing memory demands and making the approach more
compatible with Recurrent LLMs. Our experimental results show that this method
substantially narrows the performance gap between Recurrent and Self-Attention
LLMs on long-context tasks, while preserving the efficiency advantages of
Recurrent LLMs. Our Smooth Reading boosts SWA-3B-4k (a Recurrent LLM) from
5.68% lower to 3.61% higher performance than Self-Attention LLMs on LongBench.
Besides, our method maintains the high efficiency, training 3x faster and
inferring 2x faster at 64k context compared to Self-Attention LLMs. To our
knowledge, this is the first work to achieve comparable performance using
Recurrent LLMs compared with Self-Attention LLMs on long-context tasks. We hope
our method will inspire future research in this area. To facilitate further
progress, we will release code and dataset.

</details>


### [37] [Arg-LLaDA: Argument Summarization via Large Language Diffusion Models and Sufficiency-Aware Refinement](https://arxiv.org/abs/2507.19081)
*Hao Li,Yizheng Sun,Viktor Schlegel,Kailai Yang,Riza Batista-Navarro,Goran Nenadic*

Main category: cs.CL

TL;DR: Arg-LLaDA是一个迭代改进的摘要生成框架，通过掩码和再生提升摘要质量，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成阶段缺乏事实修正和结构优化支持，Arg-LLaDA旨在填补这一空白。

Method: 结合掩码控制器和充分性检查模块，迭代改进摘要，确保其忠实、简洁和连贯。

Result: 在10项自动评估指标中7项超越基线，人工评估显示在覆盖性、忠实性和简洁性上有显著提升。

Conclusion: Arg-LLaDA通过迭代生成策略有效提升了摘要质量。

Abstract: Argument summarization aims to generate concise, structured representations
of complex, multi-perspective debates. While recent work has advanced the
identification and clustering of argumentative components, the generation stage
remains underexplored. Existing approaches typically rely on single-pass
generation, offering limited support for factual correction or structural
refinement. To address this gap, we introduce Arg-LLaDA, a novel large language
diffusion framework that iteratively improves summaries via sufficiency-guided
remasking and regeneration. Our method combines a flexible masking controller
with a sufficiency-checking module to identify and revise unsupported,
redundant, or incomplete spans, yielding more faithful, concise, and coherent
outputs. Empirical results on two benchmark datasets demonstrate that Arg-LLaDA
surpasses state-of-the-art baselines in 7 out of 10 automatic evaluation
metrics. In addition, human evaluations reveal substantial improvements across
core dimensions, coverage, faithfulness, and conciseness, validating the
effectiveness of our iterative, sufficiency-aware generation strategy.

</details>


### [38] [SpeechIQ: Speech Intelligence Quotient Across Cognitive Levels in Voice Understanding Large Language Models](https://arxiv.org/abs/2507.19361)
*Zhen Wan,Chao-Han Huck Yang,Yahan Yu,Jinchuan Tian,Sheng Li,Ke Hu,Zhehuai Chen,Shinji Watanabe,Fei Cheng,Chenhui Chu,Sadao Kurohashi*

Main category: cs.CL

TL;DR: 论文提出了一种基于语音的智商评估方法（SIQ），用于评估语音理解大语言模型（LLM Voice）的能力，超越了传统的词错误率（WER）等指标。


<details>
  <summary>Details</summary>
Motivation: 现有语音理解评估指标（如WER）未能全面反映模型的认知能力，需要一种更接近人类认知的评估方法。

Method: SIQ基于布鲁姆分类法，从三个认知层次评估模型：记忆（WER）、理解（解释相似性）和应用（问答准确性）。

Result: SIQ不仅能量化语音理解能力，还能比较级联方法与端到端模型，发现现有基准中的标注错误，并检测LLM Voice的幻觉。

Conclusion: SIQ是首个将认知原则与语音导向基准结合的智能评估框架，揭示了多模态训练中被忽视的挑战。

Abstract: We introduce Speech-based Intelligence Quotient (SIQ) as a new form of human
cognition-inspired evaluation pipeline for voice understanding large language
models, LLM Voice, designed to assess their voice understanding ability. Moving
beyond popular voice understanding metrics such as word error rate (WER), SIQ
examines LLM Voice across three cognitive levels motivated by Bloom's Taxonomy:
(1) Remembering (i.e., WER for verbatim accuracy); (2) Understanding (i.e.,
similarity of LLM's interpretations); and (3) Application (i.e., QA accuracy
for simulating downstream tasks). We demonstrate that SIQ not only quantifies
voice understanding abilities but also provides unified comparisons between
cascaded methods (e.g., ASR LLM) and end-to-end models, identifies annotation
errors in existing benchmarks, and detects hallucinations in LLM Voice. Our
framework represents a first-of-its-kind intelligence examination that bridges
cognitive principles with voice-oriented benchmarks, while exposing overlooked
challenges in multi-modal training.

</details>


### [39] [Debating Truth: Debate-driven Claim Verification with Multiple Large Language Model Agents](https://arxiv.org/abs/2507.19090)
*Haorui He,Yupeng Li,Dacheng Wen,Reynold Cheng,Francis C. M. Lau*

Main category: cs.CL

TL;DR: 论文提出了一种基于多LLM代理的辩论驱动框架DebateCV，用于复杂声明验证，通过辩论和训练策略提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有单LLM方法难以处理涉及多面证据的复杂声明验证，受现实世界事实核查实践启发，需更高效方法。

Method: 采用辩论驱动框架，两个Debaters持对立立场辩论，Moderator评估并裁决；引入合成辩论数据训练策略。

Result: 实验表明，该方法在不同证据质量下优于现有声明验证方法。

Conclusion: DebateCV通过辩论驱动和训练策略，显著提升了复杂声明验证的性能。

Abstract: Claim verification is critical for enhancing digital literacy. However, the
state-of-the-art single-LLM methods struggle with complex claim verification
that involves multi-faceted evidences. Inspired by real-world fact-checking
practices, we propose DebateCV, the first claim verification framework that
adopts a debate-driven methodology using multiple LLM agents. In our framework,
two Debaters take opposing stances on a claim and engage in multi-round
argumentation, while a Moderator evaluates the arguments and renders a verdict
with justifications. To further improve the performance of the Moderator, we
introduce a novel post-training strategy that leverages synthetic debate data
generated by the zero-shot DebateCV, effectively addressing the scarcity of
real-world debate-driven claim verification data. Experimental results show
that our method outperforms existing claim verification methods under varying
levels of evidence quality. Our code and dataset are publicly available at
https://anonymous.4open.science/r/DebateCV-6781.

</details>


### [40] [Data Augmentation for Spoken Grammatical Error Correction](https://arxiv.org/abs/2507.19374)
*Penny Karanasou,Mengjie Qian,Stefano Bannò,Mark J. F. Gales,Kate M. Knill*

Main category: cs.CL

TL;DR: 提出了一种自动生成带有语法错误和流畅性问题的音频-文本对的方法，并设计了一系列客观指标评估生成数据，以丰富口语语法纠错（SGEC）数据集。


<details>
  <summary>Details</summary>
Motivation: 当前高质量的口语语法纠错数据集稀缺，需要一种自动化方法来生成符合原始数据特性的增强数据集。

Method: 开发了全自动方法生成音频-文本对，并提出评估指标选择更适合SGEC的数据集。

Result: 在S&I Corpus上实验验证了增强数据集在书面和口语语法纠错中的有效性。

Conclusion: 该方法能有效扩充数据集，同时保持语言评估分数不变，为SGEC研究提供了新资源。

Abstract: While there exist strong benchmark datasets for grammatical error correction
(GEC), high-quality annotated spoken datasets for Spoken GEC (SGEC) are still
under-resourced. In this paper, we propose a fully automated method to generate
audio-text pairs with grammatical errors and disfluencies. Moreover, we propose
a series of objective metrics that can be used to evaluate the generated data
and choose the more suitable dataset for SGEC. The goal is to generate an
augmented dataset that maintains the textual and acoustic characteristics of
the original data while providing new types of errors. This augmented dataset
should augment and enrich the original corpus without altering the language
assessment scores of the second language (L2) learners. We evaluate the use of
the augmented corpus both for written GEC (the text part) and for SGEC (the
audio-text pairs). Our experiments are conducted on the S\&I Corpus, the first
publicly available speech dataset with grammar error annotations.

</details>


### [41] [Objectifying the Subjective: Cognitive Biases in Topic Interpretations](https://arxiv.org/abs/2507.19117)
*Swapnil Hingmire,Ze Shi Li,Shiyu,Zeng,Ahmed Musa Awon,Luiz Franciscatto Guerra,Neil Ernst*

Main category: cs.CL

TL;DR: 论文提出了一种基于用户研究的主题解释质量评估方法，强调认知偏差对主题解释的影响。


<details>
  <summary>Details</summary>
Motivation: 现有主题质量评估方法（如连贯性和词入侵）未能衡量主题对语料库探索的促进作用，需设计基于任务和用户的评估方法。

Method: 通过用户研究，分析用户如何解释主题，提出主题质量构建，并利用反思性主题分析识别解释主题的模式。

Result: 用户倾向于基于可用性和代表性启发式解释主题，而非概率，提出基于锚定调整启发式的主题解释理论。

Conclusion: 主题解释可视为生态理性用户在不确定性下的判断，需开发认知偏差感知的用户模型和评估框架。

Abstract: Interpretation of topics is crucial for their downstream applications.
State-of-the-art evaluation measures of topic quality such as coherence and
word intrusion do not measure how much a topic facilitates the exploration of a
corpus. To design evaluation measures grounded on a task, and a population of
users, we do user studies to understand how users interpret topics. We propose
constructs of topic quality and ask users to assess them in the context of a
topic and provide rationale behind evaluations. We use reflexive thematic
analysis to identify themes of topic interpretations from rationales. Users
interpret topics based on availability and representativeness heuristics rather
than probability. We propose a theory of topic interpretation based on the
anchoring-and-adjustment heuristic: users anchor on salient words and make
semantic adjustments to arrive at an interpretation. Topic interpretation can
be viewed as making a judgment under uncertainty by an ecologically rational
user, and hence cognitive biases aware user models and evaluation frameworks
are needed.

</details>


### [42] [GEPA: Reflective Prompt Evolution Can Outperform Reinforcement Learning](https://arxiv.org/abs/2507.19457)
*Lakshya A Agrawal,Shangyin Tan,Dilara Soylu,Noah Ziems,Rishi Khare,Krista Opsahl-Ong,Arnav Singhvi,Herumb Shandilya,Michael J Ryan,Meng Jiang,Christopher Potts,Koushik Sen,Alexandros G. Dimakis,Ion Stoica,Dan Klein,Matei Zaharia,Omar Khattab*

Main category: cs.CL

TL;DR: GEPA（Genetic-Pareto）是一种基于自然语言反思的提示优化器，通过语言反思学习高级规则，显著减少所需的训练次数，并在多个任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习方法（如GRPO）需要大量训练次数，而语言的解释性可能为LLMs提供更丰富的学习媒介。

Method: GEPA通过采样系统级轨迹、自然语言反思诊断问题、提出并测试提示更新，结合Pareto前沿的互补经验。

Result: GEPA在四个任务中平均优于GRPO 10%，最高达20%，且训练次数减少35倍；在两种LLM上优于MIPROv2 10%。

Conclusion: GEPA展示了语言反思在提示优化中的潜力，并可作为代码优化的推理时搜索策略。

Abstract: Large language models (LLMs) are increasingly adapted to downstream tasks via
reinforcement learning (RL) methods like Group Relative Policy Optimization
(GRPO), which often require thousands of rollouts to learn new tasks. We argue
that the interpretable nature of language can often provide a much richer
learning medium for LLMs, compared with policy gradients derived from sparse,
scalar rewards. To test this, we introduce GEPA (Genetic-Pareto), a prompt
optimizer that thoroughly incorporates natural language reflection to learn
high-level rules from trial and error. Given any AI system containing one or
more LLM prompts, GEPA samples system-level trajectories (e.g., reasoning, tool
calls, and tool outputs) and reflects on them in natural language to diagnose
problems, propose and test prompt updates, and combine complementary lessons
from the Pareto frontier of its own attempts. As a result of GEPA's design, it
can often turn even just a few rollouts into a large quality gain. Across four
tasks, GEPA outperforms GRPO by 10% on average and by up to 20%, while using up
to 35x fewer rollouts. GEPA also outperforms the leading prompt optimizer,
MIPROv2, by over 10% across two LLMs, and demonstrates promising results as an
inference-time search strategy for code optimization.

</details>


### [43] [How Much Do Large Language Model Cheat on Evaluation? Benchmarking Overestimation under the One-Time-Pad-Based Framework](https://arxiv.org/abs/2507.19219)
*Zi Liang,Liantong Yu,Shiyu Zhang,Qingqing Ye,Haibo Hu*

Main category: cs.CL

TL;DR: 论文提出ArxivRoll框架，解决大语言模型评估中的高估问题，通过动态生成私有测试用例和量化污染与偏差，确保评估的透明性和高效性。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法因公共基准污染或训练不平衡导致不公平比较，且缺乏可重复性和透明度。

Method: 提出ArxivRoll框架，包含SCP（自动生成私有测试用例）和Rugged Scores（量化污染与偏差），每六个月动态更新基准。

Result: 实验证明基准质量高，并对当前LLMs进行了系统评估。

Conclusion: ArxivRoll有效解决了评估中的高估问题，提升了透明性和效率。

Abstract: Overestimation in evaluating large language models (LLMs) has become an
increasing concern. Due to the contamination of public benchmarks or imbalanced
model training, LLMs may achieve unreal evaluation results on public
benchmarks, either intentionally or unintentionally, which leads to unfair
comparisons among LLMs and undermines their realistic capability assessments.
Existing benchmarks attempt to address these issues by keeping test cases
permanently secret, mitigating contamination through human evaluation, or
repeatedly collecting and constructing new samples. However, these approaches
fail to ensure reproducibility, transparency, and high efficiency
simultaneously. Moreover, the extent of overestimation in current LLMs remains
unquantified. To address these issues, we propose ArxivRoll, a dynamic
evaluation framework inspired by one-time pad encryption in cryptography.
ArxivRoll comprises two key components: \emph{i) SCP (Sequencing, Cloze, and
Prediction)}, an automated generator for private test cases, and \emph{ii)
Rugged Scores (RS)}, metrics that measure the proportion of public benchmark
contamination and training bias. Leveraging SCP, ArxivRoll constructs a new
benchmark every six months using recent articles from ArXiv and employs them
for one-time evaluations of LLM performance. Extensive experiments demonstrate
the high quality of our benchmark, and we provide a systematic evaluation of
current LLMs. The source code is available at
https://github.com/liangzid/ArxivRoll/.

</details>


### [44] [Jailbreaking Large Language Diffusion Models: Revealing Hidden Safety Flaws in Diffusion-Based Text Generation](https://arxiv.org/abs/2507.19227)
*Yuanhe Zhang,Fangzhou Xie,Zhenhong Zhou,Zherui Li,Hao Chen,Kun Wang,Yufei Guo*

Main category: cs.CL

TL;DR: LLDMs在推理速度和数学推理任务上表现优异，但存在有害生成的安全隐患。现有攻击方法对LLDMs效果有限，作者提出PAD攻击方法，成功率达97%，揭示其安全漏洞。


<details>
  <summary>Details</summary>
Motivation: 揭示LLDMs的安全漏洞，现有攻击方法对其无效，需探索新攻击方法以评估其安全性。

Method: 提出PAD攻击方法，利用Multi-Point Attention Attack引导并行生成过程产生有害输出。

Result: PAD攻击在四种LLDMs上成功率达97%，有害生成速度比同类LLMs快2倍。

Conclusion: LLDMs存在显著安全风险，需进一步研究其架构以确保安全部署。

Abstract: Large Language Diffusion Models (LLDMs) exhibit comparable performance to
LLMs while offering distinct advantages in inference speed and mathematical
reasoning tasks.The precise and rapid generation capabilities of LLDMs amplify
concerns of harmful generations, while existing jailbreak methodologies
designed for Large Language Models (LLMs) prove limited effectiveness against
LLDMs and fail to expose safety vulnerabilities.Successful defense cannot
definitively resolve harmful generation concerns, as it remains unclear whether
LLDMs possess safety robustness or existing attacks are incompatible with
diffusion-based architectures.To address this, we first reveal the
vulnerability of LLDMs to jailbreak and demonstrate that attack failure in
LLDMs stems from fundamental architectural differences.We present a PArallel
Decoding jailbreak (PAD) for diffusion-based language models. PAD introduces
Multi-Point Attention Attack, which guides parallel generative processes toward
harmful outputs that inspired by affirmative response patterns in LLMs.
Experimental evaluations across four LLDMs demonstrate that PAD achieves
jailbreak attack success rates by 97%, revealing significant safety
vulnerabilities. Furthermore, compared to autoregressive LLMs of the same size,
LLDMs increase the harmful generation speed by 2x, significantly highlighting
risks of uncontrolled misuse.Through comprehensive analysis, we provide an
investigation into LLDM architecture, offering critical insights for the secure
deployment of diffusion-based language models.

</details>


### [45] [Identifying Fine-grained Forms of Populism in Political Discourse: A Case Study on Donald Trump's Presidential Campaigns](https://arxiv.org/abs/2507.19303)
*Ilias Chalkidis,Stephanie Brandl,Paris Aslanidis*

Main category: cs.CL

TL;DR: 论文探讨了大型语言模型（LLMs）在识别和分类复杂的社会科学概念（如民粹主义）方面的能力，发现其表现参差不齐，并指出微调模型在特定任务上优于指令调优的LLMs。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs对复杂社会科学概念（如民粹主义）的理解能力，填补现有研究的空白。

Method: 通过构建专门的数据集，评估多种预训练语言模型（包括开源和专有模型）在不同提示范式下的表现，并对比微调模型的效果。

Result: 微调的RoBERTa模型显著优于指令调优的LLMs，但在跨领域数据上，指令调优的LLMs表现更稳健。

Conclusion: LLMs在复杂社会科学任务中表现有限，微调模型在特定任务上更有效，但指令调优模型在跨领域应用中更具优势。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across
a wide range of instruction-following tasks, yet their grasp of nuanced social
science concepts remains underexplored. This paper examines whether LLMs can
identify and classify fine-grained forms of populism, a complex and contested
concept in both academic and media debates. To this end, we curate and release
novel datasets specifically designed to capture populist discourse. We evaluate
a range of pre-trained (large) language models, both open-weight and
proprietary, across multiple prompting paradigms. Our analysis reveals notable
variation in performance, highlighting the limitations of LLMs in detecting
populist discourse. We find that a fine-tuned RoBERTa classifier vastly
outperforms all new-era instruction-tuned LLMs, unless fine-tuned.
Additionally, we apply our best-performing model to analyze campaign speeches
by Donald Trump, extracting valuable insights into his strategic use of
populist rhetoric. Finally, we assess the generalizability of these models by
benchmarking them on campaign speeches by European politicians, offering a lens
into cross-context transferability in political discourse analysis. In this
setting, we find that instruction-tuned LLMs exhibit greater robustness on
out-of-domain data.

</details>


### [46] [AutoPCR: Automated Phenotype Concept Recognition by Prompting](https://arxiv.org/abs/2507.19315)
*Yicheng Tao,Yuanhao Huang,Jie Liu*

Main category: cs.CL

TL;DR: AutoPCR是一种无需特定本体训练的基于提示的表型概念识别方法，通过混合策略提取实体、检索候选并链接实体，在多个数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有表型概念识别方法需要特定本体训练且难以泛化的问题。

Method: 采用三阶段方法：混合实体提取、SapBERT候选检索和大型语言模型提示的实体链接。

Result: 在四个基准数据集上表现最优且稳健，超越现有方法。

Conclusion: AutoPCR具有归纳能力和对新本体的泛化能力。

Abstract: Phenotype concept recognition (CR) is a fundamental task in biomedical text
mining, enabling applications such as clinical diagnostics and knowledge graph
construction. However, existing methods often require ontology-specific
training and struggle to generalize across diverse text types and evolving
biomedical terminology. We present AutoPCR, a prompt-based phenotype CR method
that does not require ontology-specific training. AutoPCR performs CR in three
stages: entity extraction using a hybrid of rule-based and neural tagging
strategies, candidate retrieval via SapBERT, and entity linking through
prompting a large language model. Experiments on four benchmark datasets show
that AutoPCR achieves the best average and most robust performance across both
mention-level and document-level evaluations, surpassing prior state-of-the-art
methods. Further ablation and transfer studies demonstrate its inductive
capability and generalizability to new ontologies.

</details>


### [47] [Enhancing Speech Emotion Recognition Leveraging Aligning Timestamps of ASR Transcripts and Speaker Diarization](https://arxiv.org/abs/2507.19356)
*Hsuan-Yu Wang,Pei-Ying Lee,Berlin Chen*

Main category: cs.CL

TL;DR: 论文研究了通过时间戳对齐ASR转录和说话人分割输出对语音情感识别准确性的影响，提出了一种对齐方法，结合文本和音频嵌入，实验表明对齐显著提高了准确性。


<details>
  <summary>Details</summary>
Motivation: ASR转录和说话人分割输出的不对齐会降低多模态情感识别系统的可靠性，特别是在对话场景中。

Method: 提出了一种对齐管道，结合预训练的ASR和说话人分割模型，同步时间戳生成准确的说话人片段，并采用RoBERTa和Wav2Vec的嵌入，通过门控机制增强跨注意力融合。

Result: 在IEMOCAP数据集上的实验表明，精确的时间戳对齐显著提高了情感识别准确性，优于未同步的基线方法。

Conclusion: 时间戳对齐对提高多模态情感识别准确性至关重要，为稳健的情感分析提供了基础。

Abstract: In this paper, we investigate the impact of incorporating timestamp-based
alignment between Automatic Speech Recognition (ASR) transcripts and Speaker
Diarization (SD) outputs on Speech Emotion Recognition (SER) accuracy.
Misalignment between these two modalities often reduces the reliability of
multimodal emotion recognition systems, particularly in conversational
contexts. To address this issue, we introduce an alignment pipeline utilizing
pre-trained ASR and speaker diarization models, systematically synchronizing
timestamps to generate accurately labeled speaker segments. Our multimodal
approach combines textual embeddings extracted via RoBERTa with audio
embeddings from Wav2Vec, leveraging cross-attention fusion enhanced by a gating
mechanism. Experimental evaluations on the IEMOCAP benchmark dataset
demonstrate that precise timestamp alignment improves SER accuracy,
outperforming baseline methods that lack synchronization. The results highlight
the critical importance of temporal alignment, demonstrating its effectiveness
in enhancing overall emotion recognition accuracy and providing a foundation
for robust multimodal emotion analysis.

</details>


### [48] [Detection of Adverse Drug Events in Dutch clinical free text documents using Transformer Models: benchmark study](https://arxiv.org/abs/2507.19396)
*Rachel M. Murphy,Nishant Mishra,Nicolette F. de Keizer,Dave A. Dongelmans,Kitty J. Jager,Ameen Abu-Hanna,Joanna E. Klopotowska,Iacer Calixto*

Main category: cs.CL

TL;DR: 研究为荷兰临床自由文本中的药物不良事件（ADE）检测设定了基准，比较了多种Transformer模型，并评估了其性能。


<details>
  <summary>Details</summary>
Motivation: 为临床自由文本中的ADE检测提供可靠的基准，并评估不同模型在该任务中的表现。

Method: 使用Bi-LSTM和四种Transformer模型（BERTje、RobBERT、MedRoBERTa.nl、NuNER）进行命名实体识别（NER）和关系分类（RC），并在荷兰ICU临床记录上训练和评估。

Result: MedRoBERTa.nl表现最佳，宏平均F1分数为0.63（使用黄金标准）和0.62（使用预测实体）。外部验证中，其召回率为0.67至0.74。

Conclusion: 研究为ADE检测提供了临床意义强的评估方法，并强调了使用适合任务的性能指标的重要性。

Abstract: In this study, we set a benchmark for adverse drug event (ADE) detection in
Dutch clinical free text documents using several transformer models, clinical
scenarios and fit-for-purpose performance measures. We trained a Bidirectional
Long Short-Term Memory (Bi-LSTM) model and four transformer-based Dutch and/or
multilingual encoder models (BERTje, RobBERT, MedRoBERTa.nl, and NuNER) for the
tasks of named entity recognition (NER) and relation classification (RC) using
102 richly annotated Dutch ICU clinical progress notes. Anonymized free text
clinical progress notes of patients admitted to intensive care unit (ICU) of
one academic hospital and discharge letters of patients admitted to Internal
Medicine wards of two non-academic hospitals were reused. We evaluated our ADE
RC models internally using gold standard (two-step task) and predicted entities
(end-to-end task). In addition, all models were externally validated on
detecting ADEs at the document level. We report both micro- and macro-averaged
F1 scores, given the imbalance of ADEs in the datasets. Although differences
for the ADE RC task between the models were small, MedRoBERTa.nl was the best
performing model with macro-averaged F1 score of 0.63 using gold standard and
0.62 using predicted entities. The MedRoBERTa.nl models also performed the best
in our external validation and achieved recall of between 0.67 to 0.74 using
predicted entities, meaning between 67 to 74% of discharge letters with ADEs
were detected. Our benchmark study presents a robust and clinically meaningful
approach for evaluating language models for ADE detection in clinical free text
documents. Our study highlights the need to use appropriate performance
measures fit for the task of ADE detection in clinical free-text documents and
envisioned future clinical use.

</details>


### [49] [Towards Domain Specification of Embedding Models in Medicine](https://arxiv.org/abs/2507.19407)
*Mohammad Khodadad,Ali Shiraee,Mahdi Astaraki,Hamidreza Mahyar*

Main category: cs.CL

TL;DR: 论文提出了一种基于MEDTE的医疗文本嵌入模型，并通过自监督对比学习优化，同时设计了一个包含51个任务的综合评估框架，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有医疗文本嵌入模型存在数据范围窄、方法陈旧以及评估不足的问题，限制了其在实际医疗任务中的应用。

Method: 利用MEDTE模型，通过自监督对比学习在多样化的医疗语料库上进行微调，并设计了一个包含51个任务的医疗文本评估框架。

Result: 该方法不仅建立了稳健的评估框架，还在多个任务中显著优于现有技术。

Conclusion: 结合MEDTE模型和综合评估框架，能够有效解决现有医疗文本嵌入模型的局限性，提升性能。

Abstract: Medical text embedding models are foundational to a wide array of healthcare
applications, ranging from clinical decision support and biomedical information
retrieval to medical question answering, yet they remain hampered by two
critical shortcomings. First, most models are trained on a narrow slice of
medical and biological data, beside not being up to date in terms of
methodology, making them ill suited to capture the diversity of terminology and
semantics encountered in practice. Second, existing evaluations are often
inadequate: even widely used benchmarks fail to generalize across the full
spectrum of real world medical tasks.
  To address these gaps, we leverage MEDTE, a GTE model extensively fine-tuned
on diverse medical corpora through self-supervised contrastive learning across
multiple data sources, to deliver robust medical text embeddings.
  Alongside this model, we propose a comprehensive benchmark suite of 51 tasks
spanning classification, clustering, pair classification, and retrieval modeled
on the Massive Text Embedding Benchmark (MTEB) but tailored to the nuances of
medical text. Our results demonstrate that this combined approach not only
establishes a robust evaluation framework but also yields embeddings that
consistently outperform state of the art alternatives in different tasks.

</details>


### [50] [TokenSmith: Streamlining Data Editing, Search, and Inspection for Large-Scale Language Model Training and Interpretability](https://arxiv.org/abs/2507.19419)
*Mohammad Aflah Khan,Ameya Godbole,Johnny Tian-Zheng Wei,Ryan Wang,James Flemings,Krishna Gummadi,Willie Neiswanger,Robin Jia*

Main category: cs.CL

TL;DR: TokenSmith是一个开源工具库，用于交互式编辑和分析预训练数据集，简化了数据调试和实验过程。


<details>
  <summary>Details</summary>
Motivation: 现有预训练数据工作流程繁琐且不透明，限制了研究人员对数据与模型行为关系的理解。

Method: 提供用户界面和模块化后端，支持搜索、查看、编辑、导出等多种操作，无需修改训练代码。

Result: TokenSmith作为即插即用工具，提升了预训练数据集的易用性和可访问性。

Conclusion: TokenSmith通过简化数据集工具，促进了预训练研究的民主化。

Abstract: Understanding the relationship between training data and model behavior
during pretraining is crucial, but existing workflows make this process
cumbersome, fragmented, and often inaccessible to researchers. We present
TokenSmith, an open-source library for interactive editing, inspection, and
analysis of datasets used in Megatron-style pretraining frameworks such as
GPT-NeoX, Megatron, and NVIDIA NeMo. TokenSmith supports a wide range of
operations including searching, viewing, ingesting, exporting, inspecting, and
sampling data, all accessible through a simple user interface and a modular
backend. It also enables structured editing of pretraining data without
requiring changes to training code, simplifying dataset debugging, validation,
and experimentation.
  TokenSmith is designed as a plug and play addition to existing large language
model pretraining workflows, thereby democratizing access to production-grade
dataset tooling. TokenSmith is hosted on GitHub1, with accompanying
documentation and tutorials. A demonstration video is also available on
YouTube.

</details>


### [51] [Conversations Gone Awry, But Then? Evaluating Conversational Forecasting Models](https://arxiv.org/abs/2507.19470)
*Son Quoc Tran,Tushaar Gangavarapu,Nicholas Chernogor,Jonathan P. Chang,Cristian Danescu-Niculescu-Mizil*

Main category: cs.CL

TL;DR: 论文提出了一个统一的评估框架，用于比较不同架构在预测对话是否会失控（CGA任务）上的表现，并引入了一个新指标来衡量模型随对话进展调整预测的能力。


<details>
  <summary>Details</summary>
Motivation: 赋予自动化系统预测对话方向的能力，以辅助人类互动，并填补当前CGA任务评估方法的不足。

Method: 引入首个统一的评估框架，创建基准以直接比较不同架构，并设计新指标衡量模型动态调整预测的能力。

Result: 提供了一个当前CGA模型进展的最新概述，展示了新框架和指标的有效性。

Conclusion: 统一的评估框架和新指标为CGA任务提供了更可靠的比较标准，推动了该领域的发展。

Abstract: We often rely on our intuition to anticipate the direction of a conversation.
Endowing automated systems with similar foresight can enable them to assist
human-human interactions. Recent work on developing models with this predictive
capacity has focused on the Conversations Gone Awry (CGA) task: forecasting
whether an ongoing conversation will derail. In this work, we revisit this task
and introduce the first uniform evaluation framework, creating a benchmark that
enables direct and reliable comparisons between different architectures. This
allows us to present an up-to-date overview of the current progress in CGA
models, in light of recent advancements in language modeling. Our framework
also introduces a novel metric that captures a model's ability to revise its
forecast as the conversation progresses.

</details>
