{"id": "2506.22604", "categories": ["cs.AI", "cs.HC", "cs.RO"], "pdf": "https://arxiv.org/pdf/2506.22604", "abs": "https://arxiv.org/abs/2506.22604", "authors": ["David Porfirio", "Vincent Hsiao", "Morgan Fine-Morris", "Leslie Smith", "Laura M. Hiatt"], "title": "Bootstrapping Human-Like Planning via LLMs", "comment": "Accepted by the 2025 34th IEEE International Conference on Robot and\n  Human Interactive Communication (RO-MAN)", "summary": "Robot end users increasingly require accessible means of specifying tasks for\nrobots to perform. Two common end-user programming paradigms include\ndrag-and-drop interfaces and natural language programming. Although natural\nlanguage interfaces harness an intuitive form of human communication,\ndrag-and-drop interfaces enable users to meticulously and precisely dictate the\nkey actions of the robot's task. In this paper, we investigate the degree to\nwhich both approaches can be combined. Specifically, we construct a large\nlanguage model (LLM)-based pipeline that accepts natural language as input and\nproduces human-like action sequences as output, specified at a level of\ngranularity that a human would produce. We then compare these generated action\nsequences to another dataset of hand-specified action sequences. Although our\nresults reveal that larger models tend to outperform smaller ones in the\nproduction of human-like action sequences, smaller models nonetheless achieve\nsatisfactory performance.", "AI": {"tldr": "\u7814\u7a76\u7ed3\u5408\u81ea\u7136\u8bed\u8a00\u7f16\u7a0b\u548c\u62d6\u653e\u754c\u9762\uff0c\u901a\u8fc7LLM\u751f\u6210\u4eba\u7c7b\u7ea7\u522b\u7684\u52a8\u4f5c\u5e8f\u5217\uff0c\u5e76\u4e0e\u624b\u52a8\u6307\u5b9a\u7684\u5e8f\u5217\u8fdb\u884c\u6bd4\u8f83\u3002", "motivation": "\u63a2\u7d22\u5982\u4f55\u7ed3\u5408\u81ea\u7136\u8bed\u8a00\u7f16\u7a0b\u7684\u76f4\u89c2\u6027\u548c\u62d6\u653e\u754c\u9762\u7684\u7cbe\u786e\u6027\uff0c\u4ee5\u63d0\u5347\u673a\u5668\u4eba\u4efb\u52a1\u7f16\u7a0b\u7684\u6548\u7387\u548c\u7528\u6237\u4f53\u9a8c\u3002", "method": "\u6784\u5efa\u57fa\u4e8eLLM\u7684\u6d41\u7a0b\uff0c\u8f93\u5165\u81ea\u7136\u8bed\u8a00\u5e76\u751f\u6210\u4eba\u7c7b\u7ea7\u522b\u7684\u52a8\u4f5c\u5e8f\u5217\uff0c\u518d\u4e0e\u624b\u52a8\u6307\u5b9a\u7684\u5e8f\u5217\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "\u8f83\u5927\u6a21\u578b\u751f\u6210\u7684\u52a8\u4f5c\u5e8f\u5217\u66f4\u63a5\u8fd1\u4eba\u7c7b\u6c34\u5e73\uff0c\u4f46\u8f83\u5c0f\u6a21\u578b\u8868\u73b0\u4e5f\u4ee4\u4eba\u6ee1\u610f\u3002", "conclusion": "\u7ed3\u5408\u81ea\u7136\u8bed\u8a00\u548c\u62d6\u653e\u754c\u9762\u7684\u65b9\u6cd5\u53ef\u884c\uff0cLLM\u5728\u751f\u6210\u4eba\u7c7b\u7ea7\u522b\u52a8\u4f5c\u5e8f\u5217\u65b9\u9762\u8868\u73b0\u826f\u597d\u3002"}}
{"id": "2506.22609", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22609", "abs": "https://arxiv.org/abs/2506.22609", "authors": ["Graham Todd", "Alexander G. Padula", "Dennis J. N. J. Soemers", "Julian Togelius"], "title": "Ludax: A GPU-Accelerated Domain Specific Language for Board Games", "comment": "18 pages, 3 figures", "summary": "Games have long been used as benchmarks and testing environments for research\nin artificial intelligence. A key step in supporting this research was the\ndevelopment of game description languages: frameworks that compile\ndomain-specific code into playable and simulatable game environments, allowing\nresearchers to generalize their algorithms and approaches across multiple games\nwithout having to manually implement each one. More recently, progress in\nreinforcement learning (RL) has been largely driven by advances in hardware\nacceleration. Libraries like JAX allow practitioners to take full advantage of\ncutting-edge computing hardware, often speeding up training and testing by\norders of magnitude. Here, we present a synthesis of these strands of research:\na domain-specific language for board games which automatically compiles into\nhardware-accelerated code. Our framework, Ludax, combines the generality of\ngame description languages with the speed of modern parallel processing\nhardware and is designed to fit neatly into existing deep learning pipelines.\nWe envision Ludax as a tool to help accelerate games research generally, from\nRL to cognitive science, by enabling rapid simulation and providing a flexible\nrepresentation scheme. We present a detailed breakdown of Ludax's description\nlanguage and technical notes on the compilation process, along with speed\nbenchmarking and a demonstration of training RL agents. The Ludax framework,\nalong with implementations of existing board games, is open-source and freely\navailable.", "AI": {"tldr": "Ludax\u662f\u4e00\u4e2a\u7ed3\u5408\u6e38\u620f\u63cf\u8ff0\u8bed\u8a00\u548c\u786c\u4ef6\u52a0\u901f\u7684\u9886\u57df\u7279\u5b9a\u8bed\u8a00\uff0c\u65e8\u5728\u52a0\u901f\u6e38\u620f\u7814\u7a76\uff0c\u652f\u6301\u5feb\u901f\u6a21\u62df\u548c\u7075\u6d3b\u8868\u793a\u3002", "motivation": "\u6e38\u620f\u662f\u4eba\u5de5\u667a\u80fd\u7814\u7a76\u7684\u91cd\u8981\u6d4b\u8bd5\u73af\u5883\uff0c\u4f46\u73b0\u6709\u5de5\u5177\u7f3a\u4e4f\u786c\u4ef6\u52a0\u901f\u652f\u6301\uff0c\u9650\u5236\u4e86\u7814\u7a76\u6548\u7387\u3002", "method": "\u5f00\u53d1\u4e86Ludax\u6846\u67b6\uff0c\u5c06\u6e38\u620f\u63cf\u8ff0\u8bed\u8a00\u7f16\u8bd1\u4e3a\u786c\u4ef6\u52a0\u901f\u4ee3\u7801\uff0c\u5e76\u96c6\u6210\u5230\u6df1\u5ea6\u5b66\u4e60\u6d41\u7a0b\u4e2d\u3002", "result": "Ludax\u5b9e\u73b0\u4e86\u5feb\u901f\u6a21\u62df\uff0c\u652f\u6301\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u8bad\u7ec3\uff0c\u5e76\u63d0\u4f9b\u4e86\u5f00\u6e90\u5b9e\u73b0\u3002", "conclusion": "Ludax\u4e3a\u6e38\u620f\u7814\u7a76\u63d0\u4f9b\u4e86\u9ad8\u6548\u5de5\u5177\uff0c\u6709\u671b\u63a8\u52a8\u4ece\u5f3a\u5316\u5b66\u4e60\u5230\u8ba4\u77e5\u79d1\u5b66\u7684\u5e7f\u6cdb\u7814\u7a76\u3002"}}
{"id": "2506.22653", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22653", "abs": "https://arxiv.org/abs/2506.22653", "authors": ["Michael Grosskopf", "Russell Bent", "Rahul Somasundaram", "Isaac Michaud", "Arthur Lui", "Nathan Debardeleben", "Earl Lawrence"], "title": "URSA: The Universal Research and Scientific Agent", "comment": "31 pages, 9 figures", "summary": "Large language models (LLMs) have moved far beyond their initial form as\nsimple chatbots, now carrying out complex reasoning, planning, writing, coding,\nand research tasks. These skills overlap significantly with those that human\nscientists use day-to-day to solve complex problems that drive the cutting edge\nof research. Using LLMs in \"agentic\" AI has the potential to revolutionize\nmodern science and remove bottlenecks to progress. In this work, we present\nURSA, a scientific agent ecosystem for accelerating research tasks. URSA\nconsists of a set of modular agents and tools, including coupling to advanced\nphysics simulation codes, that can be combined to address scientific problems\nof varied complexity and impact. This work highlights the architecture of URSA,\nas well as examples that highlight the potential of the system.", "AI": {"tldr": "URSA\u662f\u4e00\u4e2a\u79d1\u5b66\u4ee3\u7406\u751f\u6001\u7cfb\u7edf\uff0c\u65e8\u5728\u901a\u8fc7\u6a21\u5757\u5316\u4ee3\u7406\u548c\u5de5\u5177\u52a0\u901f\u7814\u7a76\u4efb\u52a1\uff0c\u5305\u62ec\u4e0e\u9ad8\u7ea7\u7269\u7406\u6a21\u62df\u4ee3\u7801\u7684\u8026\u5408\uff0c\u4ee5\u89e3\u51b3\u4e0d\u540c\u590d\u6742\u6027\u548c\u5f71\u54cd\u7684\u79d1\u5b66\u95ee\u9898\u3002", "motivation": "\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u590d\u6742\u63a8\u7406\u3001\u89c4\u5212\u548c\u6267\u884c\u80fd\u529b\uff0c\u89e3\u51b3\u79d1\u5b66\u7814\u7a76\u4e2d\u7684\u74f6\u9888\u95ee\u9898\uff0c\u63a8\u52a8\u79d1\u5b66\u8fdb\u6b65\u3002", "method": "\u8bbe\u8ba1\u4e86URSA\u7cfb\u7edf\uff0c\u5305\u542b\u6a21\u5757\u5316\u4ee3\u7406\u548c\u5de5\u5177\uff0c\u80fd\u591f\u7075\u6d3b\u7ec4\u5408\u4ee5\u5e94\u5bf9\u4e0d\u540c\u79d1\u5b66\u95ee\u9898\u3002", "result": "\u5c55\u793a\u4e86URSA\u7684\u67b6\u6784\u53ca\u5176\u5728\u89e3\u51b3\u590d\u6742\u79d1\u5b66\u95ee\u9898\u4e2d\u7684\u6f5c\u529b\u3002", "conclusion": "URSA\u5c55\u793a\u4e86LLMs\u5728\u79d1\u5b66\u7814\u7a76\u4e2d\u7684\u9769\u547d\u6027\u6f5c\u529b\uff0c\u6709\u671b\u52a0\u901f\u79d1\u5b66\u53d1\u73b0\u3002"}}
{"id": "2506.22740", "categories": ["cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2506.22740", "abs": "https://arxiv.org/abs/2506.22740", "authors": ["Jessica Hullman", "Ziyang Guo", "Berk Ustun"], "title": "Explanations are a means to an end", "comment": null, "summary": "Modern methods for explainable machine learning are designed to describe how\nmodels map inputs to outputs--without deep consideration of how these\nexplanations will be used in practice. This paper argues that explanations\nshould be designed and evaluated with a specific end in mind. We describe how\nto formalize this end in a framework based in statistical decision theory. We\nshow how this functionally-grounded approach can be applied across diverse use\ncases, such as clinical decision support, providing recourse, or debugging. We\ndemonstrate its use to characterize the maximum \"boost\" in performance on a\nparticular task that an explanation could provide an idealized decision-maker,\npreventing misuse due to ambiguity by forcing researchers to specify concrete\nuse cases that can be analyzed in light of models of expected explanation use.\nWe argue that evaluation should meld theoretical and empirical perspectives on\nthe value of explanation, and contribute definitions that span these\nperspectives.", "AI": {"tldr": "\u8bba\u6587\u4e3b\u5f20\u89e3\u91ca\u6027\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5e94\u57fa\u4e8e\u5177\u4f53\u7528\u9014\u8bbe\u8ba1\u548c\u8bc4\u4f30\uff0c\u63d0\u51fa\u57fa\u4e8e\u7edf\u8ba1\u51b3\u7b56\u7406\u8bba\u7684\u6846\u67b6\uff0c\u5e76\u5c55\u793a\u5176\u5728\u591a\u79cd\u573a\u666f\u4e2d\u7684\u5e94\u7528\u3002", "motivation": "\u73b0\u6709\u89e3\u91ca\u6027\u65b9\u6cd5\u672a\u5145\u5206\u8003\u8651\u5b9e\u9645\u7528\u9014\uff0c\u9700\u8bbe\u8ba1\u66f4\u5b9e\u7528\u7684\u89e3\u91ca\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u7edf\u8ba1\u51b3\u7b56\u7406\u8bba\u7684\u6846\u67b6\uff0c\u660e\u786e\u89e3\u91ca\u7684\u5177\u4f53\u7528\u9014\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u548c\u5b9e\u8bc1\u7ed3\u5408\u8bc4\u4f30\u89e3\u91ca\u4ef7\u503c\u3002", "result": "\u5c55\u793a\u4e86\u6846\u67b6\u5728\u4e34\u5e8a\u51b3\u7b56\u3001\u63d0\u4f9b\u8865\u6551\u63aa\u65bd\u548c\u8c03\u8bd5\u7b49\u573a\u666f\u4e2d\u7684\u5e94\u7528\uff0c\u5e76\u91cf\u5316\u4e86\u89e3\u91ca\u5bf9\u7406\u60f3\u51b3\u7b56\u8005\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u89e3\u91ca\u6027\u65b9\u6cd5\u5e94\u9488\u5bf9\u5177\u4f53\u7528\u9014\u8bbe\u8ba1\uff0c\u7ed3\u5408\u7406\u8bba\u548c\u5b9e\u8bc1\u8bc4\u4f30\uff0c\u907f\u514d\u56e0\u6a21\u7cca\u6027\u5bfc\u81f4\u7684\u8bef\u7528\u3002"}}
{"id": "2506.22774", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2506.22774", "abs": "https://arxiv.org/abs/2506.22774", "authors": ["Michael Papademas", "Xenia Ziouvelou", "Antonis Troumpoukis", "Vangelis Karkaletsis"], "title": "Bridging Ethical Principles and Algorithmic Methods: An Alternative Approach for Assessing Trustworthiness in AI Systems", "comment": null, "summary": "Artificial Intelligence (AI) technology epitomizes the complex challenges\nposed by human-made artifacts, particularly those widely integrated into\nsociety and exert significant influence, highlighting potential benefits and\ntheir negative consequences. While other technologies may also pose substantial\nrisks, AI's pervasive reach makes its societal effects especially profound. The\ncomplexity of AI systems, coupled with their remarkable capabilities, can lead\nto a reliance on technologies that operate beyond direct human oversight or\nunderstanding. To mitigate the risks that arise, several theoretical tools and\nguidelines have been developed, alongside efforts to create technological tools\naimed at safeguarding Trustworthy AI. The guidelines take a more holistic view\nof the issue but fail to provide techniques for quantifying trustworthiness.\nConversely, while technological tools are better at achieving such\nquantification, they lack a holistic perspective, focusing instead on specific\naspects of Trustworthy AI. This paper aims to introduce an assessment method\nthat combines the ethical components of Trustworthy AI with the algorithmic\nprocesses of PageRank and TrustRank. The goal is to establish an assessment\nframework that minimizes the subjectivity inherent in the self-assessment\ntechniques prevalent in the field by introducing algorithmic criteria. The\napplication of our approach indicates that a holistic assessment of an AI\nsystem's trustworthiness can be achieved by providing quantitative insights\nwhile considering the theoretical content of relevant guidelines.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u4f26\u7406\u4e0e\u7b97\u6cd5\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u4ee5\u91cf\u5316AI\u7cfb\u7edf\u7684\u53ef\u4fe1\u5ea6\uff0c\u5f25\u8865\u73b0\u6709\u6307\u5357\u4e0e\u6280\u672f\u5de5\u5177\u7684\u4e0d\u8db3\u3002", "motivation": "AI\u6280\u672f\u7684\u5e7f\u6cdb\u5e94\u7528\u53ca\u5176\u6f5c\u5728\u98ce\u9669\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u91cf\u5316\u53ef\u4fe1\u5ea6\u53c8\u5177\u5907\u5168\u9762\u89c6\u89d2\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u7ed3\u5408PageRank\u548cTrustRank\u7b97\u6cd5\uff0c\u5c06\u4f26\u7406\u7ec4\u4ef6\u4e0e\u7b97\u6cd5\u6d41\u7a0b\u7ed3\u5408\uff0c\u5efa\u7acb\u8bc4\u4f30\u6846\u67b6\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u63d0\u4f9b\u5b9a\u91cf\u5206\u6790\uff0c\u540c\u65f6\u8003\u8651\u4f26\u7406\u6307\u5357\uff0c\u5b9e\u73b0AI\u7cfb\u7edf\u53ef\u4fe1\u5ea6\u7684\u5168\u9762\u8bc4\u4f30\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u6548\u51cf\u5c11\u4e86\u4e3b\u89c2\u6027\uff0c\u4e3aAI\u53ef\u4fe1\u5ea6\u8bc4\u4f30\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.22865", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22865", "abs": "https://arxiv.org/abs/2506.22865", "authors": ["Ziqi Zhong", "Xunzhu Tang"], "title": "ReasonBridge: Efficient Reasoning Transfer from Closed to Open-Source Language Models", "comment": null, "summary": "Recent advancements in Large Language Models (LLMs) have revealed a\nsignificant performance gap between closed-source and open-source models,\nparticularly in tasks requiring complex reasoning and precise instruction\nfollowing. This paper introduces ReasonBridge, a methodology that efficiently\ntransfers reasoning capabilities from powerful closed-source to open-source\nmodels through a novel hierarchical knowledge distillation framework. We\ndevelop a tailored dataset Reason1K with only 1,000 carefully curated reasoning\ntraces emphasizing difficulty, diversity, and quality. These traces are\nfiltered from across multiple domains using a structured multi-criteria\nselection algorithm. Our transfer learning approach incorporates: (1) a\nhierarchical distillation process capturing both strategic abstraction and\ntactical implementation patterns, (2) a sparse reasoning-focused adapter\narchitecture requiring only 0.3% additional trainable parameters, and (3) a\ntest-time compute scaling mechanism using guided inference interventions.\nComprehensive evaluations demonstrate that ReasonBridge improves reasoning\ncapabilities in open-source models by up to 23% on benchmark tasks,\nsignificantly narrowing the gap with closed-source models. Notably, the\nenhanced Qwen2.5-14B outperforms Claude-Sonnet3.5 on MATH500 and matches its\nperformance on competition-level AIME problems. Our methodology generalizes\neffectively across diverse reasoning domains and model architectures,\nestablishing a sample-efficient approach to reasoning enhancement for\ninstruction following.", "AI": {"tldr": "ReasonBridge\u901a\u8fc7\u5206\u5c42\u77e5\u8bc6\u84b8\u998f\u6846\u67b6\uff0c\u5c06\u95ed\u6e90\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u9ad8\u6548\u8fc1\u79fb\u5230\u5f00\u6e90\u6a21\u578b\uff0c\u663e\u8457\u7f29\u5c0f\u6027\u80fd\u5dee\u8ddd\u3002", "motivation": "\u95ed\u6e90\u4e0e\u5f00\u6e90\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\u5b58\u5728\u663e\u8457\u6027\u80fd\u5dee\u8ddd\uff0c\u9700\u9ad8\u6548\u8fc1\u79fb\u63a8\u7406\u80fd\u529b\u3002", "method": "\u91c7\u7528\u5206\u5c42\u84b8\u998f\u3001\u7a00\u758f\u9002\u914d\u5668\u67b6\u6784\u548c\u63a8\u7406\u5e72\u9884\u673a\u5236\uff0c\u4f7f\u7528\u7cbe\u5fc3\u7b5b\u9009\u7684Reason1K\u6570\u636e\u96c6\u3002", "result": "\u5f00\u6e90\u6a21\u578b\u63a8\u7406\u80fd\u529b\u63d0\u534723%\uff0cQwen2.5-14B\u5728\u90e8\u5206\u4efb\u52a1\u4e0a\u8d85\u8d8a\u95ed\u6e90\u6a21\u578b\u3002", "conclusion": "ReasonBridge\u4e3a\u9ad8\u6548\u589e\u5f3a\u5f00\u6e90\u6a21\u578b\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u6837\u672c\u6709\u6548\u7684\u65b9\u6cd5\u3002"}}
{"id": "2506.22893", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2506.22893", "abs": "https://arxiv.org/abs/2506.22893", "authors": ["Arpit Narechania", "Alex Endert", "Atanu R Sinha"], "title": "Agentic Enterprise: AI-Centric User to User-Centric AI", "comment": "12 pages, 1 figure, 2 sidebars; Preprint", "summary": "After a very long winter, the Artificial Intelligence (AI) spring is here.\nOr, so it seems over the last three years. AI has the potential to impact many\nareas of human life - personal, social, health, education, professional. In\nthis paper, we take a closer look at the potential of AI for Enterprises, where\ndecision-making plays a crucial and repeated role across functions, tasks, and\noperations. We consider Agents imbued with AI as means to increase\ndecision-productivity of enterprises. We highlight six tenets for Agentic\nsuccess in enterprises, by drawing attention to what the current, AI-Centric\nUser paradigm misses, in the face of persistent needs of and usefulness for\nEnterprise Decision-Making. In underscoring a shift to User-Centric AI, we\noffer six tenets and promote market mechanisms for platforms, aligning the\ndesign of AI and its delivery by Agents to the cause of enterprise users.", "AI": {"tldr": "AI\u5728\u4f01\u4e1a\u7684\u51b3\u7b56\u751f\u4ea7\u529b\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u63d0\u51fa\u4e86\u516d\u9879\u539f\u5219\u4ee5\u63a8\u52a8\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684AI\u8bbe\u8ba1\u3002", "motivation": "\u63a2\u8ba8AI\u5982\u4f55\u63d0\u5347\u4f01\u4e1a\u51b3\u7b56\u751f\u4ea7\u529b\uff0c\u5e76\u6307\u51fa\u5f53\u524d\u4ee5AI\u4e3a\u4e2d\u5fc3\u7684\u7528\u6237\u8303\u5f0f\u5728\u6ee1\u8db3\u4f01\u4e1a\u9700\u6c42\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u516d\u9879\u539f\u5219\uff0c\u5f3a\u8c03\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684AI\u8bbe\u8ba1\uff0c\u5e76\u5efa\u8bae\u901a\u8fc7\u5e02\u573a\u673a\u5236\u8c03\u6574AI\u5e73\u53f0\u3002", "result": "\u5f3a\u8c03\u4e86\u8f6c\u5411\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684AI\u7684\u91cd\u8981\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u516d\u9879\u539f\u5219\u4ee5\u4f18\u5316\u4f01\u4e1a\u51b3\u7b56\u3002", "conclusion": "\u901a\u8fc7\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684AI\u8bbe\u8ba1\u548c\u5e02\u573a\u673a\u5236\uff0c\u53ef\u4ee5\u66f4\u597d\u5730\u6ee1\u8db3\u4f01\u4e1a\u7684\u51b3\u7b56\u9700\u6c42\u3002"}}
{"id": "2506.22919", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22919", "abs": "https://arxiv.org/abs/2506.22919", "authors": ["Sanskar Pandey", "Ruhaan Chopra", "Saad Murtaza Bhat", "Ark Abhyudaya"], "title": "Hecto: Modular Sparse Experts for Adaptive and Interpretable Reasoning", "comment": null, "summary": "Mixture-of-Experts (MoE) models enable conditional computation by routing\ninputs to specialized experts, but these experts rely on identical inductive\nbiases, thus limiting representational diversity. This static computation\npathway is inefficient for inputs that require different types of reasoning and\nlimits specialization and interpretability. We propose Hecto, a lightweight MoE\narchitecture that leverages architectural heterogeneity by combining a GRU\nexpert for temporal reasoning and an FFNN expert for static abstraction under a\nsparse Top-1 gating mechanism. Evaluated on three reasoning benchmarks (AG\nNews, SST-2, HotpotQA) and a regression task (STS-B), Hecto matches or closely\ntrails homogeneous baselines in performance despite receiving isolated input\nrepresentations, while achieving clear expert specialization, with each expert\naligning to distinct reasoning types (temporal vs static). At larger batch\nsizes, Hecto exhibits improved performance, benefiting from relaxed\ncomputational constraints that allow its heterogeneous architecture to optimize\nmore effectively. Ablation results isolate architectural diversity as the\nsource of Hecto's stability and interpretability across diverse reasoning\ntasks. Overall, Hecto establishes itself as a new benchmark for conditional\ncomputation, offering a principled framework for specialized reasoning in\nlow-resource regimes with its model strength derived from principled\nspecialization.", "AI": {"tldr": "Hecto\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7MoE\u67b6\u6784\uff0c\u901a\u8fc7\u7ed3\u5408GRU\u548cFFNN\u4e13\u5bb6\u5b9e\u73b0\u5f02\u6784\u8ba1\u7b97\uff0c\u63d0\u5347\u63a8\u7406\u4efb\u52a1\u7684\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u4f20\u7edfMoE\u6a21\u578b\u7684\u9759\u6001\u8ba1\u7b97\u8def\u5f84\u9650\u5236\u4e86\u8868\u793a\u591a\u6837\u6027\u548c\u6548\u7387\uff0cHecto\u65e8\u5728\u901a\u8fc7\u5f02\u6784\u67b6\u6784\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "Hecto\u7ed3\u5408GRU\u4e13\u5bb6\uff08\u65f6\u5e8f\u63a8\u7406\uff09\u548cFFNN\u4e13\u5bb6\uff08\u9759\u6001\u62bd\u8c61\uff09\uff0c\u91c7\u7528\u7a00\u758fTop-1\u95e8\u63a7\u673a\u5236\u3002", "result": "\u5728\u591a\u4e2a\u4efb\u52a1\u4e2d\uff0cHecto\u6027\u80fd\u63a5\u8fd1\u6216\u4f18\u4e8e\u540c\u8d28\u57fa\u7ebf\uff0c\u540c\u65f6\u5b9e\u73b0\u4e13\u5bb6\u4e13\u4e1a\u5316\uff08\u65f6\u5e8fvs\u9759\u6001\uff09\u3002", "conclusion": "Hecto\u4e3a\u6761\u4ef6\u8ba1\u7b97\u63d0\u4f9b\u4e86\u65b0\u57fa\u51c6\uff0c\u5176\u5f02\u6784\u67b6\u6784\u5728\u4f4e\u8d44\u6e90\u573a\u666f\u4e0b\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2506.22920", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22920", "abs": "https://arxiv.org/abs/2506.22920", "authors": ["Pinzheng Wang", "Juntao Li", "Zecheng Tang", "Haijia Gui", "Min zhang"], "title": "Improving Rationality in the Reasoning Process of Language Models through Self-playing Game", "comment": "Accepted by ICML 2025", "summary": "Large language models (LLMs) have demonstrated considerable reasoning\nabilities in various tasks such as mathematics and coding. However, recent\nstudies indicate that even the best models lack true comprehension of their\nreasoning processes. In this paper, we explore how self-play can enhance the\nrationality of models in the reasoning process without supervision from humans\nor superior models. We design a Critic-Discernment Game(CDG) in which a prover\nfirst provides a solution to a given problem and is subsequently challenged by\ncritiques of its solution. These critiques either aim to assist or mislead the\nprover. The objective of the prover is to maintain the correct answer when\nfaced with misleading comments, while correcting errors in response to\nconstructive feedback. Our experiments on tasks involving mathematical\nreasoning, stepwise error detection, self-correction, and long-chain reasoning\ndemonstrate that CDG training can significantly improve the ability of\nwell-aligned LLMs to comprehend their reasoning process.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u901a\u8fc7\u81ea\u6211\u535a\u5f08\uff08CDG\u6e38\u620f\uff09\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u7406\u6027\u80fd\u529b\uff0c\u65e0\u9700\u4eba\u7c7b\u76d1\u7763\u3002\u5b9e\u9a8c\u663e\u793a\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5bf9\u63a8\u7406\u8fc7\u7a0b\u7684\u7406\u89e3\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u548c\u7f16\u7a0b\u7b49\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u5b83\u4eec\u7f3a\u4e4f\u5bf9\u63a8\u7406\u8fc7\u7a0b\u7684\u771f\u6b63\u7406\u89e3\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u81ea\u6211\u76d1\u7763\u65b9\u6cd5\u63d0\u5347\u6a21\u578b\u7684\u7406\u6027\u80fd\u529b\u3002", "method": "\u8bbe\u8ba1\u4e86Critic-Discernment Game\uff08CDG\uff09\uff0c\u5176\u4e2d\u8bc1\u660e\u8005\u63d0\u4f9b\u89e3\u51b3\u65b9\u6848\u5e76\u63a5\u53d7\u6279\u8bc4\u8005\u7684\u6311\u6218\uff0c\u6279\u8bc4\u8005\u53ef\u80fd\u63d0\u4f9b\u5e2e\u52a9\u6216\u8bef\u5bfc\u3002\u8bc1\u660e\u8005\u9700\u5728\u8bef\u5bfc\u4e0b\u4fdd\u6301\u6b63\u786e\u7b54\u6848\uff0c\u5e76\u5728\u5efa\u8bbe\u6027\u53cd\u9988\u4e2d\u4fee\u6b63\u9519\u8bef\u3002", "result": "\u5728\u6570\u5b66\u63a8\u7406\u3001\u9010\u6b65\u9519\u8bef\u68c0\u6d4b\u3001\u81ea\u6211\u4fee\u6b63\u548c\u957f\u94fe\u63a8\u7406\u4efb\u52a1\u4e2d\uff0cCDG\u8bad\u7ec3\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5bf9\u63a8\u7406\u8fc7\u7a0b\u7684\u7406\u89e3\u80fd\u529b\u3002", "conclusion": "\u81ea\u6211\u535a\u5f08\u65b9\u6cd5\uff08\u5982CDG\uff09\u53ef\u4ee5\u6709\u6548\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7406\u6027\u80fd\u529b\uff0c\u65e0\u9700\u4f9d\u8d56\u4eba\u7c7b\u6216\u66f4\u4f18\u6a21\u578b\u7684\u76d1\u7763\u3002"}}
{"id": "2506.22992", "categories": ["cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.22992", "abs": "https://arxiv.org/abs/2506.22992", "authors": ["Yulun Jiang", "Yekun Chai", "Maria Brbi\u0107", "Michael Moor"], "title": "MARBLE: A Hard Benchmark for Multimodal Spatial Reasoning and Planning", "comment": null, "summary": "The ability to process information from multiple modalities and to reason\nthrough it step-by-step remains a critical challenge in advancing artificial\nintelligence. However, existing reasoning benchmarks focus on text-only\nreasoning, or employ multimodal questions that can be answered by directly\nretrieving information from a non-text modality. Thus, complex reasoning\nremains poorly understood in multimodal domains. Here, we present MARBLE, a\nchallenging multimodal reasoning benchmark that is designed to scrutinize\nmultimodal language models (MLLMs) in their ability to carefully reason\nstep-by-step through complex multimodal problems and environments. MARBLE is\ncomposed of two highly challenging tasks, M-Portal and M-Cube, that require the\ncrafting and understanding of multistep plans under spatial, visual, and\nphysical constraints. We find that current MLLMs perform poorly on MARBLE --\nall the 12 advanced models obtain near-random performance on M-Portal and 0%\naccuracy on M-Cube. Only in simplified subtasks some models outperform the\nrandom baseline, indicating that complex reasoning is still a challenge for\nexisting MLLMs. Moreover, we show that perception remains a bottleneck, where\nMLLMs occasionally fail to extract information from the visual inputs. By\nshedding a light on the limitations of MLLMs, we hope that MARBLE will spur the\ndevelopment of the next generation of models with the ability to reason and\nplan across many, multimodal reasoning steps.", "AI": {"tldr": "MARBLE\u662f\u4e00\u4e2a\u591a\u6a21\u6001\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\uff0c\u65e8\u5728\u8bc4\u4f30\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u5728\u590d\u6742\u591a\u6a21\u6001\u95ee\u9898\u4e2d\u7684\u9010\u6b65\u63a8\u7406\u80fd\u529b\u3002\u73b0\u6709\u6a21\u578b\u8868\u73b0\u4e0d\u4f73\uff0c\u8868\u660e\u590d\u6742\u63a8\u7406\u4ecd\u662f\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u63a8\u7406\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u6587\u672c\u6216\u7b80\u5355\u591a\u6a21\u6001\u95ee\u9898\uff0c\u590d\u6742\u591a\u6a21\u6001\u63a8\u7406\u80fd\u529b\u5c1a\u672a\u88ab\u5145\u5206\u7814\u7a76\u3002", "method": "MARBLE\u5305\u542b\u4e24\u4e2a\u9ad8\u96be\u5ea6\u4efb\u52a1\uff08M-Portal\u548cM-Cube\uff09\uff0c\u8981\u6c42\u6a21\u578b\u5728\u7a7a\u95f4\u3001\u89c6\u89c9\u548c\u7269\u7406\u7ea6\u675f\u4e0b\u8fdb\u884c\u591a\u6b65\u89c4\u5212\u3002", "result": "12\u4e2a\u5148\u8fdb\u6a21\u578b\u5728MARBLE\u4e0a\u8868\u73b0\u63a5\u8fd1\u968f\u673a\u6c34\u5e73\uff0c\u90e8\u5206\u7b80\u5316\u5b50\u4efb\u52a1\u4e2d\u8868\u73b0\u7565\u4f18\uff0c\u611f\u77e5\u4ecd\u662f\u74f6\u9888\u3002", "conclusion": "MARBLE\u63ed\u793a\u4e86MLLMs\u7684\u5c40\u9650\u6027\uff0c\u5e0c\u671b\u63a8\u52a8\u4e0b\u4e00\u4ee3\u6a21\u578b\u5728\u591a\u6a21\u6001\u63a8\u7406\u80fd\u529b\u4e0a\u7684\u53d1\u5c55\u3002"}}
{"id": "2506.23049", "categories": ["cs.AI", "cs.CL", "cs.SD", "eess.AS", "68T42, 68T50,", "I.2.7; I.2.11; H.5.5"], "pdf": "https://arxiv.org/pdf/2506.23049", "abs": "https://arxiv.org/abs/2506.23049", "authors": ["Leander Melroy Maben", "Gayathri Ganesh Lakshmy", "Srijith Radhakrishnan", "Siddhant Arora", "Shinji Watanabe"], "title": "AURA: Agent for Understanding, Reasoning, and Automated Tool Use in Voice-Driven Tasks", "comment": null, "summary": "Despite advances in language and speech technologies, no open-source system\nenables full speech-to-speech, multi-turn dialogue with integrated tool use and\nagentic reasoning. We introduce AURA (Agent for Understanding, Reasoning, and\nAutomated Tool Use), the first open-source, speech-native assistant capable of\ncompleting complex, goal-driven tasks through dynamic tool invocation and\nmulti-turn conversation. AURA combines open-weight ASR, TTS, and LLMs in a\ncascaded pipeline and supports tools such as calendar booking, contact lookup,\nweb search, and email. Its modular design allows easy integration of new tools\nusing natural language prompts and action classes. On VoiceBench, AURA scores\n92.75% on OpenBookQA-outperforming all open-weight systems and nearing\nGPT-4o-and 4.39 on AlpacaEval, competitive with other open-weight systems.\nHuman evaluation shows 90% task success on complex, multi-turn speech tasks.", "AI": {"tldr": "AURA\u662f\u4e00\u4e2a\u5f00\u6e90\u7684\u8bed\u97f3\u539f\u751f\u52a9\u624b\uff0c\u652f\u6301\u591a\u8f6e\u5bf9\u8bdd\u548c\u5de5\u5177\u8c03\u7528\uff0c\u7ed3\u5408\u4e86ASR\u3001TTS\u548cLLM\u6280\u672f\uff0c\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u5f00\u6e90\u7cfb\u7edf\u652f\u6301\u8bed\u97f3\u5230\u8bed\u97f3\u7684\u591a\u8f6e\u5bf9\u8bdd\u548c\u5de5\u5177\u96c6\u6210\uff0cAURA\u586b\u8865\u4e86\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "AURA\u91c7\u7528\u6a21\u5757\u5316\u8bbe\u8ba1\uff0c\u7ed3\u5408ASR\u3001TTS\u548cLLM\u6280\u672f\uff0c\u652f\u6301\u52a8\u6001\u5de5\u5177\u8c03\u7528\u548c\u591a\u8f6e\u5bf9\u8bdd\u3002", "result": "\u5728VoiceBench\u4e0a\uff0cAURA\u8868\u73b0\u4f18\u5f02\uff0cOpenBookQA\u5f97\u520692.75%\uff0c\u63a5\u8fd1GPT-4o\uff0c\u4eba\u7c7b\u8bc4\u4f30\u4efb\u52a1\u6210\u529f\u7387\u8fbe90%\u3002", "conclusion": "AURA\u662f\u9996\u4e2a\u5f00\u6e90\u8bed\u97f3\u52a9\u624b\uff0c\u5c55\u793a\u4e86\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u9ad8\u6548\u6027\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2506.23080", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23080", "abs": "https://arxiv.org/abs/2506.23080", "authors": ["Xinmin Fang", "Lingfeng Tao", "Zhengxiong Li"], "title": "AI's Euclid's Elements Moment: From Language Models to Computable Thought", "comment": null, "summary": "This paper presents a comprehensive five-stage evolutionary framework for\nunderstanding the development of artificial intelligence, arguing that its\ntrajectory mirrors the historical progression of human cognitive technologies.\nWe posit that AI is advancing through distinct epochs, each defined by a\nrevolutionary shift in its capacity for representation and reasoning, analogous\nto the inventions of cuneiform, the alphabet, grammar and logic, mathematical\ncalculus, and formal logical systems. This \"Geometry of Cognition\" framework\nmoves beyond mere metaphor to provide a systematic, cross-disciplinary model\nthat not only explains AI's past architectural shifts-from expert systems to\nTransformers-but also charts a concrete and prescriptive path forward.\nCrucially, we demonstrate that this evolution is not merely linear but\nreflexive: as AI advances through these stages, the tools and insights it\ndevelops create a feedback loop that fundamentally reshapes its own underlying\narchitecture. We are currently transitioning into a \"Metalinguistic Moment,\"\ncharacterized by the emergence of self-reflective capabilities like\nChain-of-Thought prompting and Constitutional AI. The subsequent stages, the\n\"Mathematical Symbolism Moment\" and the \"Formal Logic System Moment,\" will be\ndefined by the development of a computable calculus of thought, likely through\nneuro-symbolic architectures and program synthesis, culminating in provably\naligned and reliable AI that reconstructs its own foundational representations.\nThis work serves as the methodological capstone to our trilogy, which\npreviously explored the economic drivers (\"why\") and cognitive nature (\"what\")\nof AI. Here, we address the \"how,\" providing a theoretical foundation for\nfuture research and offering concrete, actionable strategies for startups and\ndevelopers aiming to build the next generation of intelligent systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e94\u9636\u6bb5\u8fdb\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u7406\u89e3\u4eba\u5de5\u667a\u80fd\u7684\u53d1\u5c55\uff0c\u8ba4\u4e3a\u5176\u8f68\u8ff9\u4e0e\u4eba\u7c7b\u8ba4\u77e5\u6280\u672f\u7684\u5386\u53f2\u8fdb\u5c55\u76f8\u4f3c\u3002", "motivation": "\u901a\u8fc7\u7c7b\u6bd4\u4eba\u7c7b\u8ba4\u77e5\u6280\u672f\u7684\u53d1\u5c55\uff0c\u4e3aAI\u7684\u8fc7\u53bb\u548c\u672a\u6765\u63d0\u4f9b\u4e00\u4e2a\u7cfb\u7edf\u7684\u3001\u8de8\u5b66\u79d1\u7684\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u201c\u8ba4\u77e5\u51e0\u4f55\u201d\u6846\u67b6\uff0c\u5c06AI\u53d1\u5c55\u5206\u4e3a\u4e94\u4e2a\u9636\u6bb5\uff0c\u6bcf\u4e2a\u9636\u6bb5\u4ee5\u8868\u793a\u548c\u63a8\u7406\u80fd\u529b\u7684\u9769\u547d\u6027\u53d8\u5316\u4e3a\u6807\u5fd7\u3002", "result": "\u5c55\u793a\u4e86AI\u53d1\u5c55\u7684\u975e\u7ebf\u6027\u53cd\u9988\u5faa\u73af\uff0c\u5e76\u9884\u6d4b\u4e86\u672a\u6765\u7684\u201c\u5143\u8bed\u8a00\u65f6\u523b\u201d\u548c\u201c\u6570\u5b66\u7b26\u53f7\u65f6\u523b\u201d\u3002", "conclusion": "\u4e3a\u672a\u6765AI\u7814\u7a76\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u5e76\u4e3a\u5f00\u53d1\u4e0b\u4e00\u4ee3\u667a\u80fd\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5177\u4f53\u7b56\u7565\u3002"}}
{"id": "2506.23107", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23107", "abs": "https://arxiv.org/abs/2506.23107", "authors": ["Bing Song", "Jianing Liu", "Sisi Jian", "Chenyang Wu", "Vinayak Dixit"], "title": "Can Large Language Models Capture Human Risk Preferences? A Cross-Cultural Study", "comment": "20 pages, 1 figure", "summary": "Large language models (LLMs) have made significant strides, extending their\napplications to dialogue systems, automated content creation, and\ndomain-specific advisory tasks. However, as their use grows, concerns have\nemerged regarding their reliability in simulating complex decision-making\nbehavior, such as risky decision-making, where a single choice can lead to\nmultiple outcomes. This study investigates the ability of LLMs to simulate\nrisky decision-making scenarios. We compare model-generated decisions with\nactual human responses in a series of lottery-based tasks, using transportation\nstated preference survey data from participants in Sydney, Dhaka, Hong Kong,\nand Nanjing. Demographic inputs were provided to two LLMs -- ChatGPT 4o and\nChatGPT o1-mini -- which were tasked with predicting individual choices. Risk\npreferences were analyzed using the Constant Relative Risk Aversion (CRRA)\nframework. Results show that both models exhibit more risk-averse behavior than\nhuman participants, with o1-mini aligning more closely with observed human\ndecisions. Further analysis of multilingual data from Nanjing and Hong Kong\nindicates that model predictions in Chinese deviate more from actual responses\ncompared to English, suggesting that prompt language may influence simulation\nperformance. These findings highlight both the promise and the current\nlimitations of LLMs in replicating human-like risk behavior, particularly in\nlinguistic and cultural settings.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u6a21\u62df\u98ce\u9669\u51b3\u7b56\u884c\u4e3a\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u6a21\u578b\u6bd4\u4eba\u7c7b\u66f4\u89c4\u907f\u98ce\u9669\uff0c\u4e14\u4e2d\u6587\u63d0\u793a\u4e0b\u7684\u9884\u6d4b\u504f\u5dee\u66f4\u5927\u3002", "motivation": "\u968f\u7740LLMs\u5e94\u7528\u7684\u6269\u5c55\uff0c\u5176\u6a21\u62df\u590d\u6742\u51b3\u7b56\u884c\u4e3a\uff08\u5982\u98ce\u9669\u51b3\u7b56\uff09\u7684\u53ef\u9760\u6027\u5f15\u53d1\u5173\u6ce8\uff0c\u9700\u9a8c\u8bc1\u5176\u4e0e\u4eba\u7c7b\u884c\u4e3a\u7684\u5339\u914d\u5ea6\u3002", "method": "\u901a\u8fc7\u5f69\u7968\u4efb\u52a1\u6bd4\u8f83ChatGPT 4o\u548co1-mini\u7684\u9884\u6d4b\u4e0e\u4eba\u7c7b\u5b9e\u9645\u9009\u62e9\uff0c\u4f7f\u7528CRRA\u6846\u67b6\u5206\u6790\u98ce\u9669\u504f\u597d\uff0c\u5e76\u8003\u5bdf\u591a\u8bed\u8a00\u6570\u636e\u7684\u5f71\u54cd\u3002", "result": "\u6a21\u578b\u6bd4\u4eba\u7c7b\u66f4\u89c4\u907f\u98ce\u9669\uff0co1-mini\u66f4\u63a5\u8fd1\u4eba\u7c7b\u884c\u4e3a\uff1b\u4e2d\u6587\u63d0\u793a\u4e0b\u7684\u9884\u6d4b\u504f\u5dee\u5927\u4e8e\u82f1\u6587\u3002", "conclusion": "LLMs\u5728\u6a21\u62df\u4eba\u7c7b\u98ce\u9669\u884c\u4e3a\u65b9\u9762\u6709\u6f5c\u529b\uff0c\u4f46\u5728\u8bed\u8a00\u548c\u6587\u5316\u80cc\u666f\u4e0b\u7684\u8868\u73b0\u4ecd\u6709\u5c40\u9650\u3002"}}
{"id": "2506.23123", "categories": ["cs.AI", "cs.CY", "cs.ET"], "pdf": "https://arxiv.org/pdf/2506.23123", "abs": "https://arxiv.org/abs/2506.23123", "authors": ["Rishi Bommasani"], "title": "The Societal Impact of Foundation Models: Advancing Evidence-based AI Policy", "comment": "Stanford University PhD Dissertation of Rishi Bommasani (Department\n  of Computer Science, 2025). Also available at\n  https://purl.stanford.edu/zf669yy0336", "summary": "Artificial intelligence is humanity's most promising technology because of\nthe remarkable capabilities offered by foundation models. Yet, the same\ntechnology brings confusion and consternation: foundation models are poorly\nunderstood and they may precipitate a wide array of harms. This dissertation\nexplains how technology and society coevolve in the age of AI, organized around\nthree themes. First, the conceptual framing: the capabilities, risks, and the\nsupply chain that grounds foundation models in the broader economy. Second, the\nempirical insights that enrich the conceptual foundations: transparency created\nvia evaluations at the model level and indexes at the organization level.\nFinally, the transition from understanding to action: superior understanding of\nthe societal impact of foundation models advances evidence-based AI policy.\nView together, this dissertation makes inroads into achieving better societal\noutcomes in the age of AI by building the scientific foundations and\nresearch-policy interface required for better AI governance.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u4eba\u5de5\u667a\u80fd\u57fa\u7840\u6a21\u578b\u7684\u6280\u672f\u4e0e\u793e\u4f1a\u5171\u540c\u6f14\u5316\uff0c\u63d0\u51fa\u4e86\u6982\u5ff5\u6846\u67b6\u3001\u5b9e\u8bc1\u89c1\u89e3\u548c\u884c\u52a8\u5efa\u8bae\uff0c\u4ee5\u63a8\u52a8\u66f4\u597d\u7684AI\u6cbb\u7406\u3002", "motivation": "\u57fa\u7840\u6a21\u578b\u867d\u5177\u6f5c\u529b\uff0c\u4f46\u56e0\u5176\u4e0d\u900f\u660e\u6027\u548c\u6f5c\u5728\u5371\u5bb3\u5f15\u53d1\u793e\u4f1a\u62c5\u5fe7\uff0c\u9700\u7814\u7a76\u5982\u4f55\u5b9e\u73b0\u6280\u672f\u4e0e\u793e\u4f1a\u7684\u534f\u8c03\u53d1\u5c55\u3002", "method": "\u56f4\u7ed5\u4e09\u4e2a\u4e3b\u9898\u5c55\u5f00\uff1a\u6982\u5ff5\u6846\u67b6\uff08\u80fd\u529b\u3001\u98ce\u9669\u3001\u4f9b\u5e94\u94fe\uff09\u3001\u5b9e\u8bc1\u7814\u7a76\uff08\u6a21\u578b\u8bc4\u4f30\u4e0e\u7ec4\u7ec7\u900f\u660e\u5ea6\uff09\u3001\u884c\u52a8\u5efa\u8bae\uff08\u57fa\u4e8e\u8bc1\u636e\u7684AI\u653f\u7b56\uff09\u3002", "result": "\u901a\u8fc7\u79d1\u5b66\u57fa\u7840\u548c\u653f\u7b56\u7814\u7a76\u63a5\u53e3\uff0c\u4e3aAI\u6cbb\u7406\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u793e\u4f1a\u6210\u679c\u8def\u5f84\u3002", "conclusion": "\u8bba\u6587\u4e3aAI\u65f6\u4ee3\u7684\u793e\u4f1a\u6cbb\u7406\u5960\u5b9a\u4e86\u79d1\u5b66\u57fa\u7840\uff0c\u63a8\u52a8\u4e86\u6280\u672f\u4e0e\u793e\u4f1a\u7684\u826f\u6027\u4e92\u52a8\u3002"}}
{"id": "2506.23128", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23128", "abs": "https://arxiv.org/abs/2506.23128", "authors": ["Chi Chiu So", "Yueyue Sun", "Jun-Min Wang", "Siu Pang Yung", "Anthony Wai Keung Loh", "Chun Pong Chau"], "title": "Are Large Language Models Capable of Deep Relational Reasoning? Insights from DeepSeek-R1 and Benchmark Comparisons", "comment": "10 pages, 0 figures, accepted by 2025 IEEE international conference\n  on artificial intelligence testing (AITest)", "summary": "How far are Large Language Models (LLMs) in performing deep relational\nreasoning? In this paper, we evaluate and compare the reasoning capabilities of\nthree cutting-edge LLMs, namely, DeepSeek-R1, DeepSeek-V3 and GPT-4o, through a\nsuite of carefully designed benchmark tasks in family tree and general graph\nreasoning. Our experiments reveal that DeepSeek-R1 consistently achieves the\nhighest F1-scores across multiple tasks and problem sizes, demonstrating strong\naptitude in logical deduction and relational inference. However, all evaluated\nmodels, including DeepSeek-R1, struggle significantly as problem complexity\nincreases, largely due to token length limitations and incomplete output\nstructures. A detailed analysis of DeepSeek-R1's long Chain-of-Thought\nresponses uncovers its unique planning and verification strategies, but also\nhighlights instances of incoherent or incomplete reasoning, calling attention\nto the need for deeper scrutiny into LLMs' internal inference dynamics. We\nfurther discuss key directions for future work, including the role of\nmultimodal reasoning and the systematic examination of reasoning failures. Our\nfindings provide both empirical insights and theoretical implications for\nadvancing LLMs' reasoning abilities, particularly in tasks that demand\nstructured, multi-step logical inference. Our code repository will be publicly\navailable at https://github.com/kelvinhkcs/Deep-Relational-Reasoning.", "AI": {"tldr": "\u8bba\u6587\u8bc4\u4f30\u4e86\u4e09\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08DeepSeek-R1\u3001DeepSeek-V3\u548cGPT-4o\uff09\u5728\u6df1\u5ea6\u5173\u7cfb\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0DeepSeek-R1\u8868\u73b0\u6700\u4f73\uff0c\u4f46\u6240\u6709\u6a21\u578b\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u5747\u5b58\u5728\u5c40\u9650\u6027\u3002", "motivation": "\u7814\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6df1\u5ea6\u5173\u7cfb\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u80fd\u529b\uff0c\u4ee5\u8bc4\u4f30\u5176\u903b\u8f91\u63a8\u7406\u548c\u5173\u7cfb\u63a8\u65ad\u7684\u6f5c\u529b\u3002", "method": "\u901a\u8fc7\u8bbe\u8ba1\u5bb6\u65cf\u6811\u548c\u901a\u7528\u56fe\u63a8\u7406\u7684\u57fa\u51c6\u4efb\u52a1\uff0c\u6bd4\u8f83\u4e09\u79cd\u6a21\u578b\u7684\u6027\u80fd\uff0c\u5e76\u5206\u6790\u5176\u63a8\u7406\u7b56\u7565\u3002", "result": "DeepSeek-R1\u5728\u591a\u9879\u4efb\u52a1\u4e2d\u8868\u73b0\u6700\u4f18\uff0c\u4f46\u6240\u6709\u6a21\u578b\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u4e3b\u8981\u53d7\u9650\u4e8e\u8f93\u51fa\u7ed3\u6784\u548c\u4ee4\u724c\u957f\u5ea6\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6df1\u5ea6\u63a8\u7406\u4e2d\u7684\u6f5c\u529b\u4e0e\u5c40\u9650\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u5982\u591a\u6a21\u6001\u63a8\u7406\u548c\u7cfb\u7edf\u6027\u9519\u8bef\u5206\u6790\u3002"}}
{"id": "2506.23141", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23141", "abs": "https://arxiv.org/abs/2506.23141", "authors": ["Siyuan Li", "Ruitong Liu", "Yan Wen", "Te Sun"], "title": "Context-Driven Knowledge Graph Completion with Semantic-Aware Relational Message Passing", "comment": null, "summary": "Semantic context surrounding a triplet $(h, r, t)$ is crucial for Knowledge\nGraph Completion (KGC), providing vital cues for prediction. However,\ntraditional node-based message passing mechanisms, when applied to knowledge\ngraphs, often introduce noise and suffer from information dilution or\nover-smoothing by indiscriminately aggregating information from all neighboring\nedges. To address this challenge, we propose a semantic-aware relational\nmessage passing. A core innovation of this framework is the introduction of a\n\\textbf{semantic-aware Top-K neighbor selection strategy}. Specifically, this\nstrategy first evaluates the semantic relevance between a central node and its\nincident edges within a shared latent space, selecting only the Top-K most\npertinent ones. Subsequently, information from these selected edges is\neffectively fused with the central node's own representation using a\n\\textbf{multi-head attention aggregator} to generate a semantically focused\nnode message. In this manner, our model not only leverages the structure and\nfeatures of edges within the knowledge graph but also more accurately captures\nand propagates the contextual information most relevant to the specific link\nprediction task, thereby effectively mitigating interference from irrelevant\ninformation. Extensive experiments demonstrate that our method achieves\nsuperior performance compared to existing approaches on several established\nbenchmarks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8bed\u4e49\u611f\u77e5\u7684\u5173\u7cfb\u6d88\u606f\u4f20\u9012\u6846\u67b6\uff0c\u901a\u8fc7Top-K\u90bb\u5c45\u9009\u62e9\u7b56\u7565\u548c\u591a\u5934\u6ce8\u610f\u529b\u805a\u5408\u5668\uff0c\u6709\u6548\u51cf\u5c11\u77e5\u8bc6\u56fe\u8c31\u5b8c\u6210\u4e2d\u7684\u566a\u58f0\u548c\u4fe1\u606f\u7a00\u91ca\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u8282\u70b9\u6d88\u606f\u4f20\u9012\u673a\u5236\u5728\u77e5\u8bc6\u56fe\u8c31\u4e2d\u4f1a\u5f15\u5165\u566a\u58f0\u548c\u4fe1\u606f\u7a00\u91ca\uff0c\u9700\u8981\u66f4\u7cbe\u51c6\u7684\u8bed\u4e49\u4e0a\u4e0b\u6587\u6355\u6349\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u8bed\u4e49\u611f\u77e5\u7684Top-K\u90bb\u5c45\u9009\u62e9\u7b56\u7565\u548c\u591a\u5934\u6ce8\u610f\u529b\u805a\u5408\u5668\uff0c\u9009\u62e9\u5e76\u878d\u5408\u6700\u76f8\u5173\u7684\u8fb9\u4fe1\u606f\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u66f4\u51c6\u786e\u5730\u6355\u6349\u548c\u4f20\u64ad\u4e0e\u94fe\u63a5\u9884\u6d4b\u4efb\u52a1\u76f8\u5173\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u51cf\u5c11\u65e0\u5173\u4fe1\u606f\u7684\u5e72\u6270\u3002"}}
{"id": "2506.23168", "categories": ["cs.AI", "cs.DM", "math.CO", "math.RA", "06B99", "G.2.1"], "pdf": "https://arxiv.org/pdf/2506.23168", "abs": "https://arxiv.org/abs/2506.23168", "authors": ["Mohammad Abdulla", "Tobias Hille", "Dominik D\u00fcrrschnabel", "Gerd Stumme"], "title": "Rises for Measuring Local Distributivity in Lattices", "comment": "16 pages, 2 tables, 5 figures, International Joint Conference on\n  Conceptual Knowledge Structures", "summary": "Distributivity is a well-established and extensively studied notion in\nlattice theory. In the context of data analysis, particularly within Formal\nConcept Analysis (FCA), lattices are often observed to exhibit a high degree of\ndistributivity. However, no standardized measure exists to quantify this\nproperty. In this paper, we introduce the notion of rises in (concept) lattices\nas a means to assess distributivity. Rises capture how the number of attributes\nor objects in covering concepts change within the concept lattice. We show that\na lattice is distributive if and only if no non-unit rises occur. Furthermore,\nwe relate rises to the classical notion of meet- and join distributivity. We\nobserve that concept lattices from real-world data are to a high degree\njoin-distributive, but much less meet-distributive. We additionally study how\njoin-distributivity manifests on the level of ordered sets.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u201crises\u201d\u6765\u91cf\u5316\u6982\u5ff5\u683c\u4e2d\u5206\u914d\u6027\u7684\u65b9\u6cd5\uff0c\u5e76\u8bc1\u660e\u683c\u662f\u5206\u914d\u7684\u5f53\u4e14\u4ec5\u5f53\u4e0d\u5b58\u5728\u975e\u5355\u4f4drises\u3002", "motivation": "\u5728\u5f62\u5f0f\u6982\u5ff5\u5206\u6790\u4e2d\uff0c\u683c\u7684\u9ad8\u5206\u914d\u6027\u7f3a\u4e4f\u6807\u51c6\u5316\u5ea6\u91cf\uff0c\u9700\u8981\u4e00\u79cd\u91cf\u5316\u65b9\u6cd5\u3002", "method": "\u5f15\u5165rises\u6982\u5ff5\uff0c\u5206\u6790\u8986\u76d6\u6982\u5ff5\u4e2d\u5c5e\u6027\u6216\u5bf9\u8c61\u6570\u91cf\u7684\u53d8\u5316\uff0c\u5e76\u4e0e\u7ecf\u5178\u5206\u914d\u6027\u6982\u5ff5\u5173\u8054\u3002", "result": "\u73b0\u5b9e\u6570\u636e\u7684\u6982\u5ff5\u683c\u9ad8\u5ea6\u6ee1\u8db3join-\u5206\u914d\u6027\uff0c\u4f46\u8f83\u5c11\u6ee1\u8db3meet-\u5206\u914d\u6027\u3002", "conclusion": "rises\u662f\u91cf\u5316\u5206\u914d\u6027\u7684\u6709\u6548\u5de5\u5177\uff0c\u63ed\u793a\u4e86\u73b0\u5b9e\u6570\u636e\u4e2d\u5206\u914d\u6027\u7684\u5206\u5e03\u7279\u70b9\u3002"}}
{"id": "2506.23273", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23273", "abs": "https://arxiv.org/abs/2506.23273", "authors": ["Quang Hung Nguyen", "Phuong Anh Trinh", "Phan Quoc Hung Mai", "Tuan Phong Trinh"], "title": "FinStat2SQL: A Text2SQL Pipeline for Financial Statement Analysis", "comment": null, "summary": "Despite the advancements of large language models, text2sql still faces many\nchallenges, particularly with complex and domain-specific queries. In finance,\ndatabase designs and financial reporting layouts vary widely between financial\nentities and countries, making text2sql even more challenging. We present\nFinStat2SQL, a lightweight text2sql pipeline enabling natural language queries\nover financial statements. Tailored to local standards like VAS, it combines\nlarge and small language models in a multi-agent setup for entity extraction,\nSQL generation, and self-correction. We build a domain-specific database and\nevaluate models on a synthetic QA dataset. A fine-tuned 7B model achieves\n61.33\\% accuracy with sub-4-second response times on consumer hardware,\noutperforming GPT-4o-mini. FinStat2SQL offers a scalable, cost-efficient\nsolution for financial analysis, making AI-powered querying accessible to\nVietnamese enterprises.", "AI": {"tldr": "FinStat2SQL\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684text2sql\u7ba1\u9053\uff0c\u4e13\u4e3a\u91d1\u878d\u62a5\u8868\u7684\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u8bbe\u8ba1\uff0c\u7ed3\u5408\u5927\u5c0f\u8bed\u8a00\u6a21\u578b\uff0c\u5728\u8d8a\u5357\u4f01\u4e1a\u91d1\u878d\u5206\u6790\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u91d1\u878d\u9886\u57df\u7684\u6570\u636e\u5e93\u8bbe\u8ba1\u548c\u62a5\u8868\u5e03\u5c40\u56e0\u5b9e\u4f53\u548c\u56fd\u5bb6\u800c\u5f02\uff0c\u4f7f\u5f97text2sql\u66f4\u5177\u6311\u6218\u6027\u3002", "method": "\u91c7\u7528\u591a\u4ee3\u7406\u8bbe\u7f6e\uff0c\u7ed3\u5408\u5927\u5c0f\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5b9e\u4f53\u63d0\u53d6\u3001SQL\u751f\u6210\u548c\u81ea\u6211\u6821\u6b63\uff0c\u5e76\u6784\u5efa\u7279\u5b9a\u9886\u57df\u6570\u636e\u5e93\u3002", "result": "\u5fae\u8c03\u76847B\u6a21\u578b\u5728\u6d88\u8d39\u786c\u4ef6\u4e0a\u8fbe\u523061.33%\u51c6\u786e\u7387\uff0c\u54cd\u5e94\u65f6\u95f4\u4f4e\u4e8e4\u79d2\uff0c\u4f18\u4e8eGPT-4o-mini\u3002", "conclusion": "FinStat2SQL\u4e3a\u8d8a\u5357\u4f01\u4e1a\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u3001\u7ecf\u6d4e\u9ad8\u6548\u7684\u91d1\u878d\u5206\u6790\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.23276", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.23276", "abs": "https://arxiv.org/abs/2506.23276", "authors": ["David Guzman Piedrahita", "Yongjin Yang", "Mrinmaya Sachan", "Giorgia Ramponi", "Bernhard Sch\u00f6lkopf", "Zhijing Jin"], "title": "Corrupted by Reasoning: Reasoning Language Models Become Free-Riders in Public Goods Games", "comment": null, "summary": "As large language models (LLMs) are increasingly deployed as autonomous\nagents, understanding their cooperation and social mechanisms is becoming\nincreasingly important. In particular, how LLMs balance self-interest and\ncollective well-being is a critical challenge for ensuring alignment,\nrobustness, and safe deployment. In this paper, we examine the challenge of\ncostly sanctioning in multi-agent LLM systems, where an agent must decide\nwhether to invest its own resources to incentivize cooperation or penalize\ndefection. To study this, we adapt a public goods game with institutional\nchoice from behavioral economics, allowing us to observe how different LLMs\nnavigate social dilemmas over repeated interactions. Our analysis reveals four\ndistinct behavioral patterns among models: some consistently establish and\nsustain high levels of cooperation, others fluctuate between engagement and\ndisengagement, some gradually decline in cooperative behavior over time, and\nothers rigidly follow fixed strategies regardless of outcomes. Surprisingly, we\nfind that reasoning LLMs, such as the o1 series, struggle significantly with\ncooperation, whereas some traditional LLMs consistently achieve high levels of\ncooperation. These findings suggest that the current approach to improving\nLLMs, which focuses on enhancing their reasoning capabilities, does not\nnecessarily lead to cooperation, providing valuable insights for deploying LLM\nagents in environments that require sustained collaboration. Our code is\navailable at https://github.com/davidguzmanp/SanctSim", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u5982\u4f55\u5e73\u8861\u81ea\u5229\u4e0e\u96c6\u4f53\u5229\u76ca\uff0c\u91cd\u70b9\u5173\u6ce8\u6210\u672c\u9ad8\u6602\u7684\u60e9\u7f5a\u673a\u5236\u3002", "motivation": "\u7406\u89e3LLMs\u4f5c\u4e3a\u81ea\u4e3b\u667a\u80fd\u4f53\u7684\u5408\u4f5c\u4e0e\u793e\u4f1a\u673a\u5236\uff0c\u4ee5\u786e\u4fdd\u5176\u5bf9\u9f50\u6027\u3001\u9c81\u68d2\u6027\u548c\u5b89\u5168\u90e8\u7f72\u3002", "method": "\u901a\u8fc7\u6539\u7f16\u884c\u4e3a\u7ecf\u6d4e\u5b66\u4e2d\u7684\u516c\u5171\u7269\u54c1\u6e38\u620f\uff0c\u89c2\u5bdf\u4e0d\u540cLLMs\u5728\u91cd\u590d\u4e92\u52a8\u4e2d\u7684\u884c\u4e3a\u6a21\u5f0f\u3002", "result": "\u53d1\u73b0\u56db\u79cd\u884c\u4e3a\u6a21\u5f0f\uff1a\u6301\u7eed\u9ad8\u5408\u4f5c\u3001\u6ce2\u52a8\u5408\u4f5c\u3001\u5408\u4f5c\u9010\u6e10\u4e0b\u964d\u548c\u56fa\u5b9a\u7b56\u7565\u3002\u63a8\u7406\u80fd\u529b\u5f3a\u7684LLMs\u5408\u4f5c\u8868\u73b0\u8f83\u5dee\uff0c\u4f20\u7edfLLMs\u53cd\u800c\u66f4\u7a33\u5b9a\u3002", "conclusion": "\u5f53\u524d\u63d0\u5347LLMs\u63a8\u7406\u80fd\u529b\u7684\u65b9\u6cd5\u672a\u5fc5\u4fc3\u8fdb\u5408\u4f5c\uff0c\u4e3a\u9700\u8981\u6301\u7eed\u534f\u4f5c\u7684\u73af\u5883\u63d0\u4f9b\u4e86\u91cd\u8981\u542f\u793a\u3002"}}
{"id": "2506.23306", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23306", "abs": "https://arxiv.org/abs/2506.23306", "authors": ["Qi Liu", "Can Li", "Wanjing Ma"], "title": "GATSim: Urban Mobility Simulation with Generative Agents", "comment": null, "summary": "Traditional agent-based urban mobility simulations rely on rigid rule-based\nsystems that fail to capture the complexity, adaptability, and behavioral\ndiversity characteristic of human travel decision-making. Recent advances in\nlarge language models and AI agent technology offer opportunities to create\nagents with reasoning capabilities, persistent memory, and adaptive learning\nmechanisms. We propose GATSim (Generative-Agent Transport Simulation), a novel\nframework that leverages these advances to create generative agents with rich\nbehavioral characteristics for urban mobility simulation. Unlike conventional\napproaches, GATSim agents possess diverse socioeconomic attributes, individual\nlifestyles, and evolving preferences that shape their mobility decisions\nthrough psychologically-informed memory systems, tool usage capabilities, and\nlifelong learning mechanisms. The main contributions of this study include: (1)\na comprehensive architecture combining an urban mobility foundation model with\nagent cognitive systems and transport simulation environment, (2) a fully\nfunctional prototype implementation, and (3) systematic validation\ndemonstrating that generative agents produce believable travel behaviors.\nThrough designed reflection processes, generative agents in this study can\ntransform specific travel experiences into generalized insights, enabling\nrealistic behavioral adaptation over time with specialized mechanisms for\nactivity planning and real-time reactive behaviors tailored to urban mobility\ncontexts. Experiments show that generative agents perform competitively with\nhuman annotators in mobility scenarios while naturally producing macroscopic\ntraffic evolution patterns. The code for the prototype system is shared at\nhttps://github.com/qiliuchn/gatsim.", "AI": {"tldr": "GATSim\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548cAI\u4ee3\u7406\u6280\u672f\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u57ce\u5e02\u4ea4\u901a\u6a21\u62df\u6846\u67b6\uff0c\u751f\u6210\u5177\u6709\u4e30\u5bcc\u884c\u4e3a\u7279\u5f81\u7684\u4ee3\u7406\uff0c\u80fd\u591f\u9002\u5e94\u548c\u5b66\u4e60\uff0c\u6a21\u62df\u4eba\u7c7b\u65c5\u884c\u51b3\u7b56\u7684\u590d\u6742\u6027\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u89c4\u5219\u7684\u4ea4\u901a\u6a21\u62df\u65e0\u6cd5\u6355\u6349\u4eba\u7c7b\u65c5\u884c\u51b3\u7b56\u7684\u590d\u6742\u6027\u548c\u591a\u6837\u6027\uff0c\u800c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548cAI\u4ee3\u7406\u6280\u672f\u4e3a\u6539\u8fdb\u63d0\u4f9b\u4e86\u673a\u4f1a\u3002", "method": "\u63d0\u51faGATSim\u6846\u67b6\uff0c\u7ed3\u5408\u57ce\u5e02\u4ea4\u901a\u57fa\u7840\u6a21\u578b\u3001\u4ee3\u7406\u8ba4\u77e5\u7cfb\u7edf\u548c\u4ea4\u901a\u6a21\u62df\u73af\u5883\uff0c\u751f\u6210\u5177\u6709\u591a\u6837\u5316\u5c5e\u6027\u548c\u5b66\u4e60\u80fd\u529b\u7684\u4ee3\u7406\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cGATSim\u4ee3\u7406\u80fd\u4ea7\u751f\u53ef\u4fe1\u7684\u65c5\u884c\u884c\u4e3a\uff0c\u5e76\u5728\u5b8f\u89c2\u4ea4\u901a\u6a21\u5f0f\u4e0a\u4e0e\u4eba\u7c7b\u6807\u6ce8\u8005\u8868\u73b0\u76f8\u5f53\u3002", "conclusion": "GATSim\u901a\u8fc7\u751f\u6210\u4ee3\u7406\u5b9e\u73b0\u4e86\u66f4\u771f\u5b9e\u7684\u57ce\u5e02\u4ea4\u901a\u6a21\u62df\uff0c\u5c55\u793a\u4e86AI\u6280\u672f\u5728\u4ea4\u901a\u9886\u57df\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.23464", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23464", "abs": "https://arxiv.org/abs/2506.23464", "authors": ["Sahil Tripathi", "Md Tabrez Nafis", "Imran Hussain", "Jiechao Gao"], "title": "The Confidence Paradox: Can LLM Know When It's Wrong", "comment": null, "summary": "Document Visual Question Answering (DocVQA) systems are increasingly deployed\nin real world applications, yet they remain ethically opaque-often producing\noverconfident answers to ambiguous questions or failing to communicate\nuncertainty in a trustworthy manner. This misalignment between model confidence\nand actual knowledge poses significant risks, particularly in domains requiring\nethical accountability. Existing approaches such as LayoutLMv3, UDOP, and DONUT\nhave advanced SOTA performance by focusing on architectural sophistication and\naccuracy; however, they fall short in ethical responsiveness.\n  To address these limitations, we introduce HonestVQA, a self-supervised\nhonesty calibration framework for ethically aligned DocVQA. Our model-agnostic\nmethod quantifies uncertainty to identify knowledge gaps, aligns model\nconfidence with actual correctness using weighted loss functions, and enforces\nethical response behavior via contrastive learning. We further introduce two\nprincipled evaluation metrics--Honesty Score (H-Score) and Ethical Confidence\nIndex (ECI)--to benchmark alignment between confidence, accuracy, and ethical\ncommunication. Empirically, HonestVQA improves DocVQA accuracy by up to 4.3%\nand F1 by 4.3% across SpDocVQA, InfographicsVQA, and SROIE datasets. It reduces\noverconfidence, lowering H-Score and ECI by 0.072 and 0.078, respectively. In\ncross domain evaluation, it achieves up to 78.9% accuracy and 76.1% F1-score,\ndemonstrating strong generalization. Ablation shows a 3.8% drop in accuracy\nwithout alignment or contrastive loss.", "AI": {"tldr": "HonestVQA\u662f\u4e00\u4e2a\u81ea\u76d1\u7763\u7684\u8bda\u5b9e\u6821\u51c6\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3DocVQA\u7cfb\u7edf\u4e2d\u7684\u4f26\u7406\u95ee\u9898\uff0c\u901a\u8fc7\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\u3001\u5bf9\u9f50\u6a21\u578b\u7f6e\u4fe1\u5ea6\u548c\u5b9e\u9645\u6b63\u786e\u6027\uff0c\u5e76\u5f15\u5165\u65b0\u7684\u8bc4\u4f30\u6307\u6807\u3002", "motivation": "\u73b0\u6709DocVQA\u7cfb\u7edf\u5728\u4f26\u7406\u900f\u660e\u5ea6\u4e0a\u8868\u73b0\u4e0d\u8db3\uff0c\u6a21\u578b\u7f6e\u4fe1\u5ea6\u4e0e\u5b9e\u9645\u77e5\u8bc6\u4e0d\u5339\u914d\uff0c\u5b58\u5728\u4f26\u7406\u98ce\u9669\u3002", "method": "HonestVQA\u901a\u8fc7\u81ea\u76d1\u7763\u5b66\u4e60\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\uff0c\u4f7f\u7528\u52a0\u6743\u635f\u5931\u51fd\u6570\u5bf9\u9f50\u7f6e\u4fe1\u5ea6\u548c\u6b63\u786e\u6027\uff0c\u5e76\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u5f3a\u5316\u4f26\u7406\u54cd\u5e94\u884c\u4e3a\u3002", "result": "HonestVQA\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u63d0\u5347\u4e86\u51c6\u786e\u7387\u548cF1\u503c\uff0c\u964d\u4f4e\u4e86\u8fc7\u5ea6\u81ea\u4fe1\uff0c\u8868\u73b0\u51fa\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "HonestVQA\u6709\u6548\u89e3\u51b3\u4e86DocVQA\u7cfb\u7edf\u4e2d\u7684\u4f26\u7406\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u6027\u80fd\u548c\u4f26\u7406\u5bf9\u9f50\u3002"}}
{"id": "2506.23503", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23503", "abs": "https://arxiv.org/abs/2506.23503", "authors": ["Bosubabu Sambana", "Kondreddygari Archana", "Suram Indhra Sena Reddy", "Shaik Meethaigar Jameer Basha", "Shaik Karishma"], "title": "Data Augmentation for Cognitive Behavioral Therapy: Leveraging ERNIE Language Models using Artificial Intelligence", "comment": "6 Pages, 5 Figures, IEEE IDCIoT 2025", "summary": "Cognitive Behavioral Therapy (CBT) is a proven approach for addressing the\nirrational thought patterns associated with mental health disorders, but its\neffectiveness relies on accurately identifying cognitive pathways to provide\ntargeted treatment. In today's digital age, individuals often express negative\nemotions on social media, where they may reveal cognitive distortions, and in\nsevere cases, exhibit suicidal tendencies. However, there is a significant gap\nin methodologies designed to analyze these cognitive pathways, which could be\ncritical for psychotherapists aiming to deliver timely and effective\ninterventions in online environments. Cognitive Behavioral Therapy (CBT)\nframework leveraging acceptance, commitment and data augmentation to categorize\nand address both textual and visual content as positive or negative.\nSpecifically, the system employs BERT, RoBERTa for Sentiment Analysis and T5,\nPEGASUS for Text Summarization, mT5 for Text Translation in Multiple Languages\nfocusing on detecting negative emotions and cognitive distortions within social\nmedia data. While existing models are primarily designed to identify negative\nthoughts, the proposed system goes beyond this by predicting additional\nnegative side effects and other potential mental health disorders likes\nPhobias, Eating Disorders. This enhancement allows for a more comprehensive\nunderstanding and intervention strategy, offering psychotherapists a powerful\ntool for early detection and treatment of various psychological issues.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eCBT\u6846\u67b6\u7684\u7cfb\u7edf\uff0c\u5229\u7528BERT\u3001RoBERTa\u7b49\u6a21\u578b\u5206\u6790\u793e\u4ea4\u5a92\u4f53\u6570\u636e\u4e2d\u7684\u8d1f\u9762\u60c5\u7eea\u548c\u8ba4\u77e5\u626d\u66f2\uff0c\u5e76\u9884\u6d4b\u6f5c\u5728\u5fc3\u7406\u5065\u5eb7\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u6709\u6548\u65b9\u6cd5\u5206\u6790\u793e\u4ea4\u5a92\u4f53\u4e2d\u7684\u8ba4\u77e5\u8def\u5f84\uff0c\u8fd9\u5bf9\u5fc3\u7406\u6cbb\u7597\u5e08\u63d0\u4f9b\u53ca\u65f6\u5e72\u9884\u81f3\u5173\u91cd\u8981\u3002", "method": "\u7ed3\u5408CBT\u6846\u67b6\uff0c\u4f7f\u7528BERT\u3001RoBERTa\u8fdb\u884c\u60c5\u611f\u5206\u6790\uff0cT5\u3001PEGASUS\u8fdb\u884c\u6587\u672c\u6458\u8981\uff0cmT5\u8fdb\u884c\u591a\u8bed\u8a00\u7ffb\u8bd1\uff0c\u4ee5\u8bc6\u522b\u8d1f\u9762\u60c5\u7eea\u548c\u8ba4\u77e5\u626d\u66f2\u3002", "result": "\u7cfb\u7edf\u4e0d\u4ec5\u80fd\u8bc6\u522b\u8d1f\u9762\u601d\u7ef4\uff0c\u8fd8\u80fd\u9884\u6d4b\u6f5c\u5728\u5fc3\u7406\u5065\u5eb7\u95ee\u9898\uff08\u5982\u6050\u60e7\u75c7\u3001\u996e\u98df\u969c\u788d\uff09\uff0c\u63d0\u4f9b\u66f4\u5168\u9762\u7684\u5e72\u9884\u7b56\u7565\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u4e3a\u5fc3\u7406\u6cbb\u7597\u5e08\u63d0\u4f9b\u4e86\u65e9\u671f\u68c0\u6d4b\u548c\u6cbb\u7597\u5fc3\u7406\u95ee\u9898\u7684\u5f3a\u5927\u5de5\u5177\u3002"}}
{"id": "2506.23504", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23504", "abs": "https://arxiv.org/abs/2506.23504", "authors": ["Bosubabu Sambana", "Kotamsetty Geethika Devi", "Bandi Rajeswara Reddy", "Galeti Mohammad Hussain", "Gownivalla Siddartha"], "title": "Hybrid Approach for Electricity Price Forecasting using AlexNet and LSTM", "comment": "6 Pages, 7 Figures", "summary": "The recent development of advanced machine learning methods for hybrid models\nhas greatly addressed the need for the correct prediction of electrical prices.\nThis method combines AlexNet and LSTM algorithms, which are used to introduce a\nnew model with higher accuracy in price forecasting. Despite RNN and ANN being\neffective, they often fail to deal with forex time sequence data. The\ntraditional methods do not accurately forecast the prices. These traditional\nmethods only focus on demand and price which leads to insufficient analysis of\ndata. To address this issue, using the hybrid approach, which focuses on\nexternal variables that also effect the predicted prices. Nevertheless, due to\nAlexNet's excellent feature extraction and LSTM's learning sequential patterns,\nthe prediction accuracy is vastly increased. The model is built on the past\ndata, which has been supplied with the most significant elements like demand,\ntemperature, sunlight, and rain. For example, the model applies methods, such\nas minimum-maximum scaling and a time window, to predict the electricity prices\nof the future. The results show that this hybrid model is good than the\nstandalone ones in terms of accuracy. Although we got our accuracy rating of\n97.08, it shows higher accompaniments than remaining models RNN and ANN with\naccuracies of 96.64 and 96.63 respectively.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408AlexNet\u548cLSTM\u7684\u6df7\u5408\u6a21\u578b\uff0c\u7528\u4e8e\u63d0\u9ad8\u7535\u529b\u4ef7\u683c\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\uff08\u5982RNN\u548cANN\uff09\u5728\u5904\u7406\u5916\u6c47\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u65f6\u6548\u679c\u4e0d\u4f73\uff0c\u4e14\u4ec5\u5173\u6ce8\u9700\u6c42\u548c\u4ef7\u683c\uff0c\u5bfc\u81f4\u5206\u6790\u4e0d\u8db3\u3002", "method": "\u91c7\u7528AlexNet\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u7ed3\u5408LSTM\u5b66\u4e60\u5e8f\u5217\u6a21\u5f0f\uff0c\u5e76\u5f15\u5165\u5916\u90e8\u53d8\u91cf\uff08\u5982\u9700\u6c42\u3001\u6e29\u5ea6\u3001\u9633\u5149\u548c\u964d\u96e8\uff09\u8fdb\u884c\u9884\u6d4b\u3002", "result": "\u6df7\u5408\u6a21\u578b\u7684\u9884\u6d4b\u51c6\u786e\u7387\u8fbe\u523097.08%\uff0c\u4f18\u4e8e\u5355\u72ec\u7684RNN\uff0896.64%\uff09\u548cANN\uff0896.63%\uff09\u6a21\u578b\u3002", "conclusion": "\u8be5\u6df7\u5408\u6a21\u578b\u663e\u8457\u63d0\u5347\u4e86\u7535\u529b\u4ef7\u683c\u9884\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002"}}
{"id": "2506.23517", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.23517", "abs": "https://arxiv.org/abs/2506.23517", "authors": ["Selin Dik", "Osman Erdem", "Mehmet Dik"], "title": "Assessing GPTZero's Accuracy in Identifying AI vs. Human-Written Essays", "comment": null, "summary": "As the use of AI tools by students has become more prevalent, instructors\nhave started using AI detection tools like GPTZero and QuillBot to detect AI\nwritten text. However, the reliability of these detectors remains uncertain. In\nour study, we focused mostly on the success rate of GPTZero, the most-used AI\ndetector, in identifying AI-generated texts based on different lengths of\nrandomly submitted essays: short (40-100 word count), medium (100-350 word\ncount), and long (350-800 word count). We gathered a data set consisting of\ntwenty-eight AI-generated papers and fifty human-written papers. With this\nrandomized essay data, papers were individually plugged into GPTZero and\nmeasured for percentage of AI generation and confidence. A vast majority of the\nAI-generated papers were detected accurately (ranging from 91-100% AI believed\ngeneration), while the human generated essays fluctuated; there were a handful\nof false positives. These findings suggest that although GPTZero is effective\nat detecting purely AI-generated content, its reliability in distinguishing\nhuman-authored texts is limited. Educators should therefore exercise caution\nwhen relying solely on AI detection tools.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u4e86GPTZero\u68c0\u6d4bAI\u751f\u6210\u6587\u672c\u7684\u53ef\u9760\u6027\uff0c\u53d1\u73b0\u5176\u5bf9AI\u6587\u672c\u68c0\u6d4b\u51c6\u786e\u7387\u9ad8\uff0c\u4f46\u5bf9\u4eba\u7c7b\u6587\u672c\u5b58\u5728\u8bef\u5224\u3002", "motivation": "\u968f\u7740\u5b66\u751f\u4f7f\u7528AI\u5de5\u5177\u589e\u591a\uff0c\u6559\u5e08\u4f9d\u8d56AI\u68c0\u6d4b\u5de5\u5177\uff08\u5982GPTZero\uff09\u68c0\u6d4bAI\u751f\u6210\u6587\u672c\uff0c\u4f46\u5176\u53ef\u9760\u6027\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u7814\u7a76\u4f7f\u7528\u4e0d\u540c\u957f\u5ea6\u7684\u968f\u673a\u63d0\u4ea4\u8bba\u6587\uff08\u77ed\u3001\u4e2d\u3001\u957f\uff09\uff0c\u901a\u8fc7GPTZero\u68c0\u6d4bAI\u751f\u6210\u6bd4\u4f8b\u548c\u7f6e\u4fe1\u5ea6\u3002\u6570\u636e\u96c6\u5305\u62ec28\u7bc7AI\u751f\u6210\u548c50\u7bc7\u4eba\u7c7b\u64b0\u5199\u8bba\u6587\u3002", "result": "AI\u751f\u6210\u6587\u672c\u68c0\u6d4b\u51c6\u786e\u7387\u9ad8\uff0891-100%\uff09\uff0c\u4f46\u4eba\u7c7b\u6587\u672c\u5b58\u5728\u8bef\u5224\u3002", "conclusion": "GPTZero\u5bf9\u7eafAI\u6587\u672c\u68c0\u6d4b\u6709\u6548\uff0c\u4f46\u5bf9\u4eba\u7c7b\u6587\u672c\u533a\u5206\u80fd\u529b\u6709\u9650\uff0c\u6559\u5e08\u9700\u8c28\u614e\u4f7f\u7528\u3002"}}
{"id": "2506.23520", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23520", "abs": "https://arxiv.org/abs/2506.23520", "authors": ["Yu Zhang", "Ruijie Yu", "Jidong Tian", "Feng Zhu", "Jiapeng Liu", "Xiaokang Yang", "Yaohui Jin", "Yanyan Xu"], "title": "ChemActor: Enhancing Automated Extraction of Chemical Synthesis Actions with LLM-Generated Data", "comment": null, "summary": "With the increasing interest in robotic synthesis in the context of organic\nchemistry, the automated extraction of chemical procedures from literature is\ncritical. However, this task remains challenging due to the inherent ambiguity\nof chemical language and the high cost of human annotation required for\ndeveloping reliable computer-aided extraction protocols. Here, we present\nChemActor, a fully fine-tuned large language model (LLM), as a chemical\nexecutor to convert between unstructured experimental procedures and structured\naction sequences. We propose a sequential LLM-generated data framework to\naddress the challenges of insufficient and low-quality annotated data. This\nframework integrates a data selection module that selects data based on\ndistribution divergence, with a general-purpose LLM, to generate\nmachine-executable actions from a single molecule input. Additionally, we\nintroduce a novel multi-round LLMs circle review metric, which reflects the\nmodel's advanced understanding of chemical experimental procedures. Extensive\nexperiments on reaction-to-description (R2D) and description-to-action (D2A)\ntasks demonstrate that ChemActor, augmented by LLM-generated data, achieves\nstate-of-the-art performance, outperforming the baseline model by 10%. The code\nis available at: https://github.com/Zhanghahah/ChemActor.", "AI": {"tldr": "ChemActor\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u5316\u5b66\u6267\u884c\u5668\uff0c\u7528\u4e8e\u5c06\u975e\u7ed3\u6784\u5316\u7684\u5316\u5b66\u5b9e\u9a8c\u6b65\u9aa4\u8f6c\u6362\u4e3a\u7ed3\u6784\u5316\u7684\u52a8\u4f5c\u5e8f\u5217\uff0c\u5e76\u901a\u8fc7LLM\u751f\u6210\u7684\u6570\u636e\u6846\u67b6\u89e3\u51b3\u6807\u6ce8\u6570\u636e\u4e0d\u8db3\u548c\u8d28\u91cf\u4f4e\u7684\u95ee\u9898\u3002", "motivation": "\u968f\u7740\u673a\u5668\u4eba\u5408\u6210\u5728\u6709\u673a\u5316\u5b66\u4e2d\u7684\u5174\u8da3\u589e\u52a0\uff0c\u4ece\u6587\u732e\u4e2d\u81ea\u52a8\u63d0\u53d6\u5316\u5b66\u6b65\u9aa4\u53d8\u5f97\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u7531\u4e8e\u5316\u5b66\u8bed\u8a00\u7684\u6a21\u7cca\u6027\u548c\u4eba\u5de5\u6807\u6ce8\u7684\u9ad8\u6210\u672c\uff0c\u8fd9\u4e00\u4efb\u52a1\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u63d0\u51faChemActor\uff0c\u4e00\u4e2a\u5b8c\u5168\u5fae\u8c03\u7684LLM\uff0c\u7ed3\u5408\u6570\u636e\u9009\u62e9\u6a21\u5757\u548c\u591a\u8f6eLLM\u5faa\u73af\u8bc4\u4f30\u6307\u6807\uff0c\u4ece\u5355\u5206\u5b50\u8f93\u5165\u751f\u6210\u673a\u5668\u53ef\u6267\u884c\u7684\u52a8\u4f5c\u3002", "result": "\u5728\u53cd\u5e94\u5230\u63cf\u8ff0\uff08R2D\uff09\u548c\u63cf\u8ff0\u5230\u52a8\u4f5c\uff08D2A\uff09\u4efb\u52a1\u4e2d\uff0cChemActor\u8868\u73b0\u51fa\u8272\uff0c\u6bd4\u57fa\u7ebf\u6a21\u578b\u6027\u80fd\u63d0\u534710%\u3002", "conclusion": "ChemActor\u901a\u8fc7LLM\u751f\u6210\u7684\u6570\u636e\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5316\u5b66\u5b9e\u9a8c\u6b65\u9aa4\u7684\u81ea\u52a8\u5316\u63d0\u53d6\u6027\u80fd\uff0c\u4e3a\u5316\u5b66\u5408\u6210\u81ea\u52a8\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2506.23549", "categories": ["cs.AI", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.23549", "abs": "https://arxiv.org/abs/2506.23549", "authors": ["Huai-Chih Wang", "Hsiang-Chun Chuang", "Hsi-Chun Cheng", "Dai-Jie Wu", "Shao-Hua Sun"], "title": "CooT: Learning to Coordinate In-Context with Coordination Transformers", "comment": "23 pages, 10 tables, 8 figures", "summary": "Effective coordination among artificial agents in dynamic and uncertain\nenvironments remains a significant challenge in multi-agent systems. Existing\napproaches, such as self-play and population-based methods, either generalize\npoorly to unseen partners or require extensive training. To overcome these\nlimitations, we propose Coordination Transformers (CooT), a novel in-context\ncoordination framework that uses recent interaction histories to adapt to\nunseen partners rapidly. Unlike previous approaches that primarily aim to\nincrease the diversity of training partners, CooT explicitly focuses on\nadapting to new partner behaviors by predicting actions aligned with observed\npartner interactions. Trained on interaction trajectories collected from\ndiverse pairs of agents with complementary behaviors, CooT quickly learns\neffective coordination strategies without explicit supervision or fine-tuning.\nEvaluations on the Overcooked benchmark demonstrate that CooT significantly\noutperforms baseline methods in coordination tasks involving previously unseen\npartners. Human evaluations further confirm CooT as the most effective\ncollaborative partner, while extensive ablations highlight its robustness,\nflexibility, and sensitivity to context in multi-agent scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCoordination Transformers\uff08CooT\uff09\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u5229\u7528\u4ea4\u4e92\u5386\u53f2\u5feb\u901f\u9002\u5e94\u672a\u89c1\u8fc7\u7684\u5408\u4f5c\u4f19\u4f34\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u534f\u8c03\u80fd\u529b\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\uff08\u5982\u81ea\u535a\u5f08\u548c\u57fa\u4e8e\u79cd\u7fa4\u7684\u65b9\u6cd5\uff09\u5728\u52a8\u6001\u548c\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\u534f\u8c03\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u8981\u4e48\u6cdb\u5316\u80fd\u529b\u5dee\uff0c\u8981\u4e48\u9700\u8981\u5927\u91cf\u8bad\u7ec3\u3002", "method": "\u63d0\u51fa\u4e86CooT\u6846\u67b6\uff0c\u901a\u8fc7\u9884\u6d4b\u4e0e\u89c2\u5bdf\u5230\u7684\u5408\u4f5c\u4f19\u4f34\u884c\u4e3a\u4e00\u81f4\u7684\u52a8\u4f5c\uff0c\u5feb\u901f\u9002\u5e94\u65b0\u4f19\u4f34\u884c\u4e3a\uff0c\u65e0\u9700\u663e\u5f0f\u76d1\u7763\u6216\u5fae\u8c03\u3002", "result": "\u5728Overcooked\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCooT\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4eba\u7c7b\u8bc4\u4f30\u4e5f\u8bc1\u5b9e\u5176\u662f\u6700\u6709\u6548\u7684\u534f\u4f5c\u4f19\u4f34\u3002", "conclusion": "CooT\u5728\u591a\u667a\u80fd\u4f53\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u9c81\u68d2\u6027\u3001\u7075\u6d3b\u6027\u548c\u5bf9\u4e0a\u4e0b\u6587\u7684\u654f\u611f\u6027\uff0c\u662f\u4e00\u79cd\u9ad8\u6548\u7684\u534f\u8c03\u65b9\u6cd5\u3002"}}
{"id": "2506.23563", "categories": ["cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.23563", "abs": "https://arxiv.org/abs/2506.23563", "authors": ["Huanjin Yao", "Jiaxing Huang", "Yawen Qiu", "Michael K. Chen", "Wenzheng Liu", "Wei Zhang", "Wenjie Zeng", "Xikun Zhang", "Jingyi Zhang", "Yuxin Song", "Wenhao Wu", "Dacheng Tao"], "title": "MMReason: An Open-Ended Multi-Modal Multi-Step Reasoning Benchmark for MLLMs Toward AGI", "comment": "Technical report", "summary": "Reasoning plays a crucial role in advancing Multimodal Large Language Models\n(MLLMs) toward Artificial General Intelligence. However, existing MLLM\nbenchmarks often fall short in precisely and comprehensively evaluating\nlong-chain reasoning abilities from three key aspects: (1) lack of difficulty\nand diversity, (2) susceptibility to guessability and memorization, (3)\ninadequate assessment of intermediate reasoning steps. To fill this gap, we\nintroduce MMReason, a new benchmark designed to precisely and comprehensively\nevaluate MLLM long-chain reasoning capability with diverse, open-ended,\nchallenging questions. First, we curate challenging questions requiring\nmulti-step reasoning from various fields (i.e., 6 disciplines) and multiple\ndifficulty levels (i.e., from pre-university to university, and from\nfoundational to competition tiers). Second, these questions are reformulated\ninto an open-ended format and filtered using a multi-model voting technique to\neliminate shortcut cases related to guessing and memorization, ensuring robust\nreasoning evaluations. Third, we annotate the questions with detailed\nstep-by-step solutions, and design a reference-based ternary scoring mechanism\nto reliably assess intermediate reasoning steps. With MMReason, we benchmark\npopular leading MLLMs and provide an in-depth analysis of their reasoning\ncapabilities. We hope MMReason will serve as a valuable resource for advancing\nMLLM reasoning research. Code will be available at\nhttps://github.com/HJYao00/MMReason.", "AI": {"tldr": "MMReason\u662f\u4e00\u4e2a\u65b0\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u65e8\u5728\u5168\u9762\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u957f\u94fe\u63a8\u7406\u80fd\u529b\uff0c\u901a\u8fc7\u591a\u6837\u3001\u5f00\u653e\u548c\u5177\u6709\u6311\u6218\u6027\u7684\u95ee\u9898\u586b\u8865\u73b0\u6709\u57fa\u51c6\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u5728\u8bc4\u4f30\u957f\u94fe\u63a8\u7406\u80fd\u529b\u65f6\u5b58\u5728\u4e0d\u8db3\uff0c\u5305\u62ec\u7f3a\u4e4f\u96be\u5ea6\u548c\u591a\u6837\u6027\u3001\u6613\u53d7\u731c\u6d4b\u548c\u8bb0\u5fc6\u5f71\u54cd\uff0c\u4ee5\u53ca\u5bf9\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\u8bc4\u4f30\u4e0d\u8db3\u3002", "method": "MMReason\u901a\u8fc7\u4ece\u591a\u4e2a\u5b66\u79d1\u548c\u96be\u5ea6\u7ea7\u522b\u7b5b\u9009\u95ee\u9898\uff0c\u91c7\u7528\u5f00\u653e\u683c\u5f0f\u548c\u591a\u6a21\u578b\u6295\u7968\u6280\u672f\u6d88\u9664\u6377\u5f84\uff0c\u5e76\u8bbe\u8ba1\u57fa\u4e8e\u53c2\u8003\u7684\u4e09\u5143\u8bc4\u5206\u673a\u5236\u8bc4\u4f30\u63a8\u7406\u6b65\u9aa4\u3002", "result": "MMReason\u5bf9\u4e3b\u6d41\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u6df1\u5165\u5206\u6790\u4e86\u5b83\u4eec\u7684\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "MMReason\u6709\u671b\u6210\u4e3a\u63a8\u52a8\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u7814\u7a76\u7684\u91cd\u8981\u8d44\u6e90\u3002"}}
{"id": "2506.23576", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23576", "abs": "https://arxiv.org/abs/2506.23576", "authors": ["Maria Carolina Cornelia Wit", "Jun Pang"], "title": "Evaluating Multi-Agent Defences Against Jailbreaking Attacks on Large Language Models", "comment": "26 pages, 1 figure", "summary": "Recent advances in large language models (LLMs) have raised concerns about\njailbreaking attacks, i.e., prompts that bypass safety mechanisms. This paper\ninvestigates the use of multi-agent LLM systems as a defence against such\nattacks. We evaluate three jailbreaking strategies, including the original\nAutoDefense attack and two from Deepleaps: BetterDan and JB. Reproducing the\nAutoDefense framework, we compare single-agent setups with two- and three-agent\nconfigurations. Our results show that multi-agent systems enhance resistance to\njailbreaks, especially by reducing false negatives. However, its effectiveness\nvaries by attack type, and it introduces trade-offs such as increased false\npositives and computational overhead. These findings point to the limitations\nof current automated defences and suggest directions for improving alignment\nrobustness in future LLM systems.", "AI": {"tldr": "\u591a\u667a\u80fd\u4f53LLM\u7cfb\u7edf\u53ef\u589e\u5f3a\u5bf9\u8d8a\u72f1\u653b\u51fb\u7684\u9632\u5fa1\u80fd\u529b\uff0c\u4f46\u5b58\u5728\u8bef\u62a5\u548c\u8ba1\u7b97\u5f00\u9500\u7684\u6743\u8861\u3002", "motivation": "\u7814\u7a76\u591a\u667a\u80fd\u4f53LLM\u7cfb\u7edf\u4f5c\u4e3a\u9632\u5fa1\u8d8a\u72f1\u653b\u51fb\u7684\u6709\u6548\u6027\u3002", "method": "\u8bc4\u4f30\u4e09\u79cd\u8d8a\u72f1\u7b56\u7565\uff0c\u6bd4\u8f83\u5355\u667a\u80fd\u4f53\u4e0e\u591a\u667a\u80fd\u4f53\u914d\u7f6e\u7684\u6027\u80fd\u3002", "result": "\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u51cf\u5c11\u6f0f\u62a5\uff0c\u4f46\u6548\u679c\u56e0\u653b\u51fb\u7c7b\u578b\u800c\u5f02\uff0c\u4e14\u589e\u52a0\u8bef\u62a5\u548c\u8ba1\u7b97\u5f00\u9500\u3002", "conclusion": "\u5f53\u524d\u81ea\u52a8\u9632\u5fa1\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u6539\u8fdb\u672a\u6765LLM\u7cfb\u7edf\u7684\u5bf9\u9f50\u9c81\u68d2\u6027\u3002"}}
{"id": "2506.23626", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23626", "abs": "https://arxiv.org/abs/2506.23626", "authors": ["Ant\u00f3nio Afonso", "Iolanda Leite", "Alessandro Sestini", "Florian Fuchs", "Konrad Tollmar", "Linus Gissl\u00e9n"], "title": "Self-correcting Reward Shaping via Language Models for Reinforcement Learning Agents in Games", "comment": "16 pages in total, 10 pages of main paper, 5 figures", "summary": "Reinforcement Learning (RL) in games has gained significant momentum in\nrecent years, enabling the creation of different agent behaviors that can\ntransform a player's gaming experience. However, deploying RL agents in\nproduction environments presents two key challenges: (1) designing an effective\nreward function typically requires an RL expert, and (2) when a game's content\nor mechanics are modified, previously tuned reward weights may no longer be\noptimal. Towards the latter challenge, we propose an automated approach for\niteratively fine-tuning an RL agent's reward function weights, based on a\nuser-defined language based behavioral goal. A Language Model (LM) proposes\nupdated weights at each iteration based on this target behavior and a summary\nof performance statistics from prior training rounds. This closed-loop process\nallows the LM to self-correct and refine its output over time, producing\nincreasingly aligned behavior without the need for manual reward engineering.\nWe evaluate our approach in a racing task and show that it consistently\nimproves agent performance across iterations. The LM-guided agents show a\nsignificant increase in performance from $9\\%$ to $74\\%$ success rate in just\none iteration. We compare our LM-guided tuning against a human expert's manual\nweight design in the racing task: by the final iteration, the LM-tuned agent\nachieved an $80\\%$ success rate, and completed laps in an average of $855$ time\nsteps, a competitive performance against the expert-tuned agent's peak $94\\%$\nsuccess, and $850$ time steps.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u8fed\u4ee3\u4f18\u5316\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u7684\u5956\u52b1\u51fd\u6570\u6743\u91cd\uff0c\u89e3\u51b3\u4e86\u6e38\u620f\u5185\u5bb9\u6216\u673a\u5236\u4fee\u6539\u65f6\u5956\u52b1\u6743\u91cd\u4e0d\u518d\u6700\u4f18\u7684\u95ee\u9898\u3002", "motivation": "\u5728\u6e38\u620f\u4e2d\u90e8\u7f72\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u65f6\uff0c\u8bbe\u8ba1\u6709\u6548\u7684\u5956\u52b1\u51fd\u6570\u901a\u5e38\u9700\u8981\u4e13\u5bb6\uff0c\u4e14\u6e38\u620f\u5185\u5bb9\u6216\u673a\u5236\u4fee\u6539\u540e\uff0c\u539f\u6709\u5956\u52b1\u6743\u91cd\u53ef\u80fd\u5931\u6548\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u8bed\u8a00\u6a21\u578b\u6839\u636e\u7528\u6237\u5b9a\u4e49\u7684\u884c\u4e3a\u76ee\u6807\u548c\u5148\u524d\u8bad\u7ec3\u8f6e\u6b21\u7684\u6027\u80fd\u7edf\u8ba1\uff0c\u8fed\u4ee3\u63d0\u51fa\u66f4\u65b0\u7684\u5956\u52b1\u51fd\u6570\u6743\u91cd\uff0c\u5f62\u6210\u95ed\u73af\u4f18\u5316\u8fc7\u7a0b\u3002", "result": "\u5728\u8d5b\u8f66\u4efb\u52a1\u4e2d\uff0c\u8bed\u8a00\u6a21\u578b\u5f15\u5bfc\u7684\u4ee3\u7406\u6027\u80fd\u4ece9%\u63d0\u5347\u523074%\u7684\u6210\u529f\u7387\uff0c\u6700\u7ec8\u8fbe\u523080%\u7684\u6210\u529f\u7387\u548c855\u65f6\u95f4\u6b65\uff0c\u63a5\u8fd1\u4e13\u5bb6\u8c03\u4f18\u768494%\u548c850\u65f6\u95f4\u6b65\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u65e0\u9700\u624b\u52a8\u8bbe\u8ba1\u5956\u52b1\u51fd\u6570\uff0c\u80fd\u81ea\u52a8\u4f18\u5316\u4ee3\u7406\u884c\u4e3a\uff0c\u6027\u80fd\u63a5\u8fd1\u4e13\u5bb6\u8c03\u4f18\u7ed3\u679c\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2506.23673", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23673", "abs": "https://arxiv.org/abs/2506.23673", "authors": ["Jingsong Liu", "Han Li", "Chen Yang", "Michael Deutges", "Ario Sadafi", "Xin You", "Katharina Breininger", "Nassir Navab", "Peter J. Sch\u00fcffler"], "title": "HASD: Hierarchical Adaption for pathology Slide-level Domain-shift", "comment": null, "summary": "Domain shift is a critical problem for pathology AI as pathology data is\nheavily influenced by center-specific conditions. Current pathology domain\nadaptation methods focus on image patches rather than WSI, thus failing to\ncapture global WSI features required in typical clinical scenarios. In this\nwork, we address the challenges of slide-level domain shift by proposing a\nHierarchical Adaptation framework for Slide-level Domain-shift (HASD). HASD\nachieves multi-scale feature consistency and computationally efficient\nslide-level domain adaptation through two key components: (1) a hierarchical\nadaptation framework that integrates a Domain-level Alignment Solver for\nfeature alignment, a Slide-level Geometric Invariance Regularization to\npreserve the morphological structure, and a Patch-level Attention Consistency\nRegularization to maintain local critical diagnostic cues; and (2) a prototype\nselection mechanism that reduces computational overhead. We validate our method\non two slide-level tasks across five datasets, achieving a 4.1\\% AUROC\nimprovement in a Breast Cancer HER2 Grading cohort and a 3.9\\% C-index gain in\na UCEC survival prediction cohort. Our method provides a practical and reliable\nslide-level domain adaption solution for pathology institutions, minimizing\nboth computational and annotation costs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aHASD\u7684\u5206\u5c42\u9002\u5e94\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u75c5\u7406\u5b66AI\u4e2d\u7684\u5e7b\u706f\u7247\u7ea7\u57df\u504f\u79fb\u95ee\u9898\uff0c\u901a\u8fc7\u591a\u5c3a\u5ea6\u7279\u5f81\u4e00\u81f4\u6027\u548c\u8ba1\u7b97\u9ad8\u6548\u7684\u9002\u5e94\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u75c5\u7406\u5b66\u6570\u636e\u53d7\u4e2d\u5fc3\u7279\u5b9a\u6761\u4ef6\u5f71\u54cd\u4e25\u91cd\uff0c\u73b0\u6709\u65b9\u6cd5\u4ec5\u5173\u6ce8\u56fe\u50cf\u5757\u800c\u5ffd\u7565\u4e86\u5168\u5c40WSI\u7279\u5f81\uff0c\u65e0\u6cd5\u6ee1\u8db3\u4e34\u5e8a\u9700\u6c42\u3002", "method": "HASD\u6846\u67b6\u5305\u542b\u5206\u5c42\u9002\u5e94\u7ec4\u4ef6\uff08\u57df\u7ea7\u5bf9\u9f50\u3001\u5e7b\u706f\u7247\u7ea7\u51e0\u4f55\u4e0d\u53d8\u6027\u6b63\u5219\u5316\u548c\u5757\u7ea7\u6ce8\u610f\u529b\u4e00\u81f4\u6027\u6b63\u5219\u5316\uff09\u548c\u539f\u578b\u9009\u62e9\u673a\u5236\u3002", "result": "\u5728\u4e24\u4e2a\u5e7b\u706f\u7247\u7ea7\u4efb\u52a1\u4e2d\uff0cHASD\u5728\u4e73\u817a\u764cHER2\u5206\u7ea7\u961f\u5217\u4e2dAUROC\u63d0\u53474.1%\uff0c\u5728UCEC\u751f\u5b58\u9884\u6d4b\u961f\u5217\u4e2dC-index\u63d0\u53473.9%\u3002", "conclusion": "HASD\u4e3a\u75c5\u7406\u5b66\u673a\u6784\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u4e14\u53ef\u9760\u7684\u5e7b\u706f\u7247\u7ea7\u57df\u9002\u5e94\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u548c\u6807\u6ce8\u6210\u672c\u3002"}}
{"id": "2506.23689", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2506.23689", "abs": "https://arxiv.org/abs/2506.23689", "authors": ["Zihao Liu", "Xinhang Sui", "Yueran Song", "Siwen Wang"], "title": "Pok\u00e9AI: A Goal-Generating, Battle-Optimizing Multi-agent System for Pokemon Red", "comment": null, "summary": "We introduce Pok\\'eAI, the first text-based, multi-agent large language model\n(LLM) framework designed to autonomously play and progress through Pok\\'emon\nRed. Our system consists of three specialized agents-Planning, Execution, and\nCritique-each with its own memory bank, role, and skill set. The Planning Agent\nfunctions as the central brain, generating tasks to progress through the game.\nThese tasks are then delegated to the Execution Agent, which carries them out\nwithin the game environment. Upon task completion, the Critique Agent evaluates\nthe outcome to determine whether the objective was successfully achieved. Once\nverification is complete, control returns to the Planning Agent, forming a\nclosed-loop decision-making system.\n  As a preliminary step, we developed a battle module within the Execution\nAgent. Our results show that the battle AI achieves an average win rate of\n80.8% across 50 wild encounters, only 6% lower than the performance of an\nexperienced human player. Furthermore, we find that a model's battle\nperformance correlates strongly with its LLM Arena score on language-related\ntasks, indicating a meaningful link between linguistic ability and strategic\nreasoning. Finally, our analysis of gameplay logs reveals that each LLM\nexhibits a unique playstyle, suggesting that individual models develop distinct\nstrategic behaviors.", "AI": {"tldr": "Pok\\'eAI\u662f\u4e00\u4e2a\u57fa\u4e8e\u6587\u672c\u7684\u591a\u667a\u80fd\u4f53LLM\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u4e3b\u73a9Pok\\'emon Red\u3002\u5b83\u5305\u542b\u89c4\u5212\u3001\u6267\u884c\u548c\u8bc4\u4f30\u4e09\u4e2a\u667a\u80fd\u4f53\uff0c\u5f62\u6210\u95ed\u73af\u51b3\u7b56\u7cfb\u7edf\u3002\u521d\u6b65\u7ed3\u679c\u663e\u793a\uff0c\u6218\u6597\u6a21\u5757\u7684\u80dc\u7387\u4e3a80.8%\uff0c\u63a5\u8fd1\u4eba\u7c7b\u6c34\u5e73\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u80fd\u591f\u81ea\u4e3b\u73a9Pok\\'emon Red\u7684\u591a\u667a\u80fd\u4f53LLM\u6846\u67b6\uff0c\u63a2\u7d22\u8bed\u8a00\u80fd\u529b\u4e0e\u6218\u7565\u63a8\u7406\u7684\u5173\u8054\u3002", "method": "\u7cfb\u7edf\u7531\u4e09\u4e2a\u667a\u80fd\u4f53\uff08\u89c4\u5212\u3001\u6267\u884c\u3001\u8bc4\u4f30\uff09\u7ec4\u6210\uff0c\u5206\u522b\u8d1f\u8d23\u4efb\u52a1\u751f\u6210\u3001\u6267\u884c\u548c\u7ed3\u679c\u8bc4\u4f30\uff0c\u5f62\u6210\u95ed\u73af\u3002", "result": "\u6218\u6597\u6a21\u5757\u572850\u573a\u91ce\u751f\u5bf9\u6218\u4e2d\u5e73\u5747\u80dc\u7387\u4e3a80.8%\uff0c\u63a5\u8fd1\u4eba\u7c7b\u6c34\u5e73\uff0886.8%\uff09\u3002\u8bed\u8a00\u80fd\u529b\u4e0e\u6218\u6597\u8868\u73b0\u76f8\u5173\u3002", "conclusion": "Pok\\'eAI\u5c55\u793a\u4e86LLM\u5728\u6e38\u620f\u4e2d\u7684\u6f5c\u529b\uff0c\u667a\u80fd\u4f53\u8868\u73b0\u51fa\u72ec\u7279\u7684\u7b56\u7565\u884c\u4e3a\uff0c\u8bed\u8a00\u80fd\u529b\u4e0e\u6218\u7565\u63a8\u7406\u76f8\u5173\u3002"}}
{"id": "2506.23692", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23692", "abs": "https://arxiv.org/abs/2506.23692", "authors": ["Boyuan Zheng", "Zerui Fang", "Zhe Xu", "Rui Wang", "Yiwen Chen", "Cunshi Wang", "Mengwei Qu", "Lei Lei", "Zhen Feng", "Yan Liu", "Yuyang Li", "Mingzhou Tan", "Jiaji Wu", "Jianwei Shuai", "Jia Li", "Fangfu Ye"], "title": "Agent4S: The Transformation of Research Paradigms from the Perspective of Large Language Models", "comment": null, "summary": "While AI for Science (AI4S) serves as an analytical tool in the current\nresearch paradigm, it doesn't solve its core inefficiency. We propose \"Agent\nfor Science\" (Agent4S)-the use of LLM-driven agents to automate the entire\nresearch workflow-as the true Fifth Scientific Paradigm. This paper introduces\na five-level classification for Agent4S, outlining a clear roadmap from simple\ntask automation to fully autonomous, collaborative \"AI Scientists.\" This\nframework defines the next revolutionary step in scientific discovery.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u7528LLM\u9a71\u52a8\u7684Agent4S\u4f5c\u4e3a\u7b2c\u4e94\u79d1\u5b66\u8303\u5f0f\uff0c\u4ee5\u81ea\u52a8\u5316\u6574\u4e2a\u79d1\u7814\u6d41\u7a0b\uff0c\u89e3\u51b3\u5f53\u524dAI4S\u7684\u4f4e\u6548\u95ee\u9898\u3002", "motivation": "\u5f53\u524dAI4S\u4f5c\u4e3a\u5206\u6790\u5de5\u5177\u672a\u80fd\u89e3\u51b3\u79d1\u7814\u6838\u5fc3\u4f4e\u6548\u95ee\u9898\uff0c\u9700\u66f4\u5168\u9762\u7684\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e94\u7ea7\u5206\u7c7b\u6846\u67b6\uff0c\u4ece\u7b80\u5355\u4efb\u52a1\u81ea\u52a8\u5316\u5230\u5b8c\u5168\u81ea\u4e3b\u534f\u4f5c\u7684AI\u79d1\u5b66\u5bb6\u3002", "result": "\u5b9a\u4e49\u4e86\u79d1\u7814\u53d1\u73b0\u7684\u4e0b\u4e00\u4e2a\u9769\u547d\u6027\u6b65\u9aa4\u3002", "conclusion": "Agent4S\u662f\u771f\u6b63\u7684\u7b2c\u4e94\u79d1\u5b66\u8303\u5f0f\uff0c\u5c06\u63a8\u52a8\u79d1\u7814\u81ea\u52a8\u5316\u9769\u547d\u3002"}}
{"id": "2506.23703", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23703", "abs": "https://arxiv.org/abs/2506.23703", "authors": ["Lars Ullrich", "Walter Zimmer", "Ross Greer", "Knut Graichen", "Alois C. Knoll", "Mohan Trivedi"], "title": "A New Perspective On AI Safety Through Control Theory Methodologies", "comment": "Accepted to be published as part of the 2025 IEEE Open Journal of\n  Intelligent Transportation Systems (OJ-ITS)", "summary": "While artificial intelligence (AI) is advancing rapidly and mastering\nincreasingly complex problems with astonishing performance, the safety\nassurance of such systems is a major concern. Particularly in the context of\nsafety-critical, real-world cyber-physical systems, AI promises to achieve a\nnew level of autonomy but is hampered by a lack of safety assurance. While\ndata-driven control takes up recent developments in AI to improve control\nsystems, control theory in general could be leveraged to improve AI safety.\nTherefore, this article outlines a new perspective on AI safety based on an\ninterdisciplinary interpretation of the underlying data-generation process and\nthe respective abstraction by AI systems in a system theory-inspired and system\nanalysis-driven manner. In this context, the new perspective, also referred to\nas data control, aims to stimulate AI engineering to take advantage of existing\nsafety analysis and assurance in an interdisciplinary way to drive the paradigm\nof data control. Following a top-down approach, a generic foundation for safety\nanalysis and assurance is outlined at an abstract level that can be refined for\nspecific AI systems and applications and is prepared for future innovation.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7cfb\u7edf\u7406\u8bba\u548c\u6570\u636e\u5206\u6790\u7684\u65b0\u89c6\u89d2\uff0c\u65e8\u5728\u901a\u8fc7\u8de8\u5b66\u79d1\u65b9\u6cd5\u63d0\u5347AI\u5b89\u5168\u6027\uff0c\u79f0\u4e3a\u201c\u6570\u636e\u63a7\u5236\u201d\u3002", "motivation": "AI\u5728\u5b89\u5168\u5173\u952e\u7cfb\u7edf\u4e2d\u7f3a\u4e4f\u5b89\u5168\u4fdd\u969c\uff0c\u9700\u8981\u7ed3\u5408\u63a7\u5236\u7406\u8bba\u548cAI\u6280\u672f\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u7406\u8bba\u548c\u7cfb\u7edf\u5206\u6790\u9a71\u52a8\u7684\u65b9\u6cd5\uff0c\u63d0\u51fa\u6570\u636e\u63a7\u5236\u7684\u6982\u5ff5\uff0c\u7ed3\u5408\u73b0\u6709\u5b89\u5168\u5206\u6790\u548c\u4fdd\u969c\u6280\u672f\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u7528\u7684\u5b89\u5168\u5206\u6790\u548c\u4fdd\u969c\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u7279\u5b9aAI\u7cfb\u7edf\u548c\u672a\u6765\u521b\u65b0\u3002", "conclusion": "\u901a\u8fc7\u8de8\u5b66\u79d1\u7684\u6570\u636e\u63a7\u5236\u65b9\u6cd5\uff0c\u53ef\u4ee5\u63d0\u5347AI\u7cfb\u7edf\u7684\u5b89\u5168\u6027\uff0c\u5e76\u4e3a\u672a\u6765\u7814\u7a76\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2506.23706", "categories": ["cs.AI", "cs.CL", "cs.CR"], "pdf": "https://arxiv.org/pdf/2506.23706", "abs": "https://arxiv.org/abs/2506.23706", "authors": ["Christoph Schnabl", "Daniel Hugenroth", "Bill Marino", "Alastair R. Beresford"], "title": "Attestable Audits: Verifiable AI Safety Benchmarks Using Trusted Execution Environments", "comment": "ICML 2024 Workshop TAIG", "summary": "Benchmarks are important measures to evaluate safety and compliance of AI\nmodels at scale. However, they typically do not offer verifiable results and\nlack confidentiality for model IP and benchmark datasets. We propose Attestable\nAudits, which run inside Trusted Execution Environments and enable users to\nverify interaction with a compliant AI model. Our work protects sensitive data\neven when model provider and auditor do not trust each other. This addresses\nverification challenges raised in recent AI governance frameworks. We build a\nprototype demonstrating feasibility on typical audit benchmarks against\nLlama-3.1.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53ef\u4fe1\u6267\u884c\u73af\u5883\uff08TEE\uff09\u7684\u53ef\u9a8c\u8bc1\u5ba1\u8ba1\u65b9\u6cd5\uff0c\u7528\u4e8e\u4fdd\u62a4AI\u6a21\u578b\u548c\u57fa\u51c6\u6570\u636e\u7684\u673a\u5bc6\u6027\uff0c\u5e76\u9a8c\u8bc1\u5408\u89c4\u6027\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u65e0\u6cd5\u63d0\u4f9b\u53ef\u9a8c\u8bc1\u7ed3\u679c\u4e14\u7f3a\u4e4f\u6570\u636e\u673a\u5bc6\u6027\u7684\u95ee\u9898\uff0c\u6ee1\u8db3AI\u6cbb\u7406\u6846\u67b6\u7684\u9700\u6c42\u3002", "method": "\u4f7f\u7528\u53ef\u4fe1\u6267\u884c\u73af\u5883\uff08TEE\uff09\u5b9e\u73b0\u53ef\u9a8c\u8bc1\u5ba1\u8ba1\uff0c\u4fdd\u62a4\u6a21\u578b\u548c\u6570\u636e\u9690\u79c1\u3002", "result": "\u539f\u578b\u7cfb\u7edf\u5728Llama-3.1\u4e0a\u9a8c\u8bc1\u4e86\u53ef\u884c\u6027\u3002", "conclusion": "Attestable Audits\u4e3aAI\u6a21\u578b\u7684\u5408\u89c4\u6027\u548c\u6570\u636e\u4fdd\u62a4\u63d0\u4f9b\u4e86\u53ef\u884c\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.23773", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2506.23773", "abs": "https://arxiv.org/abs/2506.23773", "authors": ["Stefano M. Nicoletti", "Mari\u00eblle Stoelinga"], "title": "BayesL: Towards a Logical Framework for Bayesian Networks", "comment": null, "summary": "We introduce BayesL, a novel logical framework for specifying, querying, and\nverifying the behaviour of Bayesian networks (BNs). BayesL (pronounced \"Basil\")\nis a structured language that allows for the creation of queries over BNs. It\nfacilitates versatile reasoning concerning causal and evidence-based\nrelationships, and permits comprehensive what-if scenario evaluations without\nthe need for manual modifications to the model.", "AI": {"tldr": "BayesL\u662f\u4e00\u4e2a\u65b0\u7684\u903b\u8f91\u6846\u67b6\uff0c\u7528\u4e8e\u6307\u5b9a\u3001\u67e5\u8be2\u548c\u9a8c\u8bc1\u8d1d\u53f6\u65af\u7f51\u7edc\u7684\u884c\u4e3a\u3002", "motivation": "\u63d0\u4f9b\u4e00\u4e2a\u7ed3\u6784\u5316\u8bed\u8a00\uff0c\u652f\u6301\u5bf9\u8d1d\u53f6\u65af\u7f51\u7edc\u7684\u67e5\u8be2\u548c\u63a8\u7406\uff0c\u907f\u514d\u624b\u52a8\u4fee\u6539\u6a21\u578b\u3002", "method": "\u5f00\u53d1BayesL\u8bed\u8a00\uff0c\u652f\u6301\u56e0\u679c\u548c\u8bc1\u636e\u5173\u7cfb\u7684\u63a8\u7406\uff0c\u4ee5\u53ca\u5168\u9762\u7684\u5047\u8bbe\u60c5\u666f\u8bc4\u4f30\u3002", "result": "BayesL\u80fd\u591f\u7075\u6d3b\u5730\u63a8\u7406\u8d1d\u53f6\u65af\u7f51\u7edc\u7684\u884c\u4e3a\uff0c\u652f\u6301\u591a\u79cd\u67e5\u8be2\u548c\u9a8c\u8bc1\u9700\u6c42\u3002", "conclusion": "BayesL\u662f\u4e00\u4e2a\u6709\u6548\u7684\u5de5\u5177\uff0c\u7b80\u5316\u4e86\u5bf9\u8d1d\u53f6\u65af\u7f51\u7edc\u7684\u5206\u6790\u548c\u9a8c\u8bc1\u3002"}}
{"id": "2506.23784", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.23784", "abs": "https://arxiv.org/abs/2506.23784", "authors": ["Parosh Aziz Abdulla", "Mohamed Faouzi Atig", "Julie Cailler", "Chencheng Liang", "Philipp R\u00fcmmer"], "title": "When GNNs Met a Word Equations Solver: Learning to Rank Equations (Extended Technical Report)", "comment": null, "summary": "Nielsen transformation is a standard approach for solving word equations: by\nrepeatedly splitting equations and applying simplification steps, equations are\nrewritten until a solution is reached. When solving a conjunction of word\nequations in this way, the performance of the solver will depend considerably\non the order in which equations are processed. In this work, the use of Graph\nNeural Networks (GNNs) for ranking word equations before and during the solving\nprocess is explored. For this, a novel graph-based representation for word\nequations is presented, preserving global information across conjuncts,\nenabling the GNN to have a holistic view during ranking. To handle the variable\nnumber of conjuncts, three approaches to adapt a multi-classification task to\nthe problem of ranking equations are proposed. The training of the GNN is done\nwith the help of minimum unsatisfiable subsets (MUSes) of word equations. The\nexperimental results show that, compared to state-of-the-art string solvers,\nthe new framework solves more problems in benchmarks where each variable\nappears at most once in each equation.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u7d22\u4e86\u4f7f\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNN\uff09\u5bf9\u8bcd\u65b9\u7a0b\u8fdb\u884c\u6392\u5e8f\u4ee5\u4f18\u5316\u6c42\u89e3\u8fc7\u7a0b\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u56fe\u8868\u793a\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u89e3\u51b3\u8bcd\u65b9\u7a0b\u8054\u7acb\u65f6\u7684\u6c42\u89e3\u987a\u5e8f\u95ee\u9898\uff0c\u4ee5\u63d0\u9ad8\u6c42\u89e3\u5668\u7684\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u56fe\u8868\u793a\u65b9\u6cd5\uff0c\u5229\u7528GNN\u5bf9\u8bcd\u65b9\u7a0b\u8fdb\u884c\u6392\u5e8f\uff0c\u5e76\u91c7\u7528\u4e09\u79cd\u65b9\u6cd5\u5904\u7406\u591a\u5206\u7c7b\u4efb\u52a1\u3002\u8bad\u7ec3\u65f6\u4f7f\u7528\u4e86\u6700\u5c0f\u4e0d\u53ef\u6ee1\u8db3\u5b50\u96c6\uff08MUSes\uff09\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u65b0\u6846\u67b6\u5728\u53d8\u91cf\u5728\u6bcf\u4e2a\u65b9\u7a0b\u4e2d\u6700\u591a\u51fa\u73b0\u4e00\u6b21\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u6c42\u89e3\u5668\u3002", "conclusion": "GNN\u7ed3\u5408\u56fe\u8868\u793a\u65b9\u6cd5\u80fd\u6709\u6548\u4f18\u5316\u8bcd\u65b9\u7a0b\u6c42\u89e3\u987a\u5e8f\uff0c\u63d0\u5347\u6c42\u89e3\u6548\u7387\u3002"}}
{"id": "2506.23793", "categories": ["cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2506.23793", "abs": "https://arxiv.org/abs/2506.23793", "authors": ["Anton Andreychuk", "Konstantin Yakovlev", "Aleksandr Panov", "Alexey Skrynnik"], "title": "Advancing Learnable Multi-Agent Pathfinding Solvers with Active Fine-Tuning", "comment": null, "summary": "Multi-agent pathfinding (MAPF) is a common abstraction of multi-robot\ntrajectory planning problems, where multiple homogeneous robots simultaneously\nmove in the shared environment. While solving MAPF optimally has been proven to\nbe NP-hard, scalable, and efficient, solvers are vital for real-world\napplications like logistics, search-and-rescue, etc. To this end, decentralized\nsuboptimal MAPF solvers that leverage machine learning have come on stage.\nBuilding on the success of the recently introduced MAPF-GPT, a pure imitation\nlearning solver, we introduce MAPF-GPT-DDG. This novel approach effectively\nfine-tunes the pre-trained MAPF model using centralized expert data. Leveraging\na novel delta-data generation mechanism, MAPF-GPT-DDG accelerates training\nwhile significantly improving performance at test time. Our experiments\ndemonstrate that MAPF-GPT-DDG surpasses all existing learning-based MAPF\nsolvers, including the original MAPF-GPT, regarding solution quality across\nmany testing scenarios. Remarkably, it can work with MAPF instances involving\nup to 1 million agents in a single environment, setting a new milestone for\nscalability in MAPF domains.", "AI": {"tldr": "MAPF-GPT-DDG\u662f\u4e00\u79cd\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u591a\u667a\u80fd\u4f53\u8def\u5f84\u89c4\u5212\uff08MAPF\uff09\u6c42\u89e3\u5668\uff0c\u901a\u8fc7\u6539\u8fdb\u9884\u8bad\u7ec3\u6a21\u578b\u548c\u5f15\u5165\u65b0\u7684\u6570\u636e\u751f\u6210\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u548c\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u8def\u5f84\u89c4\u5212\uff08MAPF\uff09\u95ee\u9898\u7684\u9ad8\u6548\u6c42\u89e3\u9700\u6c42\uff0c\u5c24\u5176\u662f\u5728\u5927\u89c4\u6a21\u573a\u666f\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u5229\u7528\u96c6\u4e2d\u5f0f\u4e13\u5bb6\u6570\u636e\u5bf9\u9884\u8bad\u7ec3\u7684MAPF-GPT\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\uff0c\u5e76\u91c7\u7528\u65b0\u7684delta-data\u751f\u6210\u673a\u5236\u52a0\u901f\u8bad\u7ec3\u3002", "result": "MAPF-GPT-DDG\u5728\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u5b66\u4e60\u578b\u6c42\u89e3\u5668\uff0c\u652f\u6301\u5355\u73af\u5883\u4e2d\u591a\u8fbe100\u4e07\u4e2a\u667a\u80fd\u4f53\u7684\u8def\u5f84\u89c4\u5212\u3002", "conclusion": "MAPF-GPT-DDG\u4e3aMAPF\u9886\u57df\u8bbe\u5b9a\u4e86\u65b0\u7684\u53ef\u6269\u5c55\u6027\u6807\u51c6\uff0c\u9002\u7528\u4e8e\u7269\u6d41\u3001\u641c\u6551\u7b49\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2506.23844", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23844", "abs": "https://arxiv.org/abs/2506.23844", "authors": ["Hang Su", "Jun Luo", "Chang Liu", "Xiao Yang", "Yichi Zhang", "Yinpeng Dong", "Jun Zhu"], "title": "A Survey on Autonomy-Induced Security Risks in Large Model-Based Agents", "comment": "18 pages", "summary": "Recent advances in large language models (LLMs) have catalyzed the rise of\nautonomous AI agents capable of perceiving, reasoning, and acting in dynamic,\nopen-ended environments. These large-model agents mark a paradigm shift from\nstatic inference systems to interactive, memory-augmented entities. While these\ncapabilities significantly expand the functional scope of AI, they also\nintroduce qualitatively novel security risks - such as memory poisoning, tool\nmisuse, reward hacking, and emergent misalignment - that extend beyond the\nthreat models of conventional systems or standalone LLMs. In this survey, we\nfirst examine the structural foundations and key capabilities that underpin\nincreasing levels of agent autonomy, including long-term memory retention,\nmodular tool use, recursive planning, and reflective reasoning. We then analyze\nthe corresponding security vulnerabilities across the agent stack, identifying\nfailure modes such as deferred decision hazards, irreversible tool chains, and\ndeceptive behaviors arising from internal state drift or value misalignment.\nThese risks are traced to architectural fragilities that emerge across\nperception, cognition, memory, and action modules. To address these challenges,\nwe systematically review recent defense strategies deployed at different\nautonomy layers, including input sanitization, memory lifecycle control,\nconstrained decision-making, structured tool invocation, and introspective\nreflection. We introduce the Reflective Risk-Aware Agent Architecture (R2A2), a\nunified cognitive framework grounded in Constrained Markov Decision Processes\n(CMDPs), which incorporates risk-aware world modeling, meta-policy adaptation,\nand joint reward-risk optimization to enable principled, proactive safety\nacross the agent's decision-making loop.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u8fdb\u6b65\u63a8\u52a8\u4e86\u81ea\u4e3bAI\u4ee3\u7406\u7684\u53d1\u5c55\uff0c\u4f46\u4e5f\u5e26\u6765\u4e86\u65b0\u7684\u5b89\u5168\u98ce\u9669\u3002\u672c\u6587\u8c03\u67e5\u4e86\u4ee3\u7406\u7684\u7ed3\u6784\u57fa\u7840\u3001\u80fd\u529b\u53ca\u5b89\u5168\u6f0f\u6d1e\uff0c\u5e76\u63d0\u51fa\u4e86\u9632\u5fa1\u7b56\u7565\u548cR2A2\u6846\u67b6\u3002", "motivation": "\u7814\u7a76\u81ea\u4e3bAI\u4ee3\u7406\u7684\u80fd\u529b\u53ca\u5176\u5e26\u6765\u7684\u65b0\u578b\u5b89\u5168\u98ce\u9669\uff0c\u4ee5\u586b\u8865\u4f20\u7edf\u7cfb\u7edf\u6216\u72ec\u7acbLLM\u7684\u5a01\u80c1\u6a21\u578b\u7a7a\u767d\u3002", "method": "\u5206\u6790\u4e86\u4ee3\u7406\u7684\u7ed3\u6784\u57fa\u7840\uff08\u5982\u957f\u671f\u8bb0\u5fc6\u3001\u5de5\u5177\u4f7f\u7528\u3001\u9012\u5f52\u89c4\u5212\u548c\u53cd\u601d\u63a8\u7406\uff09\uff0c\u5e76\u8bc6\u522b\u4e86\u5b89\u5168\u6f0f\u6d1e\u3002\u63d0\u51fa\u4e86\u9632\u5fa1\u7b56\u7565\u548cR2A2\u6846\u67b6\u3002", "result": "\u63ed\u793a\u4e86\u4ee3\u7406\u5728\u611f\u77e5\u3001\u8ba4\u77e5\u3001\u8bb0\u5fc6\u548c\u884c\u52a8\u6a21\u5757\u4e2d\u7684\u8106\u5f31\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u9488\u5bf9\u6027\u7684\u9632\u5fa1\u63aa\u65bd\u3002", "conclusion": "\u901a\u8fc7R2A2\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u57fa\u4e8e\u98ce\u9669\u611f\u77e5\u7684\u51b3\u7b56\u4f18\u5316\uff0c\u4e3a\u81ea\u4e3bAI\u4ee3\u7406\u7684\u5b89\u5168\u6027\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.23908", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.23908", "abs": "https://arxiv.org/abs/2506.23908", "authors": ["Andr\u00e1s Gy\u00f6rgy", "Tor Lattimore", "Nevena Lazi\u0107", "Csaba Szepesv\u00e1ri"], "title": "Beyond Statistical Learning: Exact Learning Is Essential for General Intelligence", "comment": null, "summary": "Sound deductive reasoning -- the ability to derive new knowledge from\nexisting facts and rules -- is an indisputably desirable aspect of general\nintelligence. Despite the major advances of AI systems in areas such as math\nand science, especially since the introduction of transformer architectures, it\nis well-documented that even the most advanced frontier systems regularly and\nconsistently falter on easily-solvable deductive reasoning tasks. Hence, these\nsystems are unfit to fulfill the dream of achieving artificial general\nintelligence capable of sound deductive reasoning. We argue that their unsound\nbehavior is a consequence of the statistical learning approach powering their\ndevelopment. To overcome this, we contend that to achieve reliable deductive\nreasoning in learning-based AI systems, researchers must fundamentally shift\nfrom optimizing for statistical performance against distributions on reasoning\nproblems and algorithmic tasks to embracing the more ambitious exact learning\nparadigm, which demands correctness on all inputs. We argue that exact learning\nis both essential and possible, and that this ambitious objective should guide\nalgorithm design.", "AI": {"tldr": "\u8bba\u6587\u4e3b\u5f20AI\u7cfb\u7edf\u9700\u4ece\u7edf\u8ba1\u5b66\u4e60\u8f6c\u5411\u7cbe\u786e\u5b66\u4e60\uff0c\u4ee5\u5b9e\u73b0\u53ef\u9760\u7684\u6f14\u7ece\u63a8\u7406\u3002", "motivation": "\u5f53\u524dAI\u7cfb\u7edf\u5728\u6f14\u7ece\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u65e0\u6cd5\u5b9e\u73b0\u901a\u7528\u4eba\u5de5\u667a\u80fd\u3002", "method": "\u63d0\u51fa\u4ece\u7edf\u8ba1\u6027\u80fd\u4f18\u5316\u8f6c\u5411\u7cbe\u786e\u5b66\u4e60\u8303\u5f0f\uff0c\u8981\u6c42\u5bf9\u6240\u6709\u8f93\u5165\u7684\u6b63\u786e\u6027\u3002", "result": "\u7cbe\u786e\u5b66\u4e60\u662f\u5b9e\u73b0\u53ef\u9760\u6f14\u7ece\u63a8\u7406\u7684\u5173\u952e\u3002", "conclusion": "\u7cbe\u786e\u5b66\u4e60\u5e94\u6210\u4e3a\u7b97\u6cd5\u8bbe\u8ba1\u7684\u6307\u5bfc\u76ee\u6807\u3002"}}
{"id": "2506.23924", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23924", "abs": "https://arxiv.org/abs/2506.23924", "authors": ["Akshit Kumar", "Tianyi Peng", "Yuhang Wu", "Assaf Zeevi"], "title": "Performance of LLMs on Stochastic Modeling Operations Research Problems: From Theory to Practice", "comment": null, "summary": "Large language models (LLMs) have exhibited expert-level capabilities across\nvarious domains. However, their abilities to solve problems in Operations\nResearch (OR) -- the analysis and optimization of mathematical models derived\nfrom real-world problems or their verbal descriptions -- remain underexplored.\nIn this work, we take a first step toward evaluating LLMs' abilities to solve\nstochastic modeling problems, a core class of OR problems characterized by\nuncertainty and typically involving tools from probability, statistics, and\nstochastic processes. We manually procure a representative set of\ngraduate-level homework and doctoral qualification-exam problems and test LLMs'\nabilities to solve them. We further leverage SimOpt, an open-source library of\nsimulation-optimization problems and solvers, to investigate LLMs' abilities to\nmake real-world decisions under uncertainty. Our results show that, though a\nnontrivial amount of work is still needed to reliably automate the stochastic\nmodeling pipeline in reality, state-of-the-art LLMs demonstrate proficiency on\npar with human experts in both classroom and practical settings. These findings\nhighlight the potential of building AI agents that assist OR researchers and\namplify the real-world impact of OR through automation.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u89e3\u51b3\u8fd0\u7b79\u5b66\uff08OR\uff09\u4e2d\u968f\u673a\u5efa\u6a21\u95ee\u9898\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u5176\u5728\u8bfe\u5802\u548c\u5b9e\u9645\u573a\u666f\u4e2d\u8868\u73b0\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u76f8\u5f53\u3002", "motivation": "\u63a2\u7d22LLMs\u5728\u89e3\u51b3\u8fd0\u7b79\u5b66\u95ee\u9898\u4e2d\u7684\u80fd\u529b\uff0c\u5c24\u5176\u662f\u968f\u673a\u5efa\u6a21\u95ee\u9898\uff0c\u4ee5\u586b\u8865\u8fd9\u4e00\u9886\u57df\u7684\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u624b\u52a8\u6536\u96c6\u7814\u7a76\u751f\u8bfe\u7a0b\u4f5c\u4e1a\u548c\u535a\u58eb\u8d44\u683c\u8003\u8bd5\u9898\u76ee\uff0c\u5e76\u5229\u7528\u5f00\u6e90\u5e93SimOpt\u6d4b\u8bd5LLMs\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u51b3\u7b56\u80fd\u529b\u3002", "result": "LLMs\u5728\u89e3\u51b3\u968f\u673a\u5efa\u6a21\u95ee\u9898\u65f6\u8868\u73b0\u51fa\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u76f8\u5f53\u7684\u80fd\u529b\uff0c\u4f46\u4ecd\u9700\u8fdb\u4e00\u6b65\u5de5\u4f5c\u4ee5\u5b9e\u73b0\u53ef\u9760\u81ea\u52a8\u5316\u3002", "conclusion": "LLMs\u5728\u8fd0\u7b79\u5b66\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u53ef\u6784\u5efaAI\u52a9\u624b\u4ee5\u652f\u6301\u7814\u7a76\u5e76\u63a8\u52a8\u81ea\u52a8\u5316\u5e94\u7528\u3002"}}
{"id": "2506.23926", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.23926", "abs": "https://arxiv.org/abs/2506.23926", "authors": ["Junping Wang", "Bicheng Wang", "Yibo Xuea", "Yuan Xie"], "title": "Industrial brain: a human-like autonomous neuro-symbolic cognitive decision-making system", "comment": null, "summary": "Resilience non-equilibrium measurement, the ability to maintain fundamental\nfunctionality amidst failures and errors, is crucial for scientific management\nand engineering applications of industrial chain. The problem is particularly\nchallenging when the number or types of multiple co-evolution of resilience\n(for example, randomly placed) are extremely chaos. Existing end-to-end deep\nlearning ordinarily do not generalize well to unseen full-feld reconstruction\nof spatiotemporal co-evolution structure, and predict resilience of network\ntopology, especially in multiple chaos data regimes typically seen in\nreal-world applications. To address this challenge, here we propose industrial\nbrain, a human-like autonomous cognitive decision-making and planning framework\nintegrating higher-order activity-driven neuro network and CT-OODA symbolic\nreasoning to autonomous plan resilience directly from observational data of\nglobal variable. The industrial brain not only understands and model structure\nof node activity dynamics and network co-evolution topology without simplifying\nassumptions, and reveal the underlying laws hidden behind complex networks, but\nalso enabling accurate resilience prediction, inference, and planning.\nExperimental results show that industrial brain significantly outperforms\nresilience prediction and planning methods, with an accurate improvement of up\nto 10.8\\% over GoT and OlaGPT framework and 11.03\\% over spectral dimension\nreduction. It also generalizes to unseen topologies and dynamics and maintains\nrobust performance despite observational disturbances. Our findings suggest\nthat industrial brain addresses an important gap in resilience prediction and\nplanning for industrial chain.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201c\u5de5\u4e1a\u5927\u8111\u201d\u7684\u6846\u67b6\uff0c\u7ed3\u5408\u9ad8\u9636\u795e\u7ecf\u7f51\u548c\u7b26\u53f7\u63a8\u7406\uff0c\u7528\u4e8e\u9884\u6d4b\u548c\u89c4\u5212\u5de5\u4e1a\u94fe\u7684\u97e7\u6027\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5728\u590d\u6742\u65f6\u7a7a\u5171\u6f14\u7ed3\u6784\u548c\u591a\u6df7\u6c8c\u6570\u636e\u4e0b\u7684\u97e7\u6027\u9884\u6d4b\u8868\u73b0\u4e0d\u4f73\uff0c\u4e9f\u9700\u65b0\u65b9\u6cd5\u3002", "method": "\u6574\u5408\u9ad8\u9636\u6d3b\u52a8\u9a71\u52a8\u795e\u7ecf\u7f51\u548cCT-OODA\u7b26\u53f7\u63a8\u7406\uff0c\u76f4\u63a5\u4ece\u89c2\u6d4b\u6570\u636e\u4e2d\u81ea\u4e3b\u89c4\u5212\u97e7\u6027\u3002", "result": "\u5de5\u4e1a\u5927\u8111\u5728\u97e7\u6027\u9884\u6d4b\u548c\u89c4\u5212\u4e0a\u663e\u8457\u4f18\u4e8eGoT\u3001OlaGPT\u548c\u8c31\u964d\u7ef4\u65b9\u6cd5\uff0c\u51c6\u786e\u7387\u63d0\u5347\u8fbe10.8%\u548c11.03%\u3002", "conclusion": "\u5de5\u4e1a\u5927\u8111\u586b\u8865\u4e86\u5de5\u4e1a\u94fe\u97e7\u6027\u9884\u6d4b\u548c\u89c4\u5212\u7684\u91cd\u8981\u7a7a\u767d\uff0c\u5177\u6709\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2506.23949", "categories": ["cs.AI", "cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2506.23949", "abs": "https://arxiv.org/abs/2506.23949", "authors": ["Anthony M. Barrett", "Jessica Newman", "Brandie Nonnecke", "Nada Madkour", "Dan Hendrycks", "Evan R. Murphy", "Krystal Jackson", "Deepika Raman"], "title": "AI Risk-Management Standards Profile for General-Purpose AI (GPAI) and Foundation Models", "comment": null, "summary": "Increasingly multi-purpose AI models, such as cutting-edge large language\nmodels or other 'general-purpose AI' (GPAI) models, 'foundation models,'\ngenerative AI models, and 'frontier models' (typically all referred to\nhereafter with the umbrella term 'GPAI/foundation models' except where greater\nspecificity is needed), can provide many beneficial capabilities but also risks\nof adverse events with profound consequences. This document provides\nrisk-management practices or controls for identifying, analyzing, and\nmitigating risks of GPAI/foundation models. We intend this document primarily\nfor developers of large-scale, state-of-the-art GPAI/foundation models; others\nthat can benefit from this guidance include downstream developers of end-use\napplications that build on a GPAI/foundation model. This document facilitates\nconformity with or use of leading AI risk management-related standards,\nadapting and building on the generic voluntary guidance in the NIST AI Risk\nManagement Framework and ISO/IEC 23894, with a focus on the unique issues faced\nby developers of GPAI/foundation models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9488\u5bf9\u901a\u7528\u4eba\u5de5\u667a\u80fd\uff08GPAI\uff09\u548c\u57fa\u7840\u6a21\u578b\u7684\u98ce\u9669\u7ba1\u7406\u5b9e\u8df5\uff0c\u65e8\u5728\u5e2e\u52a9\u5f00\u53d1\u8005\u8bc6\u522b\u3001\u5206\u6790\u548c\u51cf\u8f7b\u76f8\u5173\u98ce\u9669\u3002", "motivation": "GPAI\u548c\u57fa\u7840\u6a21\u578b\u867d\u7136\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u4f46\u4e5f\u4f34\u968f\u7740\u91cd\u5927\u98ce\u9669\uff0c\u9700\u8981\u4e13\u95e8\u7684\u98ce\u9669\u7ba1\u7406\u63aa\u65bd\u3002", "method": "\u7ed3\u5408NIST AI\u98ce\u9669\u7ba1\u7406\u6846\u67b6\u548cISO/IEC 23894\u6807\u51c6\uff0c\u9488\u5bf9GPAI/\u57fa\u7840\u6a21\u578b\u7684\u72ec\u7279\u95ee\u9898\u63d0\u51fa\u98ce\u9669\u7ba1\u7406\u5b9e\u8df5\u3002", "result": "\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u4e00\u5957\u5b9e\u7528\u7684\u98ce\u9669\u7ba1\u7406\u6307\u5357\uff0c\u9002\u7528\u4e8eGPAI/\u57fa\u7840\u6a21\u578b\u7684\u5f00\u53d1\u548c\u5e94\u7528\u3002", "conclusion": "\u672c\u6587\u4e3aGPAI/\u57fa\u7840\u6a21\u578b\u7684\u98ce\u9669\u7ba1\u7406\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u5b89\u5168\u53ef\u9760\u7684AI\u53d1\u5c55\u3002"}}
{"id": "2506.23992", "categories": ["cs.AI", "cs.ET"], "pdf": "https://arxiv.org/pdf/2506.23992", "abs": "https://arxiv.org/abs/2506.23992", "authors": ["Aditya Shrivastava", "Komal Gupta", "Shraddha Arora"], "title": "Harnessing AI Agents to Advance Research on Refugee Child Mental Health", "comment": "14 page , 2 image , 2 tables , accepted under 5th International\n  Conference on Innovations in Computational Intelligence and Computer Vision\n  (ICICV-2025)", "summary": "The international refugee crisis deepens, exposing millions of dis placed\nchildren to extreme psychological trauma. This research suggests a com pact,\nAI-based framework for processing unstructured refugee health data and\ndistilling knowledge on child mental health. We compare two Retrieval-Aug\nmented Generation (RAG) pipelines, Zephyr-7B-beta and DeepSeek R1-7B, to\ndetermine how well they process challenging humanitarian datasets while avoid\ning hallucination hazards. By combining cutting-edge AI methods with migration\nresearch and child psychology, this study presents a scalable strategy to\nassist policymakers, mental health practitioners, and humanitarian agencies to\nbetter assist displaced children and recognize their mental wellbeing. In\ntotal, both the models worked properly but significantly Deepseek R1 is\nsuperior to Zephyr with an accuracy of answer relevance 0.91", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eAI\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5904\u7406\u96be\u6c11\u5065\u5eb7\u6570\u636e\u5e76\u5206\u6790\u513f\u7ae5\u5fc3\u7406\u5065\u5eb7\uff0c\u6bd4\u8f83\u4e86\u4e24\u79cdRAG\u6a21\u578b\uff08Zephyr-7B-beta\u548cDeepSeek R1-7B\uff09\uff0c\u53d1\u73b0DeepSeek R1\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u89e3\u51b3\u56fd\u9645\u96be\u6c11\u5371\u673a\u4e2d\u513f\u7ae5\u5fc3\u7406\u5065\u5eb7\u95ee\u9898\uff0c\u901a\u8fc7AI\u6280\u672f\u63d0\u4f9b\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f7f\u7528\u4e24\u79cdRAG\u6a21\u578b\u5904\u7406\u96be\u6c11\u5065\u5eb7\u6570\u636e\uff0c\u8bc4\u4f30\u5176\u6027\u80fd\u548c\u907f\u514d\u5e7b\u89c9\u98ce\u9669\u7684\u80fd\u529b\u3002", "result": "DeepSeek R1-7B\u5728\u7b54\u6848\u76f8\u5173\u6027\u4e0a\u8868\u73b0\u4f18\u4e8eZephyr-7B-beta\uff0c\u51c6\u786e\u7387\u4e3a0.91\u3002", "conclusion": "\u7814\u7a76\u4e3a\u653f\u7b56\u5236\u5b9a\u8005\u548c\u4eba\u9053\u673a\u6784\u63d0\u4f9b\u4e86\u6709\u6548\u7684AI\u5de5\u5177\uff0c\u4ee5\u66f4\u597d\u5730\u652f\u6301\u96be\u6c11\u513f\u7ae5\u7684\u5fc3\u7406\u5065\u5eb7\u3002"}}
{"id": "2506.24026", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.24026", "abs": "https://arxiv.org/abs/2506.24026", "authors": ["Yongyi Wang", "Wenxin Li"], "title": "Constructing Non-Markovian Decision Process via History Aggregator", "comment": null, "summary": "In the domain of algorithmic decision-making, non-Markovian dynamics manifest\nas a significant impediment, especially for paradigms such as Reinforcement\nLearning (RL), thereby exerting far-reaching consequences on the advancement\nand effectiveness of the associated systems. Nevertheless, the existing\nbenchmarks are deficient in comprehensively assessing the capacity of decision\nalgorithms to handle non-Markovian dynamics. To address this deficiency, we\nhave devised a generalized methodology grounded in category theory. Notably, we\nestablished the category of Markov Decision Processes (MDP) and the category of\nnon-Markovian Decision Processes (NMDP), and proved the equivalence\nrelationship between them. This theoretical foundation provides a novel\nperspective for understanding and addressing non-Markovian dynamics. We further\nintroduced non-Markovianity into decision-making problem settings via the\nHistory Aggregator for State (HAS). With HAS, we can precisely control the\nstate dependency structure of decision-making problems in the time series. Our\nanalysis demonstrates the effectiveness of our method in representing a broad\nrange of non-Markovian dynamics. This approach facilitates a more rigorous and\nflexible evaluation of decision algorithms by testing them in problem settings\nwhere non-Markovian dynamics are explicitly constructed.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8303\u7574\u8bba\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u51b3\u7b56\u7b97\u6cd5\u5904\u7406\u975e\u9a6c\u5c14\u53ef\u592b\u52a8\u6001\u7684\u80fd\u529b\uff0c\u901a\u8fc7\u5efa\u7acbMDP\u548cNMDP\u7684\u8303\u7574\u7b49\u4ef7\u5173\u7cfb\uff0c\u5e76\u5f15\u5165HAS\u5de5\u5177\u7cbe\u786e\u63a7\u5236\u72b6\u6001\u4f9d\u8d56\u7ed3\u6784\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u65e0\u6cd5\u5168\u9762\u8bc4\u4f30\u51b3\u7b56\u7b97\u6cd5\u5904\u7406\u975e\u9a6c\u5c14\u53ef\u592b\u52a8\u6001\u7684\u80fd\u529b\uff0c\u8fd9\u9650\u5236\u4e86\u76f8\u5173\u7cfb\u7edf\u7684\u8fdb\u5c55\u548c\u6548\u679c\u3002", "method": "\u57fa\u4e8e\u8303\u7574\u8bba\u5efa\u7acbMDP\u548cNMDP\u7684\u8303\u7574\u7b49\u4ef7\u5173\u7cfb\uff0c\u5e76\u5f15\u5165HAS\u5de5\u5177\u63a7\u5236\u72b6\u6001\u4f9d\u8d56\u7ed3\u6784\u3002", "result": "\u65b9\u6cd5\u80fd\u6709\u6548\u8868\u793a\u5e7f\u6cdb\u7684\u975e\u9a6c\u5c14\u53ef\u592b\u52a8\u6001\uff0c\u4e3a\u51b3\u7b56\u7b97\u6cd5\u63d0\u4f9b\u66f4\u4e25\u683c\u548c\u7075\u6d3b\u7684\u8bc4\u4f30\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u7406\u89e3\u548c\u89e3\u51b3\u975e\u9a6c\u5c14\u53ef\u592b\u52a8\u6001\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u5e76\u63d0\u5347\u4e86\u51b3\u7b56\u7b97\u6cd5\u7684\u8bc4\u4f30\u80fd\u529b\u3002"}}
{"id": "2506.24119", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.24119", "abs": "https://arxiv.org/abs/2506.24119", "authors": ["Bo Liu", "Leon Guertler", "Simon Yu", "Zichen Liu", "Penghui Qi", "Daniel Balcells", "Mickel Liu", "Cheston Tan", "Weiyan Shi", "Min Lin", "Wee Sun Lee", "Natasha Jaques"], "title": "SPIRAL: Self-Play on Zero-Sum Games Incentivizes Reasoning via Multi-Agent Multi-Turn Reinforcement Learning", "comment": "Work in Progress", "summary": "Recent advances in reinforcement learning have shown that language models can\ndevelop sophisticated reasoning through training on tasks with verifiable\nrewards, but these approaches depend on human-curated problem-answer pairs and\ndomain-specific reward engineering. We introduce SPIRAL, a self-play framework\nwhere models learn by playing multi-turn, zero-sum games against continuously\nimproving versions of themselves, eliminating the need for human supervision.\nThrough self-play, SPIRAL generates an infinite curriculum of progressively\nchallenging problems as models must constantly adapt to stronger opponents. To\nenable this self-play training at scale, We implement a fully online,\nmulti-turn, multi-agent reinforcement learning system for LLMs and propose\nrole-conditioned advantage estimation (RAE) to stabilize multi-agent training.\nUsing SPIRAL, self-play on zero-sum games produces reasoning capabilities that\ntransfer broadly. Training Qwen3-4B-Base on Kuhn Poker alone achieves 8.6%\nimprovement on math and 8.4% on general reasoning, outperforming SFT on 25,000\nexpert game trajectories. Analysis reveals that this transfer occurs through\nthree cognitive patterns: systematic decomposition, expected value calculation,\nand case-by-case analysis. Multi-game training (TicTacToe, Kuhn Poker, Simple\nNegotiation) further enhances performance as each game develops distinct\nreasoning strengths. Applying SPIRAL to a strong reasoning model\n(DeepSeek-R1-Distill-Qwen-7B) can still lead to 2.0% average improvement. These\nresults demonstrate that zero-sum games naturally develop transferable\nreasoning capabilities, highlighting a promising direction for autonomous\nreasoning development.", "AI": {"tldr": "SPIRAL\u662f\u4e00\u4e2a\u901a\u8fc7\u81ea\u6211\u5bf9\u5f08\u6846\u67b6\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u65e0\u9700\u4eba\u5de5\u76d1\u7763\uff0c\u80fd\u591f\u751f\u6210\u65e0\u9650\u96be\u5ea6\u9012\u589e\u7684\u95ee\u9898\uff0c\u63d0\u5347\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u6807\u6ce8\u7684\u95ee\u9898-\u7b54\u6848\u5bf9\u548c\u9886\u57df\u7279\u5b9a\u7684\u5956\u52b1\u8bbe\u8ba1\uff0c\u9650\u5236\u4e86\u6a21\u578b\u7684\u81ea\u4e3b\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "method": "SPIRAL\u91c7\u7528\u591a\u8f6e\u96f6\u548c\u6e38\u620f\u7684\u81ea\u6211\u5bf9\u5f08\u6846\u67b6\uff0c\u7ed3\u5408\u5728\u7ebf\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7cfb\u7edf\u548c\u89d2\u8272\u6761\u4ef6\u4f18\u52bf\u4f30\u8ba1\uff08RAE\uff09\u6765\u7a33\u5b9a\u8bad\u7ec3\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cSPIRAL\u5728\u5355\u4e00\u6e38\u620f\uff08\u5982Kuhn Poker\uff09\u548c\u591a\u6e38\u620f\u8bad\u7ec3\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u7684\u6570\u5b66\u548c\u901a\u7528\u63a8\u7406\u80fd\u529b\uff0c\u4e14\u80fd\u8fc1\u79fb\u5230\u5176\u4ed6\u4efb\u52a1\u3002", "conclusion": "\u96f6\u548c\u6e38\u620f\u80fd\u81ea\u7136\u53d1\u5c55\u51fa\u53ef\u8fc1\u79fb\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4e3a\u81ea\u4e3b\u63a8\u7406\u5f00\u53d1\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
