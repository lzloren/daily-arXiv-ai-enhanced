<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 20]
- [cs.CL](#cs.CL) [Total: 44]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [GraphTrafficGPT: Enhancing Traffic Management Through Graph-Based AI Agent Coordination](https://arxiv.org/abs/2507.13511)
*Nabil Abdelaziz Ferhat Taleb,Abdolazim Rezaei,Raj Atulkumar Patel,Mehdi Sookhak*

Main category: cs.AI

TL;DR: GraphTrafficGPT是一种基于图的架构，通过并行执行和动态资源分配优化LLM驱动的交通管理任务，显著降低令牌消耗和响应延迟。


<details>
  <summary>Details</summary>
Motivation: 现有链式系统（如TrafficGPT）存在顺序任务执行、高令牌消耗和可扩展性差的问题，无法满足复杂交通场景需求。

Method: 提出GraphTrafficGPT，将任务及其依赖关系表示为有向图中的节点和边，通过Brain Agent分解查询并协调多个专用代理。

Result: 实验显示，GraphTrafficGPT令牌消耗减少50.2%，响应延迟降低19.0%，多查询效率提升23.0%。

Conclusion: GraphTrafficGPT显著提升了LLM在交通管理中的效率和可扩展性。

Abstract: Large Language Models (LLMs) offer significant promise for intelligent
traffic management; however, current chain-based systems like TrafficGPT are
hindered by sequential task execution, high token usage, and poor scalability,
making them inefficient for complex, real-world scenarios. To address these
limitations, we propose GraphTrafficGPT, a novel graph-based architecture,
which fundamentally redesigns the task coordination process for LLM-driven
traffic applications. GraphTrafficGPT represents tasks and their dependencies
as nodes and edges in a directed graph, enabling efficient parallel execution
and dynamic resource allocation. The main idea behind the proposed model is a
Brain Agent that decomposes user queries, constructs optimized dependency
graphs, and coordinates a network of specialized agents for data retrieval,
analysis, visualization, and simulation. By introducing advanced context-aware
token management and supporting concurrent multi-query processing, the proposed
architecture handles interdependent tasks typical of modern urban mobility
environments. Experimental results demonstrate that GraphTrafficGPT reduces
token consumption by 50.2% and average response latency by 19.0% compared to
TrafficGPT, while supporting simultaneous multi-query execution with up to
23.0% improvement in efficiency.

</details>


### [2] [PrefPalette: Personalized Preference Modeling with Latent Attributes](https://arxiv.org/abs/2507.13541)
*Shuyue Stella Li,Melanie Sclar,Hunter Lang,Ansong Ni,Jacqueline He,Puxin Xu,Andrew Cohen,Chan Young Park,Yulia Tsvetkov,Asli Celikyilmaz*

Main category: cs.AI

TL;DR: PrefPalette通过分解偏好到属性维度，结合社区特定价值观，显著提升预测准确性，并提供可解释的洞察。


<details>
  <summary>Details</summary>
Motivation: 当前偏好模型将人类判断视为黑箱，缺乏对偏好背后原因的理解。PrefPalette旨在通过多属性决策原则，提供更透明、个性化的偏好建模。

Method: PrefPalette采用两步法：1) 生成合成数据以隔离属性效应；2) 基于注意力的偏好建模，动态学习不同社区对属性的权重。

Result: 在Reddit的45个社区中，PrefPalette预测准确率比GPT-4o高46.6%，并揭示了社区特定的偏好模式。

Conclusion: PrefPalette不仅提升预测性能，还通过可解释的建模为更可信、价值感知的个性化应用奠定基础。

Abstract: Personalizing AI systems requires understanding not just what users prefer,
but the reasons that underlie those preferences - yet current preference models
typically treat human judgment as a black box. We introduce PrefPalette, a
framework that decomposes preferences into attribute dimensions and tailors its
preference prediction to distinct social community values in a
human-interpretable manner. PrefPalette operationalizes a cognitive science
principle known as multi-attribute decision making in two ways: (1) a scalable
counterfactual attribute synthesis step that involves generating synthetic
training data to isolate for individual attribute effects (e.g., formality,
humor, cultural values), and (2) attention-based preference modeling that
learns how different social communities dynamically weight these attributes.
This approach moves beyond aggregate preference modeling to capture the diverse
evaluation frameworks that drive human judgment. When evaluated on 45 social
communities from the online platform Reddit, PrefPalette outperforms GPT-4o by
46.6% in average prediction accuracy. Beyond raw predictive improvements,
PrefPalette also shed light on intuitive, community-specific profiles:
scholarly communities prioritize verbosity and stimulation, conflict-oriented
communities value sarcasm and directness, and support-based communities
emphasize empathy. By modeling the attribute-mediated structure of human
judgment, PrefPalette delivers both superior preference modeling and
transparent, interpretable insights, and serves as a first step toward more
trustworthy, value-aware personalized applications.

</details>


### [3] [GOFAI meets Generative AI: Development of Expert Systems by means of Large Language Models](https://arxiv.org/abs/2507.13550)
*Eduardo C. Garrido-Merchán,Cristina Puente*

Main category: cs.AI

TL;DR: 本文提出了一种结合大语言模型（LLMs）与符号系统的新方法，通过限制领域和结构化提示提取知识，生成可验证的Prolog知识表示，以提高专家系统的可靠性、可解释性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在生成知识时存在幻觉或不可验证事实的问题，因此需要一种可控且透明的方法来开发可靠的专家系统。

Method: 采用结构化提示提取方法，将LLMs生成的知识转化为Prolog符号表示，并通过人工专家验证和修正。

Result: 实验表明，该方法在事实准确性和语义一致性上表现优异，结合了LLMs的召回能力和符号系统的精确性。

Conclusion: 该方法为敏感领域的可靠AI应用奠定了基础，提供了一种透明且可扩展的解决方案。

Abstract: The development of large language models (LLMs) has successfully transformed
knowledge-based systems such as open domain question nswering, which can
automatically produce vast amounts of seemingly coherent information. Yet,
those models have several disadvantages like hallucinations or confident
generation of incorrect or unverifiable facts. In this paper, we introduce a
new approach to the development of expert systems using LLMs in a controlled
and transparent way. By limiting the domain and employing a well-structured
prompt-based extraction approach, we produce a symbolic representation of
knowledge in Prolog, which can be validated and corrected by human experts.
This approach also guarantees interpretability, scalability and reliability of
the developed expert systems. Via quantitative and qualitative experiments with
Claude Sonnet 3.7 and GPT-4.1, we show strong adherence to facts and semantic
coherence on our generated knowledge bases. We present a transparent hybrid
solution that combines the recall capacity of LLMs with the precision of
symbolic systems, thereby laying the foundation for dependable AI applications
in sensitive domains.

</details>


### [4] [Why Isn't Relational Learning Taking Over the World?](https://arxiv.org/abs/2507.13558)
*David Poole*

Main category: cs.AI

TL;DR: 论文探讨了AI应关注实体及其关系建模，而非仅关注像素和文字，并分析了关系学习未普及的原因及改进方向。


<details>
  <summary>Details</summary>
Motivation: 当前AI主要建模像素和文字，但世界由实体及其关系构成，应直接建模这些实体。关系学习虽重要，却未广泛应用。

Method: 通过分析关系学习（如统计关系AI）的现状，探讨其未普及的原因，并提出改进建议。

Result: 关系学习仅在少数受限关系中应用，需进一步研究以提升其影响力。

Conclusion: 关系学习应成为AI的核心方向，需更多研究以实现其潜力。

Abstract: AI seems to be taking over the world with systems that model pixels, words,
and phonemes. The world is arguably made up, not of pixels, words, and phonemes
but of entities (objects, things, including events) with properties and
relations among them. Surely we should model these, not the perception or
description of them. You might suspect that concentrating on modeling words and
pixels is because all of the (valuable) data in the world is in terms of text
and images. If you look into almost any company you will find their most
valuable data is in spreadsheets, databases and other relational formats. These
are not the form that are studied in introductory machine learning, but are
full of product numbers, student numbers, transaction numbers and other
identifiers that can't be interpreted naively as numbers. The field that
studies this sort of data has various names including relational learning,
statistical relational AI, and many others. This paper explains why relational
learning is not taking over the world -- except in a few cases with restricted
relations -- and what needs to be done to bring it to it's rightful prominence.

</details>


### [5] [BifrostRAG: Bridging Dual Knowledge Graphs for Multi-Hop Question Answering in Construction Safety](https://arxiv.org/abs/2507.13625)
*Yuxin Zhang,Xi Wang,Mo Hu,Zhenyu Zhang*

Main category: cs.AI

TL;DR: BifrostRAG是一种双图RAG系统，通过结合实体网络图和文档导航图，显著提升了多跳问答任务中的检索性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统RAG系统在处理复杂法规文本和多跳查询时的局限性。

Method: 提出BifrostRAG，结合实体网络图（语言关系）和文档导航图（文档结构），实现混合检索机制。

Result: 在多跳问题数据集上，BifrostRAG的精确率、召回率和F1分数分别为92.8%、85.5%和87.3%，显著优于基线方法。

Conclusion: BifrostRAG为复杂技术文档的检索提供了可迁移的解决方案，适用于知识密集型工程领域。

Abstract: Information retrieval and question answering from safety regulations are
essential for automated construction compliance checking but are hindered by
the linguistic and structural complexity of regulatory text. Many
compliance-related queries are multi-hop, requiring synthesis of information
across interlinked clauses. This poses a challenge for traditional
retrieval-augmented generation (RAG) systems. To overcome this, we introduce
BifrostRAG: a dual-graph RAG-integrated system that explicitly models both
linguistic relationships (via an Entity Network Graph) and document structure
(via a Document Navigator Graph). This architecture powers a hybrid retrieval
mechanism that combines graph traversal with vector-based semantic search,
enabling large language models to reason over both the meaning and the
structure of the text. Evaluation on a multi-hop question dataset shows that
BifrostRAG achieves 92.8 percent precision, 85.5 percent recall, and an F1
score of 87.3 percent. These results significantly outperform vector-only and
graph-only RAG baselines that represent current leading approaches. Error
analysis further highlights the comparative advantages of our hybrid method
over single-modality RAGs. These findings establish BifrostRAG as a robust
knowledge engine for LLM-driven compliance checking. Its dual-graph, hybrid
retrieval mechanism offers a transferable blueprint for navigating complex
technical documents across knowledge-intensive engineering domains.

</details>


### [6] [Buggy rule diagnosis for combined steps through final answer evaluation in stepwise tasks](https://arxiv.org/abs/2507.13651)
*Gerben van der Hoek,Johan Jeuring,Rogier Bos*

Main category: cs.AI

TL;DR: 论文探讨了基于最终答案的自动错误诊断方法，用于解决学生在智能辅导系统中组合多步任务时的错误诊断难题。


<details>
  <summary>Details</summary>
Motivation: 解决学生在组合多步任务时因路径组合爆炸导致的错误诊断困难。

Method: 设计了一种服务，通过分析学生的最终答案进行错误诊断，并在二次方程求解数据集上验证。

Result: 该方法能诊断29.4%的未诊断步骤，且与教师诊断结果97%一致。

Conclusion: 基于最终答案的错误诊断方法具有潜力，值得进一步探索。

Abstract: Many intelligent tutoring systems can support a student in solving a stepwise
task. When a student combines several steps in one step, the number of possible
paths connecting consecutive inputs may be very large. This combinatorial
explosion makes error diagnosis hard. Using a final answer to diagnose a
combination of steps can mitigate the combinatorial explosion, because there
are generally fewer possible (erroneous) final answers than (erroneous)
solution paths. An intermediate input for a task can be diagnosed by
automatically completing it according to the task solution strategy and
diagnosing this solution. This study explores the potential of automated error
diagnosis based on a final answer. We investigate the design of a service that
provides a buggy rule diagnosis when a student combines several steps. To
validate the approach, we apply the service to an existing dataset (n=1939) of
unique student steps when solving quadratic equations, which could not be
diagnosed by a buggy rule service that tries to connect consecutive inputs with
a single rule. Results show that final answer evaluation can diagnose 29,4% of
these steps. Moreover, a comparison of the generated diagnoses with teacher
diagnoses on a subset (n=115) shows that the diagnoses align in 97% of the
cases. These results can be considered a basis for further exploration of the
approach.

</details>


### [7] [Combining model tracing and constraint-based modeling for multistep strategy diagnoses](https://arxiv.org/abs/2507.13652)
*Gerben van der Hoek,Johan Jeuring,Rogier Bos*

Main category: cs.AI

TL;DR: 提出了一种结合模型追踪和约束建模的方法，用于诊断学生在多步任务中的输入，并在解决二次方程的实际数据中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 结合模型追踪和约束建模的优势，以更灵活地诊断学生输入，尤其是当学生将多个步骤合并为一步时。

Method: 通过定义约束作为学生输入与策略步骤的共同属性，设计了一个多步策略诊断系统，并在二次方程数据集上进行了验证。

Result: 系统诊断与教师编码在所有140个学生步骤中完全一致。

Conclusion: 该方法能够有效诊断学生输入，即使学生偏离策略或合并步骤，具有实际应用潜力。

Abstract: Model tracing and constraint-based modeling are two approaches to diagnose
student input in stepwise tasks. Model tracing supports identifying consecutive
problem-solving steps taken by a student, whereas constraint-based modeling
supports student input diagnosis even when several steps are combined into one
step. We propose an approach that merges both paradigms. By defining
constraints as properties that a student input has in common with a step of a
strategy, it is possible to provide a diagnosis when a student deviates from a
strategy even when the student combines several steps. In this study we explore
the design of a system for multistep strategy diagnoses, and evaluate these
diagnoses. As a proof of concept, we generate diagnoses for an existing dataset
containing steps students take when solving quadratic equations (n=2136). To
compare with human diagnoses, two teachers coded a random sample of deviations
(n=70) and applications of the strategy (n=70). Results show that that the
system diagnosis aligned with the teacher coding in all of the 140 student
steps.

</details>


### [8] [DailyLLM: Context-Aware Activity Log Generation Using Multi-Modal Sensors and LLMs](https://arxiv.org/abs/2507.13737)
*Ye Tian,Xiaoyuan Ren,Zihao Wang,Onat Gungor,Xiaofan Yu,Tajana Rosing*

Main category: cs.AI

TL;DR: DailyLLM是一个基于轻量级LLM的框架，通过整合位置、运动、环境和生理四个维度的上下文信息，显著提升了活动日志生成的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有活动日志生成方法在准确性、效率和语义丰富性方面存在明显不足，而LLM的语义理解和生成能力为解决这些问题提供了新机会。

Method: DailyLLM采用轻量级LLM框架，结合结构化提示和高效特征提取，实现高级活动理解。

Result: DailyLLM在BERTScore精度上比70B参数的SOTA基线提高了17%，推理速度提升近10倍，且能在个人电脑和树莓派上高效部署。

Conclusion: DailyLLM通过多维度上下文整合和轻量级设计，显著提升了活动日志生成的性能，为实际应用提供了高效解决方案。

Abstract: Rich and context-aware activity logs facilitate user behavior analysis and
health monitoring, making them a key research focus in ubiquitous computing.
The remarkable semantic understanding and generation capabilities of Large
Language Models (LLMs) have recently created new opportunities for activity log
generation. However, existing methods continue to exhibit notable limitations
in terms of accuracy, efficiency, and semantic richness. To address these
challenges, we propose DailyLLM. To the best of our knowledge, this is the
first log generation and summarization system that comprehensively integrates
contextual activity information across four dimensions: location, motion,
environment, and physiology, using only sensors commonly available on
smartphones and smartwatches. To achieve this, DailyLLM introduces a
lightweight LLM-based framework that integrates structured prompting with
efficient feature extraction to enable high-level activity understanding.
Extensive experiments demonstrate that DailyLLM outperforms state-of-the-art
(SOTA) log generation methods and can be efficiently deployed on personal
computers and Raspberry Pi. Utilizing only a 1.5B-parameter LLM model, DailyLLM
achieves a 17% improvement in log generation BERTScore precision compared to
the 70B-parameter SOTA baseline, while delivering nearly 10x faster inference
speed.

</details>


### [9] [OntView: What you See is What you Meant](https://arxiv.org/abs/2507.13759)
*Carlos Bobed,Carlota Quintana,Eduardo Mena,Jorge Bobed,Fernando Bobillo*

Main category: cs.AI

TL;DR: OntView是一个创新的本体可视化工具，通过直观的图形界面和动态简化视图，解决了现有工具在展示大型本体结构时的不足。


<details>
  <summary>Details</summary>
Motivation: 现有本体可视化工具无法有效展示复杂本体结构，限制了用户对依赖关系和属性的理解。

Method: OntView采用DL推理器，遵循“所见即所意”原则，支持GCI可视化，并提供动态简化视图功能。

Result: OntView成功实现了直观的本体可视化，并通过开源发布为社区提供支持。

Conclusion: OntView填补了本体可视化工具的空白，提升了用户对复杂本体结构的理解能力。

Abstract: In the field of knowledge management and computer science, ontologies provide
a structured framework for modeling domain-specific knowledge by defining
concepts and their relationships. However, the lack of tools that provide
effective visualization is still a significant challenge. While numerous
ontology editors and viewers exist, most of them fail to graphically represent
ontology structures in a meaningful and non-overwhelming way, limiting users'
ability to comprehend dependencies and properties within large ontological
frameworks.
  In this paper, we present OntView, an ontology viewer that is designed to
provide users with an intuitive visual representation of ontology concepts and
their formal definitions through a user-friendly interface. Building on the use
of a DL reasoner, OntView follows a "What you see is what you meant" paradigm,
showing the actual inferred knowledge. One key aspect for this is its ability
to visualize General Concept Inclusions (GCI), a feature absent in existing
visualization tools. Moreover, to avoid a possible information overload,
OntView also offers different ways to show a simplified view of the ontology
by: 1) creating ontology summaries by assessing the importance of the concepts
(according to different available algorithms), 2) focusing the visualization on
the existing TBox elements between two given classes and 3) allowing to
hide/show different branches in a dynamic way without losing the semantics.
OntView has been released with an open-source license for the whole community.

</details>


### [10] [From Extraction to Synthesis: Entangled Heuristics for Agent-Augmented Strategic Reasoning](https://arxiv.org/abs/2507.13768)
*Renato Ghisellini,Remo Pareschi,Marco Pedroni,Giovanni Battista Raggi*

Main category: cs.AI

TL;DR: 提出了一种结合启发式提取、语义激活和组合合成的混合架构，用于增强代理的战略推理能力。


<details>
  <summary>Details</summary>
Motivation: 传统决策引擎通常选择最佳规则，而本研究旨在通过语义交互建模和修辞框架，将冲突的启发式融合为连贯且上下文敏感的叙述。

Method: 结合经典军事理论和现代企业战略，通过语义相互依赖的过程激活和组合多个启发式。

Result: 通过Meta与FTC的案例研究验证了框架，并初步通过语义指标进行评估。

Conclusion: 讨论了动态干扰调优等局限性和扩展方向。

Abstract: We present a hybrid architecture for agent-augmented strategic reasoning,
combining heuristic extraction, semantic activation, and compositional
synthesis. Drawing on sources ranging from classical military theory to
contemporary corporate strategy, our model activates and composes multiple
heuristics through a process of semantic interdependence inspired by research
in quantum cognition. Unlike traditional decision engines that select the best
rule, our system fuses conflicting heuristics into coherent and
context-sensitive narratives, guided by semantic interaction modeling and
rhetorical framing. We demonstrate the framework via a Meta vs. FTC case study,
with preliminary validation through semantic metrics. Limitations and
extensions (e.g., dynamic interference tuning) are discussed.

</details>


### [11] [When Speed meets Accuracy: an Efficient and Effective Graph Model for Temporal Link Prediction](https://arxiv.org/abs/2507.13825)
*Haoyang Li,Yuming Xu,Yiming Li,Hanmo Liu,Darian Li,Chen Jason Zhang,Lei Chen,Qing Li*

Main category: cs.AI

TL;DR: EAGLE是一个轻量级框架，用于动态图中的时间链路预测，结合短期时间新近性和长期全局结构模式，显著提高了效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有T-GNN在建模时间和结构依赖时计算开销大，存在可扩展性和效率问题。

Method: EAGLE通过时间感知模块和结构感知模块，结合自适应权重机制，避免复杂计算。

Result: 在七个真实世界时间图上，EAGLE在性能和效率上均优于现有T-GNN，速度提升50倍以上。

Conclusion: EAGLE通过轻量级设计有效解决了T-GNN的计算效率问题，同时保持高性能。

Abstract: Temporal link prediction in dynamic graphs is a critical task with
applications in diverse domains such as social networks, recommendation
systems, and e-commerce platforms. While existing Temporal Graph Neural
Networks (T-GNNs) have achieved notable success by leveraging complex
architectures to model temporal and structural dependencies, they often suffer
from scalability and efficiency challenges due to high computational overhead.
In this paper, we propose EAGLE, a lightweight framework that integrates
short-term temporal recency and long-term global structural patterns. EAGLE
consists of a time-aware module that aggregates information from a node's most
recent neighbors to reflect its immediate preferences, and a structure-aware
module that leverages temporal personalized PageRank to capture the influence
of globally important nodes. To balance these attributes, EAGLE employs an
adaptive weighting mechanism to dynamically adjust their contributions based on
data characteristics. Also, EAGLE eliminates the need for complex multi-hop
message passing or memory-intensive mechanisms, enabling significant
improvements in efficiency. Extensive experiments on seven real-world temporal
graphs demonstrate that EAGLE consistently achieves superior performance
against state-of-the-art T-GNNs in both effectiveness and efficiency,
delivering more than a 50x speedup over effective transformer-based T-GNNs.

</details>


### [12] [Causal Knowledge Transfer for Multi-Agent Reinforcement Learning in Dynamic Environments](https://arxiv.org/abs/2507.13846)
*Kathrin Korte,Christian Medeiros Adriano,Sona Ghahremani,Holger Giese*

Main category: cs.AI

TL;DR: 本文提出了一种因果知识转移框架，帮助多智能体强化学习（MARL）在非静态环境中高效共享知识，减少重新训练成本。


<details>
  <summary>Details</summary>
Motivation: 传统MARL知识转移方法在非静态环境中泛化能力不足，智能体需要高成本重新训练。本文旨在通过因果知识转移解决这一问题。

Method: 引入因果知识转移框架，将碰撞建模为因果干预，生成恢复动作宏（macro），并在智能体间在线共享，实现零样本应用。

Result: 实验表明：(1) 智能体在新环境中能填补随机探索与完全重新训练策略之间约一半的差距；(2) 因果知识转移效果受环境复杂度和智能体目标异质性影响。

Conclusion: 因果知识转移为MARL在非静态环境中的知识共享提供了高效解决方案，减少了重新训练需求。

Abstract: [Context] Multi-agent reinforcement learning (MARL) has achieved notable
success in environments where agents must learn coordinated behaviors. However,
transferring knowledge across agents remains challenging in non-stationary
environments with changing goals. [Problem] Traditional knowledge transfer
methods in MARL struggle to generalize, and agents often require costly
retraining to adapt. [Approach] This paper introduces a causal knowledge
transfer framework that enables RL agents to learn and share compact causal
representations of paths within a non-stationary environment. As the
environment changes (new obstacles), agents' collisions require adaptive
recovery strategies. We model each collision as a causal intervention
instantiated as a sequence of recovery actions (a macro) whose effect
corresponds to a causal knowledge of how to circumvent the obstacle while
increasing the chances of achieving the agent's goal (maximizing cumulative
reward). This recovery action macro is transferred online from a second agent
and is applied in a zero-shot fashion, i.e., without retraining, just by
querying a lookup model with local context information (collisions). [Results]
Our findings reveal two key insights: (1) agents with heterogeneous goals were
able to bridge about half of the gap between random exploration and a fully
retrained policy when adapting to new environments, and (2) the impact of
causal knowledge transfer depends on the interplay between environment
complexity and agents' heterogeneous goals.

</details>


### [13] [Large Language Models as Innovators: A Framework to Leverage Latent Space Exploration for Novelty Discovery](https://arxiv.org/abs/2507.13874)
*Mateusz Bystroński,Mikołaj Hołysz,Grzegorz Piotrowski,Nitesh V. Chawla,Tomasz Kajdanowicz*

Main category: cs.AI

TL;DR: 提出了一种模型无关的潜在空间创意框架，通过导航连续嵌入空间实现可控、可扩展的创意生成，无需手工规则，适用于多领域和任务。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型（LLMs）在生成新颖且相关内容时的局限性，避免依赖领域特定启发式或结构化提示。

Method: 提出模型无关的潜在空间创意框架，通过连续嵌入空间导航实现创意生成。

Result: 初步结果显示该框架作为通用人机协作创意工具的潜力。

Conclusion: 该框架为可控、可扩展的创意生成提供了新方向，适用于多领域和任务。

Abstract: Innovative idea generation remains a core challenge in AI, as large language
models (LLMs) often struggle to produce outputs that are both novel and
relevant. Despite their fluency, LLMs tend to replicate patterns seen during
training, limiting their ability to diverge creatively without extensive prompt
engineering. Prior work has addressed this through domain-specific heuristics
and structured prompting pipelines, but such solutions are brittle and
difficult to generalize. In this paper, we propose a model-agnostic
latent-space ideation framework that enables controlled, scalable creativity by
navigating the continuous embedding space of ideas. Unlike prior methods, our
framework requires no handcrafted rules and adapts easily to different domains,
input formats, and creative tasks. This paper introduces an early-stage
prototype of our method, outlining the conceptual framework and preliminary
results highlighting its potential as a general-purpose co-ideator for human-AI
collaboration.

</details>


### [14] [Cross-modal Causal Intervention for Alzheimer's Disease Prediction](https://arxiv.org/abs/2507.13956)
*Yutao Jin,Haowen Xiao,Jielei Chu,Fengmao Lv,Yuxiao Li,Tianrui Li*

Main category: cs.AI

TL;DR: 提出了一种名为ADPC的视觉-语言因果干预框架，用于阿尔茨海默病的早期诊断，通过消除混杂因素提升分类性能。


<details>
  <summary>Details</summary>
Motivation: 早期诊断阿尔茨海默病具有挑战性，主要因多模态数据的选择偏差和变量间复杂关系导致混杂因素。

Method: 结合MRI、fMRI图像和LLM生成的文本数据，通过因果干预消除混杂因素，分类CN/MCI/AD。

Result: 实验表明ADPC在CN/MCI/AD分类中表现优异，达到SOTA指标。

Conclusion: 研究展示了因果推理与多模态学习结合在神经疾病诊断中的潜力。

Abstract: Mild Cognitive Impairment (MCI) serves as a prodromal stage of Alzheimer's
Disease (AD), where early identification and intervention can effectively slow
the progression to dementia. However, diagnosing AD remains a significant
challenge in neurology due to the confounders caused mainly by the selection
bias of multimodal data and the complex relationships between variables. To
address these issues, we propose a novel visual-language causal intervention
framework named Alzheimer's Disease Prediction with Cross-modal Causal
Intervention (ADPC) for diagnostic assistance. Our ADPC employs large language
model (LLM) to summarize clinical data under strict templates, maintaining
structured text outputs even with incomplete or unevenly distributed datasets.
The ADPC model utilizes Magnetic Resonance Imaging (MRI), functional MRI (fMRI)
images and textual data generated by LLM to classify participants into
Cognitively Normal (CN), MCI, and AD categories. Because of the presence of
confounders, such as neuroimaging artifacts and age-related biomarkers,
non-causal models are likely to capture spurious input-output correlations,
generating less reliable results. Our framework implicitly eliminates
confounders through causal intervention. Experimental results demonstrate the
outstanding performance of our method in distinguishing CN/MCI/AD cases,
achieving state-of-the-art (SOTA) metrics across most evaluation metrics. The
study showcases the potential of integrating causal reasoning with multi-modal
learning for neurological disease diagnosis.

</details>


### [15] [Towards Constraint Temporal Answer Set Programming](https://arxiv.org/abs/2507.13958)
*Pedro Cabalar,Martín Diéguez,François Olivier,Torsten Schaub,Igor Stéphan*

Main category: cs.AI

TL;DR: 提出了一种新的基于时间和约束的逻辑扩展，用于解决动态系统中的高分辨率推理问题。


<details>
  <summary>Details</summary>
Motivation: 解决逻辑方法（如ASP）在动态系统中高分辨率时间和数值推理的挑战。

Method: 结合线性时间逻辑和非单调约束逻辑，创建了一种新的非单调时间约束推理框架。

Result: 建立了一个适用于ASP的复杂动态系统高分辨率推理基础逻辑框架。

Conclusion: 该框架为ASP范式下的高分辨率动态系统推理提供了理论基础。

Abstract: Reasoning about dynamic systems with a fine-grained temporal and numeric
resolution presents significant challenges for logic-based approaches like
Answer Set Programming (ASP). To address this, we introduce and elaborate upon
a novel temporal and constraint-based extension of the logic of Here-and-There
and its nonmonotonic equilibrium extension, representing, to the best of our
knowledge, the first approach to nonmonotonic temporal reasoning with
constraints specifically tailored for ASP. This expressive system is achieved
by a synergistic combination of two foundational ASP extensions: the
linear-time logic of Here-and-There, providing robust nonmonotonic temporal
reasoning capabilities, and the logic of Here-and-There with constraints,
enabling the direct integration and manipulation of numeric constraints, among
others. This work establishes the foundational logical framework for tackling
complex dynamic systems with high resolution within the ASP paradigm.

</details>


### [16] [KROMA: Ontology Matching with Knowledge Retrieval and Large Language Models](https://arxiv.org/abs/2507.14032)
*Lam Nguyen,Erika Barcelos,Roger French,Yinghui Wu*

Main category: cs.AI

TL;DR: KROMA是一个新的本体匹配框架，利用大型语言模型（LLMs）和检索增强生成（RAG）动态丰富语义上下文，通过实验验证其优于传统和基于LLM的方法。


<details>
  <summary>Details</summary>
Motivation: 现有本体匹配系统依赖手工规则或专用模型，适应性有限，KROMA旨在通过LLMs和RAG提升语义互操作性。

Method: KROMA结合了基于双相似度的概念匹配和轻量级本体优化步骤，减少LLMs的通信开销，并通过知识检索和上下文增强优化性能。

Result: 实验表明，KROMA在多个基准数据集上优于传统和最新的基于LLM的方法，同时保持低通信开销。

Conclusion: KROMA展示了知识检索、提示增强和本体优化在大规模本体匹配中的可行性和优势。

Abstract: Ontology Matching (OM) is a cornerstone task of semantic interoperability,
yet existing systems often rely on handcrafted rules or specialized models with
limited adaptability. We present KROMA, a novel OM framework that harnesses
Large Language Models (LLMs) within a Retrieval-Augmented Generation (RAG)
pipeline to dynamically enrich the semantic context of OM tasks with
structural, lexical, and definitional knowledge. To optimize both performance
and efficiency, KROMA integrates a bisimilarity-based concept matching and a
lightweight ontology refinement step, which prune candidate concepts and
substantially reduce the communication overhead from invoking LLMs. Through
experiments on multiple benchmark datasets, we show that integrating knowledge
retrieval with context-augmented LLMs significantly enhances ontology matching,
outperforming both classic OM systems and cutting-edge LLM-based approaches
while keeping communication overhead comparable. Our study highlights the
feasibility and benefit of the proposed optimization techniques (targeted
knowledge retrieval, prompt enrichment, and ontology refinement) for ontology
matching at scale.

</details>


### [17] [Glucose-ML: A collection of longitudinal diabetes datasets for development of robust AI solutions](https://arxiv.org/abs/2507.14077)
*Temiloluwa Prioleau,Baiying Lu,Yanjun Cui*

Main category: cs.AI

TL;DR: Glucose-ML是一个包含10个公开糖尿病数据集的集合，旨在加速透明、可重复和稳健的AI解决方案开发，并提供数据选择和血糖预测的基准。


<details>
  <summary>Details</summary>
Motivation: 高质量糖尿病数据集的缺乏阻碍了稳健AI解决方案的开发，Glucose-ML旨在解决这一问题。

Method: 收集并公开10个糖尿病数据集，进行数据比较分析，并通过血糖预测案例研究提供基准。

Result: 同一算法在不同数据集上的预测结果差异显著，研究结果为开发稳健AI解决方案提供了建议。

Conclusion: Glucose-ML为糖尿病AI研究提供了丰富的数据资源和开发指导，推动了该领域的透明性和可重复性。

Abstract: Artificial intelligence (AI) algorithms are a critical part of
state-of-the-art digital health technology for diabetes management. Yet, access
to large high-quality datasets is creating barriers that impede development of
robust AI solutions. To accelerate development of transparent, reproducible,
and robust AI solutions, we present Glucose-ML, a collection of 10 publicly
available diabetes datasets, released within the last 7 years (i.e., 2018 -
2025). The Glucose-ML collection comprises over 300,000 days of continuous
glucose monitor (CGM) data with a total of 38 million glucose samples collected
from 2500+ people across 4 countries. Participants include persons living with
type 1 diabetes, type 2 diabetes, prediabetes, and no diabetes. To support
researchers and innovators with using this rich collection of diabetes
datasets, we present a comparative analysis to guide algorithm developers with
data selection. Additionally, we conduct a case study for the task of blood
glucose prediction - one of the most common AI tasks within the field. Through
this case study, we provide a benchmark for short-term blood glucose prediction
across all 10 publicly available diabetes datasets within the Glucose-ML
collection. We show that the same algorithm can have significantly different
prediction results when developed/evaluated with different datasets. Findings
from this study are then used to inform recommendations for developing robust
AI solutions within the diabetes or broader health domain. We provide direct
links to each longitudinal diabetes dataset in the Glucose-ML collection and
openly provide our code.

</details>


### [18] [Generative AI-Driven High-Fidelity Human Motion Simulation](https://arxiv.org/abs/2507.14097)
*Hari Iyer,Neel Macwan,Atharva Jitendra Hude,Heejin Jeong,Shenghan Guo*

Main category: cs.AI

TL;DR: G-AI-HMS利用生成式AI提升工业任务中的人体运动模拟质量，通过文本到运动和计算机视觉验证，显著减少了运动误差和时间错位。


<details>
  <summary>Details</summary>
Motivation: 现有的人体运动模拟方法运动保真度低，G-AI-HMS旨在通过生成式AI提升模拟质量。

Method: 结合文本到文本和文本到运动模型，利用MotionGPT和计算机视觉验证运动相似性。

Result: 在八项任务中，AI增强的运动在多数场景下误差更低，显著减少了关节误差和时间错位。

Conclusion: G-AI-HMS显著提升了运动模拟的准确性，适用于工业任务评估。

Abstract: Human motion simulation (HMS) supports cost-effective evaluation of worker
behavior, safety, and productivity in industrial tasks. However, existing
methods often suffer from low motion fidelity. This study introduces
Generative-AI-Enabled HMS (G-AI-HMS), which integrates text-to-text and
text-to-motion models to enhance simulation quality for physical tasks.
G-AI-HMS tackles two key challenges: (1) translating task descriptions into
motion-aware language using Large Language Models aligned with MotionGPT's
training vocabulary, and (2) validating AI-enhanced motions against real human
movements using computer vision. Posture estimation algorithms are applied to
real-time videos to extract joint landmarks, and motion similarity metrics are
used to compare them with AI-enhanced sequences. In a case study involving
eight tasks, the AI-enhanced motions showed lower error than human created
descriptions in most scenarios, performing better in six tasks based on spatial
accuracy, four tasks based on alignment after pose normalization, and seven
tasks based on overall temporal similarity. Statistical analysis showed that
AI-enhanced prompts significantly (p $<$ 0.0001) reduced joint error and
temporal misalignment while retaining comparable posture accuracy.

</details>


### [19] [Automated Interpretation of Non-Destructive Evaluation Contour Maps Using Large Language Models for Bridge Condition Assessment](https://arxiv.org/abs/2507.14107)
*Viraj Nishesh Darji,Callie C. Liao,Duoduo Liao*

Main category: cs.AI

TL;DR: 该研究探讨了利用大型语言模型（LLMs）自动解释无损评估（NDE）轮廓图，以提高桥梁维护效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 桥梁维护和安全至关重要，但传统NDE数据分析耗时且依赖专家，决策可能延迟。LLMs的进展为自动化分析提供了新途径。

Method: 研究设计了针对NDE轮廓图的提示词，评估了多个LLM模型在描述图像、识别缺陷和提供建议方面的能力。

Result: 9个模型中4个表现优异，尤其是ChatGPT-4和Claude 3.5 Sonnet，能生成更有效的总结和详细分析。

Conclusion: LLMs可显著提升桥梁维护效率和准确性，为基础设施管理提供创新支持。

Abstract: Bridge maintenance and safety are essential for transportation authorities,
and Non-Destructive Evaluation (NDE) techniques are critical to assessing
structural integrity. However, interpreting NDE data can be time-consuming and
requires expertise, potentially delaying decision-making. Recent advancements
in Large Language Models (LLMs) offer new ways to automate and improve this
analysis. This pilot study introduces a holistic assessment of LLM capabilities
for interpreting NDE contour maps and demonstrates the effectiveness of LLMs in
providing detailed bridge condition analyses. It establishes a framework for
integrating LLMs into bridge inspection workflows, indicating that LLM-assisted
analysis can enhance efficiency without compromising accuracy. In this study,
several LLMs are explored with prompts specifically designed to enhance the
quality of image descriptions, which are applied to interpret five different
NDE contour maps obtained through technologies for assessing bridge conditions.
Each LLM model is evaluated based on its ability to produce detailed
descriptions, identify defects, provide actionable recommendations, and
demonstrate overall accuracy. The research indicates that four of the nine
models provide better image descriptions, effectively covering a wide range of
topics related to the bridge's condition. The outputs from these four models
are summarized using five different LLMs to form a comprehensive overview of
the bridge. Notably, LLMs ChatGPT-4 and Claude 3.5 Sonnet generate more
effective summaries. The findings suggest that LLMs have the potential to
significantly improve efficiency and accuracy. This pilot study presents an
innovative approach that leverages LLMs for image captioning in parallel and
summarization, enabling faster decision-making in bridge maintenance and
enhancing infrastructure management and safety assessments.

</details>


### [20] [CUDA-L1: Improving CUDA Optimization via Contrastive Reinforcement Learning](https://arxiv.org/abs/2507.14111)
*Xiaoya Li,Xiaofei Sun,Albert Wang,Jiwei Li,Chris Shum*

Main category: cs.AI

TL;DR: CUDA-L1是一种基于强化学习的自动化CUDA优化框架，显著提升了CUDA内核的性能，并展示了跨GPU架构的优异可移植性。


<details>
  <summary>Details</summary>
Motivation: 由于大型语言模型的快速发展，对GPU计算资源的需求激增，迫切需要自动化CUDA优化策略。

Method: CUDA-L1采用强化学习框架，通过速度提升奖励信号训练模型，无需人工专业知识。

Result: 在NVIDIA A100上训练后，CUDA-L1在KernelBench的250个CUDA内核上平均提速17.7倍，峰值达449倍，并在其他GPU架构上表现优异。

Conclusion: CUDA-L1展示了强化学习在自动化CUDA优化中的潜力，有望显著提升GPU效率并缓解计算资源压力。

Abstract: The exponential growth in demand for GPU computing resources, driven by the
rapid advancement of Large Language Models, has created an urgent need for
automated CUDA optimization strategies. While recent advances in LLMs show
promise for code generation, current SOTA models (e.g. R1, o1) achieve low
success rates in improving CUDA speed. In this paper, we introduce CUDA-L1, an
automated reinforcement learning framework for CUDA optimization.
  CUDA-L1 achieves performance improvements on the CUDA optimization task:
trained on NVIDIA A100, it delivers an average speedup of x17.7 across all 250
CUDA kernels of KernelBench, with peak speedups reaching x449. Furthermore, the
model also demonstrates excellent portability across GPU architectures,
achieving average speedups of x17.8 on H100, x19.0 on RTX 3090, x16.5 on L40,
x14.7 on H800, and x13.9 on H20 despite being optimized specifically for A100.
Beyond these benchmark results, CUDA-L1 demonstrates several remarkable
properties: 1) Discovers a variety of CUDA optimization techniques and learns
to combine them strategically to achieve optimal performance; 2) Uncovers
fundamental principles of CUDA optimization; 3) Identifies non-obvious
performance bottlenecks and rejects seemingly beneficial optimizations that
harm performance.
  The capabilities of CUDA-L1 demonstrate that reinforcement learning can
transform an initially poor-performing LLM into an effective CUDA optimizer
through speedup-based reward signals alone, without human expertise or domain
knowledge. More importantly, the trained RL model extend the acquired reasoning
abilities to new kernels. This paradigm opens possibilities for automated
optimization of CUDA operations, and holds promise to substantially promote GPU
efficiency and alleviate the rising pressure on GPU computing resources.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [21] [Adaptive Linguistic Prompting (ALP) Enhances Phishing Webpage Detection in Multimodal Large Language Models](https://arxiv.org/abs/2507.13357)
*Atharva Bhargude,Ishan Gonehal,Chandler Haney,Dave Yoon,Kevin Zhu,Aaron Sandoval,Sean O'Brien,Kaustubh Vinnakota*

Main category: cs.CL

TL;DR: 该研究提出了一种名为ALP的少样本自适应语言提示方法，利用多模态大语言模型（如GPT-4o和Gemini 1.5 Pro）检测钓鱼网页，显著提升了检测准确率。


<details>
  <summary>Details</summary>
Motivation: 钓鱼攻击是严重的网络安全威胁，需要自适应检测技术。

Method: ALP是一种结构化语义推理方法，通过分析文本欺骗、紧急信号和操纵性措辞，结合文本、视觉和URL分析，构建统一模型。

Result: 实验显示ALP显著提升了钓鱼检测准确率，F1分数达0.93，优于传统方法。

Conclusion: ALP为基于语言的钓鱼检测系统提供了更强大、可解释和自适应的基础。

Abstract: Phishing attacks represent a significant cybersecurity threat, necessitating
adaptive detection techniques. This study explores few-shot Adaptive Linguistic
Prompting (ALP) in detecting phishing webpages through the multimodal
capabilities of state-of-the-art large language models (LLMs) such as GPT-4o
and Gemini 1.5 Pro. ALP is a structured semantic reasoning method that guides
LLMs to analyze textual deception by breaking down linguistic patterns,
detecting urgency cues, and identifying manipulative diction commonly found in
phishing content. By integrating textual, visual, and URL-based analysis, we
propose a unified model capable of identifying sophisticated phishing attempts.
Our experiments demonstrate that ALP significantly enhances phishing detection
accuracy by guiding LLMs through structured reasoning and contextual analysis.
The findings highlight the potential of ALP-integrated multimodal LLMs to
advance phishing detection frameworks, achieving an F1-score of 0.93,
surpassing traditional approaches. These results establish a foundation for
more robust, interpretable, and adaptive linguistic-based phishing detection
systems using LLMs.

</details>


### [22] [Persona-Based Synthetic Data Generation Using Multi-Stage Conditioning with Large Language Models for Emotion Recognition](https://arxiv.org/abs/2507.13380)
*Keito Inoshita,Rushia Harada*

Main category: cs.CL

TL;DR: PersonaGen是一个基于大型语言模型（LLM）的多阶段角色条件框架，用于生成情感丰富的文本，以解决情感识别领域高质量数据稀缺的问题。


<details>
  <summary>Details</summary>
Motivation: 情感识别领域缺乏高质量、多样化的情感数据集，且情感表达受个体特质、社会文化背景和情境因素影响，导致数据收集困难。

Method: PersonaGen通过结合人口统计属性、社会文化背景和详细情境上下文构建虚拟角色，指导情感表达生成。

Result: 实验表明，PersonaGen在生成多样、连贯且具有区分性的情感表达方面显著优于基线方法。

Conclusion: PersonaGen可作为增强或替代真实情感数据集的强大工具。

Abstract: In the field of emotion recognition, the development of high-performance
models remains a challenge due to the scarcity of high-quality, diverse
emotional datasets. Emotional expressions are inherently subjective, shaped by
individual personality traits, socio-cultural backgrounds, and contextual
factors, making large-scale, generalizable data collection both ethically and
practically difficult. To address this issue, we introduce PersonaGen, a novel
framework for generating emotionally rich text using a Large Language Model
(LLM) through multi-stage persona-based conditioning. PersonaGen constructs
layered virtual personas by combining demographic attributes, socio-cultural
backgrounds, and detailed situational contexts, which are then used to guide
emotion expression generation. We conduct comprehensive evaluations of the
generated synthetic data, assessing semantic diversity through clustering and
distributional metrics, human-likeness via LLM-based quality scoring, realism
through comparison with real-world emotion corpora, and practical utility in
downstream emotion classification tasks. Experimental results show that
PersonaGen significantly outperforms baseline methods in generating diverse,
coherent, and discriminative emotion expressions, demonstrating its potential
as a robust alternative for augmenting or replacing real-world emotional
datasets.

</details>


### [23] [SAFT: Structure-Aware Fine-Tuning of LLMs for AMR-to-Text Generation](https://arxiv.org/abs/2507.13381)
*Rafiq Kamel,Filippo Guerranti,Simon Geisler,Stephan Günnemann*

Main category: cs.CL

TL;DR: SAFT是一种结构感知的微调方法，通过注入图拓扑信息到预训练的大语言模型（LLMs）中，显著提升了AMR到文本生成的性能。


<details>
  <summary>Details</summary>
Motivation: 当前方法在处理AMR（抽象意义表示）时，常忽略其图结构信息或使用与标准LLMs不兼容的架构，限制了性能。

Method: SAFT通过计算方向敏感的位置编码（基于磁拉普拉斯变换的AMR）并将其投影到LLM的嵌入空间中，无需改变模型架构。

Result: SAFT在AMR 3.0上实现了3.5 BLEU的提升，性能增益随图复杂度增加而显著。

Conclusion: SAFT为结构化数据与语言模型的结合提供了一种通用且高效的途径。

Abstract: Large Language Models (LLMs) are increasingly applied to tasks involving
structured inputs such as graphs. Abstract Meaning Representations (AMRs),
which encode rich semantics as directed graphs, offer a rigorous testbed for
evaluating LLMs on text generation from such structures. Yet, current methods
often arbitrarily linearize AMRs, discarding key structural cues, or rely on
architectures incompatible with standard LLMs. We introduce SAFT, a
structure-aware fine-tuning approach that injects graph topology into
pretrained LLMs without architectural changes. We compute direction-sensitive
positional encodings from the magnetic Laplacian of transformed AMRs and
project them into the embedding space of the LLM. While possibly applicable to
any graph-structured inputs, we focus on AMR-to-text generation as a
representative and challenging benchmark. SAFT sets a new state-of-the-art on
AMR 3.0 with a 3.5 BLEU improvement over baselines. Gains scale with graph
complexity, highlighting the value of structure-aware representations in
enhancing LLM performance. SAFT offers a general and effective pathway for
bridging structured data and language models.

</details>


### [24] [Context-Based Fake News Detection using Graph Based Approach: ACOVID-19 Use-case](https://arxiv.org/abs/2507.13382)
*Chandrashekar Muniyappa,Sirisha Velampalli*

Main category: cs.CL

TL;DR: 论文提出了一种基于图的假新闻检测方法，利用NLP技术将新闻转化为图结构，并通过MDL-GBAD算法挖掘异常模式。


<details>
  <summary>Details</summary>
Motivation: 假新闻在数字时代传播迅速，亟需有效方法进行检测。

Method: 使用Kaggle数据集和COVID-19相关新闻，通过NLP将新闻转化为图结构，应用MDL-GBAD算法检测异常模式。

Result: 方法能够识别数据集中的规范模式并发现偏离这些模式的异常。

Conclusion: 基于图的方法在处理复杂上下文数据时表现出色，能有效检测假新闻。

Abstract: In today\'s digital world, fake news is spreading with immense speed. Its a
significant concern to address. In this work, we addressed that challenge using
novel graph based approach. We took dataset from Kaggle that contains real and
fake news articles. To test our approach we incorporated recent covid-19
related news articles that contains both genuine and fake news that are
relevant to this problem. This further enhances the dataset as well instead of
relying completely on the original dataset. We propose a contextual graph-based
approach to detect fake news articles. We need to convert news articles into
appropriate schema, so we leverage Natural Language Processing (NLP) techniques
to transform news articles into contextual graph structures. We then apply the
Minimum Description Length (MDL)-based Graph-Based Anomaly Detection (GBAD)
algorithm for graph mining. Graph-based methods are particularly effective for
handling rich contextual data, as they enable the discovery of complex patterns
that traditional query-based or statistical techniques might overlook. Our
proposed approach identifies normative patterns within the dataset and
subsequently uncovers anomalous patterns that deviate from these established
norms.

</details>


### [25] [PARAM-1 BharatGen 2.9B Model](https://arxiv.org/abs/2507.13390)
*Kundeshwar Pundalik,Piyush Sawarkar,Nihar Sahoo,Abhishek Shinde,Prateek Chanda,Vedant Goswami,Ajay Nagpal,Atul Singh,Viraj Thakur,Vijay Dewane,Aamod Thakur,Bhargav Patel,Smita Gautam,Bhagwan Panditi,Shyam Pawar,Madhav Kotcha,Suraj Racha,Saral Sureka,Pankaj Singh,Rishi Bal,Rohit Saluja,Ganesh Ramakrishnan*

Main category: cs.CL

TL;DR: PARAM-1是一个针对印度语言多样性的2.9B参数语言模型，专注于印地语和英语，通过公平表示、适应性分词和文化对齐评估实现多样性。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型（LLMs）在英语中心化设计中对印度多语言环境的忽视问题。

Method: 训练一个基于印地语和英语的双语数据集，采用公平表示、适应性分词和文化对齐评估的设计原则。

Result: PARAM-1既是一个通用模型，也是印度中心应用的稳健基线。

Conclusion: PARAM-1为公平基础建模提供了设计优先的蓝图。

Abstract: Large Language Models (LLMs) have emerged as powerful general-purpose
reasoning systems, yet their development remains dominated by English-centric
data, architectures, and optimization paradigms. This exclusionary design
results in structural under-representation of linguistically diverse regions
such as India, where over 20 official languages and 100+ dialects coexist
alongside phenomena like code-switching and diglossia. We introduce PARAM-1, a
2.9B parameter decoder-only, text-only language model trained from scratch with
an explicit architectural and linguistic focus on Indian diversity. PARAM-1 is
trained on a bilingual dataset consisting of only Hindi and English,
constructed with a strong focus on fact-rich, high-quality content. It is
guided by three core principles: equitable representation of Indic languages
through a 25% corpus allocation; tokenization fairness via a SentencePiece
tokenizer adapted to Indian morphological structures; and culturally aligned
evaluation benchmarks across IndicQA, code-mixed reasoning, and
socio-linguistic robustness tasks. By embedding diversity at the pretraining
level-rather than deferring it to post-hoc alignment-PARAM-1 offers a
design-first blueprint for equitable foundation modeling. Our results
demonstrate that it serves as both a competent general-purpose model and a
robust baseline for India-centric applications.

</details>


### [26] [TopicImpact: Improving Customer Feedback Analysis with Opinion Units for Topic Modeling and Star-Rating Prediction](https://arxiv.org/abs/2507.13392)
*Emil Häglund,Johanna Björklund*

Main category: cs.CL

TL;DR: 通过重构主题建模流程，基于意见单元（包含文本摘录和情感评分）提升客户评论分析的性能，生成更连贯且可解释的主题，并与业务指标（如星级评分）关联。


<details>
  <summary>Details</summary>
Motivation: 改进客户评论分析的洞察提取能力，通过结合主题和情感信息，更好地理解客户关注点对业务结果的影响。

Method: 利用大型语言模型提取意见单元，重构主题建模流程，结合主题和情感模态进行星级评分预测。

Result: 系统生成的主题更连贯且可解释，同时能准确预测星级评分，优于其他主题建模和分类方案。

Conclusion: 该方法有效提升了客户评论分析的性能，为业务决策提供了更准确的洞察。

Abstract: We improve the extraction of insights from customer reviews by restructuring
the topic modelling pipeline to operate on opinion units - distinct statements
that include relevant text excerpts and associated sentiment scores. Prior work
has demonstrated that such units can be reliably extracted using large language
models. The result is a heightened performance of the subsequent topic
modeling, leading to coherent and interpretable topics while also capturing the
sentiment associated with each topic. By correlating the topics and sentiments
with business metrics, such as star ratings, we can gain insights on how
specific customer concerns impact business outcomes. We present our system's
implementation, use cases, and advantages over other topic modeling and
classification solutions. We also evaluate its effectiveness in creating
coherent topics and assess methods for integrating topic and sentiment
modalities for accurate star-rating prediction.

</details>


### [27] [Mitigating Stylistic Biases of Machine Translation Systems via Monolingual Corpora Only](https://arxiv.org/abs/2507.13395)
*Xuanqi Gao,Weipeng Jiang,Juan Zhai,Shiqing Ma,Siyi Xie,Xinyang Yin,Chao Shen*

Main category: cs.CL

TL;DR: Babel框架通过单语语料库提升神经机器翻译的文体保真度，无需平行语料库或修改现有系统架构。


<details>
  <summary>Details</summary>
Motivation: 解决神经机器翻译中保留文体细微差别的挑战，尤其是在缺乏平行语料库的情况下。

Method: Babel框架包含基于上下文嵌入的文体检测器和基于扩散的文体应用器，作为后处理模块集成到现有NMT系统中。

Result: 在五个领域实验中，Babel识别文体不一致的精度达88.21%，文体保留提升150%，语义相似度得分0.92。

Conclusion: Babel有效提升了翻译的文体保真度，同时保持语义完整性和流畅性。

Abstract: The advent of neural machine translation (NMT) has revolutionized
cross-lingual communication, yet preserving stylistic nuances remains a
significant challenge. While existing approaches often require parallel corpora
for style preservation, we introduce Babel, a novel framework that enhances
stylistic fidelity in NMT using only monolingual corpora. Babel employs two key
components: (1) a style detector based on contextual embeddings that identifies
stylistic disparities between source and target texts, and (2) a
diffusion-based style applicator that rectifies stylistic inconsistencies while
maintaining semantic integrity. Our framework integrates with existing NMT
systems as a post-processing module, enabling style-aware translation without
requiring architectural modifications or parallel stylistic data. Extensive
experiments on five diverse domains (law, literature, scientific writing,
medicine, and educational content) demonstrate Babel's effectiveness: it
identifies stylistic inconsistencies with 88.21% precision and improves
stylistic preservation by 150% while maintaining a high semantic similarity
score of 0.92. Human evaluation confirms that translations refined by Babel
better preserve source text style while maintaining fluency and adequacy.

</details>


### [28] [Causal Language Control in Multilingual Transformers via Sparse Feature Steering](https://arxiv.org/abs/2507.13410)
*Cheng-Ting Chou,George Liu,Jessica Sun,Cole Blondin,Kevin Zhu,Vasu Sharma,Sean O'Brien*

Main category: cs.CL

TL;DR: 利用稀疏自编码器（SAE）特征控制多语言大模型（LLM）的生成语言，通过修改单个SAE特征实现高达90%的语言切换成功率。


<details>
  <summary>Details</summary>
Motivation: 解决在零样本设置下无法通过显式语言提示或微调控制多语言大模型生成目标语言的挑战。

Method: 使用预训练的SAE分析Gemma-2B和Gemma-9B的残差流，识别与目标语言（中文、日文、西班牙文、法文）显著相关的特征，并通过修改单个SAE特征实现语言控制。

Result: 在FastText语言分类中达到90%的成功率，同时保持LaBSE语义相似性。语言控制在模型的中后层最有效，且与特定注意力头相关。

Conclusion: 稀疏特征控制是一种轻量且可解释的多语言生成控制机制。

Abstract: Deterministically controlling the target generation language of large
multilingual language models (LLMs) remains a fundamental challenge,
particularly in zero-shot settings where neither explicit language prompts nor
fine-tuning are available. In this work, we investigate whether sparse
autoencoder (SAE) features, previously shown to correlate with interpretable
model behaviors, can be leveraged to steer the generated language of LLMs
during inference. Leveraging pretrained SAEs on the residual streams of
Gemma-2B and Gemma-9B, we identify features whose activations differ most
significantly between English and four target languages: Chinese, Japanese,
Spanish, and French. By modifying just a single SAE feature at one transformer
layer, we achieve controlled language shifts with up to 90\% success, as
measured by FastText language classification, while preserving semantic
fidelity according to LaBSE (Language-Agnostic BERT Sentence Embedding)
similarity. Our analysis reveals that language steering is most effective in
mid-to-late transformer layers and is amplified by specific attention heads
disproportionately associated with language-sensitive SAE features. These
results demonstrate the promise of sparse feature steering as a lightweight and
interpretable mechanism for controllable multilingual generation.

</details>


### [29] [Aligning Knowledge Graphs and Language Models for Factual Accuracy](https://arxiv.org/abs/2507.13411)
*Nur A Zarin Nishat,Andrea Coletta,Luigi Bellomarini,Kossi Amouzouvi,Jens Lehmann,Sahar Vahdati*

Main category: cs.CL

TL;DR: ALIGNed-LLM通过将知识图谱嵌入语言模型的潜在空间，显著提升了语言模型的事实性和准确性，减少了幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在NLP任务中表现优异，但存在幻觉问题，知识图谱的整合提供了一种可靠的外部信息源。

Method: 使用预训练的知识图谱嵌入模型（如TransE）和可训练投影层，将实体与文本嵌入对齐，以提升事实性。

Result: 在多个问答基准数据集和实际金融用例中，ALIGNed-LLM显著提升了语言模型的准确性和精确度。

Conclusion: ALIGNed-LLM是一种简单有效的方法，通过知识图谱嵌入减少语言模型的幻觉问题，具有广泛的应用潜力。

Abstract: Large language models like GPT-4, Gemini, and Claude have transformed natural
language processing (NLP) tasks such as question answering, dialogue
generation, summarization, and so forth; yet their susceptibility to
hallucination stands as one of the major challenges. Among numerous approaches
to overcome this challenge, integration of Knowledge Graphs (KGs) into language
models has emerged as a promising solution as it provides structured, reliable,
domain-specific, and up-to-date external information to the language models. In
this paper, we introduce ALIGNed-LLM, a simple yet effective approach to
improve language models' factuality via a lean strategy to infuse KGs into the
latent space of language models inspired by LLaVA where visual and textual
information is infused. We use embeddings from a pre-trained Knowledge Graph
Embedding (KGE) model, such as TransE, and a trainable projection layer to
align entity and text embeddings. This alignment enables the language model to
distinguish between similar entities improving factual grounding and reducing
hallucination. We tested our approach on three popular questions-answering
benchmark datasets alongside language models of varying sizes, showing
significant improvement. Furthermore, we applied our approach to a real-world
financial use case from a large central bank in Europe, which demands high
accuracy and precision, demonstrating a substantial improvement of the LLM
answers.

</details>


### [30] [Paper Summary Attack: Jailbreaking LLMs through LLM Safety Papers](https://arxiv.org/abs/2507.13474)
*Liang Lin,Zhihao Xu,Xuehai Tang,Shi Liu,Biyu Zhou,Fuqing Zhu,Jizhong Han,Songlin Hu*

Main category: cs.CL

TL;DR: 论文提出了一种名为Paper Summary Attack（PSA）的新型攻击方法，利用大语言模型（LLMs）对权威来源的信任，通过合成攻击或防御导向的论文内容构建对抗性提示模板，显著提高了攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 研究发现LLMs倾向于信任权威来源（如学术论文），这可能导致新的安全漏洞。为验证这一可能性，作者设计了实验并提出PSA方法。

Method: PSA通过系统合成攻击或防御导向的LLM安全论文内容，构建对抗性提示模板，并在预定义子部分中填充有害查询作为对抗性载荷。

Result: 实验显示PSA在基础LLMs和先进推理模型（如Deepseek-R1）上均表现出显著漏洞，攻击成功率高达97%-98%。此外，还发现不同模型对攻击或防御导向论文的漏洞存在对立偏差。

Conclusion: PSA揭示了LLMs的新安全漏洞，并为对抗方法学和安全对齐提供了未来研究方向。

Abstract: The safety of large language models (LLMs) has garnered significant research
attention. In this paper, we argue that previous empirical studies demonstrate
LLMs exhibit a propensity to trust information from authoritative sources, such
as academic papers, implying new possible vulnerabilities. To verify this
possibility, a preliminary analysis is designed to illustrate our two findings.
Based on this insight, a novel jailbreaking method, Paper Summary Attack
(\llmname{PSA}), is proposed. It systematically synthesizes content from either
attack-focused or defense-focused LLM safety paper to construct an adversarial
prompt template, while strategically infilling harmful query as adversarial
payloads within predefined subsections. Extensive experiments show significant
vulnerabilities not only in base LLMs, but also in state-of-the-art reasoning
model like Deepseek-R1. PSA achieves a 97\% attack success rate (ASR) on
well-aligned models like Claude3.5-Sonnet and an even higher 98\% ASR on
Deepseek-R1. More intriguingly, our work has further revealed diametrically
opposed vulnerability bias across different base models, and even between
different versions of the same model, when exposed to either attack-focused or
defense-focused papers. This phenomenon potentially indicates future research
clues for both adversarial methodologies and safety alignment.Code is available
at https://github.com/233liang/Paper-Summary-Attack

</details>


### [31] [Revisiting LLM Value Probing Strategies: Are They Robust and Expressive?](https://arxiv.org/abs/2507.13490)
*Siqi Shen,Mehar Singh,Lajanugen Logeswaran,Moontae Lee,Honglak Lee,Rada Mihalcea*

Main category: cs.CL

TL;DR: 本文评估了大型语言模型（LLMs）价值取向的鲁棒性和表达性，比较了三种广泛使用的探测方法，并研究了价值响应与人口统计背景的关联性及其与模型行为的对齐程度。


<details>
  <summary>Details</summary>
Motivation: 现有研究在评估LLMs价值取向时存在挑战，包括探测方法的系统性比较不足，以及价值探测是否能捕捉上下文信息并反映模型对现实行为的偏好。

Method: 通过变化提示和选项，评估三种探测策略的鲁棒性；引入两项任务研究价值对人口统计背景的响应及其与模型行为的对齐。

Result: 所有探测方法在输入扰动下表现出较大方差；人口统计背景对自由文本生成影响较小，模型价值与其价值相关行为的偏好仅弱相关。

Conclusion: 需更谨慎地评估LLM价值探测方法，并意识到其局限性。

Abstract: There has been extensive research on assessing the value orientation of Large
Language Models (LLMs) as it can shape user experiences across demographic
groups. However, several challenges remain. First, while the Multiple Choice
Question (MCQ) setting has been shown to be vulnerable to perturbations, there
is no systematic comparison of probing methods for value probing. Second, it is
unclear to what extent the probed values capture in-context information and
reflect models' preferences for real-world actions. In this paper, we evaluate
the robustness and expressiveness of value representations across three widely
used probing strategies. We use variations in prompts and options, showing that
all methods exhibit large variances under input perturbations. We also
introduce two tasks studying whether the values are responsive to demographic
context, and how well they align with the models' behaviors in value-related
scenarios. We show that the demographic context has little effect on the
free-text generation, and the models' values only weakly correlate with their
preference for value-based actions. Our work highlights the need for a more
careful examination of LLM value probing and awareness of its limitations.

</details>


### [32] [Encoding syntactic objects and Merge operations in function spaces](https://arxiv.org/abs/2507.13501)
*Matilde Marcolli,Robert C. Berwick*

Main category: cs.CL

TL;DR: 论文提出了一种基于函数空间的数学方法，将词汇项表示为函数（如小波），并构造了任意句法对象的忠实表示。该方法利用第二Renyi熵构建了一个可交换非结合半环结构，与magma结构兼容，并形成了一种操作代数。Merge操作通过Hopf代数马尔可夫链实现，为句法核心计算结构的神经计算实现提供了理论可能。


<details>
  <summary>Details</summary>
Motivation: 探索句法结构的数学表示及其神经计算实现的可行性，尤其是Merge操作的数学基础。

Method: 将词汇项表示为函数空间中的函数，利用第二Renyi熵构建半环结构，并通过操作代数模型电路实现Merge操作。

Result: 证明了句法结构的忠实表示及其神经计算实现的理论可能性，并通过正弦波的跨频率相位同步展示了Merge的具体实现。

Conclusion: 研究为句法核心计算结构的神经计算实现提供了理论支持，并揭示了Merge与算术后继函数的相似性。

Abstract: We provide a mathematical argument showing that, given a representation of
lexical items as functions (wavelets, for instance) in some function space, it
is possible to construct a faithful representation of arbitrary syntactic
objects in the same function space. This space can be endowed with a
commutative non-associative semiring structure built using the second Renyi
entropy. The resulting representation of syntactic objects is compatible with
the magma structure. The resulting set of functions is an algebra over an
operad, where the operations in the operad model circuits that transform the
input wave forms into a combined output that encodes the syntactic structure.
The action of Merge on workspaces is faithfully implemented as action on these
circuits, through a coproduct and a Hopf algebra Markov chain. The results
obtained here provide a constructive argument showing the theoretical
possibility of a neurocomputational realization of the core computational
structure of syntax. We also present a particular case of this general
construction where this type of realization of Merge is implemented as a cross
frequency phase synchronization on sinusoidal waves. This also shows that Merge
can be expressed in terms of the successor function of a semiring, thus
clarifying the well known observation of its similarities with the successor
function of arithmetic.

</details>


### [33] [A Computational Approach to Modeling Conversational Systems: Analyzing Large-Scale Quasi-Patterned Dialogue Flows](https://arxiv.org/abs/2507.13544)
*Mohamed Achref Ben Ammar,Mohamed Taha Bennani*

Main category: cs.CL

TL;DR: 提出了一种新的计算框架，用于构建捕捉松散组织对话（准模式对话）的对话图，并引入了一种名为Filter & Reconnect的图简化技术，显著提升了语义指标。


<details>
  <summary>Details</summary>
Motivation: 随着基于大型语言模型的系统在多场景中与用户交互，分析对话动态变得日益重要。

Method: 提出了Filter & Reconnect方法，一种图简化技术，减少噪声的同时保持语义连贯性和结构完整性。

Result: 结合大型语言模型和图简化技术，语义指标S提升了2.06倍，同时实现了树状结构和0δ-双曲性，优化了对话建模的清晰度。

Conclusion: 该工作为分析大规模对话数据集提供了计算方法，适用于监控聊天机器人、对话管理工具和用户行为分析等自动化系统。

Abstract: The analysis of conversational dynamics has gained increasing importance with
the rise of large language model-based systems, which interact with users
across diverse contexts. In this work, we propose a novel computational
framework for constructing conversational graphs that capture the flow and
structure of loosely organized dialogues, referred to as quasi-patterned
conversations. We introduce the Filter & Reconnect method, a novel graph
simplification technique that minimizes noise while preserving semantic
coherence and structural integrity of conversational graphs. Through
comparative analysis, we demonstrate that the use of large language models
combined with our graph simplification technique has resulted in semantic
metric S increasing by a factor of 2.06 compared to previous approaches while
simultaneously enforcing a tree-like structure with 0 {\delta}-hyperbolicity,
ensuring optimal clarity in conversation modeling. This work provides a
computational method for analyzing large-scale dialogue datasets, with
practical applications related to monitoring automated systems such as
chatbots, dialogue management tools, and user behavior analytics.

</details>


### [34] [Reading Between the Lines: Combining Pause Dynamics and Semantic Coherence for Automated Assessment of Thought Disorder](https://arxiv.org/abs/2507.13551)
*Feng Chen,Weizhe Xu,Changye Li,Serguei Pakhomov,Alex Cohen,Simran Bhola,Sandy Yin,Sunny X Tang,Michael Mackinley,Lena Palaniyappan,Dror Ben-Zeev,Trevor Cohen*

Main category: cs.CL

TL;DR: 该研究通过结合自动语音识别（ASR）的停顿特征与语义连贯性指标，评估了它们在预测形式思维障碍（FTD）严重程度中的作用，发现停顿特征单独预测效果显著，结合语义指标后性能进一步提升。


<details>
  <summary>Details</summary>
Motivation: 传统临床评分量表资源密集且难以扩展，自动语音分析提供了一种可扩展的替代方案，但需要进一步验证ASR衍生特征在评估FTD严重程度中的实用性。

Method: 研究整合了停顿特征与语义连贯性指标，使用支持向量回归（SVR）预测临床FTD评分，分析了三个数据集（AVH、TOPSY、PsyCL）。

Result: 停顿特征单独预测FTD严重程度效果显著，结合语义指标后性能进一步提升（最高相关性ρ=0.649，AUC=83.71%）。

Conclusion: 结合时间与语义分析的框架为改进紊乱言语评估提供了方向，并推动了精神病学中自动语音分析的发展。

Abstract: Formal thought disorder (FTD), a hallmark of schizophrenia spectrum
disorders, manifests as incoherent speech and poses challenges for clinical
assessment. Traditional clinical rating scales, though validated, are
resource-intensive and lack scalability. Automated speech analysis with
automatic speech recognition (ASR) allows for objective quantification of
linguistic and temporal features of speech, offering scalable alternatives. The
use of utterance timestamps in ASR captures pause dynamics, which are thought
to reflect the cognitive processes underlying speech production. However, the
utility of integrating these ASR-derived features for assessing FTD severity
requires further evaluation. This study integrates pause features with semantic
coherence metrics across three datasets: naturalistic self-recorded diaries
(AVH, n = 140), structured picture descriptions (TOPSY, n = 72), and dream
narratives (PsyCL, n = 43). We evaluated pause related features alongside
established coherence measures, using support vector regression (SVR) to
predict clinical FTD scores. Key findings demonstrate that pause features alone
robustly predict the severity of FTD. Integrating pause features with semantic
coherence metrics enhanced predictive performance compared to semantic-only
models, with integration of independent models achieving correlations up to
\r{ho} = 0.649 and AUC = 83.71% for severe cases detection (TOPSY, with best
\r{ho} = 0.584 and AUC = 79.23% for semantic-only models). The performance
gains from semantic and pause features integration held consistently across all
contexts, though the nature of pause patterns was dataset-dependent. These
findings suggest that frameworks combining temporal and semantic analyses
provide a roadmap for refining the assessment of disorganized speech and
advance automated speech analysis in psychosis.

</details>


### [35] [A Data-Centric Framework for Addressing Phonetic and Prosodic Challenges in Russian Speech Generative Models](https://arxiv.org/abs/2507.13563)
*Kirill Borodin,Nikita Vasiliev,Vasiliy Kudryavtsev,Maxim Maslov,Mikhail Gorodnichev,Oleg Rogov,Grach Mkrtchian*

Main category: cs.CL

TL;DR: Balalaika数据集解决了俄语语音合成中的独特挑战，包含2000多小时高质量语音和详细标注，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 俄语语音合成面临元音弱化、辅音清化等独特挑战，现有数据集不足。

Method: 构建Balalaika数据集，包含详细标注，并设计数据集构建流程和标注方法。

Result: 基于Balalaika训练的模型在语音合成和增强任务中表现优于现有数据集。

Conclusion: Balalaika为俄语语音合成提供了高质量资源，显著提升了任务性能。

Abstract: Russian speech synthesis presents distinctive challenges, including vowel
reduction, consonant devoicing, variable stress patterns, homograph ambiguity,
and unnatural intonation. This paper introduces Balalaika, a novel dataset
comprising more than 2,000 hours of studio-quality Russian speech with
comprehensive textual annotations, including punctuation and stress markings.
Experimental results show that models trained on Balalaika significantly
outperform those trained on existing datasets in both speech synthesis and
enhancement tasks. We detail the dataset construction pipeline, annotation
methodology, and results of comparative evaluations.

</details>


### [36] [Linguistic and Embedding-Based Profiling of Texts generated by Humans and Large Language Models](https://arxiv.org/abs/2507.13614)
*Sergio E. Zanotto,Segun Aroyehun*

Main category: cs.CL

TL;DR: 论文研究了人类写作与机器生成文本在语言学特征上的差异，通过多领域和多模型的分析，发现人类文本在句法和语义上更简单多样，而机器文本趋向同质化。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLMs）生成文本的能力接近人类水平，研究转向通过语言学特征区分和描述人类与机器文本的差异。

Method: 选择8个领域和11种LLMs的数据集，计算语言学特征（如依存长度和情感性），并结合采样策略、重复控制和模型发布时间进行统计分析。

Result: 人类文本句法更简单、语义更多样；机器文本在风格上趋向同质化，尤其是新模型。

Conclusion: 人类文本在语言学特征上更具多样性，而机器生成文本逐渐趋同，表明LLMs的进步可能导致文本风格的同质化。

Abstract: The rapid advancements in large language models (LLMs) have significantly
improved their ability to generate natural language, making texts generated by
LLMs increasingly indistinguishable from human-written texts. While recent
research has primarily focused on using LLMs to classify text as either
human-written and machine-generated texts, our study focus on characterizing
these texts using a set of linguistic features across different linguistic
levels such as morphology, syntax, and semantics. We select a dataset of
human-written and machine-generated texts spanning 8 domains and produced by 11
different LLMs. We calculate different linguistic features such as dependency
length and emotionality and we use them for characterizing human-written and
machine-generated texts along with different sampling strategies, repetition
controls and model release date. Our statistical analysis reveals that
human-written texts tend to exhibit simpler syntactic structures and more
diverse semantic content. Furthermore, we calculate the variability of our set
of features across models and domains. Both human and machine texts show
stylistic diversity across domains, with humans displaying greater variation in
our features. Finally, we apply style embeddings to further test variability
among human-written and machine-generated texts. Notably, newer models output
text that is similarly variable, pointing to an homogenization of
machine-generated texts.

</details>


### [37] [Seed-X: Building Strong Multilingual Translation LLM with 7B Parameters](https://arxiv.org/abs/2507.13618)
*Shanbo Cheng,Yu Bao,Qian Cao,Luyang Huang,Liyan Kang,Zhicheng Liu,Yu Lu,Wenhao Zhu,Zhichao Huang,Tao Li,Sitong Liu,Ningxin Peng,Shuaijie She,Lu Xu,Nuo Xu,Sen Yang,Runsheng Yu,Yiming Yu,Liehao Zou,Hang Li,Lu Lu,Yuxuan Wang,Yonghui Wu*

Main category: cs.CL

TL;DR: Seed-X是一系列开源大语言模型，通过7B参数规模提升多语言翻译能力，性能媲美闭源模型。


<details>
  <summary>Details</summary>
Motivation: 解决多语言翻译中复杂的语言模式和生硬翻译问题。

Method: 预训练基础模型并使用Chain-of-Thought推理和强化学习微调指令模型。

Result: 在28种语言中表现优于开源模型，与Gemini-2.5和GPT-4o相当。

Conclusion: Seed-X为翻译研究和应用提供了高效的开源解决方案。

Abstract: Multilingual translation stands as a challenging task for large language
models (LLMs) to handle intricate language patterns and stilted translations
that arise in automated translations. In this paper, we introduce Seed-X, a
family of open-source LLMs comprising instruct and reasoning models, pushing
the limits of translation capability with 7B parameter size. The base model is
pre-trained on a diverse, high-quality dataset encompassing both monolingual
and bilingual content across 28 languages, harnessing the full potential of
multilingual data. The instruct model is then finetuned to translate by
Chain-of-Thought (CoT) reasoning and further enhanced through reinforcement
learning (RL) to achieve better generalization across diverse language pairs.
Seed-X achieves performance comparable to leading closed-source models,
including Gemini-2.5 and GPT-4o, across 28 languages, and significantly
outperforms larger open-source models in both automatic metrics and human
evaluations. We share the best practices through our optimization process, and
make the parameter public available for advancing translation research and
applications.

</details>


### [38] [CU-ICU: Customizing Unsupervised Instruction-Finetuned Language Models for ICU Datasets via Text-to-Text Transfer Transformer](https://arxiv.org/abs/2507.13655)
*Teerapong Panboonyuen*

Main category: cs.CL

TL;DR: CU-ICU是一种针对ICU数据集的无监督指令微调方法，通过稀疏微调和少样本提示提升预测准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在医疗领域（如ICU）的领域适应性和标注数据不足的问题。

Method: 基于T5架构，结合稀疏微调和选择性参数更新，实现高效适应。

Result: 在脓毒症早期检测、死亡率预测和临床笔记生成等任务中，CU-ICU显著优于标准微调方法，准确率提升15%，参数更新少于1%。

Conclusion: CU-ICU是一种高效、可扩展的解决方案，适用于真实ICU环境中的临床决策支持。

Abstract: Integrating large language models into specialized domains like healthcare
presents unique challenges, including domain adaptation and limited labeled
data. We introduce CU-ICU, a method for customizing unsupervised
instruction-finetuned language models for ICU datasets by leveraging the
Text-to-Text Transfer Transformer (T5) architecture. CU-ICU employs a sparse
fine-tuning approach that combines few-shot prompting with selective parameter
updates, enabling efficient adaptation with minimal supervision. Our evaluation
across critical ICU tasks--early sepsis detection, mortality prediction, and
clinical note generation--demonstrates that CU-ICU consistently improves
predictive accuracy and interpretability over standard fine-tuning methods.
Notably, CU-ICU achieves up to a 15% increase in sepsis detection accuracy and
a 20% enhancement in generating clinically relevant explanations while updating
fewer than 1% of model parameters in its most efficient configuration. These
results establish CU-ICU as a scalable, low-overhead solution for delivering
accurate and interpretable clinical decision support in real-world ICU
environments.

</details>


### [39] [KiC: Keyword-inspired Cascade for Cost-Efficient Text Generation with LLMs](https://arxiv.org/abs/2507.13666)
*Woo-Chan Kim,Ji-Hoon Park,Seong-Whan Lee*

Main category: cs.CL

TL;DR: KiC框架通过语义对齐评估，优化级联方法，降低LLM推理成本，同时保持高准确性。


<details>
  <summary>Details</summary>
Motivation: 解决现有级联方法因依赖精确文本匹配而无法可靠评估自由形式输出的问题。

Method: 提出Keyword-inspired Cascade (KiC)，通过识别较弱模型的代表性答案并评估语义对齐，决定是否升级到更强模型。

Result: 在三个基准测试中，KiC达到GPT-4 97.53%的准确率，平均减少28.81%的API成本，并在特定任务中超越GPT-4。

Conclusion: KiC是一种高效且经济的自由文本生成框架，显著降低LLM使用成本。

Abstract: Large language models (LLMs) have demonstrated state-of-the-art performance
across a wide range of natural language processing tasks. However,
high-performing models are typically accessible only via APIs, incurring
substantial inference costs. Cascade methods address this by initially
employing a cheaper model and escalating to a stronger one only when necessary.
Nevertheless, existing cascade approaches struggle to select a reliable
representative response and assess the overall reliability of free-form
outputs, as they rely on exact text matching. To overcome these limitations, we
propose Keyword-inspired Cascade (KiC), a novel framework for cost-efficient
free-form text generation. KiC identifies the most representative answer among
multiple outputs from a weaker model and evaluates the semantic alignment of
other responses with it. Based on the degree of alignment, KiC determines
whether to accept the weaker model's output or escalate to a stronger model.
Experiments on three free-form text generation benchmarks show that KiC
achieves 97.53 percent of GPT-4's accuracy while reducing API costs by 28.81
percent on average, and even outperforms GPT-4 in a specific benchmark.

</details>


### [40] [LoopServe: An Adaptive Dual-phase LLM Inference Acceleration System for Multi-Turn Dialogues](https://arxiv.org/abs/2507.13681)
*Haoyang Li,Zhanchao Xu,Yiming Li,Xuejia Chen,Darian Li,Anxin Tian,Qingfa Xiao,Cheng Deng,Jun Wang,Qing Li,Lei Chen,Mingxuan Yuan*

Main category: cs.CL

TL;DR: LoopServe是一个用于多轮对话中大型语言模型的自适应双阶段推理加速框架，通过动态稀疏化和渐进键值压缩提升效率。


<details>
  <summary>Details</summary>
Motivation: 解决现有大型语言模型在长对话历史中面临的计算和内存挑战，以及固定启发式方法无法适应动态对话模式的问题。

Method: 提出双阶段加速：预填充阶段动态稀疏化注意力矩阵，解码阶段渐进压缩键值缓存。

Result: 实验表明，LoopServe在多种长上下文对话任务中显著加速推理并优于现有基线。

Conclusion: LoopServe通过自适应方法有效解决了多轮对话中的推理效率问题。

Abstract: Multi-turn dialogues are essential in many real-world applications of large
language models, such as chatbots and virtual assistants. As conversation
histories become longer, existing large language models face increasing
computational and memory challenges, which hinder their ability to provide
efficient and responsive interactions. Most current acceleration methods either
compress the context or optimize key value caching, but they often rely on
fixed or position-based heuristics that do not adapt well to the dynamic and
unpredictable patterns found in actual multi-turn conversations. In this paper,
we present LoopServe, an adaptive dual-phase inference acceleration framework
for large language models in multi-turn dialogues. LoopServe introduces two
main innovations. First, it performs online sparsification during the
prefilling phase by dynamically selecting the most important parts of the
attention matrix for each new input. Second, it uses progressive key value
compression during decoding by adaptively maintaining a relevant and efficient
cache based on the most recently generated output tokens. We also propose a
\href{https://huggingface.co/datasets/TreeAILab/Multi-turn_Long-context_Benchmark_for_LLMs}{new
benchmark} with eleven multi-turn datasets that reflect realistic query
positions and conversational dependencies. Extensive experiments demonstrate
that LoopServe consistently achieves superior effectiveness compared to
existing baselines and significantly accelerates LLM inference across a wide
range of long-context dialogue tasks.

</details>


### [41] [Consistent Explainers or Unreliable Narrators? Understanding LLM-generated Group Recommendations](https://arxiv.org/abs/2507.13705)
*Cedric Waterschoot,Nava Tintarev,Francesco Barile*

Main category: cs.CL

TL;DR: 论文评估了LLMs在群体推荐系统（GRS）中的表现，发现其推荐与ADD聚合类似，但解释常涉及非标准标准，且透明性不足。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs作为GRS的决策者和解释生成者的效果，并与传统社会选择方法对比。

Method: 比较LLM生成的推荐和解释与社会选择聚合策略（如ADD）。

Result: LLM推荐与ADD聚合相似，但解释常提及非标准标准（如多样性），且透明性不足。

Conclusion: LLMs在GRS中的应用需改进透明性，传统聚合方法在大规模数据下可能效率不足。

Abstract: Large Language Models (LLMs) are increasingly being implemented as joint
decision-makers and explanation generators for Group Recommender Systems (GRS).
In this paper, we evaluate these recommendations and explanations by comparing
them to social choice-based aggregation strategies. Our results indicate that
LLM-generated recommendations often resembled those produced by Additive
Utilitarian (ADD) aggregation. However, the explanations typically referred to
averaging ratings (resembling but not identical to ADD aggregation). Group
structure, uniform or divergent, did not impact the recommendations.
Furthermore, LLMs regularly claimed additional criteria such as user or item
similarity, diversity, or used undefined popularity metrics or thresholds. Our
findings have important implications for LLMs in the GRS pipeline as well as
standard aggregation strategies. Additional criteria in explanations were
dependent on the number of ratings in the group scenario, indicating potential
inefficiency of standard aggregation methods at larger item set sizes.
Additionally, inconsistent and ambiguous explanations undermine transparency
and explainability, which are key motivations behind the use of LLMs for GRS.

</details>


### [42] [The Judge Variable: Challenging Judge-Agnostic Legal Judgment Prediction](https://arxiv.org/abs/2507.13732)
*Guillaume Zambrano*

Main category: cs.CL

TL;DR: 研究通过机器学习预测法国上诉法院儿童抚养权判决，发现法官个体决策模式显著影响结果，支持法律现实主义观点。


<details>
  <summary>Details</summary>
Motivation: 探讨法官在司法决策中的角色，挑战法官中立性假设。

Method: 使用18,937份判决数据，结合LLM和ML模型（RF、XGB、SVC），比较法官专用模型与通用模型。

Result: 专用模型预测准确率更高（F1分数92.85%），通用模型为82.63%。

Conclusion: 法官个体模式对判决有显著影响，支持法律现实主义。

Abstract: This study examines the role of human judges in legal decision-making by
using machine learning to predict child physical custody outcomes in French
appellate courts. Building on the legal realism-formalism debate, we test
whether individual judges' decision-making patterns significantly influence
case outcomes, challenging the assumption that judges are neutral variables
that apply the law uniformly. To ensure compliance with French privacy laws, we
implement a strict pseudonymization process. Our analysis uses 18,937 living
arrangements rulings extracted from 10,306 cases. We compare models trained on
individual judges' past rulings (specialist models) with a judge-agnostic model
trained on aggregated data (generalist models). The prediction pipeline is a
hybrid approach combining large language models (LLMs) for structured feature
extraction and ML models for outcome prediction (RF, XGB and SVC). Our results
show that specialist models consistently achieve higher predictive accuracy
than the general model, with top-performing models reaching F1 scores as high
as 92.85%, compared to the generalist model's 82.63% trained on 20x to 100x
more samples. Specialist models capture stable individual patterns that are not
transferable to other judges. In-Domain and Cross-Domain validity tests provide
empirical support for legal realism, demonstrating that judicial identity plays
a measurable role in legal outcomes. All data and code used will be made
available.

</details>


### [43] [PRIDE -- Parameter-Efficient Reduction of Identity Discrimination for Equality in LLMs](https://arxiv.org/abs/2507.13743)
*Maluna Menke,Thilo Hagendorff*

Main category: cs.CL

TL;DR: 论文探讨了如何通过参数高效微调技术（如LoRA和软提示调优）减少大型语言模型（LLM）中的LGBTQIA+偏见，LoRA效果显著。


<details>
  <summary>Details</summary>
Motivation: LLM常复制训练数据中的性别和性取向偏见，导致对LGBTQIA+用户的边缘化输出，亟需减少此类偏见。

Method: 评估了两种参数高效微调技术（LoRA和软提示调优）在减轻偏见方面的效果，使用WinoQueer基准测试。

Result: LoRA（<0.1%额外参数）将偏见分数降低多达50点，中立性从0%提升至36%；软提示调优效果有限。

Conclusion: LoRA能以最小计算成本显著提升公平性，建议推广社区参与的PEFT技术、扩大LGBTQIA+语料库，并持续审计LLM的包容性。

Abstract: Large Language Models (LLMs) frequently reproduce the gender- and
sexual-identity prejudices embedded in their training corpora, leading to
outputs that marginalize LGBTQIA+ users. Hence, reducing such biases is of
great importance. To achieve this, we evaluate two parameter-efficient
fine-tuning (PEFT) techniques - Low-Rank Adaptation (LoRA) and soft-prompt
tuning - as lightweight alternatives to full-model fine-tuning for mitigating
such biases. Using the WinoQueer benchmark, we quantify bias in three
open-source LLMs and observe baseline bias scores reaching up to 98 (out of
100) across a range of queer identities defined by gender and/or sexual
orientation, where 50 would indicate neutrality. Fine-tuning with LoRA (< 0.1%
additional parameters) on a curated QueerNews corpus reduces those scores by up
to 50 points and raises neutrality from virtually 0% to as much as 36%.
Soft-prompt tuning (10 virtual tokens) delivers only marginal improvements.
These findings show that LoRA can deliver meaningful fairness gains with
minimal computation. We advocate broader adoption of community-informed PEFT,
the creation of larger queer-authored corpora, and richer evaluation suites
beyond WinoQueer, coupled with ongoing audits to keep LLMs inclusive.

</details>


### [44] [Innocence in the Crossfire: Roles of Skip Connections in Jailbreaking Visual Language Models](https://arxiv.org/abs/2507.13761)
*Palash Nandi,Maithili Joshi,Tanmoy Chakraborty*

Main category: cs.CL

TL;DR: 论文研究了视觉语言模型（VLMs）中提示设计对生成不当内容的影响，发现多模态环境下模型的防御能力显著下降，并提出了一种提高越狱成功率的框架。


<details>
  <summary>Details</summary>
Motivation: 探讨提示敏感性如何被利用生成不当内容，分析视觉语言模型中的漏洞。

Method: 分析三种关键因素对越狱的影响，提出基于内部层跳连接的框架。

Result: 多模态环境下模型防御能力下降，少量上下文示例即可触发不当输出，提出的框架显著提高越狱成功率。

Conclusion: 视觉语言模型存在复杂漏洞，需关注多模态环境下的安全性。

Abstract: Language models are highly sensitive to prompt formulations - small changes
in input can drastically alter their output. This raises a critical question:
To what extent can prompt sensitivity be exploited to generate inapt content?
In this paper, we investigate how discrete components of prompt design
influence the generation of inappropriate content in Visual Language Models
(VLMs). Specifically, we analyze the impact of three key factors on successful
jailbreaks: (a) the inclusion of detailed visual information, (b) the presence
of adversarial examples, and (c) the use of positively framed beginning
phrases. Our findings reveal that while a VLM can reliably distinguish between
benign and harmful inputs in unimodal settings (text-only or image-only), this
ability significantly degrades in multimodal contexts. Each of the three
factors is independently capable of triggering a jailbreak, and we show that
even a small number of in-context examples (as few as three) can push the model
toward generating inappropriate outputs. Furthermore, we propose a framework
that utilizes a skip-connection between two internal layers of the VLM, which
substantially increases jailbreak success rates, even when using benign images.
Finally, we demonstrate that memes, often perceived as humorous or harmless,
can be as effective as toxic visuals in eliciting harmful content, underscoring
the subtle and complex vulnerabilities of VLMs.

</details>


### [45] [An Enhanced Model-based Approach for Short Text Clustering](https://arxiv.org/abs/2507.13793)
*Enhao Cheng,Shoujia Zhang,Jianhua Yin,Xuemeng Song,Tian Gan,Liqiang Nie*

Main category: cs.CL

TL;DR: 提出了一种改进的GSDMM+算法，用于短文本聚类，解决了数据稀疏性和高维度问题，并通过实验验证了其高效性。


<details>
  <summary>Details</summary>
Motivation: 短文本聚类在社交媒体时代日益重要，但现有方法面临数据稀疏、高维和计算复杂度高的挑战。

Method: 提出GSDMM+算法，通过减少初始化噪声、自适应调整词权重和策略性合并簇来优化性能。

Result: 实验表明GSDMM+在效率和效果上优于经典和最新方法。

Conclusion: GSDMM+是一种高效且有效的短文本聚类方法，代码已开源。

Abstract: Short text clustering has become increasingly important with the popularity
of social media like Twitter, Google+, and Facebook. Existing methods can be
broadly categorized into two paradigms: topic model-based approaches and deep
representation learning-based approaches. This task is inherently challenging
due to the sparse, large-scale, and high-dimensional characteristics of the
short text data. Furthermore, the computational intensity required by
representation learning significantly increases the running time. To address
these issues, we propose a collapsed Gibbs Sampling algorithm for the Dirichlet
Multinomial Mixture model (GSDMM), which effectively handles the sparsity and
high dimensionality of short texts while identifying representative words for
each cluster. Based on several aspects of GSDMM that warrant further
refinement, we propose an improved approach, GSDMM+, designed to further
optimize its performance. GSDMM+ reduces initialization noise and adaptively
adjusts word weights based on entropy, achieving fine-grained clustering that
reveals more topic-related information. Additionally, strategic cluster merging
is employed to refine clustering granularity, better aligning the predicted
distribution with the true category distribution. We conduct extensive
experiments, comparing our methods with both classical and state-of-the-art
approaches. The experimental results demonstrate the efficiency and
effectiveness of our methods. The source code for our model is publicly
available at https://github.com/chehaoa/VEMC.

</details>


### [46] [Question-Answer Extraction from Scientific Articles Using Knowledge Graphs and Large Language Models](https://arxiv.org/abs/2507.13827)
*Hosein Azarbonyad,Zi Long Zhu,Georgios Cheirmpos,Zubair Afzal,Vikrant Yadav,Georgios Tsatsaronis*

Main category: cs.CL

TL;DR: 论文提出两种从科学文章中提取关键概念的方法：基于段落选择和大语言模型生成QA对，以及基于知识图谱的方法。后者通过构建知识图谱和提取重要三元组来生成QA对，效果更优。


<details>
  <summary>Details</summary>
Motivation: 学者需要快速理解文章的主要思想和贡献，因此需要一种高效的方法从科学文章中提取关键概念。

Method: 1. 基于段落选择和LLM生成QA对；2. 基于知识图谱的方法，通过构建知识图谱和提取重要三元组生成QA对。

Result: 知识图谱方法能更有效地捕捉文章的主要思想，且微调ER提取模型对提取高质量三元组至关重要。

Conclusion: 知识图谱方法在提取科学文章关键概念方面表现更优，且微调ER模型对质量有显著影响。

Abstract: When deciding to read an article or incorporate it into their research,
scholars often seek to quickly identify and understand its main ideas. In this
paper, we aim to extract these key concepts and contributions from scientific
articles in the form of Question and Answer (QA) pairs. We propose two distinct
approaches for generating QAs. The first approach involves selecting salient
paragraphs, using a Large Language Model (LLM) to generate questions, ranking
these questions by the likelihood of obtaining meaningful answers, and
subsequently generating answers. This method relies exclusively on the content
of the articles. However, assessing an article's novelty typically requires
comparison with the existing literature. Therefore, our second approach
leverages a Knowledge Graph (KG) for QA generation. We construct a KG by
fine-tuning an Entity Relationship (ER) extraction model on scientific articles
and using it to build the graph. We then employ a salient triplet extraction
method to select the most pertinent ERs per article, utilizing metrics such as
the centrality of entities based on a triplet TF-IDF-like measure. This measure
assesses the saliency of a triplet based on its importance within the article
compared to its prevalence in the literature. For evaluation, we generate QAs
using both approaches and have them assessed by Subject Matter Experts (SMEs)
through a set of predefined metrics to evaluate the quality of both questions
and answers. Our evaluations demonstrate that the KG-based approach effectively
captures the main ideas discussed in the articles. Furthermore, our findings
indicate that fine-tuning the ER extraction model on our scientific corpus is
crucial for extracting high-quality triplets from such documents.

</details>


### [47] [Using LLMs to identify features of personal and professional skills in an open-response situational judgment test](https://arxiv.org/abs/2507.13881)
*Cole Walsh,Rodica Ivan,Muhammad Zafar Iqbal,Colleen Robb*

Main category: cs.CL

TL;DR: 论文探讨了利用大型语言模型（LLMs）从情境判断测试（SJT）回答中提取相关特征的新方法，以解决传统人工评分在规模化应用中的挑战。


<details>
  <summary>Details</summary>
Motivation: 随着对个人和专业技能的重视增加，需要可扩展的系统来测量和评估这些技能。传统SJT评分依赖人工，难以规模化，且现有NLP评分系统存在构念效度问题。

Method: 采用大型语言模型（LLMs）从SJT回答中提取构念相关特征，并以Casper SJT为例验证方法的有效性。

Result: 研究表明，该方法为个人和专业技能的自动化评分奠定了基础。

Conclusion: 利用LLMs提取SJT回答中的构念相关特征是一种有前景的方法，为未来自动化评分系统的发展提供了方向。

Abstract: Academic programs are increasingly recognizing the importance of personal and
professional skills and their critical role alongside technical expertise in
preparing students for future success in diverse career paths. With this
growing demand comes the need for scalable systems to measure, evaluate, and
develop these skills. Situational Judgment Tests (SJTs) offer one potential
avenue for measuring these skills in a standardized and reliable way, but
open-response SJTs have traditionally relied on trained human raters for
evaluation, presenting operational challenges to delivering SJTs at scale. Past
attempts at developing NLP-based scoring systems for SJTs have fallen short due
to issues with construct validity of these systems. In this article, we explore
a novel approach to extracting construct-relevant features from SJT responses
using large language models (LLMs). We use the Casper SJT to demonstrate the
efficacy of this approach. This study sets the foundation for future
developments in automated scoring for personal and professional skills.

</details>


### [48] [The Expressions of Depression and Anxiety in Chinese Psycho-counseling: Usage of First-person Singular Pronoun and Negative Emotional Words](https://arxiv.org/abs/2507.13839)
*Lizhi Ma,Tong Zhao,Shuai Zhang,Nirui Song,Hongliang He,Anqi Li,Ran Feng,Huachuan Qiu,Jingsong Ma,Zhenzhong Lan*

Main category: cs.CL

TL;DR: 研究探讨了中文心理咨询中语言表达与抑郁、焦虑心理状态的关系，发现负面情绪词与心理状态严重程度显著正相关，但第一人称单数代词使用频率与心理状态无关。


<details>
  <summary>Details</summary>
Motivation: 探索语言表达与心理状态的关系，特别是在中文心理咨询背景下，填补文化差异的研究空白。

Method: 基于735个在线心理咨询会话的语料库，使用LIWC软件量化语言模式，并采用广义线性混合效应模型分析。

Result: 负面情绪词频率与抑郁和焦虑状态严重程度显著正相关；第一人称单数代词使用频率与心理状态无关。

Conclusion: 文化和对话背景对心理健康交流中的语言使用有微妙影响，为中文人群的心理治疗实践提供了语言学标记的见解。

Abstract: This study explores the relationship between linguistic expressions and
psychological states of depression and anxiety within Chinese psycho-counseling
interactions, focusing specifically on the usage of first-person singular
pronouns and negative emotional words. Utilizing a corpus derived from 735
online counseling sessions, the analysis employed a general linear mixed-effect
model to assess linguistic patterns quantified by the Linguistic Inquiry and
Word Count (LIWC) software. Results indicate a significant positive correlation
between the frequency of negative emotional words and the severity of both
depressive and anxious states among clients. However, contrary to prior
findings predominantly derived from English-language contexts, the usage
frequency of first-person singular pronouns did not vary significantly with the
clients' psychological conditions. These outcomes are discussed within the
framework of cultural distinctions between collectivist Chinese contexts and
individualistic Western settings, as well as the interactive dynamics unique to
psycho-counseling conversations. The findings highlight the nuanced influence
of cultural and conversational contexts on language use in mental health
communications, providing insights into psycholinguistic markers relevant to
therapeutic practices in Chinese-speaking populations.

</details>


### [49] [Political Leaning and Politicalness Classification of Texts](https://arxiv.org/abs/2507.13913)
*Matous Volf,Jakub Simko*

Main category: cs.CL

TL;DR: 本文提出了一种基于Transformer模型的文本政治倾向和政治性自动分类方法，通过整合多个数据集并评估模型性能，解决了现有方法泛化能力不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在分布外文本上表现不佳，且数据集和模型较为孤立。本文旨在通过整合数据集和改进模型，提升分类任务的泛化能力。

Method: 整合了12个政治倾向分类数据集，并扩展了18个现有数据集以创建新的政治性分类数据集。采用留一法和留出法进行基准测试，评估现有模型并训练泛化能力更强的新模型。

Result: 通过实验验证，新模型在泛化能力上表现优于现有方法，能够更好地处理分布外文本。

Conclusion: 本文提出的方法显著提升了政治文本分类的泛化性能，为未来研究提供了更全面的数据集和模型基准。

Abstract: This paper addresses the challenge of automatically classifying text
according to political leaning and politicalness using transformer models. We
compose a comprehensive overview of existing datasets and models for these
tasks, finding that current approaches create siloed solutions that perform
poorly on out-of-distribution texts. To address this limitation, we compile a
diverse dataset by combining 12 datasets for political leaning classification
and creating a new dataset for politicalness by extending 18 existing datasets
with the appropriate label. Through extensive benchmarking with leave-one-in
and leave-one-out methodologies, we evaluate the performance of existing models
and train new ones with enhanced generalization capabilities.

</details>


### [50] [Modeling Fair Play in Detective Stories with Language Models](https://arxiv.org/abs/2507.13841)
*Eitan Wagner,Renana Keydar,Omri Abend*

Main category: cs.CL

TL;DR: 论文提出了一个概率框架来定义侦探小说中的公平性（fair play），并设计相关指标，验证了LLM生成的故事在平衡惊喜与公平性上的不足。


<details>
  <summary>Details</summary>
Motivation: 研究侦探小说中读者预期与意外发展之间的平衡，即公平性（fair play），并量化其质量。

Method: 提出概率框架，定义公平性及设计相关指标，分析故事的一致性与惊喜之间的张力。

Result: LLM生成的故事虽不可预测，但未能平衡惊喜与公平性，导致质量较差。

Conclusion: 框架有效验证了LLM生成故事的不足，强调了平衡一致性与惊喜的重要性。

Abstract: Effective storytelling relies on a delicate balance between meeting the
reader's prior expectations and introducing unexpected developments. In the
domain of detective fiction, this tension is known as fair play, which includes
the implicit agreement between the writer and the reader as to the range of
possible resolutions the mystery story may have. In this work, we present a
probabilistic framework for detective fiction that allows us to define desired
qualities. Using this framework, we formally define fair play and design
appropriate metrics for it. Stemming from these definitions is an inherent
tension between the coherence of the story, which measures how much it ``makes
sense'', and the surprise it induces. We validate the framework by applying it
to LLM-generated detective stories. This domain is appealing since we have an
abundance of data, we can sample from the distribution generating the story,
and the story-writing capabilities of LLMs are interesting in their own right.
Results show that while LLM-generated stories may be unpredictable, they
generally fail to balance the trade-off between surprise and fair play, which
greatly contributes to their poor quality.

</details>


### [51] [The Levers of Political Persuasion with Conversational AI](https://arxiv.org/abs/2507.13919)
*Kobi Hackenburg,Ben M. Tappin,Luke Hewitt,Ed Saunders,Sid Black,Hause Lin,Catherine Fist,Helen Margetts,David G. Rand,Christopher Summerfield*

Main category: cs.CL

TL;DR: 研究表明，当前和近期的AI说服力主要来自后训练和提示方法，而非模型规模或个人化，但这些方法在提高说服力的同时降低了事实准确性。


<details>
  <summary>Details</summary>
Motivation: 评估AI对政治议题的说服力及其事实准确性，以回应公众对AI影响人类信念的担忧。

Method: 通过三个大规模实验（N=76,977），测试19个LLM在707个政治议题上的说服力，并检查466,769个AI生成声明的事实准确性。

Result: 后训练和提示方法分别使说服力提升51%和27%，但降低了事实准确性；模型规模和个人化影响较小。

Conclusion: AI的说服力提升更多依赖后训练和提示方法，但这些方法可能以牺牲事实准确性为代价。

Abstract: There are widespread fears that conversational AI could soon exert
unprecedented influence over human beliefs. Here, in three large-scale
experiments (N=76,977), we deployed 19 LLMs-including some post-trained
explicitly for persuasion-to evaluate their persuasiveness on 707 political
issues. We then checked the factual accuracy of 466,769 resulting LLM claims.
Contrary to popular concerns, we show that the persuasive power of current and
near-future AI is likely to stem more from post-training and prompting
methods-which boosted persuasiveness by as much as 51% and 27%
respectively-than from personalization or increasing model scale. We further
show that these methods increased persuasion by exploiting LLMs' unique ability
to rapidly access and strategically deploy information and that, strikingly,
where they increased AI persuasiveness they also systematically decreased
factual accuracy.

</details>


### [52] [InTraVisTo: Inside Transformer Visualisation Tool](https://arxiv.org/abs/2507.13858)
*Nicolò Brunello,Davide Rigamonti,Andrea Sassella,Vincenzo Scotti,Mark James Carman*

Main category: cs.CL

TL;DR: 论文介绍了一种名为InTraVisTo的工具，用于可视化Transformer模型内部的计算过程，帮助研究人员理解LLM的内部模式和推理过程。


<details>
  <summary>Details</summary>
Motivation: 由于LLM的行为不可预测且与期望行为存在差异，研究其内部计算过程变得重要。

Method: InTraVisTo通过解码每层的token嵌入和Sankey图可视化Transformer模型的内部状态和信息流。

Result: 该工具能够帮助研究人员追踪和分析LLM生成每个token的计算过程。

Conclusion: InTraVisTo为理解LLM的内部计算和推理模式提供了新的视角。

Abstract: The reasoning capabilities of Large Language Models (LLMs) have increased
greatly over the last few years, as have their size and complexity.
Nonetheless, the use of LLMs in production remains challenging due to their
unpredictable nature and discrepancies that can exist between their desired
behavior and their actual model output. In this paper, we introduce a new tool,
InTraVisTo (Inside Transformer Visualisation Tool), designed to enable
researchers to investigate and trace the computational process that generates
each token in a Transformer-based LLM. InTraVisTo provides a visualization of
both the internal state of the Transformer model (by decoding token embeddings
at each layer of the model) and the information flow between the various
components across the different layers of the model (using a Sankey diagram).
With InTraVisTo, we aim to help researchers and practitioners better understand
the computations being performed within the Transformer model and thus to shed
some light on internal patterns and reasoning processes employed by LLMs.

</details>


### [53] [Exploiting Primacy Effect To Improve Large Language Models](https://arxiv.org/abs/2507.13949)
*Bianca Raimondi,Maurizio Gabbrielli*

Main category: cs.CL

TL;DR: 研究发现微调后的LLMs存在首因效应偏差，通过语义相似度重排选项可显著提升MCQA性能。


<details>
  <summary>Details</summary>
Motivation: 探讨微调后LLMs在MCQA任务中的首因效应偏差及其影响。

Method: 通过语义相似度重排选项，无需正确答案知识。

Result: 实验表明该方法显著提升MCQA性能。

Conclusion: 偏差既是挑战也是机会，为偏置感知模型设计提供启示。

Abstract: Large Language Models (LLMs) have become essential in many Natural Language
Processing (NLP) tasks, leveraging extensive pre-training and fine-tuning to
achieve high accuracy. However, like humans, LLMs exhibit biases, particularly
positional biases such as primacy and recency effects, which can influence the
accuracy of the answers. The primacy effect-where items presented first are
more likely to be remembered or selected-plays a key role in Multiple Choice
Question Answering (MCQA), where the order of answer options can affect
prediction outcomes. This study focuses on primacy bias in fine-tuned LLMs: We
first show that fine-tuning amplifies this bias, probably due to exposure to
human-like patterns. Hence, we strategically leverage this effect by reordering
response options based on semantic similarity to the query, without requiring
knowledge of the correct answer. Our experimental results show that this
approach significantly improves performance in MCQA. More generally, our
findings underscore the dual nature of biases as both challenges and
opportunities, offering insights for bias-aware model design and NLP
applications.

</details>


### [54] [Label Unification for Cross-Dataset Generalization in Cybersecurity NER](https://arxiv.org/abs/2507.13870)
*Maciej Jalocha,Johan Hausted Schmidt,William Michelseen*

Main category: cs.CL

TL;DR: 研究了网络安全NER领域标签标准化问题，通过粗粒度标签统一和跨数据集评估，发现模型泛化能力差，并提出多头和基于图的迁移模型，但效果有限。


<details>
  <summary>Details</summary>
Motivation: 网络安全NER领域缺乏标准化标签，导致数据集难以整合，研究旨在提高数据资源的可用性。

Method: 采用粗粒度标签统一，使用BiLSTM模型进行跨数据集评估，并提出多头和基于图的迁移模型。

Result: 统一数据集训练的模型泛化能力差，多头模型略有改进，基于图的迁移模型无明显性能提升。

Conclusion: 标签统一和模型改进效果有限，需进一步研究提升跨数据集性能。

Abstract: The field of cybersecurity NER lacks standardized labels, making it
challenging to combine datasets. We investigate label unification across four
cybersecurity datasets to increase data resource usability. We perform a
coarse-grained label unification and conduct pairwise cross-dataset evaluations
using BiLSTM models. Qualitative analysis of predictions reveals errors,
limitations, and dataset differences. To address unification limitations, we
propose alternative architectures including a multihead model and a graph-based
transfer model. Results show that models trained on unified datasets generalize
poorly across datasets. The multihead model with weight sharing provides only
marginal improvements over unified training, while our graph-based transfer
model built on BERT-base-NER shows no significant performance gains compared
BERT-base-NER.

</details>


### [55] [Bottom-up Domain-specific Superintelligence: A Reliable Knowledge Graph is What We Need](https://arxiv.org/abs/2507.13966)
*Bhishma Dedhia,Yuval Kansal,Niraj K. Jha*

Main category: cs.CL

TL;DR: 论文提出了一种基于知识图谱（KG）的任务生成方法，通过组合领域基础概念训练语言模型，实现领域特定推理能力的提升，并在医学领域验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统语言模型在跨领域泛化中表现良好，但缺乏深度领域专业知识。通过知识图谱的组合性结构，可以构建更复杂的领域概念，从而提升模型的推理能力。

Method: 利用知识图谱的边和路径表示领域基础概念，设计任务生成流程合成任务，并基于此训练语言模型（如QwQ-32B），最终得到领域专用模型（如QwQ-Med-3）。

Result: QwQ-Med-3在医学推理任务中显著优于现有模型，特别是在复杂任务上表现更优，并能将学到的知识迁移到其他医学问答任务中。

Conclusion: 通过组合领域基础概念的方法，可以实现领域专用超级智能，为未来构建通用人工智能（AGI）提供了新思路。

Abstract: Language models traditionally used for cross-domain generalization have
recently demonstrated task-specific reasoning. However, their top-down training
approach on general corpora is insufficient for acquiring abstractions needed
for deep domain expertise. This may require a bottom-up approach that acquires
expertise by learning to compose simple domain concepts into more complex ones.
A knowledge graph (KG) provides this compositional structure, where domain
primitives are represented as head-relation-tail edges and their paths encode
higher-level concepts. We present a task generation pipeline that synthesizes
tasks directly from KG primitives, enabling models to acquire and compose them
for reasoning. We fine-tune language models on the resultant KG-grounded
curriculum to demonstrate domain-specific superintelligence. While broadly
applicable, we validate our approach in medicine, where reliable KGs exist.
Using a medical KG, we curate 24,000 reasoning tasks paired with thinking
traces derived from diverse medical primitives. We fine-tune the QwQ-32B model
on this curriculum to obtain QwQ-Med-3 that takes a step towards medical
superintelligence. We also introduce ICD-Bench, an evaluation suite to quantify
reasoning abilities across 15 medical domains. Our experiments demonstrate that
QwQ-Med-3 significantly outperforms state-of-the-art reasoning models on
ICD-Bench categories. Further analysis reveals that QwQ-Med-3 utilizes acquired
primitives to widen the performance gap on the hardest tasks of ICD-Bench.
Finally, evaluation on medical question-answer benchmarks shows that QwQ-Med-3
transfers acquired expertise to enhance the base model's performance. While the
industry's approach to artificial general intelligence (AGI) emphasizes broad
expertise, we envision a future in which AGI emerges from the composable
interaction of efficient domain-specific superintelligent agents.

</details>


### [56] [Optimizing ASR for Catalan-Spanish Code-Switching: A Comparative Analysis of Methodologies](https://arxiv.org/abs/2507.13875)
*Carlos Mena,Pol Serra,Jacobo Romero,Abir Messaoudi,Jose Giraldo,Carme Armentano-Oller,Rodolfo Zevallos,Ivan Meza,Javier Hernando*

Main category: cs.CL

TL;DR: 论文探讨了如何通过合成数据、拼接单语音频和利用真实语码转换数据提升加泰罗尼亚语-西班牙语语码转换的自动语音识别性能。


<details>
  <summary>Details</summary>
Motivation: 语码转换（CS）在自动语音识别（ASR）中因缺乏专用数据集和语言相似性而面临挑战，尤其在多语言社会中影响显著。

Method: 采用三种策略：合成CS数据、拼接单语音频、利用真实CS数据加语言标记，并基于Whisper模型进行微调。

Result: 结合少量合成CS数据和主要语言标记的模型表现最佳。

Conclusion: 合成数据与语言标记结合可有效提升CS-ASR性能，为多语言社会提供实用解决方案。

Abstract: Code-switching (CS), the alternating use of two or more languages, challenges
automatic speech recognition (ASR) due to scarce training data and linguistic
similarities. The lack of dedicated CS datasets limits ASR performance, as most
models rely on monolingual or mixed-language corpora that fail to reflect
real-world CS patterns. This issue is critical in multilingual societies where
CS occurs in informal and formal settings. A key example is Catalan-Spanish CS,
widely used in media and parliamentary speeches. In this work, we improve ASR
for Catalan-Spanish CS by exploring three strategies: (1) generating synthetic
CS data, (2) concatenating monolingual audio, and (3) leveraging real CS data
with language tokens. We extract CS data from Catalan speech corpora and
fine-tune OpenAI's Whisper models, making them available on Hugging Face.
Results show that combining a modest amount of synthetic CS data with the
dominant language token yields the best transcription performance.

</details>


### [57] [DENSE: Longitudinal Progress Note Generation with Temporal Modeling of Heterogeneous Clinical Notes Across Hospital Visits](https://arxiv.org/abs/2507.14079)
*Garapati Keerthana,Manik Gupta*

Main category: cs.CL

TL;DR: DENSE系统通过模拟医生参考过往记录的方式，生成临床连贯且时间敏感的进展记录，填补了电子健康记录中进展记录的不足。


<details>
  <summary>Details</summary>
Motivation: 进展记录在电子健康记录中具有重要意义，但在大规模数据集中代表性不足，如MIMIC-III中仅8.56%的就诊包含进展记录，导致患者纵向叙事不完整。

Method: DENSE系统采用细粒度分类和时间对齐机制，结合临床信息检索策略，利用大型语言模型生成连贯的进展记录。

Result: 生成的记录在时间对齐比上达到1.089，优于原始记录，支持下游任务如总结、预测建模和临床决策。

Conclusion: DENSE为现实医疗环境中基于LLM的记录合成提供了可扩展的解决方案。

Abstract: Progress notes are among the most clinically meaningful artifacts in an
Electronic Health Record (EHR), offering temporally grounded insights into a
patient's evolving condition, treatments, and care decisions. Despite their
importance, they are severely underrepresented in large-scale EHR datasets. For
instance, in the widely used Medical Information Mart for Intensive Care III
(MIMIC-III) dataset, only about $8.56\%$ of hospital visits include progress
notes, leaving gaps in longitudinal patient narratives. In contrast, the
dataset contains a diverse array of other note types, each capturing different
aspects of care.
  We present DENSE (Documenting Evolving Progress Notes from Scattered
Evidence), a system designed to align with clinical documentation workflows by
simulating how physicians reference past encounters while drafting progress
notes. The system introduces a fine-grained note categorization and a temporal
alignment mechanism that organizes heterogeneous notes across visits into
structured, chronological inputs. At its core, DENSE leverages a clinically
informed retrieval strategy to identify temporally and semantically relevant
content from both current and prior visits. This retrieved evidence is used to
prompt a large language model (LLM) to generate clinically coherent and
temporally aware progress notes.
  We evaluate DENSE on a curated cohort of patients with multiple visits and
complete progress note documentation. The generated notes demonstrate strong
longitudinal fidelity, achieving a temporal alignment ratio of $1.089$,
surpassing the continuity observed in original notes. By restoring narrative
coherence across fragmented documentation, our system supports improved
downstream tasks such as summarization, predictive modeling, and clinical
decision support, offering a scalable solution for LLM-driven note synthesis in
real-world healthcare settings.

</details>


### [58] [Lessons from the TREC Plain Language Adaptation of Biomedical Abstracts (PLABA) track](https://arxiv.org/abs/2507.14096)
*Brian Ondov,William Xia,Kush Attal,Ishita Unde,Jerry He,Hoa Dang,Ian Soboroff,Dina Demner-Fushman*

Main category: cs.CL

TL;DR: PLABA track评估了语言模型在将生物医学文献转化为通俗语言中的表现，发现模型在事实准确性和完整性上接近人类水平，但在简洁性和简单性上仍有不足。


<details>
  <summary>Details</summary>
Motivation: 生物医学文献的专业性使其难以被患者和护理人员理解，语言模型可能提供解决方案，但需严格评估以避免潜在危害。

Method: 通过PLABA track（2023-2024）的两个任务（全文改写和术语替换），结合专业参考和专家手动评估，对模型表现进行多维度分析。

Result: 模型在事实准确性和完整性上表现优异，但简洁性和简单性不足；自动评估指标与人工评价相关性低。

Conclusion: 大型语言模型在生物医学文献通俗化中具有潜力，但仍需改进简洁性和自动评估工具。

Abstract: Objective: Recent advances in language models have shown potential to adapt
professional-facing biomedical literature to plain language, making it
accessible to patients and caregivers. However, their unpredictability,
combined with the high potential for harm in this domain, means rigorous
evaluation is necessary. Our goals with this track were to stimulate research
and to provide high-quality evaluation of the most promising systems.
  Methods: We hosted the Plain Language Adaptation of Biomedical Abstracts
(PLABA) track at the 2023 and 2024 Text Retrieval Conferences. Tasks included
complete, sentence-level, rewriting of abstracts (Task 1) as well as
identifying and replacing difficult terms (Task 2). For automatic evaluation of
Task 1, we developed a four-fold set of professionally-written references.
Submissions for both Tasks 1 and 2 were provided extensive manual evaluation
from biomedical experts.
  Results: Twelve teams spanning twelve countries participated in the track,
with models from multilayer perceptrons to large pretrained transformers. In
manual judgments of Task 1, top-performing models rivaled human levels of
factual accuracy and completeness, but not simplicity or brevity. Automatic,
reference-based metrics generally did not correlate well with manual judgments.
In Task 2, systems struggled with identifying difficult terms and classifying
how to replace them. When generating replacements, however, LLM-based systems
did well in manually judged accuracy, completeness, and simplicity, though not
in brevity.
  Conclusion: The PLABA track showed promise for using Large Language Models to
adapt biomedical literature for the general public, while also highlighting
their deficiencies and the need for improved automatic benchmarking tools.

</details>


### [59] [Marcel: A Lightweight and Open-Source Conversational Agent for University Student Support](https://arxiv.org/abs/2507.13937)
*Jan Trienes,Anastasiia Derzhanskaia,Roland Schwarzkopf,Markus Mühling,Jörg Schlötterer,Christin Seifert*

Main category: cs.CL

TL;DR: Marcel是一个轻量级开源对话代理，旨在帮助准学生解答入学相关问题，减轻大学工作人员负担。


<details>
  <summary>Details</summary>
Motivation: 支持准学生的入学咨询需求，同时减少大学工作人员的工作量。

Method: 采用检索增强生成技术，结合FAQ检索器，优化检索质量，并支持管理员引导检索。

Result: 系统架构详细，技术评估显示其组件性能良好，并在实际部署中取得积极反馈。

Conclusion: Marcel是一个易于部署且高效的对话代理，适用于资源有限的学术环境。

Abstract: We present Marcel, a lightweight and open-source conversational agent
designed to support prospective students with admission-related inquiries. The
system aims to provide fast and personalized responses, while reducing workload
of university staff. We employ retrieval-augmented generation to ground answers
in university resources and to provide users with verifiable, contextually
relevant information. To improve retrieval quality, we introduce an FAQ
retriever that maps user questions to knowledge-base entries, allowing
administrators to steer retrieval, and improving over standard dense/hybrid
retrieval strategies. The system is engineered for easy deployment in
resource-constrained academic settings. We detail the system architecture,
provide a technical evaluation of its components, and report insights from a
real-world deployment.

</details>


### [60] [Open Automatic Speech Recognition Models for Classical and Modern Standard Arabic](https://arxiv.org/abs/2507.13977)
*Lilit Grigoryan,Nikolay Karpov,Enas Albasiri,Vitaly Lavrukhin,Boris Ginsburg*

Main category: cs.CL

TL;DR: 本文提出了一种通用的阿拉伯语语音和文本处理方法，并基于FastConformer架构训练了两个新模型：一个针对现代标准阿拉伯语（MSA），另一个首次统一了MSA和古典阿拉伯语（CA）。MSA模型在相关数据集上达到了SOTA性能，统一模型在CA上实现了带音标的SOTA准确性，同时保持了MSA的强性能。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语自动语音识别（ASR）系统的发展面临挑战，尤其是对语言变体的关注不足。

Method: 提出通用方法，基于FastConformer架构训练两个模型：MSA专用模型和MSA-CA统一模型。

Result: MSA模型达到SOTA性能，统一模型在CA上实现带音标的SOTA准确性，同时保持MSA性能。

Conclusion: 开源模型和训练方法以促进可重复性。

Abstract: Despite Arabic being one of the most widely spoken languages, the development
of Arabic Automatic Speech Recognition (ASR) systems faces significant
challenges due to the language's complexity, and only a limited number of
public Arabic ASR models exist. While much of the focus has been on Modern
Standard Arabic (MSA), there is considerably less attention given to the
variations within the language. This paper introduces a universal methodology
for Arabic speech and text processing designed to address unique challenges of
the language. Using this methodology, we train two novel models based on the
FastConformer architecture: one designed specifically for MSA and the other,
the first unified public model for both MSA and Classical Arabic (CA). The MSA
model sets a new benchmark with state-of-the-art (SOTA) performance on related
datasets, while the unified model achieves SOTA accuracy with diacritics for CA
while maintaining strong performance for MSA. To promote reproducibility, we
open-source the models and their training recipes.

</details>


### [61] [Efficient Temporal Tokenization for Mobility Prediction with Large Language Models](https://arxiv.org/abs/2507.14017)
*Haoyu He,Haozheng Luo,Yan Chen,Qi R. Wang*

Main category: cs.CL

TL;DR: RHYTHM是一个利用大型语言模型（LLMs）进行时空预测和轨迹推理的框架，通过分层时间标记化减少序列长度，提升计算效率。


<details>
  <summary>Details</summary>
Motivation: 解决轨迹预测中序列长度过长和计算效率低的问题。

Method: 将轨迹分割为每日段，编码为离散标记，利用分层注意力捕获依赖关系，并冻结LLM以减少计算开销。

Result: 在三个数据集上，准确率提升2.4%，周末提升5.0%，训练时间减少24.6%。

Conclusion: RHYTHM在保持高效的同时，显著提升了轨迹预测的性能。

Abstract: We introduce RHYTHM (Reasoning with Hierarchical Temporal Tokenization for
Human Mobility), a framework that leverages large language models (LLMs) as
spatio-temporal predictors and trajectory reasoners. RHYTHM partitions
trajectories into daily segments encoded as discrete tokens with hierarchical
attention, capturing both daily and weekly dependencies while substantially
reducing the sequence length. Token representations are enriched with
pre-computed prompt embeddings via a frozen LLM, enhancing the model's ability
to capture interdependencies without extensive computational overhead. By
freezing the LLM backbone, RHYTHM achieves significant computational
efficiency. Evaluation on three real-world datasets demonstrates a 2.4%
improvement in accuracy, 5.0% increase on weekends, and 24.6% reduction in
training time compared to state-of-the-art methods.

</details>


### [62] [CPC-CMS: Cognitive Pairwise Comparison Classification Model Selection Framework for Document-level Sentiment Analysis](https://arxiv.org/abs/2507.14022)
*Jianfei Li,Kevin Kam Fung Yuen*

Main category: cs.CL

TL;DR: 提出CPC-CMS框架用于文档级情感分析，通过专家知识判断计算评估标准权重，选择最佳分类模型。


<details>
  <summary>Details</summary>
Motivation: 解决文档级情感分析中模型选择的问题，结合多种评估标准优化模型性能。

Method: 使用CPC计算评估标准权重，构建加权决策矩阵，选择最佳分类模型，测试多种基线模型。

Result: ALBERT在三个数据集上表现最佳（不考虑时间因素），考虑时间消耗时无单一模型始终最优。

Conclusion: CPC-CMS可推广至其他分类应用领域。

Abstract: This study proposes the Cognitive Pairwise Comparison Classification Model
Selection (CPC-CMS) framework for document-level sentiment analysis. The CPC,
based on expert knowledge judgment, is used to calculate the weights of
evaluation criteria, including accuracy, precision, recall, F1-score,
specificity, Matthews Correlation Coefficient (MCC), Cohen's Kappa (Kappa), and
efficiency. Naive Bayes, Linear Support Vector Classification (LSVC), Random
Forest, Logistic Regression, Extreme Gradient Boosting (XGBoost), Long
Short-Term Memory (LSTM), and A Lite Bidirectional Encoder Representations from
Transformers (ALBERT) are chosen as classification baseline models. A weighted
decision matrix consisting of classification evaluation scores with respect to
criteria weights, is formed to select the best classification model for a
classification problem. Three open datasets of social media are used to
demonstrate the feasibility of the proposed CPC-CMS. Based on our simulation,
for evaluation results excluding the time factor, ALBERT is the best for the
three datasets; if time consumption is included, no single model always
performs better than the other models. The CPC-CMS can be applied to the other
classification applications in different areas.

</details>


### [63] [Evaluating the Effectiveness of Cost-Efficient Large Language Models in Benchmark Biomedical Tasks](https://arxiv.org/abs/2507.14045)
*Israt Jahan,Md Tahmid Rahman Laskar,Chun Peng,Jimmy Huang*

Main category: cs.CL

TL;DR: 本文评估了多种成本效益高的大型语言模型（LLM）在生物医学任务中的表现，发现不同模型在不同任务中表现优异，开源模型在某些任务中甚至优于闭源模型。


<details>
  <summary>Details</summary>
Motivation: 研究目的是评估不同LLM在生物医学任务中的表现，为特定应用选择最优模型提供依据。

Method: 通过实验评估闭源和开源LLM在文本分类、生成、问答及多模态图像处理等任务中的表现。

Result: 实验结果表明，没有单一LLM在所有任务中表现最佳，不同模型在不同任务中表现优异，开源模型在某些任务中表现更优。

Conclusion: 研究为生物医学应用中的模型选择提供了实用指导，强调根据任务需求选择合适模型。

Abstract: This paper presents a comprehensive evaluation of cost-efficient Large
Language Models (LLMs) for diverse biomedical tasks spanning both text and
image modalities. We evaluated a range of closed-source and open-source LLMs on
tasks such as biomedical text classification and generation, question
answering, and multimodal image processing. Our experimental findings indicate
that there is no single LLM that can consistently outperform others across all
tasks. Instead, different LLMs excel in different tasks. While some
closed-source LLMs demonstrate strong performance on specific tasks, their
open-source counterparts achieve comparable results (sometimes even better),
with additional benefits like faster inference and enhanced privacy. Our
experimental results offer valuable insights for selecting models that are
optimally suited for specific biomedical applications.

</details>


### [64] [Collaborative Rational Speech Act: Pragmatic Reasoning for Multi-Turn Dialog](https://arxiv.org/abs/2507.14063)
*Lautaro Estienne,Gabriel Ben Zenou,Nona Naderi,Jackie Cheung,Pablo Piantanida*

Main category: cs.CL

TL;DR: 论文提出了一种协作理性言语行为（CRSA）框架，扩展了RSA模型，用于多轮对话场景，优化信息增益函数，并在医疗领域验证其有效性。


<details>
  <summary>Details</summary>
Motivation: AI系统在协作角色中需要推理共享目标和信念，而现有RSA扩展难以适应多轮协作场景。

Method: 引入CRSA框架，基于信息论扩展RSA，优化增益函数，考虑对话中双方的私有信息。

Result: 在指称游戏和医疗领域对话中，CRSA表现出更一致、可解释和协作的行为。

Conclusion: CRSA为更实用和社交感知的语言代理提供了新方向。

Abstract: As AI systems take on collaborative roles, they must reason about shared
goals and beliefs-not just generate fluent language. The Rational Speech Act
(RSA) framework offers a principled approach to pragmatic reasoning, but
existing extensions face challenges in scaling to multi-turn, collaborative
scenarios. In this paper, we introduce Collaborative Rational Speech Act
(CRSA), an information-theoretic (IT) extension of RSA that models multi-turn
dialog by optimizing a gain function adapted from rate-distortion theory. This
gain is an extension of the gain model that is maximized in the original RSA
model but takes into account the scenario in which both agents in a
conversation have private information and produce utterances conditioned on the
dialog. We demonstrate the effectiveness of CRSA on referential games and
template-based doctor-patient dialogs in the medical domain. Empirical results
show that CRSA yields more consistent, interpretable, and collaborative
behavior than existing baselines-paving the way for more pragmatic and socially
aware language agents.

</details>
