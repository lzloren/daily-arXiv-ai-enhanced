<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 11]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Rethinking the Illusion of Thinking](https://arxiv.org/abs/2507.01231)
*Iñaki Dellibarda Varela,Pablo Romero-Sorozabal,Eduardo Rocon,Manuel Cebrian*

Main category: cs.AI

TL;DR: 论文澄清了关于大型推理模型（LRMs）是否具备真正推理能力的争议，通过复现和改进实验，发现LRMs在特定条件下表现良好，但仍有认知限制。


<details>
  <summary>Details</summary>
Motivation: 解决AI社区对LRMs是否具备真正推理能力的争议，澄清实验设计和结论的合理性。

Method: 复现并改进原始研究中的两个争议性基准测试（Towers of Hanoi和River Crossing），引入逐步提示和协作对话方法。

Result: 发现LRMs在复杂任务（如8个盘子的Towers of Hanoi）中表现受限，但在可解问题（如100+代理对的River Crossing）中表现优异。

Conclusion: LRMs是离散状态空间中的随机搜索器，未来需通过精细实验进一步探索其推理能力。

Abstract: Earlier this year, Apple ignited controversy by publishing "The Illusion of
Thinking," prompting heated debate within the AI community. Critics seized upon
the findings as conclusive evidence that Large Reasoning Models (LRMs) lack
genuine reasoning capabilities, branding them as mere stochastic parrots.
Meanwhile, defenders-spearheaded by Lawsen et al. (2025)-fired back, condemning
the experimental setup as flawed and the conclusions overstated. We clarify
this debate by replicating and refining two of the original study's most
contentious benchmarks: Towers of Hanoi and River Crossing. By introducing
incremental stepwise prompting and agentic collaborative dialogue, we show that
previously reported failures solving the Towers of Hanoi were not purely result
of output constraints, but also partly a result of cognition limitations: LRMs
still stumble when complexity rises moderately (around 8 disks). Moreover, the
River Crossing results initially heralded as catastrophic failures turn out to
hinge upon testing unsolvable configurations. Once we limit tests strictly to
solvable problems-LRMs effortlessly solve large instances involving over 100
agent pairs. Our findings ultimately defy simplistic narratives: today's LRMs
are stochastic, RL-tuned searchers in a discrete state space we barely
understand. Real progress in symbolic, long-horizon reasoning demands mapping
that terrain through fine-grained ablations like those introduced here.

</details>


### [2] [Beyond Black-Box AI: Interpretable Hybrid Systems for Dementia Care](https://arxiv.org/abs/2507.01282)
*Matthew JY Kang,Wenli Yang,Monica R Roberts,Byeong Ho Kang,Charles B Malpas*

Main category: cs.AI

TL;DR: 大型语言模型（LLMs）在医疗诊断中潜力巨大，但实际临床贡献有限，尤其在痴呆症诊断中。混合方法结合统计学习和专家知识可能更有效。


<details>
  <summary>Details</summary>
Motivation: 探讨AI在临床环境中的实际贡献限制，特别是在痴呆症诊断和护理中，以推动未来研究方向。

Method: 通过范围综述分析AI在临床中的局限性，提出混合方法（如PEIRS和ATHENA-CDS）以提升解释性和工作流适配性。

Result: 当前AI在临床中的主要问题包括黑箱输出、幻觉和弱因果推理，混合方法能改善解释性和工作流适配性。

Conclusion: 未来AI决策支持应注重解释性，结合神经符号或混合AI，并衡量临床理解、工作流适配性和患者结果。

Abstract: The recent boom of large language models (LLMs) has re-ignited the hope that
artificial intelligence (AI) systems could aid medical diagnosis. Yet despite
dazzling benchmark scores, LLM assistants have yet to deliver measurable
improvements at the bedside. This scoping review aims to highlight the areas
where AI is limited to make practical contributions in the clinical setting,
specifically in dementia diagnosis and care.
  Standalone machine-learning models excel at pattern recognition but seldom
provide actionable, interpretable guidance, eroding clinician trust. Adjacent
use of LLMs by physicians did not result in better diagnostic accuracy or
speed. Key limitations trace to the data-driven paradigm: black-box outputs
which lack transparency, vulnerability to hallucinations, and weak causal
reasoning. Hybrid approaches that combine statistical learning with expert
rule-based knowledge, and involve clinicians throughout the process help bring
back interpretability. They also fit better with existing clinical workflows,
as seen in examples like PEIRS and ATHENA-CDS.
  Future decision-support should prioritise explanatory coherence by linking
predictions to clinically meaningful causes. This can be done through
neuro-symbolic or hybrid AI that combines the language ability of LLMs with
human causal expertise. AI researchers have addressed this direction, with
explainable AI and neuro-symbolic AI being the next logical steps in further
advancement in AI. However, they are still based on data-driven knowledge
integration instead of human-in-the-loop approaches. Future research should
measure success not only by accuracy but by improvements in clinician
understanding, workflow fit, and patient outcomes. A better understanding of
what helps improve human-computer interactions is greatly needed for AI systems
to become part of clinical practice.

</details>


### [3] [AI Agents and Agentic AI-Navigating a Plethora of Concepts for Future Manufacturing](https://arxiv.org/abs/2507.01376)
*Yinwang Ren,Yangyang Liu,Tang Ji,Xun Xu*

Main category: cs.AI

TL;DR: 本文综述了AI代理技术的发展，重点分析了基于LLMs和MLLMs的AI代理及Agentic AI在智能制造中的应用与挑战。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI的快速发展，AI代理的能力显著提升，但其在智能制造中的定义、能力边界和应用尚不明确，需系统性研究。

Method: 系统回顾AI和AI代理技术的演进，分析LLM-Agents、MLLM-Agents和Agentic AI的核心概念与技术进展，探讨其在智能制造中的应用与挑战。

Result: LLM-Agents、MLLM-Agents和Agentic AI为智能制造的信息处理、环境感知和自主决策提供了新途径。

Conclusion: 研究明确了这些新兴AI范式在智能制造中的潜力，但也指出了定义模糊和实际应用中的挑战。

Abstract: AI agents are autonomous systems designed to perceive, reason, and act within
dynamic environments. With the rapid advancements in generative AI (GenAI),
large language models (LLMs) and multimodal large language models (MLLMs) have
significantly improved AI agents' capabilities in semantic comprehension,
complex reasoning, and autonomous decision-making. At the same time, the rise
of Agentic AI highlights adaptability and goal-directed autonomy in dynamic and
complex environments. LLMs-based AI Agents (LLM-Agents), MLLMs-based AI Agents
(MLLM-Agents), and Agentic AI contribute to expanding AI's capabilities in
information processing, environmental perception, and autonomous
decision-making, opening new avenues for smart manufacturing. However, the
definitions, capability boundaries, and practical applications of these
emerging AI paradigms in smart manufacturing remain unclear. To address this
gap, this study systematically reviews the evolution of AI and AI agent
technologies, examines the core concepts and technological advancements of
LLM-Agents, MLLM-Agents, and Agentic AI, and explores their potential
applications in and integration into manufacturing, along with the potential
challenges they may face.

</details>


### [4] [A Fuzzy Approach to the Specification, Verification and Validation of Risk-Based Ethical Decision Making Models](https://arxiv.org/abs/2507.01410)
*Abeer Dyoub,Francesca A. Lisi*

Main category: cs.AI

TL;DR: 提出了一种基于伦理风险评估的伦理决策模型形式化方法，并利用模糊Petri网进行验证和验证，通过医学案例研究展示其应用。


<details>
  <summary>Details</summary>
Motivation: 道德领域的本体论和认识论复杂性使得评估道德机器性能的标准难以确立。

Method: 提出形式化方法描述伦理决策模型，基于模糊规则，并使用模糊Petri网进行验证和验证。

Result: 通过医学领域的案例研究验证了方法的有效性。

Conclusion: 该方法为道德机器的伦理决策提供了一种可行的验证和验证途径。

Abstract: The ontological and epistemic complexities inherent in the moral domain make
it challenging to establish clear standards for evaluating the performance of a
moral machine. In this paper, we present a formal method to describe Ethical
Decision Making models based on ethical risk assessment. Then, we show how
these models that are specified as fuzzy rules can be verified and validated
using fuzzy Petri nets. A case study from the medical field is considered to
illustrate the proposed approach.

</details>


### [5] [Pensieve Grader: An AI-Powered, Ready-to-Use Platform for Effortless Handwritten STEM Grading](https://arxiv.org/abs/2507.01431)
*Yoonseok Yang,Minjune Kim,Marlon Rondinelli,Keren Shao*

Main category: cs.AI

TL;DR: Pensieve是一个AI辅助评分平台，利用大语言模型（LLMs）转录和评估学生作业，显著减少评分时间并保持高准确性。


<details>
  <summary>Details</summary>
Motivation: 解决大规模STEM课程中手写开放式作业评分效率低下的问题。

Method: 开发Pensieve平台，整合LLMs进行转录和评分，支持从扫描提交到最终反馈的完整流程。

Result: 在20多所机构的实际课程中部署，评分超过30万份作业，评分时间减少65%，高置信度预测与教师评分一致率达95.4%。

Conclusion: Pensieve有效提升评分效率，同时保持高准确性，适用于多学科STEM课程。

Abstract: Grading handwritten, open-ended responses remains a major bottleneck in large
university STEM courses. We introduce Pensieve (https://www.pensieve.co), an
AI-assisted grading platform that leverages large language models (LLMs) to
transcribe and evaluate student work, providing instructors with rubric-aligned
scores, transcriptions, and confidence ratings. Unlike prior tools that focus
narrowly on specific tasks like transcription or rubric generation, Pensieve
supports the entire grading pipeline-from scanned student submissions to final
feedback-within a human-in-the-loop interface.
  Pensieve has been deployed in real-world courses at over 20 institutions and
has graded more than 300,000 student responses. We present system details and
empirical results across four core STEM disciplines: Computer Science,
Mathematics, Physics, and Chemistry. Our findings show that Pensieve reduces
grading time by an average of 65%, while maintaining a 95.4% agreement rate
with instructor-assigned grades for high-confidence predictions.

</details>


### [6] [Using multi-agent architecture to mitigate the risk of LLM hallucinations](https://arxiv.org/abs/2507.01446)
*Abd Elrahman Amer,Magdi Amer*

Main category: cs.AI

TL;DR: 提出了一种基于多代理系统和模糊逻辑的方法，用于处理客户短信请求，以减少LLM的幻觉风险。


<details>
  <summary>Details</summary>
Motivation: 提升客户服务质量和响应时间是维持客户忠诚度和增加市场份额的关键，但LLM的幻觉风险是主要挑战。

Method: 采用多代理系统，结合LLM和模糊逻辑来处理客户短信请求。

Result: 系统能够有效减少LLM的幻觉风险。

Conclusion: 多代理系统结合模糊逻辑是解决LLM幻觉问题的有效方法。

Abstract: Improving customer service quality and response time are critical factors for
maintaining customer loyalty and increasing a company's market share. While
adopting emerging technologies such as Large Language Models (LLMs) is becoming
a necessity to achieve these goals, the risk of hallucination remains a major
challenge. In this paper, we present a multi-agent system to handle customer
requests sent via SMS. This system integrates LLM based agents with fuzzy logic
to mitigate hallucination risks.

</details>


### [7] [Agent-as-Tool: A Study on the Hierarchical Decision Making with Reinforcement Learning](https://arxiv.org/abs/2507.01489)
*Yanfei Zhang*

Main category: cs.AI

TL;DR: 提出了一种分层框架Agent-as-tool，分离工具调用和推理过程，提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究同时处理工具调用和推理过程，导致模型负担过重，影响推理能力。

Method: 采用分层框架Agent-as-tool，将工具调用和推理过程分离，由不同代理处理。

Result: 仅需少量强化微调（180样本），在Bamboogle上表现优异（63.2%精确匹配，75.2%覆盖精确匹配）。

Conclusion: 分层框架有效减轻模型负担，显著提升性能。

Abstract: Large Language Models (LLMs) have emerged as one of the most significant
technological advancements in artificial intelligence in recent years. Their
ability to understand, generate, and reason with natural language has
transformed how we interact with AI systems. With the development of LLM-based
agents and reinforcement-learning-based reasoning models, the study of applying
reinforcement learning in agent frameworks has become a new research focus.
However, all previous studies face the challenge of deciding the tool calling
process and the reasoning process simultaneously, and the chain of reasoning
was solely relied on the unprocessed raw result with redundant information and
symbols unrelated to the task from the tool, which impose a heavy burden on the
model's capability to reason. Therefore, in our research, we proposed a
hierarchical framework Agent-as-tool that detach the tool calling process and
the reasoning process, which enables the model to focus on the verbally
reasoning process while the tool calling process is handled by another agent.
Our work had achieved comparable results with only a slight reinforcement
fine-tuning on 180 samples, and had achieved exceptionally well performance in
Bamboogle with 63.2% of exact match and 75.2% in cover exact match, exceeding
Search-R1 by 4.8% in exact match and 3.2% in cover exact match.

</details>


### [8] [T3DM: Test-Time Training-Guided Distribution Shift Modelling for Temporal Knowledge Graph Reasoning](https://arxiv.org/abs/2507.01597)
*Yuehang Si,Zefan Zeng,Jincai Huang,Qing Cheng*

Main category: cs.AI

TL;DR: 论文提出了一种新的TKG推理方法T3DM，通过建模分布偏移和设计高质量负采样策略，显著提升了推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有TKG推理方法在建模训练与测试样本间的分布偏移和生成高质量负样本方面存在不足。

Method: 提出T3DM方法，结合测试时训练指导的分布偏移建模和基于对抗训练的负采样策略。

Result: 实验表明T3DM在多数情况下优于现有基线方法。

Conclusion: T3DM通过改进分布偏移建模和负采样策略，显著提升了TKG推理的鲁棒性和性能。

Abstract: Temporal Knowledge Graph (TKG) is an efficient method for describing the
dynamic development of facts along a timeline. Most research on TKG reasoning
(TKGR) focuses on modelling the repetition of global facts and designing
patterns of local historical facts. However, they face two significant
challenges: inadequate modeling of the event distribution shift between
training and test samples, and reliance on random entity substitution for
generating negative samples, which often results in low-quality sampling. To
this end, we propose a novel distributional feature modeling approach for
training TKGR models, Test-Time Training-guided Distribution shift Modelling
(T3DM), to adjust the model based on distribution shift and ensure the global
consistency of model reasoning. In addition, we design a negative-sampling
strategy to generate higher-quality negative quadruples based on adversarial
training. Extensive experiments show that T3DM provides better and more robust
results than the state-of-the-art baselines in most cases.

</details>


### [9] [Agent Ideate: A Framework for Product Idea Generation from Patents Using Agentic AI](https://arxiv.org/abs/2507.01717)
*Gopichand Kanumolu,Ashok Urlana,Charaka Vinayak Kumar,Bala Mallikarjunarao Garlapati*

Main category: cs.AI

TL;DR: 论文探讨了利用大型语言模型（LLMs）和自主代理从专利中挖掘和生成产品概念的方法，提出了Agent Ideate框架，并在多个领域验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 专利蕴含丰富的技术知识，但获取和解读这些信息仍具挑战性，因此需要一种自动化方法来生成基于专利的商业创意。

Method: 设计了Agent Ideate框架，结合开源LLMs和基于代理的架构，在计算机科学、自然语言处理和材料化学三个领域进行实验。

Result: 代理方法在创意质量、相关性和新颖性上均优于独立LLMs。

Conclusion: 结合LLMs与代理工作流可显著提升创新流程，释放专利数据在商业创意生成中的潜力。

Abstract: Patents contain rich technical knowledge that can inspire innovative product
ideas, yet accessing and interpreting this information remains a challenge.
This work explores the use of Large Language Models (LLMs) and autonomous
agents to mine and generate product concepts from a given patent. In this work,
we design Agent Ideate, a framework for automatically generating product-based
business ideas from patents. We experimented with open-source LLMs and
agent-based architectures across three domains: Computer Science, Natural
Language Processing, and Material Chemistry. Evaluation results show that the
agentic approach consistently outperformed standalone LLMs in terms of idea
quality, relevance, and novelty. These findings suggest that combining LLMs
with agentic workflows can significantly enhance the innovation pipeline by
unlocking the untapped potential of business idea generation from patent data.

</details>


### [10] [Joint Matching and Pricing for Crowd-shipping with In-store Customers](https://arxiv.org/abs/2507.01749)
*Arash Dehghan,Mucahit Cevik,Merve Bodur,Bissan Ghaddar*

Main category: cs.AI

TL;DR: 论文研究了利用店内顾客作为配送员的集中式众包配送系统，通过MDP模型和NeurADP+DDQN联合优化策略，显著提升了配送效率和成本节约。


<details>
  <summary>Details</summary>
Motivation: 针对城市最后一公里配送效率的需求增长，探索利用现有顾客资源进行众包配送的可行性。

Method: 提出MDP模型处理订单和配送员的不确定性，结合NeurADP和DDQN进行动态定价和订单分配优化。

Result: 实验显示，NeurADP+DDQN策略节省了6.7%的配送成本，灵活配送和多目的地路由进一步降低了8%和17%的成本。

Conclusion: 动态前瞻性策略在众包配送系统中具有显著优势，为城市物流运营商提供了实用指导。

Abstract: This paper examines the use of in-store customers as delivery couriers in a
centralized crowd-shipping system, targeting the growing need for efficient
last-mile delivery in urban areas. We consider a brick-and-mortar retail
setting where shoppers are offered compensation to deliver time-sensitive
online orders. To manage this process, we propose a Markov Decision Process
(MDP) model that captures key uncertainties, including the stochastic arrival
of orders and crowd-shippers, and the probabilistic acceptance of delivery
offers. Our solution approach integrates Neural Approximate Dynamic Programming
(NeurADP) for adaptive order-to-shopper assignment with a Deep Double Q-Network
(DDQN) for dynamic pricing. This joint optimization strategy enables multi-drop
routing and accounts for offer acceptance uncertainty, aligning more closely
with real-world operations. Experimental results demonstrate that the
integrated NeurADP + DDQN policy achieves notable improvements in delivery cost
efficiency, with up to 6.7\% savings over NeurADP with fixed pricing and
approximately 18\% over myopic baselines. We also show that allowing flexible
delivery delays and enabling multi-destination routing further reduces
operational costs by 8\% and 17\%, respectively. These findings underscore the
advantages of dynamic, forward-looking policies in crowd-shipping systems and
offer practical guidance for urban logistics operators.

</details>


### [11] [Refining Gelfond Rationality Principle Towards More Comprehensive Foundational Principles for Answer Set Semantics](https://arxiv.org/abs/2507.01833)
*Yi-Dong Shen,Thomas Eiter*

Main category: cs.AI

TL;DR: 论文探讨了非单调逻辑编程中答案集语义的一般原则，质疑了传统的最小模型属性、约束单调性和基础性是否必须，并提出了基于Gelfond答案集原则的改进方法。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探讨答案集语义的一般原则，质疑传统条件是否过于严格，并提出更合理的替代方案。

Method: 方法包括：1）通过例子说明传统条件的局限性；2）改进Gelfond答案集原则，引入良好支持性、默认否定最小化和认知否定最小化；3）扩展良好支持性概念；4）定义新的答案集语义；5）评估现有语义；6）分析计算复杂性。

Result: 结果表明传统条件有时过于严格，改进后的原则能更合理地定义答案集语义，并提供了新的语义定义和复杂性分析。

Conclusion: 结论是传统条件并非必须，改进的Gelfond答案集原则为答案集语义提供了更灵活和合理的基础。

Abstract: Non-monotonic logic programming is the basis for a declarative problem
solving paradigm known as answer set programming (ASP). Departing from the
seminal definition by Gelfond and Lifschitz in 1988 for simple normal logic
programs, various answer set semantics have been proposed for extensions. We
consider two important questions: (1) Should the minimal model property,
constraint monotonicity and foundedness as defined in the literature be
mandatory conditions for an answer set semantics in general? (2) If not, what
other properties could be considered as general principles for answer set
semantics? We address the two questions. First, it seems that the three
aforementioned conditions may sometimes be too strong, and we illustrate with
examples that enforcing them may exclude expected answer sets. Second, we
evolve the Gelfond answer set (GAS) principles for answer set construction by
refining the Gelfond's rationality principle to well-supportedness, minimality
w.r.t. negation by default and minimality w.r.t. epistemic negation. The
principle of well-supportedness guarantees that every answer set is
constructible from if-then rules obeying a level mapping and is thus free of
circular justification, while the two minimality principles ensure that the
formalism minimizes knowledge both at the level of answer sets and of world
views. Third, to embody the refined GAS principles, we extend the notion of
well-supportedness substantially to answer sets and world views, respectively.
Fourth, we define new answer set semantics in terms of the refined GAS
principles. Fifth, we use the refined GAS principles as an alternative baseline
to intuitively assess the existing answer set semantics. Finally, we analyze
the computational complexity.

</details>
