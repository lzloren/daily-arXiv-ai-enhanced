<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 36]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [SAMEP: A Secure Protocol for Persistent Context Sharing Across AI Agents](https://arxiv.org/abs/2507.10562)
*Hari Masoor*

Main category: cs.AI

TL;DR: SAMEP是一种新型框架，通过持久、安全且可语义搜索的内存共享解决AI代理的短暂记忆限制问题。


<details>
  <summary>Details</summary>
Motivation: 当前AI代理架构存在短暂记忆限制，阻碍了跨会话和代理边界的有效协作与知识共享。

Method: SAMEP采用分布式内存存储库，结合向量语义搜索、加密访问控制（AES-256-GCM）和标准化API（兼容MCP、A2A）。

Result: 实验显示，SAMEP减少了73%冗余计算，提升了89%上下文相关性得分，并完全符合法规要求。

Conclusion: SAMEP为持久、协作的AI代理生态系统提供了新范式，同时保障安全与隐私。

Abstract: Current AI agent architectures suffer from ephemeral memory limitations,
preventing effective collaboration and knowledge sharing across sessions and
agent boundaries. We introduce SAMEP (Secure Agent Memory Exchange Protocol), a
novel framework that enables persistent, secure, and semantically searchable
memory sharing among AI agents. Our protocol addresses three critical
challenges: (1) persistent context preservation across agent sessions, (2)
secure multi-agent collaboration with fine-grained access control, and (3)
efficient semantic discovery of relevant historical context. SAMEP implements a
distributed memory repository with vector-based semantic search, cryptographic
access controls (AES-256-GCM), and standardized APIs compatible with existing
agent communication protocols (MCP, A2A). We demonstrate SAMEP's effectiveness
across diverse domains including multi-agent software development, healthcare
AI with HIPAA compliance, and multi-modal processing pipelines. Experimental
results show 73% reduction in redundant computations, 89% improvement in
context relevance scores, and complete compliance with regulatory requirements
including audit trail generation. SAMEP enables a new paradigm of persistent,
collaborative AI agent ecosystems while maintaining security and privacy
guarantees.

</details>


### [2] [AI Mother Tongue: Self-Emergent Communication in MARL via Endogenous Symbol Systems](https://arxiv.org/abs/2507.10566)
*Hung Ming Liu*

Main category: cs.AI

TL;DR: 研究通过AIM框架证明，无需外部归纳偏置，多智能体强化学习中的通信可通过内生符号系统自然实现语义压缩与收敛。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法中人工归纳偏置可能导致的过度工程问题，探索更自然的通信涌现机制。

Method: 采用基于VQ-VAE的AIM框架，分析内生符号系统的自发语义压缩与纳什均衡驱动的语义收敛。

Result: AIM框架在通用性和效率上优于传统方法，符号使用呈现幂律分布，并提出了三项理论见解。

Conclusion: 内生符号系统为连接符号主义与连接主义提供了新途径，未来将探索HQ-VAE和RL预训练以增强表达能力。

Abstract: In Decentralized Multi-Agent Reinforcement Learning (MARL), the development
of Emergent Communication has long been constrained by the ``Joint Exploration
Dilemma'', leading agents to fall into a ``Communication Vacuum Equilibrium'' .
Traditional methods address this by introducing inductive biases to facilitate
communication emergence . This study fundamentally questions whether such
artificial inductive biases are, in fact, over-engineering. Through experiments
with the ``AI Mother Tongue'' (AIM) framework, based on a Vector Quantized
Variational Autoencoder (VQ-VAE), we demonstrate that when agents possess an
endogenous symbol system, their neural representations naturally exhibit
spontaneous semantic compression and Nash equilibrium-driven semantic
convergence, achieving effective symbolic communication without external
inductive biases. This aligns with recent neuroscience findings suggesting that
the human brain does not directly use human language for internal thought , and
resonates with research on ``soft thinking'' capabilities in Large Language
Models (LLMs) . Compared to traditional explicit communication methods, AIM
demonstrates stronger generality and efficiency. The interpretable analysis
toolkit developed in this study confirms that symbol usage exhibits a
significant power-law distribution, leading to three major theoretical
insights: the ``Neural Communication Hypothesis'', the ``Tool-First
Principle'', and the ``Semantic Interpretability Paradigm''. Future research
will explore the integration of Hierarchical Quantized Variational Autoencoders
(HQ-VAE) to enhance AIM's complex expressive capabilities and investigate the
potential for ``Reinforcement Learning (RL) Low-Level Pre-training''. This
discovery offers new avenues for bridging symbolism and connectionism.

</details>


### [3] [Orchestrator-Agent Trust: A Modular Agentic AI Visual Classification System with Trust-Aware Orchestration and RAG-Based Reasoning](https://arxiv.org/abs/2507.10571)
*Konstantinos I. Roumeliotis,Ranjan Sapkota,Manoj Karkee,Nikolaos D. Tselikas*

Main category: cs.AI

TL;DR: 论文提出了一种新型模块化AI视觉分类框架，结合多模态代理和非视觉推理协调器，通过信任校准和RAG模块提升零样本场景下的可信度。


<details>
  <summary>Details</summary>
Motivation: 解决多代理AI在零样本场景下的信任问题，特别是在无需微调的情况下。

Method: 引入模块化框架，结合多模态代理、协调器和RAG模块，通过信任校准指标（ECE、OCR、CCC）调节代理信任度。

Result: 在零样本场景下，信任感知协调和RAG使准确率提升77.94%，总体达到85.63%。

Conclusion: 该系统将感知与元推理分离，可扩展至诊断、生物学等信任关键领域，并开源所有资源以支持复现和透明性。

Abstract: Modern Artificial Intelligence (AI) increasingly relies on multi-agent
architectures that blend visual and language understanding. Yet, a pressing
challenge remains: How can we trust these agents especially in zero-shot
settings with no fine-tuning? We introduce a novel modular Agentic AI visual
classification framework that integrates generalist multimodal agents with a
non-visual reasoning orchestrator and a Retrieval-Augmented Generation (RAG)
module. Applied to apple leaf disease diagnosis, we benchmark three
configurations: (I) zero-shot with confidence-based orchestration, (II)
fine-tuned agents with improved performance, and (III) trust-calibrated
orchestration enhanced by CLIP-based image retrieval and re-evaluation loops.
Using confidence calibration metrics (ECE, OCR, CCC), the orchestrator
modulates trust across agents. Our results demonstrate a 77.94\% accuracy
improvement in the zero-shot setting using trust-aware orchestration and RAG,
achieving 85.63\% overall. GPT-4o showed better calibration, while Qwen-2.5-VL
displayed overconfidence. Furthermore, image-RAG grounded predictions with
visually similar cases, enabling correction of agent overconfidence via
iterative re-evaluation. The proposed system separates perception (vision
agents) from meta-reasoning (orchestrator), enabling scalable and interpretable
multi-agent AI. This blueprint is extensible to diagnostics, biology, and other
trust-critical domains. All models, prompts, results, and system components
including the complete software source code are openly released to support
reproducibility, transparency, and community benchmarking at Github:
https://github.com/Applied-AI-Research-Lab/Orchestrator-Agent-Trust

</details>


### [4] [Comprehension Without Competence: Architectural Limits of LLMs in Symbolic Computation and Reasoning](https://arxiv.org/abs/2507.10624)
*Zheng Zhang*

Main category: cs.AI

TL;DR: LLMs表面流畅但符号推理、算术准确性和逻辑一致性任务表现差，研究发现其问题源于计算执行而非知识获取，称为“计算分裂脑综合征”。


<details>
  <summary>Details</summary>
Motivation: 揭示LLMs在符号推理和逻辑任务中失败的根本原因，并探讨其架构限制。

Method: 通过控制实验和架构分析，研究LLMs在任务中的表现及其计算执行问题。

Result: 发现LLMs能表达正确原则但无法可靠应用，原因是计算执行中的几何和功能分离。

Conclusion: LLMs缺乏结构化推理能力，未来模型需改进元认知控制和执行架构。

Abstract: Large Language Models (LLMs) display striking surface fluency yet
systematically fail at tasks requiring symbolic reasoning, arithmetic accuracy,
and logical consistency. This paper offers a structural diagnosis of such
failures, revealing a persistent gap between \textit{comprehension} and
\textit{competence}. Through controlled experiments and architectural analysis,
we demonstrate that LLMs often articulate correct principles without reliably
applying them--a failure rooted not in knowledge access, but in computational
execution. We term this phenomenon the computational \textit{split-brain
syndrome}, where instruction and action pathways are geometrically and
functionally dissociated. This core limitation recurs across domains, from
mathematical operations to relational inferences, and explains why model
behavior remains brittle even under idealized prompting. We argue that LLMs
function as powerful pattern completion engines, but lack the architectural
scaffolding for principled, compositional reasoning. Our findings delineate the
boundary of current LLM capabilities and motivate future models with
metacognitive control, principle lifting, and structurally grounded execution.
This diagnosis also clarifies why mechanistic interpretability findings may
reflect training-specific pattern coordination rather than universal
computational principles, and why the geometric separation between instruction
and execution pathways suggests limitations in neural introspection and
mechanistic analysis.

</details>


### [5] [Enhancing the Capabilities of Large Language Models for API calls through Knowledge Graphs](https://arxiv.org/abs/2507.10630)
*Ye Yang,Xue Xiao,Ping Yin,Taotao Xie*

Main category: cs.AI

TL;DR: KG2data结合知识图谱、LLM、ReAct代理和工具使用技术，提升气象领域数据获取和查询的智能性，性能优于RAG2data和chat2data。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在知识密集型领域（如气象学）中工具使用能力不足的问题。

Method: 整合知识图谱、LLM、ReAct代理和虚拟API，评估API调用准确性。

Result: KG2data在名称识别失败（1.43%）、幻觉失败（0%）和调用正确性（88.57%）上表现优异。

Conclusion: KG2data为高知识需求领域提供了智能问答和数据分析的新方案。

Abstract: API calls by large language models (LLMs) offer a cutting-edge approach for
data analysis. However, their ability to effectively utilize tools via API
calls remains underexplored in knowledge-intensive domains like meteorology.
This paper introduces KG2data, a system that integrates knowledge graphs, LLMs,
ReAct agents, and tool-use technologies to enable intelligent data acquisition
and query handling in the meteorological field. Using a virtual API, we
evaluate API call accuracy across three metrics: name recognition failure,
hallucination failure, and call correctness. KG2data achieves superior
performance (1.43%, 0%, 88.57%) compared to RAG2data (16%, 10%, 72.14%) and
chat2data (7.14%, 8.57%, 71.43%). KG2data differs from typical LLM-based
systems by addressing their limited access to domain-specific knowledge, which
hampers performance on complex or terminology-rich queries. By using a
knowledge graph as persistent memory, our system enhances content retrieval,
complex query handling, domain-specific reasoning, semantic relationship
resolution, and heterogeneous data integration. It also mitigates the high cost
of fine-tuning LLMs, making the system more adaptable to evolving domain
knowledge and API structures. In summary, KG2data provides a novel solution for
intelligent, knowledge-based question answering and data analysis in domains
with high knowledge demands.

</details>


### [6] [From Semantic Web and MAS to Agentic AI: A Unified Narrative of the Web of Agents](https://arxiv.org/abs/2507.10644)
*Tatiana Petrova,Aleksandr Puzikov,Boris Bliznukov,Radu State*

Main category: cs.AI

TL;DR: 本文提出了Web of Agents (WoA) 的全面进化概述，揭示了从传统多智能体系统 (MAS) 和语义网到现代基于LLM的智能体的范式转变，并提出了一个四轴分类法以统一分析不同世代的智能体架构。


<details>
  <summary>Details</summary>
Motivation: 研究WoA领域的碎片化问题，揭示现代系统与传统智能体技术之间的关联，推动对领域发展的整体理解。

Method: 通过四轴分类法（语义基础、通信范式、智能中心、发现机制）系统分析智能体架构的演变，并比较不同世代的技术。

Result: 发现智能中心从外部数据或平台转向智能体核心模型的范式转变，为现代Agentic AI奠定了基础。

Conclusion: 新协议虽重要，但不足以构建健壮、开放、可信的生态系统；未来研究应聚焦于解决去中心化身份、经济模型、安全和治理等社会技术挑战。

Abstract: The concept of the Web of Agents (WoA), which transforms the static,
document-centric Web into an environment of autonomous agents acting on users'
behalf, has attracted growing interest as large language models (LLMs) become
more capable. However, research in this area is still fragmented across
different communities. Contemporary surveys catalog the latest LLM-powered
frameworks, while the rich histories of Multi-Agent Systems (MAS) and the
Semantic Web are often treated as separate, legacy domains. This fragmentation
obscures the intellectual lineage of modern systems and hinders a holistic
understanding of the field's trajectory. We present the first comprehensive
evolutionary overview of the WoA. We show that modern protocols like A2A and
the MCP, are direct evolutionary responses to the well-documented limitations
of earlier standards like FIPA standards and OWL-based semantic agents. To
systematize this analysis, we introduce a four-axis taxonomy (semantic
foundation, communication paradigm, locus of intelligence, discovery
mechanism). This framework provides a unified analytical lens for comparing
agent architectures across all generations, revealing a clear line of descent
where others have seen a disconnect. Our analysis identifies a paradigm shift
in the 'locus of intelligence': from being encoded in external data (Semantic
Web) or the platform (MAS) to being embedded within the agent's core model
(LLM). This shift is foundational to modern Agentic AI, enabling the scalable
and adaptive systems the WoA has long envisioned. We conclude that while new
protocols are essential, they are insufficient for building a robust, open,
trustworthy ecosystem. Finally, we argue that the next research frontier lies
in solving persistent socio-technical challenges, and we map out a new agenda
focused on decentralized identity, economic models, security, and governance
for the emerging WoA.

</details>


### [7] [Parsing Musical Structure to Enable Meaningful Variations](https://arxiv.org/abs/2507.10740)
*Maziar Kanani,Sean O Leary,James McDermott*

Main category: cs.AI

TL;DR: 本文提出了一种基于规则的创新方法，通过变异现有曲调生成音乐，使用语法变异而非直接修改曲调，分析了变异对曲调的影响。


<details>
  <summary>Details</summary>
Motivation: 探索如何通过语法变异生成与原始曲调相关的新曲调，并研究变异对曲调结构和音乐性的影响。

Method: 使用Sequitur算法解析曲调为语法结构（PA），随机应用19种变异类型（如添加、删除、交换或反转部分），再扩展语法生成新曲调。

Result: 通过编辑距离、结构复杂度和曲调长度等指标分析变异效果，并评估每种变异类型的影响大小。

Conclusion: 该方法能有效生成与原始曲调相关的新曲调，但仅关注音高序列生成，未涉及其他音乐元素。

Abstract: This paper presents a novel rule-based approach for generating music by
varying existing tunes. We parse each tune to find the Pathway Assembly (PA) [
1], that is a structure representing all repetitions in the tune. The Sequitur
algorithm [2 ] is used for this. The result is a grammar. We then carry out
mutation on the grammar, rather than on a tune directly. There are potentially
19 types of mutations such as adding, removing, swapping or reversing parts of
the grammar that can be applied to the grammars. The system employs one of the
mutations randomly in this step to automatically manipulate the grammar.
Following the mutation, we need to expand the grammar which returns a new tune.
The output after 1 or more mutations will be a new tune related to the original
tune. Our study examines how tunes change gradually over the course of multiple
mutations. Edit distances, structural complexity and length of the tunes are
used to show how a tune is changed after multiple mutations. In addition, the
size of effect of each mutation type is analyzed. As a final point, we review
the musical aspect of the output tunes. It should be noted that the study only
focused on generating new pitch sequences. The study is based on an Irish
traditional tune dataset and a list of integers has been used to represent each
tune's pitch values.

</details>


### [8] [AI and the Net-Zero Journey: Energy Demand, Emissions, and the Potential for Transition](https://arxiv.org/abs/2507.10750)
*Pandu Devarakota,Nicolas Tsesmetzis,Faruk O. Alpak,Apurva Gala,Detlef Hohl*

Main category: cs.AI

TL;DR: 本文探讨了AI对数据中心的能源消耗及温室气体排放的影响，分析了短期（2030年前）和长期（2035年后）的潜在影响，并讨论了AI在减排中的潜力。


<details>
  <summary>Details</summary>
Motivation: 随着AI在各行业的广泛应用，数据中心的能源消耗和碳排放问题日益突出，研究AI对环境的净影响具有重要意义。

Method: 通过分析数据中心的能源消耗和AI技术的应用，评估其对CO2排放的短期和长期影响。

Result: 短期内AI可能增加碳排放，但长期来看，AI的自动化和优化能力有望显著减少碳足迹。

Conclusion: AI初期可能对环境造成压力，但长期将成为气候缓解的重要工具。

Abstract: Thanks to the availability of massive amounts of data, computing resources,
and advanced algorithms, AI has entered nearly every sector. This has sparked
significant investment and interest, particularly in building data centers with
the necessary hardware and software to develop and operate AI models and
AI-based workflows. In this technical review article, we present energy
consumption scenarios of data centers and impact on GHG emissions, considering
both near-term projections (up to 2030) and long-term outlook (2035 and
beyond). We address the quintessential question of whether AI will have a net
positive, neutral, or negative impact on CO2 emissions by 2035. Additionally,
we discuss AI's potential to automate, create efficient and disruptive
workflows across various fields related to energy production, supply and
consumption. In the near-term scenario, the growing demand for AI will likely
strain computing resources, lead to increase in electricity consumption and
therefore associated CO2 emissions. This is due to the power-hungry nature of
big data centers and the requirements for training and running of large and
complex AI models, as well as the penetration of AI assistant search and
applications for public use. However, the long-term outlook could be more
promising. AI has the potential to be a game-changer in CO2 reduction. Its
ability to further automate and optimize processes across industries, from
energy production to logistics, could significantly decrease our carbon
footprint. This positive impact is anticipated to outweigh the initial
emissions bump, creating value for businesses and society in areas where
traditional solutions have fallen short. In essence, AI might cause some
initial growing pains for the environment, but it has the potential to support
climate mitigation efforts.

</details>


### [9] [IoT Malware Network Traffic Detection using Deep Learning and GraphSAGE Models](https://arxiv.org/abs/2507.10758)
*Nikesh Prajapati,Bimal Karki,Saroj Gopali,Akbar Siami Namin*

Main category: cs.AI

TL;DR: 该论文通过深度学习模型检测物联网恶意攻击，评估了多种模型（如GraphSAGE、BERT、TCN等）的性能，其中BERT表现最佳，准确率达99.94%。


<details>
  <summary>Details</summary>
Motivation: 物联网系统流量模式具有时序性和多样性，为模型学习提供了丰富的时间模式，因此需要高效的方法检测恶意攻击。

Method: 采用GraphSAGE、BERT、TCN、Multi-Head Attention、BI-LSTM等模型，评估其在恶意流量检测中的性能。

Result: BERT表现最优，准确率99.94%，其他模型如Multi-Head Attention和GraphSAGE各有优劣。

Conclusion: BERT在捕获时间依赖性方面表现卓越，而不同模型在准确性和计算效率上各有特点。

Abstract: This paper intends to detect IoT malicious attacks through deep learning
models and demonstrates a comprehensive evaluation of the deep learning and
graph-based models regarding malicious network traffic detection. The models
particularly are based on GraphSAGE, Bidirectional encoder representations from
transformers (BERT), Temporal Convolutional Network (TCN) as well as Multi-Head
Attention, together with Bidirectional Long Short-Term Memory (BI-LSTM)
Multi-Head Attention and BI-LSTM and LSTM models. The chosen models
demonstrated great performance to model temporal patterns and detect feature
significance. The observed performance are mainly due to the fact that IoT
system traffic patterns are both sequential and diverse, leaving a rich set of
temporal patterns for the models to learn. Experimental results showed that
BERT maintained the best performance. It achieved 99.94% accuracy rate
alongside high precision and recall, F1-score and AUC-ROC score of 99.99% which
demonstrates its capabilities through temporal dependency capture. The
Multi-Head Attention offered promising results by providing good detection
capabilities with interpretable results. On the other side, the Multi-Head
Attention model required significant processing time like BI-LSTM variants. The
GraphSAGE model achieved good accuracy while requiring the shortest training
time but yielded the lowest accuracy, precision, and F1 score compared to the
other models

</details>


### [10] [Detecting AI Assistance in Abstract Complex Tasks](https://arxiv.org/abs/2507.10761)
*Tyler King,Nikolos Gurney,John H. Miller,Volkan Ustun*

Main category: cs.AI

TL;DR: 论文提出将AI辅助检测视为分类任务，通过预处理数据使常见模型能有效分类抽象任务数据，并展示了四种图像和时间序列数据表示方法，验证了时空编码对检测AI辅助的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着AI在复杂任务中的普及，检测AI辅助变得重要，但抽象任务数据对机器学习不友好，需探索有效方法。

Method: 构建四种神经网络友好的图像表示方法和时间序列表示方法，结合经典深度学习架构和并行CNN-RNN架构进行测试。

Result: 实验表明，适当预处理的数据和时空编码能显著提升AI辅助检测性能。

Conclusion: 时空编码和预处理对检测抽象任务中的AI辅助至关重要，为其他任务提供了通用性。

Abstract: Detecting assistance from artificial intelligence is increasingly important
as they become ubiquitous across complex tasks such as text generation, medical
diagnosis, and autonomous driving. Aid detection is challenging for humans,
especially when looking at abstract task data. Artificial neural networks excel
at classification thanks to their ability to quickly learn from and process
large amounts of data -- assuming appropriate preprocessing. We posit detecting
help from AI as a classification task for such models. Much of the research in
this space examines the classification of complex but concrete data classes,
such as images. Many AI assistance detection scenarios, however, result in data
that is not machine learning-friendly. We demonstrate that common models can
effectively classify such data when it is appropriately preprocessed. To do so,
we construct four distinct neural network-friendly image formulations along
with an additional time-series formulation that explicitly encodes the
exploration/exploitation of users, which allows for generalizability to other
abstract tasks. We benchmark the quality of each image formulation across three
classical deep learning architectures, along with a parallel CNN-RNN
architecture that leverages the additional time series to maximize testing
performance, showcasing the importance of encoding temporal and spatial
quantities for detecting AI aid in abstract tasks.

</details>


### [11] [Uncertainty-Informed Scheduling of Decision Points for Intelligent Mobile Health Interventions](https://arxiv.org/abs/2507.10798)
*Asim H. Gazi,Bhanu T. Gullapalli,Daiqi Gao,Benjamin M. Marlin,Vivek Shetty,Susan A. Murphy*

Main category: cs.AI

TL;DR: SigmaScheduling动态调整决策点时间，提高移动健康干预的及时性。


<details>
  <summary>Details</summary>
Motivation: 固定时间间隔的决策点调度对习惯性行为干预效果不佳，尤其是对作息不规律的用户。

Method: 提出SigmaScheduling方法，根据行为时间预测的不确定性动态调整决策点。

Result: 在68名参与者的试验中，SigmaScheduling在70%以上的案例中成功在行为发生前调度决策点。

Conclusion: SigmaScheduling能提升精准移动健康干预的效果，尤其适用于时间敏感的习惯性行为。

Abstract: Timely decision making is critical to the effectiveness of mobile health
(mHealth) interventions. At predefined timepoints called "decision points,"
intelligent mHealth systems such as just-in-time adaptive interventions
(JITAIs) estimate an individual's biobehavioral context from sensor or survey
data and determine whether and how to intervene. For interventions targeting
habitual behavior (e.g., oral hygiene), effectiveness often hinges on
delivering support shortly before the target behavior is likely to occur.
Current practice schedules decision points at a fixed interval (e.g., one hour)
before user-provided behavior times, and the fixed interval is kept the same
for all individuals. However, this one-size-fits-all approach performs poorly
for individuals with irregular routines, often scheduling decision points after
the target behavior has already occurred, rendering interventions ineffective.
In this paper, we propose SigmaScheduling, a method to dynamically schedule
decision points based on uncertainty in predicted behavior times. When behavior
timing is more predictable, SigmaScheduling schedules decision points closer to
the predicted behavior time; when timing is less certain, SigmaScheduling
schedules decision points earlier, increasing the likelihood of timely
intervention. We evaluated SigmaScheduling using real-world data from 68
participants in a 10-week trial of Oralytics, a JITAI designed to improve daily
toothbrushing. SigmaScheduling increased the likelihood that decision points
preceded brushing events in at least 70% of cases, preserving opportunities to
intervene and impact behavior. Our results indicate that SigmaScheduling can
advance precision mHealth, particularly for JITAIs targeting time-sensitive,
habitual behaviors such as oral hygiene or dietary habits.

</details>


### [12] [Automated Thematic Analyses Using LLMs: Xylazine Wound Management Social Media Chatter Use Case](https://arxiv.org/abs/2507.10803)
*JaMor Hairston,Ritvik Ranjan,Sahithi Lakamana,Anthony Spadaro,Selen Bozkurt,Jeanmarie Perrone,Abeed Sarker*

Main category: cs.AI

TL;DR: 大语言模型（LLMs）在归纳主题分析任务中表现良好，尤其是GPT-4o在少量样本提示下效果最佳，可作为定性研究的补充工具。


<details>
  <summary>Details</summary>
Motivation: 评估LLMs在复制专家驱动的社交媒体数据主题分析中的可行性，以解决其在该任务中的挑战。

Method: 使用两个Reddit数据集，将任务建模为一系列二元分类，采用零样本、单样本和少量样本提示策略，评估五个LLMs的性能。

Result: GPT-4o在少量样本提示下表现最佳（准确率90.9%，F1分数0.71），高流行主题的分布与专家分类接近。

Conclusion: 少量样本LLM方法可自动化主题分析，为定性研究提供可扩展的补充手段。

Abstract: Background Large language models (LLMs) face challenges in inductive thematic
analysis, a task requiring deep interpretive and domain-specific expertise. We
evaluated the feasibility of using LLMs to replicate expert-driven thematic
analysis of social media data. Methods Using two temporally non-intersecting
Reddit datasets on xylazine (n=286 and n=686, for model optimization and
validation, respectively) with twelve expert-derived themes, we evaluated five
LLMs against expert coding. We modeled the task as a series of binary
classifications, rather than a single, multi-label classification, employing
zero-, single-, and few-shot prompting strategies and measuring performance via
accuracy, precision, recall, and F1-score. Results On the validation set,
GPT-4o with two-shot prompting performed best (accuracy: 90.9%; F1-score:
0.71). For high-prevalence themes, model-derived thematic distributions closely
mirrored expert classifications (e.g., xylazine use: 13.6% vs. 17.8%; MOUD use:
16.5% vs. 17.8%). Conclusions Our findings suggest that few-shot LLM-based
approaches can automate thematic analyses, offering a scalable supplement for
qualitative research. Keywords: thematic analysis, large language models,
natural language processing, qualitative analysis, social media, prompt
engineering, public health

</details>


### [13] [AF-XRAY: Visual Explanation and Resolution of Ambiguity in Legal Argumentation Frameworks](https://arxiv.org/abs/2507.10831)
*Yilin Xia,Heng Zheng,Shawn Bowers,Bertram Ludäscher*

Main category: cs.AI

TL;DR: AF-XRAY是一个开源工具包，用于探索、分析和可视化法律推理中的抽象论证框架，帮助非专家识别歧义来源并解释论证接受性。


<details>
  <summary>Details</summary>
Motivation: 解决法律推理中论证框架的歧义问题，为非专家提供工具以理解和分析论证接受性。

Method: AF-XRAY通过分层可视化、攻击边分类、替代解决方案叠加和关键攻击集识别等方法分析论证框架。

Result: 工具能将歧义场景转化为明确的解决方案，揭示不同假设如何导致不同结论，支持法律推理。

Conclusion: AF-XRAY有效支持法律推理，帮助用户识别歧义原因并探索替代解决方案。

Abstract: Argumentation frameworks (AFs) provide formal approaches for legal reasoning,
but identifying sources of ambiguity and explaining argument acceptance remains
challenging for non-experts. We present AF-XRAY, an open-source toolkit for
exploring, analyzing, and visualizing abstract AFs in legal reasoning. AF-XRAY
introduces: (i) layered visualizations based on game-theoretic argument length
revealing well-founded derivation structures; (ii) classification of attack
edges by semantic roles (primary, secondary, blunders); (iii) overlay
visualizations of alternative 2-valued solutions on ambiguous 3-valued grounded
semantics; and (iv) identification of critical attack sets whose suspension
resolves undecided arguments. Through systematic generation of critical attack
sets, AF-XRAY transforms ambiguous scenarios into grounded solutions, enabling
users to pinpoint specific causes of ambiguity and explore alternative
resolutions. We use real-world legal cases (e.g., Wild Animals as modeled by
Bench-Capon) to show that our tool supports teleological legal reasoning by
revealing how different assumptions lead to different justified conclusions.

</details>


### [14] [NavComposer: Composing Language Instructions for Navigation Trajectories through Action-Scene-Object Modularization](https://arxiv.org/abs/2507.10894)
*Zongtao He,Liuyi Wang,Lu Chen,Chengju Liu,Qijun Chen*

Main category: cs.AI

TL;DR: NavComposer是一个自动生成高质量导航指令的框架，通过分解和重组语义实体生成自然语言指令。NavInstrCritic是一个无需标注的评估系统，从三个维度评估指令质量。


<details>
  <summary>Details</summary>
Motivation: 解决专家提供的导航指令数量有限和合成标注质量不足的问题，以支持大规模研究。

Method: NavComposer分解语义实体（动作、场景、对象）并重组为自然语言指令；NavInstrCritic通过对比匹配、语义一致性和语言多样性评估指令质量。

Result: 实验证明该方法有效，支持更可扩展和通用的研究。

Conclusion: NavComposer和NavInstrCritic为语言引导导航提供了高质量指令生成和评估的解决方案。

Abstract: Language-guided navigation is a cornerstone of embodied AI, enabling agents
to interpret language instructions and navigate complex environments. However,
expert-provided instructions are limited in quantity, while synthesized
annotations often lack quality, making them insufficient for large-scale
research. To address this, we propose NavComposer, a novel framework for
automatically generating high-quality navigation instructions. NavComposer
explicitly decomposes semantic entities such as actions, scenes, and objects,
and recomposes them into natural language instructions. Its modular
architecture allows flexible integration of state-of-the-art techniques, while
the explicit use of semantic entities enhances both the richness and accuracy
of instructions. Moreover, it operates in a data-agnostic manner, supporting
adaptation to diverse navigation trajectories without domain-specific training.
Complementing NavComposer, we introduce NavInstrCritic, a comprehensive
annotation-free evaluation system that assesses navigation instructions on
three dimensions: contrastive matching, semantic consistency, and linguistic
diversity. NavInstrCritic provides a holistic evaluation of instruction
quality, addressing limitations of traditional metrics that rely heavily on
expert annotations. By decoupling instruction generation and evaluation from
specific navigation agents, our method enables more scalable and generalizable
research. Extensive experiments provide direct and practical evidence for the
effectiveness of our method.

</details>


### [15] [Lessons Learned from Evaluation of LLM based Multi-agents in Safer Therapy Recommendation](https://arxiv.org/abs/2507.10911)
*Yicong Wu,Ting Chen,Irit Hochberg,Zhoujian Sun,Ruth Edry,Zhengxing Huang,Mor Peleg*

Main category: cs.AI

TL;DR: 研究了基于大型语言模型（LLM）的多智能体系统（MAS）在慢性多病患者的治疗推荐中的可行性和价值，发现单智能体与多智能体表现相当，但建议仍存在不完整和不必要的药物问题。


<details>
  <summary>Details</summary>
Motivation: 由于多病患者的治疗冲突风险，现有决策支持系统存在可扩展性限制，研究旨在探索LLM-MAS模拟多学科团队（MDT）决策的潜力。

Method: 设计了单智能体和MAS框架，模拟MDT决策过程，通过LLM智能体间的讨论解决医疗冲突，并在多病患者治疗任务上进行评估。

Result: 当前LLM下，单智能体表现与MDT相当，但建议存在不完整和不必要的药物问题。

Conclusion: LLM-MAS在多病治疗推荐中具有潜力，但需进一步优化以减少不完整和不必要的药物建议。

Abstract: Therapy recommendation for chronic patients with multimorbidity is
challenging due to risks of treatment conflicts. Existing decision support
systems face scalability limitations. Inspired by the way in which general
practitioners (GP) manage multimorbidity patients, occasionally convening
multidisciplinary team (MDT) collaboration, this study investigated the
feasibility and value of using a Large Language Model (LLM)-based multi-agent
system (MAS) for safer therapy recommendations. We designed a single agent and
a MAS framework simulating MDT decision-making by enabling discussion among LLM
agents to resolve medical conflicts. The systems were evaluated on therapy
planning tasks for multimorbidity patients using benchmark cases. We compared
MAS performance with single-agent approaches and real-world benchmarks. An
important contribution of our study is the definition of evaluation metrics
that go beyond the technical precision and recall and allow the inspection of
clinical goals met and medication burden of the proposed advices to a gold
standard benchmark. Our results show that with current LLMs, a single agent GP
performs as well as MDTs. The best-scoring models provide correct
recommendations that address all clinical goals, yet the advices are
incomplete. Some models also present unnecessary medications, resulting in
unnecessary conflicts between medication and conditions or drug-drug
interactions.

</details>


### [16] [Enhancing Safe and Controllable Protein Generation via Knowledge Preference Optimization](https://arxiv.org/abs/2507.10923)
*Yuhao Wang,Keyan Ding,Kehua Feng,Zeyuan Wang,Ming Qin,Xiaotong Li,Qiang Zhang,Huajun Chen*

Main category: cs.AI

TL;DR: 提出了一种知识引导的偏好优化（KPO）框架，通过蛋白质安全知识图谱整合先验知识，以减少生成有害蛋白质序列的风险。


<details>
  <summary>Details</summary>
Motivation: 蛋白质语言模型在序列生成中表现出强大能力，但也可能生成有害序列，如增强病毒传播性或逃避免疫反应的蛋白质，这带来了生物安全和伦理挑战。

Method: KPO框架结合了蛋白质安全知识图谱和高效的图剪枝策略，通过强化学习最小化有害蛋白质的生成风险。

Result: 实验表明，KPO能有效降低有害序列的生成概率，同时保持高功能性。

Conclusion: KPO为生物技术中生成模型的应用提供了一个安全可靠的框架。

Abstract: Protein language models have emerged as powerful tools for sequence
generation, offering substantial advantages in functional optimization and
denovo design. However, these models also present significant risks of
generating harmful protein sequences, such as those that enhance viral
transmissibility or evade immune responses. These concerns underscore critical
biosafety and ethical challenges. To address these issues, we propose a
Knowledge-guided Preference Optimization (KPO) framework that integrates prior
knowledge via a Protein Safety Knowledge Graph. This framework utilizes an
efficient graph pruning strategy to identify preferred sequences and employs
reinforcement learning to minimize the risk of generating harmful proteins.
Experimental results demonstrate that KPO effectively reduces the likelihood of
producing hazardous sequences while maintaining high functionality, offering a
robust safety assurance framework for applying generative models in
biotechnology.

</details>


### [17] [Modeling Habitat Shifts: Integrating Convolutional Neural Networks and Tabular Data for Species Migration Prediction](https://arxiv.org/abs/2507.10993)
*Emir Durakovic,Min-Hong Shih*

Main category: cs.AI

TL;DR: 结合卷积神经网络（CNN）和表格数据，准确预测鸟类在特定栖息地的存在。


<details>
  <summary>Details</summary>
Motivation: 由于气候变化导致栖息地范围变化，需要一种可靠的方法预测鸟类分布。

Method: 使用卫星图像和环境特征（如温度、降水、海拔）结合CNN和表格数据建模。

Result: 模型预测鸟类分布的准确率达到85%。

Conclusion: 该方法为理解鸟类迁徙提供了可扩展且可靠的解决方案。

Abstract: Due to climate-induced changes, many habitats are experiencing range shifts
away from their traditional geographic locations (Piguet, 2011). We propose a
solution to accurately model whether bird species are present in a specific
habitat through the combination of Convolutional Neural Networks (CNNs)
(O'Shea, 2015) and tabular data. Our approach makes use of satellite imagery
and environmental features (e.g., temperature, precipitation, elevation) to
predict bird presence across various climates. The CNN model captures spatial
characteristics of landscapes such as forestation, water bodies, and
urbanization, whereas the tabular method uses ecological and geographic data.
Both systems predict the distribution of birds with an average accuracy of 85%,
offering a scalable but reliable method to understand bird migration.

</details>


### [18] [Personalized Exercise Recommendation with Semantically-Grounded Knowledge Tracing](https://arxiv.org/abs/2507.11060)
*Yilmazcan Ozyurt,Tunaberk Almaci,Stefan Feuerriegel,Mrinmaya Sachan*

Main category: cs.AI

TL;DR: ExRec是一个基于语义知识追踪的个性化练习推荐框架，通过结合问题语义和学生学习的结构化进展，优化强化学习方法，提升推荐效果。


<details>
  <summary>Details</summary>
Motivation: 现有练习推荐方法常忽略问题的语义内容和学生学习的结构化进展，ExRec旨在解决这一问题。

Method: ExRec采用端到端流程，包括问题知识组件标注、语义表示学习、知识追踪模型训练和强化学习优化，并提出基于模型的价值估计方法。

Result: 在四个真实数学学习任务中验证了ExRec的有效性，能泛化到新问题并生成可解释的学习轨迹。

Conclusion: ExRec展示了知识追踪引导的强化学习在教育个性化中的潜力。

Abstract: We introduce ExRec, a general framework for personalized exercise
recommendation with semantically-grounded knowledge tracing. Our method builds
on the observation that existing exercise recommendation approaches simulate
student performance via knowledge tracing (KT) but they often overlook two key
aspects: (a) the semantic content of questions and (b) the sequential,
structured progression of student learning. To address this, our ExRec presents
an end-to-end pipeline, from annotating the KCs of questions and learning their
semantic representations to training KT models and optimizing several
reinforcement learning (RL) methods. Moreover, we improve standard
Q-learning-based continuous RL methods via a tailored model-based value
estimation (MVE) approach that directly leverages the components of KT model in
estimating cumulative knowledge improvement. We validate the effectiveness of
our ExRec using various RL methods across four real-world tasks with different
educational goals in online math learning. We further show that ExRec
generalizes robustly to new, unseen questions and that it produces
interpretable student learning trajectories. Together, our findings highlight
the promise of KT-guided RL for effective personalization in education.

</details>


### [19] [Tactical Decision for Multi-UGV Confrontation with a Vision-Language Model-Based Commander](https://arxiv.org/abs/2507.11079)
*Li Wang,Qizhen Wu,Lei Chen*

Main category: cs.AI

TL;DR: 提出了一种基于视觉语言模型的指挥官方法，用于解决无人地面车辆对抗中的智能感知到决策推理问题，结合了视觉语言模型和轻量级大语言模型，实现了高适应性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统基于规则的方法在复杂战场环境中表现脆弱，而现有强化学习方法缺乏可解释性且主要关注动作而非战略决策。

Method: 整合视觉语言模型用于场景理解和轻量级大语言模型用于战略推理，在共享语义空间中实现感知与决策的统一。

Result: 仿真和消融实验表明，该方法在基线模型对比中胜率超过80%。

Conclusion: 该方法通过模拟人类指挥官的认知过程，实现了全链条的感知到决策推理，具有强适应性和可解释性。

Abstract: In multiple unmanned ground vehicle confrontations, autonomously evolving
multi-agent tactical decisions from situational awareness remain a significant
challenge. Traditional handcraft rule-based methods become vulnerable in the
complicated and transient battlefield environment, and current reinforcement
learning methods mainly focus on action manipulation instead of strategic
decisions due to lack of interpretability. Here, we propose a vision-language
model-based commander to address the issue of intelligent
perception-to-decision reasoning in autonomous confrontations. Our method
integrates a vision language model for scene understanding and a lightweight
large language model for strategic reasoning, achieving unified perception and
decision within a shared semantic space, with strong adaptability and
interpretability. Unlike rule-based search and reinforcement learning methods,
the combination of the two modules establishes a full-chain process, reflecting
the cognitive process of human commanders. Simulation and ablation experiments
validate that the proposed approach achieves a win rate of over 80% compared
with baseline models.

</details>


### [20] [Function-to-Style Guidance of LLMs for Code Translation](https://arxiv.org/abs/2507.11083)
*Longhui Zhang,Bin Wang,Jiahao Wang,Xiaofeng Zhao,Min Zhang,Hao Yang,Meishan Zhang,Yu Li,Jing Li,Jun Yu,Min Zhang*

Main category: cs.AI

TL;DR: F2STrans提出了一种分阶段的代码翻译方法，通过功能学习和风格学习提升LLMs的翻译性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLMs在代码翻译中难以同时保证正确性和可读性，限制了实际应用。

Method: 采用功能学习和风格学习两阶段方法，结合高质量代码对和正负风格示例。

Result: 实验表明，F2STrans显著提升性能，小模型Qwen-1.5B甚至优于大模型Qwen-32B和GPT-4。

Conclusion: F2STrans通过分阶段优化，有效解决了代码翻译中的正确性和可读性问题。

Abstract: Large language models (LLMs) have made significant strides in code
translation tasks. However, ensuring both the correctness and readability of
translated code remains a challenge, limiting their effective adoption in
real-world software development. In this work, we propose F2STrans, a
function-to-style guiding paradigm designed to progressively improve the
performance of LLMs in code translation. Our approach comprises two key stages:
(1) Functional learning, which optimizes translation correctness using
high-quality source-target code pairs mined from online programming platforms,
and (2) Style learning, which improves translation readability by incorporating
both positive and negative style examples. Additionally, we introduce a novel
code translation benchmark that includes up-to-date source code, extensive test
cases, and manually annotated ground-truth translations, enabling comprehensive
functional and stylistic evaluations. Experiments on both our new benchmark and
existing datasets demonstrate that our approach significantly improves code
translation performance. Notably, our approach enables Qwen-1.5B to outperform
prompt-enhanced Qwen-32B and GPT-4 on average across 20 diverse code
translation scenarios.

</details>


### [21] [AI Agent Architecture for Decentralized Trading of Alternative Assets](https://arxiv.org/abs/2507.11117)
*Ailiya Borjigin,Cong He,Charles CC Lee,Wei Zhou*

Main category: cs.AI

TL;DR: GoldMine OS是一个研究导向的架构，利用多个专用AI代理自动化和安全地将实物黄金代币化为区块链稳定币（OZ）。通过结合链上智能合约和链下AI代理决策，系统在模拟和试点部署中表现出高效、安全和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 解决实物资产（如黄金）在区块链上的去中心化交易问题，需满足合规性、流动性和风险管理要求。

Method: 采用多代理协作架构（合规、代币发行、做市和风险控制）和协调核心，结合链上智能合约与链下AI决策。

Result: 原型系统实现1.2秒内按需代币发行，做市代理在波动条件下保持0.5%以内的价差，系统可扩展至每秒5000笔交易。

Conclusion: AI代理驱动的去中心化交易所可满足高性能和安全性需求，为传统非流动性资产提供民主化访问途径。

Abstract: Decentralized trading of real-world alternative assets (e.g., gold) requires
bridging physical asset custody with blockchain systems while meeting strict
requirements for compliance, liquidity, and risk management. We present
GoldMine OS, a research oriented architecture that employs multiple specialized
AI agents to automate and secure the tokenization and exchange of physical gold
into a blockchain based stablecoin ("OZ"). Our approach combines on chain smart
contracts for critical risk controls with off chain AI agents for decision
making, blending the transparency and reliability of blockchains with the
flexibility of AI driven automation. We describe four cooperative agents
(Compliance, Token Issuance, Market Making, and Risk Control) and a
coordinating core, and evaluate the system through simulation and a controlled
pilot deployment. In experiments the prototype delivers on demand token
issuance in under 1.2 s, more than 100 times faster than manual workflows. The
Market Making agent maintains tight liquidity with spreads often below 0.5
percent even under volatile conditions. Fault injection tests show resilience:
an oracle price spoofing attack is detected and mitigated within 10 s, and a
simulated vault mis reporting halts issuance immediately with minimal user
impact. The architecture scales to 5000 transactions per second with 10000
concurrent users in benchmarks. These results indicate that an AI agent based
decentralized exchange for alternative assets can satisfy rigorous performance
and safety requirements. We discuss broader implications for democratizing
access to traditionally illiquid assets and explain how our governance model --
multi signature agent updates and on chain community voting on risk parameters
-- provides ongoing transparency, adaptability, and formal assurance of system
integrity.

</details>


### [22] [Defining neurosymbolic AI](https://arxiv.org/abs/2507.11127)
*Lennert De Smet,Luc De Raedt*

Main category: cs.AI

TL;DR: 该论文提出了一个神经符号AI的形式化定义，抽象了其关键组成部分，并展示了其代表性。


<details>
  <summary>Details</summary>
Motivation: 神经符号AI领域缺乏普遍接受的形式化定义，阻碍了其发展。

Method: 通过定义神经符号推理为逻辑函数和信念函数乘积的积分，抽象了关键要素。

Result: 提出的定义能够抽象代表性神经符号AI系统的核心特征。

Conclusion: 该形式化定义有助于统一神经符号AI领域的理解和发展。

Abstract: Neurosymbolic AI focuses on integrating learning and reasoning, in
particular, on unifying logical and neural representations. Despite the
existence of an alphabet soup of neurosymbolic AI systems, the field is lacking
a generally accepted formal definition of what neurosymbolic models and
inference really are. We introduce a formal definition for neurosymbolic AI
that makes abstraction of its key ingredients. More specifically, we define
neurosymbolic inference as the computation of an integral over a product of a
logical and a belief function. We show that our neurosymbolic AI definition
makes abstraction of key representative neurosymbolic AI systems.

</details>


### [23] [Collaborative Trustworthiness for Good Decision Making in Autonomous Systems](https://arxiv.org/abs/2507.11135)
*Selma Saidi,Omar Laimona,Christoph Schmickler,Dirk Ziegenbein*

Main category: cs.AI

TL;DR: 提出了一种基于协作的信任增强方法，利用系统感知质量等属性确定可信度，并通过BDD模型实现高效决策。


<details>
  <summary>Details</summary>
Motivation: 解决自主系统在动态复杂环境中安全可靠决策的挑战，提升信任度和决策质量。

Method: 利用感知质量等属性评估可信度，结合社会认识论定义聚合与传播规则，使用BDD模型进行高效计算。

Result: 通过BDD模型和简化规则，实现了协作自动化推理的高效计算结构。

Conclusion: 该方法提升了自主系统的信任度和决策可靠性，适用于动态复杂环境。

Abstract: Autonomous systems are becoming an integral part of many application domains,
like in the mobility sector. However, ensuring their safe and correct behaviour
in dynamic and complex environments remains a significant challenge, where
systems should autonomously make decisions e.g., about manoeuvring. We propose
in this paper a general collaborative approach for increasing the level of
trustworthiness in the environment of operation and improve reliability and
good decision making in autonomous system. In the presence of conflicting
information, aggregation becomes a major issue for trustworthy decision making
based on collaborative data sharing. Unlike classical approaches in the
literature that rely on consensus or majority as aggregation rule, we exploit
the fact that autonomous systems have different quality attributes like
perception quality. We use this criteria to determine which autonomous systems
are trustworthy and borrow concepts from social epistemology to define
aggregation and propagation rules, used for automated decision making. We use
Binary Decision Diagrams (BDDs) as formal models for beliefs aggregation and
propagation, and formulate reduction rules to reduce the size of the BDDs and
allow efficient computation structures for collaborative automated reasoning.

</details>


### [24] [Fine-grained Timing Analysis of Digital Integrated Circuits in Answer Set Programming](https://arxiv.org/abs/2507.11150)
*Alessandro Bertagnon,Marcello Dalpasso,Michele Favalli,Marco Gavanelli*

Main category: cs.AI

TL;DR: 论文提出了一种使用答案集编程（ASP）精确计算组合电路最大延迟的方法，以替代传统的静态时序分析，从而优化处理器性能。


<details>
  <summary>Details</summary>
Motivation: 传统静态时序分析虽然能在多项式时间内计算最大延迟的上界，但可能导致处理器性能未达最优。本文旨在精确计算最大延迟。

Method: 将问题建模为答案集编程（ASP），并提出非平凡的编码方法。

Result: 实验结果表明，ASP是解决硬件设计中复杂问题的可行方案。

Conclusion: ASP为精确计算组合电路最大延迟提供了有效方法，有助于提升处理器性能。

Abstract: In the design of integrated circuits, one critical metric is the maximum
delay introduced by combinational modules within the circuit. This delay is
crucial because it represents the time required to perform a computation: in an
Arithmetic-Logic Unit it represents the maximum time taken by the circuit to
perform an arithmetic operation. When such a circuit is part of a larger,
synchronous system, like a CPU, the maximum delay directly impacts the maximum
clock frequency of the entire system. Typically, hardware designers use Static
Timing Analysis to compute an upper bound of the maximum delay because it can
be determined in polynomial time. However, relying on this upper bound can lead
to suboptimal processor speeds, thereby missing performance opportunities. In
this work, we tackle the challenging task of computing the actual maximum
delay, rather than an approximate value. Since the problem is computationally
hard, we model it in Answer Set Programming (ASP), a logic language featuring
extremely efficient solvers. We propose non-trivial encodings of the problem
into ASP. Experimental results show that ASP is a viable solution to address
complex problems in hardware design.

</details>


### [25] [DuetGraph: Coarse-to-Fine Knowledge Graph Reasoning with Dual-Pathway Global-Local Fusion](https://arxiv.org/abs/2507.11229)
*Jin Li,Zezhong Ding,Xike Xie*

Main category: cs.AI

TL;DR: DuetGraph提出了一种双路径全局-局部融合的知识图推理机制，通过分离全局和局部信息处理路径解决分数过平滑问题，并通过粗到细优化提升推理质量。


<details>
  <summary>Details</summary>
Motivation: 现有知识图推理方法因全局和局部信息堆叠导致分数过平滑，模糊正确答案与错误答案的区分，影响推理效果。

Method: DuetGraph采用双路径机制分离全局（注意力）和局部（消息传递）信息处理，并引入粗到细优化策略，将实体分为高、低分集以缩小候选空间。

Result: 实验表明，DuetGraph在推理质量上提升8.7%，训练效率提高1.8倍，达到SOTA性能。

Conclusion: DuetGraph通过双路径融合和粗到细优化有效解决了分数过平滑问题，显著提升了知识图推理的效果和效率。

Abstract: Knowledge graphs (KGs) are vital for enabling knowledge reasoning across
various domains. Recent KG reasoning methods that integrate both global and
local information have achieved promising results. However, existing methods
often suffer from score over-smoothing, which blurs the distinction between
correct and incorrect answers and hinders reasoning effectiveness. To address
this, we propose DuetGraph, a coarse-to-fine KG reasoning mechanism with
dual-pathway global-local fusion. DuetGraph tackles over-smoothing by
segregating -- rather than stacking -- the processing of local (via message
passing) and global (via attention) information into two distinct pathways,
preventing mutual interference and preserving representational discrimination.
In addition, DuetGraph introduces a coarse-to-fine optimization, which
partitions entities into high- and low-score subsets. This strategy narrows the
candidate space and sharpens the score gap between the two subsets, which
alleviates over-smoothing and enhances inference quality. Extensive experiments
on various datasets demonstrate that DuetGraph achieves state-of-the-art (SOTA)
performance, with up to an 8.7% improvement in reasoning quality and a
1.8$\times$ acceleration in training efficiency.

</details>


### [26] [Taming Uncertainty via Automation: Observing, Analyzing, and Optimizing Agentic AI Systems](https://arxiv.org/abs/2507.11277)
*Dany Moshkovich,Sergey Zeltyn*

Main category: cs.AI

TL;DR: AgentOps是一个用于观察、分析和优化基于LLM的代理系统的框架，旨在解决其不确定性带来的挑战。


<details>
  <summary>Details</summary>
Motivation: LLM驱动的代理系统在复杂任务中表现出色，但也引入了新的不确定性，传统方法无法应对。

Method: 提出了AgentOps框架和六阶段的自动化流程，涵盖从观察到运行时自动化的全过程。

Result: 框架支持开发、测试、运维和业务用户，通过自动化管理不确定性。

Conclusion: AgentOps通过驯服而非消除不确定性，确保代理系统的安全、适应性和高效运行。

Abstract: Large Language Models (LLMs) are increasingly deployed within agentic
systems-collections of interacting, LLM-powered agents that execute complex,
adaptive workflows using memory, tools, and dynamic planning. While enabling
powerful new capabilities, these systems also introduce unique forms of
uncertainty stemming from probabilistic reasoning, evolving memory states, and
fluid execution paths. Traditional software observability and operations
practices fall short in addressing these challenges.
  This paper introduces AgentOps: a comprehensive framework for observing,
analyzing, optimizing, and automating operation of agentic AI systems. We
identify distinct needs across four key roles-developers, testers, site
reliability engineers (SREs), and business users-each of whom engages with the
system at different points in its lifecycle. We present the AgentOps Automation
Pipeline, a six-stage process encompassing behavior observation, metric
collection, issue detection, root cause analysis, optimized recommendations,
and runtime automation. Throughout, we emphasize the critical role of
automation in managing uncertainty and enabling self-improving AI systems-not
by eliminating uncertainty, but by taming it to ensure safe, adaptive, and
effective operation.

</details>


### [27] [Opus: A Prompt Intention Framework for Complex Workflow Generation](https://arxiv.org/abs/2507.11288)
*Théo Fagnoni,Mahsun Altin,Chia En Chung,Phillip Kingston,Alan Tuning,Dana O. Mohamed,Inès Adnani*

Main category: cs.AI

TL;DR: Opus Prompt Intention Framework通过引入意图捕捉层，显著提升了基于LLM的复杂工作流生成质量。


<details>
  <summary>Details</summary>
Motivation: 解决直接基于用户查询生成工作流时逻辑性和扩展性的不足，特别是在多意图查询场景下。

Method: 提出Opus工作流意图框架，包括从用户查询中提取工作流信号、解析为结构化意图对象，并基于意图生成工作流。

Result: 在1000个多意图查询-工作流对的基准测试中，语义相似度指标显著提升。

Conclusion: 该框架通过意图捕捉层有效提高了工作流生成的逻辑性和可靠性，尤其在混合意图场景下表现突出。

Abstract: This paper introduces the Opus Prompt Intention Framework, designed to
improve complex Workflow Generation with instruction-tuned Large Language
Models (LLMs). We propose an intermediate Intention Capture layer between user
queries and Workflow Generation, implementing the Opus Workflow Intention
Framework, which consists of extracting Workflow Signals from user queries,
interpreting them into structured Workflow Intention objects, and generating
Workflows based on these Intentions. Our results show that this layer enables
LLMs to produce logical and meaningful outputs that scale reliably as query
complexity increases. On a synthetic benchmark of 1,000 multi-intent
query-Workflow(s) pairs, applying the Opus Prompt Intention Framework to
Workflow Generation yields consistent improvements in semantic Workflow
similarity metrics. In this paper, we introduce the Opus Prompt Intention
Framework by applying the concepts of Workflow Signal and Workflow Intention to
LLM-driven Workflow Generation. We present a reproducible, customizable
LLM-based Intention Capture system to extract Workflow Signals and Workflow
Intentions from user queries. Finally, we provide empirical evidence that the
proposed system significantly improves Workflow Generation quality compared to
direct generation from user queries, particularly in cases of Mixed Intention
Elicitation.

</details>


### [28] [Contestability in Quantitative Argumentation](https://arxiv.org/abs/2507.11323)
*Xiang Yin,Nico Potyka,Antonio Rago,Timotheus Kampik,Francesca Toni*

Main category: cs.AI

TL;DR: 本文探讨了如何利用边加权定量双极论证框架（EW-QBAFs）实现可争议AI决策，提出了基于梯度的关系归因解释（G-RAEs）和迭代算法，以调整边权重达到目标论证强度。


<details>
  <summary>Details</summary>
Motivation: 研究如何使AI驱动的决策更符合人类偏好，通过EW-QBAFs支持可争议性。

Method: 提出G-RAEs量化边权重对论证强度的影响，并开发迭代算法调整权重。

Result: 在模拟推荐系统和多层感知器的合成EW-QBAFs上验证了方法的有效性。

Conclusion: G-RAEs和迭代算法能有效解决EW-QBAFs中的可争议性问题。

Abstract: Contestable AI requires that AI-driven decisions align with human
preferences. While various forms of argumentation have been shown to support
contestability, Edge-Weighted Quantitative Bipolar Argumentation Frameworks
(EW-QBAFs) have received little attention. In this work, we show how EW-QBAFs
can be deployed for this purpose. Specifically, we introduce the contestability
problem for EW-QBAFs, which asks how to modify edge weights (e.g., preferences)
to achieve a desired strength for a specific argument of interest (i.e., a
topic argument). To address this problem, we propose gradient-based relation
attribution explanations (G-RAEs), which quantify the sensitivity of the topic
argument's strength to changes in individual edge weights, thus providing
interpretable guidance for weight adjustments towards contestability. Building
on G-RAEs, we develop an iterative algorithm that progressively adjusts the
edge weights to attain the desired strength. We evaluate our approach
experimentally on synthetic EW-QBAFs that simulate the structural
characteristics of personalised recommender systems and multi-layer
perceptrons, and demonstrate that it can solve the problem effectively.

</details>


### [29] [CogDDN: A Cognitive Demand-Driven Navigation with Decision Optimization and Dual-Process Thinking](https://arxiv.org/abs/2507.11334)
*Yuehao Huang,Liang Liu,Shuangming Lei,Yukai Ma,Hao Su,Jianbiao Mei,Pengxiang Zhao,Yaqing Gu,Yong Liu,Jiajun Lv*

Main category: cs.AI

TL;DR: CogDDN是一个基于视觉语言模型（VLM）的框架，通过模拟人类认知和学习机制，结合快速和慢速思维系统，提升机器人在未知环境中的导航和交互能力。


<details>
  <summary>Details</summary>
Motivation: 传统的数据驱动需求导航（DDN）方法依赖预收集的数据，限制了其在未知场景中的泛化能力。CogDDN旨在通过模拟人类认知机制解决这一问题。

Method: CogDDN结合快速（启发式）和慢速（分析式）决策模块，通过语义对齐识别关键目标对象，并利用链式思维（CoT）推理优化决策过程。

Result: 在AI2Thor模拟器和ProcThor数据集上的评估显示，CogDDN比单视角相机方法导航准确率提高了15%。

Conclusion: CogDDN通过模拟人类认知机制，显著提升了机器人在未知环境中的导航适应性和准确性。

Abstract: Mobile robots are increasingly required to navigate and interact within
unknown and unstructured environments to meet human demands. Demand-driven
navigation (DDN) enables robots to identify and locate objects based on
implicit human intent, even when object locations are unknown. However,
traditional data-driven DDN methods rely on pre-collected data for model
training and decision-making, limiting their generalization capability in
unseen scenarios. In this paper, we propose CogDDN, a VLM-based framework that
emulates the human cognitive and learning mechanisms by integrating fast and
slow thinking systems and selectively identifying key objects essential to
fulfilling user demands. CogDDN identifies appropriate target objects by
semantically aligning detected objects with the given instructions.
Furthermore, it incorporates a dual-process decision-making module, comprising
a Heuristic Process for rapid, efficient decisions and an Analytic Process that
analyzes past errors, accumulates them in a knowledge base, and continuously
improves performance. Chain of Thought (CoT) reasoning strengthens the
decision-making process. Extensive closed-loop evaluations on the AI2Thor
simulator with the ProcThor dataset show that CogDDN outperforms single-view
camera-only methods by 15%, demonstrating significant improvements in
navigation accuracy and adaptability. The project page is available at
https://yuehaohuang.github.io/CogDDN/.

</details>


### [30] [Foundation Models for Logistics: Toward Certifiable, Conversational Planning Interfaces](https://arxiv.org/abs/2507.11352)
*Yunhao Yang,Neel P. Bhatt,Christian Ellis,Alvaro Velasquez,Zhangyang Wang,Ufuk Topcu*

Main category: cs.AI

TL;DR: 论文提出了一种结合自然语言对话与可验证保证的神经符号框架，用于物流决策，提升实时性和安全性。


<details>
  <summary>Details</summary>
Motivation: 物流决策常需快速调整且涉及不确定性，现有方法（如整数规划）速度慢且假设理想环境，而大语言模型（LLMs）易产生误解和幻觉。

Method: 引入神经符号框架，将用户请求转为结构化规划，量化不确定性，并在置信度低时触发交互式澄清循环。

Result: 轻量级模型在100个不确定性过滤示例上微调，性能超越GPT-4.1，推理延迟降低近50%。

Conclusion: 该框架为复杂物流提供了可验证、实时且用户对齐的决策路径。

Abstract: Logistics operators, from battlefield coordinators rerouting airlifts ahead
of a storm to warehouse managers juggling late trucks, often face life-critical
decisions that demand both domain expertise and rapid and continuous
replanning. While popular methods like integer programming yield logistics
plans that satisfy user-defined logical constraints, they are slow and assume
an idealized mathematical model of the environment that does not account for
uncertainty. On the other hand, large language models (LLMs) can handle
uncertainty and promise to accelerate replanning while lowering the barrier to
entry by translating free-form utterances into executable plans, yet they
remain prone to misinterpretations and hallucinations that jeopardize safety
and cost. We introduce a neurosymbolic framework that pairs the accessibility
of natural-language dialogue with verifiable guarantees on goal interpretation.
It converts user requests into structured planning specifications, quantifies
its own uncertainty at the field and token level, and invokes an interactive
clarification loop whenever confidence falls below an adaptive threshold. A
lightweight model, fine-tuned on just 100 uncertainty-filtered examples,
surpasses the zero-shot performance of GPT-4.1 while cutting inference latency
by nearly 50%. These preliminary results highlight a practical path toward
certifiable, real-time, and user-aligned decision-making for complex logistics.

</details>


### [31] [Modeling Code: Is Text All You Need?](https://arxiv.org/abs/2507.11467)
*Daniel Nichols,Konstantinos Parasyris,Harshitha Menon,Brian R. Bartoldson,Giorgis Georgakoudis,Tal Ben-Nun,Abhinav Bhatele*

Main category: cs.AI

TL;DR: 论文提出了一种结合代码文本建模和结构化建模优势的新方法，以弥补现有模型在代码分析和生成能力上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的代码大语言模型（LLMs）在处理代码的结构化分析属性（如控制流和数据流）时能力有限，而结构化建模方法又缺乏生成能力和规模。

Method: 提出了一种新颖的方法，结合代码的文本建模和结构化建模。

Result: 未明确提及具体结果，但旨在提升模型在代码分析和生成任务上的表现。

Conclusion: 通过结合两种建模方式的优势，有望提升代码LLMs在结构化分析和生成任务中的能力。

Abstract: Code LLMs have become extremely popular recently for modeling source code
across a variety of tasks, such as generation, translation, and summarization.
However, transformer-based models are limited in their capabilities to reason
through structured, analytical properties of code, such as control and data
flow. Previous work has explored the modeling of these properties with
structured data and graph neural networks. However, these approaches lack the
generative capabilities and scale of modern LLMs. In this work, we introduce a
novel approach to combine the strengths of modeling both code as text and more
structured forms.

</details>


### [32] [Chain of Thought Monitorability: A New and Fragile Opportunity for AI Safety](https://arxiv.org/abs/2507.11473)
*Tomek Korbak,Mikita Balesni,Elizabeth Barnes,Yoshua Bengio,Joe Benton,Joseph Bloom,Mark Chen,Alan Cooney,Allan Dafoe,Anca Dragan,Scott Emmons,Owain Evans,David Farhi,Ryan Greenblatt,Dan Hendrycks,Marius Hobbhahn,Evan Hubinger,Geoffrey Irving,Erik Jenner,Daniel Kokotajlo,Victoria Krakovna,Shane Legg,David Lindner,David Luan,Aleksander Mądry,Julian Michael,Neel Nanda,Dave Orr,Jakub Pachocki,Ethan Perez,Mary Phuong,Fabien Roger,Joshua Saxe,Buck Shlegeris,Martín Soto,Eric Steinberger,Jasmine Wang,Wojciech Zaremba,Bowen Baker,Rohin Shah,Vlad Mikulik*

Main category: cs.AI

TL;DR: AI系统通过人类语言“思考”为AI安全提供了新机会，可通过监控思维链（CoT）检测不良意图。尽管不完美，但值得进一步研究和投资。


<details>
  <summary>Details</summary>
Motivation: 探索AI系统通过语言“思考”的特性，为AI安全提供新的监控手段。

Method: 提出监控思维链（CoT）的方法，以检测AI的不良意图。

Result: CoT监控虽不完美，但显示出潜力，建议进一步研究和投资。

Conclusion: 建议前沿模型开发者考虑开发决策对CoT可监控性的影响。

Abstract: AI systems that "think" in human language offer a unique opportunity for AI
safety: we can monitor their chains of thought (CoT) for the intent to
misbehave. Like all other known AI oversight methods, CoT monitoring is
imperfect and allows some misbehavior to go unnoticed. Nevertheless, it shows
promise and we recommend further research into CoT monitorability and
investment in CoT monitoring alongside existing safety methods. Because CoT
monitorability may be fragile, we recommend that frontier model developers
consider the impact of development decisions on CoT monitorability.

</details>


### [33] [Perspective-Aware AI in Extended Reality](https://arxiv.org/abs/2507.11479)
*Daniel Platnick,Matti Gruener,Marjan Alirezaie,Kent Larson,Dava J. Newman,Hossein Rahnama*

Main category: cs.AI

TL;DR: PAiR框架通过整合Perspective-Aware AI与XR，利用多模态数字足迹构建用户身份模型，实现基于用户认知和体验的沉浸式环境动态调整。


<details>
  <summary>Details</summary>
Motivation: 当前AI增强的XR系统因用户建模浅显和认知上下文有限而表现不足，需要更深入的用户理解和上下文感知。

Method: 提出PAiR框架，基于Chronicles（多模态数字足迹构建的身份模型），采用闭环系统动态链接用户状态与沉浸式环境。

Result: 通过Unity-based OpenDome引擎实现两个概念验证场景，展示了PAiR的实用性。

Conclusion: PAiR为人类-AI交互开辟了新方向，通过嵌入基于视角的身份模型提升沉浸式系统的表现。

Abstract: AI-enhanced Extended Reality (XR) aims to deliver adaptive, immersive
experiences-yet current systems fall short due to shallow user modeling and
limited cognitive context. We introduce Perspective-Aware AI in Extended
Reality (PAiR), a foundational framework for integrating Perspective-Aware AI
(PAi) with XR to enable interpretable, context-aware experiences grounded in
user identity. PAi is built on Chronicles: reasoning-ready identity models
learned from multimodal digital footprints that capture users' cognitive and
experiential evolution. PAiR employs these models in a closed-loop system
linking dynamic user states with immersive environments. We present PAiR's
architecture, detailing its modules and system flow, and demonstrate its
utility through two proof-of-concept scenarios implemented in the Unity-based
OpenDome engine. PAiR opens a new direction for human-AI interaction by
embedding perspective-based identity models into immersive systems.

</details>


### [34] [Illuminating the Three Dogmas of Reinforcement Learning under Evolutionary Light](https://arxiv.org/abs/2507.11482)
*Mani Hamidi,Terrence W. Deacon*

Main category: cs.AI

TL;DR: 论文提出一个受开放式进化理论启发的框架，重新审视强化学习的三个核心信条，并探讨其理论和应用意义。


<details>
  <summary>Details</summary>
Motivation: 重新定义强化学习中的三个核心信条（代理、学习目标和奖励假设），以解决理论和实践中的问题。

Method: 结合进化理论，重新审视这三个信条，并讨论其在生物学习模型中的适用性。

Result: 进化理论为强化学习的信条提供了新的视角，但代理问题仍需结合生命起源理论解决。

Conclusion: 进化理论为强化学习提供了有益的补充，但代理问题需要更广泛的理论框架。

Abstract: Three core tenets of reinforcement learning (RL)--concerning the definition
of agency, the objective of learning, and the scope of the reward
hypothesis--have been highlighted as key targets for conceptual revision, with
major implications for theory and application. We propose a framework, inspired
by open-ended evolutionary theory, to reconsider these three "dogmas." We
revisit each assumption and address related concerns raised alongside them. To
make our arguments relevant to RL as a model of biological learning, we first
establish that evolutionary dynamics can plausibly operate within living brains
over an individual's lifetime, and are not confined to cross-generational
processes. We begin by revisiting the second dogma, drawing on evolutionary
insights to enrich the "adaptation-rather-than-search" view of learning. We
then address the third dogma regarding the limits of the reward hypothesis,
using analogies from evolutionary fitness to illuminate the scalar reward vs.
multi-objective debate. After discussing practical implications for exploration
in RL, we turn to the first--and arguably most fundamental--issue: the absence
of a formal account of agency. We argue that unlike the other two problems, the
evolutionary paradigm alone cannot resolve the agency question, though it
gestures in a productive direction. We advocate integrating ideas from
origins-of-life theory, where the thermodynamics of sustenance and replication
offer promising foundations for understanding agency and resource-constrained
reinforcement learning in biological systems.

</details>


### [35] [DrafterBench: Benchmarking Large Language Models for Tasks Automation in Civil Engineering](https://arxiv.org/abs/2507.11527)
*Yinsheng Li,Zhen Dong,Yi Shao*

Main category: cs.AI

TL;DR: DrafterBench是一个用于评估LLM代理在土木工程图纸修订任务中的开源基准，包含12类任务、46个定制功能和1920个任务，旨在全面测试代理的能力。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏从工业角度系统评估自动化代理的基准，尤其是在土木工程领域。

Method: 提出DrafterBench，包含从实际图纸文件中总结的任务类型和定制功能，用于测试代理的多方面能力。

Result: DrafterBench能详细分析任务准确性和错误统计，为LLM在工程应用中的改进提供依据。

Conclusion: DrafterBench为评估和提升LLM代理在工程任务中的能力提供了重要工具。

Abstract: Large Language Model (LLM) agents have shown great potential for solving
real-world problems and promise to be a solution for tasks automation in
industry. However, more benchmarks are needed to systematically evaluate
automation agents from an industrial perspective, for example, in Civil
Engineering. Therefore, we propose DrafterBench for the comprehensive
evaluation of LLM agents in the context of technical drawing revision, a
representation task in civil engineering. DrafterBench contains twelve types of
tasks summarized from real-world drawing files, with 46 customized
functions/tools and 1920 tasks in total. DrafterBench is an open-source
benchmark to rigorously test AI agents' proficiency in interpreting intricate
and long-context instructions, leveraging prior knowledge, and adapting to
dynamic instruction quality via implicit policy awareness. The toolkit
comprehensively assesses distinct capabilities in structured data
comprehension, function execution, instruction following, and critical
reasoning. DrafterBench offers detailed analysis of task accuracy and error
statistics, aiming to provide deeper insight into agent capabilities and
identify improvement targets for integrating LLMs in engineering applications.
Our benchmark is available at https://github.com/Eason-Li-AIS/DrafterBench,
with the test set hosted at
https://huggingface.co/datasets/Eason666/DrafterBench.

</details>


### [36] [How Many Instructions Can LLMs Follow at Once?](https://arxiv.org/abs/2507.11538)
*Daniel Jaroslawicz,Brendan Whiting,Parth Shah,Karime Maamari*

Main category: cs.AI

TL;DR: IFScale是一个用于评估LLM在高密度指令下性能的基准测试，结果显示即使最先进的模型在500条指令下准确率仅为68%。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试仅评估模型在少量指令下的表现，无法满足生产级LLM系统对高密度指令的需求。

Method: 引入IFScale基准，包含500条关键词包含指令，用于商业报告写作任务，评估20种前沿模型。

Result: 最佳模型在500条指令下准确率为68%，模型规模和推理能力与性能下降模式相关。

Conclusion: 研究结果有助于设计高密度指令提示，并揭示了性能与延迟的权衡，所有数据和结果已开源。

Abstract: Production-grade LLM systems require robust adherence to dozens or even
hundreds of instructions simultaneously. However, the instruction-following
capabilities of LLMs at high instruction densities have not yet been
characterized, as existing benchmarks only evaluate models on tasks with a
single or few instructions. We introduce IFScale, a simple benchmark of 500
keyword-inclusion instructions for a business report writing task to measure
how instruction-following performance degrades as instruction density
increases. We evaluate 20 state-of-the-art models across seven major providers
and find that even the best frontier models only achieve 68% accuracy at the
max density of 500 instructions. Our analysis reveals model size and reasoning
capability to correlate with 3 distinct performance degradation patterns, bias
towards earlier instructions, and distinct categories of instruction-following
errors. Our insights can help inform design of instruction-dense prompts in
real-world applications and highlight important performance-latency tradeoffs.
We open-source the benchmark and all results for further analysis at
https://distylai.github.io/IFScale.

</details>
