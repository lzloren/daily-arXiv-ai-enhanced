{"id": "2507.00008", "categories": ["cs.AI", "cs.CV", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.00008", "abs": "https://arxiv.org/abs/2507.00008", "authors": ["Hang Wu", "Hongkai Chen", "Yujun Cai", "Chang Liu", "Qingwen Ye", "Ming-Hsuan Yang", "Yiwei Wang"], "title": "DiMo-GUI: Advancing Test-time Scaling in GUI Grounding via Modality-Aware Visual Reasoning", "comment": "8 pages, 6 figures", "summary": "Grounding natural language queries in graphical user interfaces (GUIs) poses\nunique challenges due to the diversity of visual elements, spatial clutter, and\nthe ambiguity of language. In this paper, we introduce DiMo-GUI, a\ntraining-free framework for GUI grounding that leverages two core strategies:\ndynamic visual grounding and modality-aware optimization. Instead of treating\nthe GUI as a monolithic image, our method splits the input into textual\nelements and iconic elements, allowing the model to reason over each modality\nindependently using general-purpose vision-language models. When predictions\nare ambiguous or incorrect, DiMo-GUI dynamically focuses attention by\ngenerating candidate focal regions centered on the model's initial predictions\nand incrementally zooms into subregions to refine the grounding result. This\nhierarchical refinement process helps disambiguate visually crowded layouts\nwithout the need for additional training or annotations. We evaluate our\napproach on standard GUI grounding benchmarks and demonstrate consistent\nimprovements over baseline inference pipelines, highlighting the effectiveness\nof combining modality separation with region-focused reasoning.", "AI": {"tldr": "DiMo-GUI\u662f\u4e00\u4e2a\u65e0\u9700\u8bad\u7ec3\u7684GUI\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u89c6\u89c9\u5b9a\u4f4d\u548c\u6a21\u6001\u611f\u77e5\u4f18\u5316\u89e3\u51b3GUI\u4e2d\u7684\u89c6\u89c9\u591a\u6837\u6027\u548c\u8bed\u8a00\u6a21\u7cca\u6027\u95ee\u9898\u3002", "motivation": "GUI\u4e2d\u7684\u89c6\u89c9\u5143\u7d20\u591a\u6837\u3001\u7a7a\u95f4\u6742\u4e71\u4ee5\u53ca\u8bed\u8a00\u6a21\u7cca\u6027\u4f7f\u5f97\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u7684\u5b9a\u4f4d\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u5c06GUI\u62c6\u5206\u4e3a\u6587\u672c\u5143\u7d20\u548c\u56fe\u6807\u5143\u7d20\uff0c\u5229\u7528\u901a\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u72ec\u7acb\u5904\u7406\u5404\u6a21\u6001\uff0c\u5e76\u901a\u8fc7\u52a8\u6001\u805a\u7126\u5019\u9009\u533a\u57df\u9010\u6b65\u7ec6\u5316\u5b9a\u4f4d\u7ed3\u679c\u3002", "result": "\u5728\u6807\u51c6GUI\u5b9a\u4f4d\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u6a21\u6001\u5206\u79bb\u4e0e\u533a\u57df\u805a\u7126\u63a8\u7406\u7684\u6709\u6548\u6027\u3002", "conclusion": "DiMo-GUI\u901a\u8fc7\u6a21\u6001\u5206\u79bb\u548c\u52a8\u6001\u533a\u57df\u805a\u7126\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u5373\u53ef\u663e\u8457\u63d0\u5347GUI\u5b9a\u4f4d\u6027\u80fd\u3002"}}
{"id": "2507.00041", "categories": ["cs.AI", "cs.CV", "cs.IR"], "pdf": "https://arxiv.org/pdf/2507.00041", "abs": "https://arxiv.org/abs/2507.00041", "authors": ["Varun Mannam", "Fang Wang", "Chaochun Liu", "Xin Chen"], "title": "TalentMine: LLM-Based Extraction and Question-Answering from Multimodal Talent Tables", "comment": "Submitted to KDD conference, workshop: Talent and Management\n  Computing (TMC 2025), https://tmcworkshop.github.io/2025/", "summary": "In talent management systems, critical information often resides in complex\ntabular formats, presenting significant retrieval challenges for conventional\nlanguage models. These challenges are pronounced when processing Talent\ndocumentation that requires precise interpretation of tabular relationships for\naccurate information retrieval and downstream decision-making. Current table\nextraction methods struggle with semantic understanding, resulting in poor\nperformance when integrated into retrieval-augmented chat applications. This\npaper identifies a key bottleneck - while structural table information can be\nextracted, the semantic relationships between tabular elements are lost,\ncausing downstream query failures. To address this, we introduce TalentMine, a\nnovel LLM-enhanced framework that transforms extracted tables into semantically\nenriched representations. Unlike conventional approaches relying on CSV or text\nlinearization, our method employs specialized multimodal reasoning to preserve\nboth structural and semantic dimensions of tabular data. Experimental\nevaluation across employee benefits document collections demonstrates\nTalentMine's superior performance, achieving 100% accuracy in query answering\ntasks compared to 0% for standard AWS Textract extraction and 40% for AWS\nTextract Visual Q&A capabilities. Our comparative analysis also reveals that\nthe Claude v3 Haiku model achieves optimal performance for talent management\napplications. The key contributions of this work include (1) a systematic\nanalysis of semantic information loss in current table extraction pipelines,\n(2) a novel LLM-based method for semantically enriched table representation,\n(3) an efficient integration framework for retrieval-augmented systems as\nend-to-end systems, and (4) comprehensive benchmarks on talent analytics tasks\nshowing substantial improvements across multiple categories.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faTalentMine\u6846\u67b6\uff0c\u901a\u8fc7LLM\u589e\u5f3a\u7684\u8bed\u4e49\u8868\u8868\u793a\u89e3\u51b3\u4f20\u7edf\u8868\u683c\u63d0\u53d6\u65b9\u6cd5\u5728\u8bed\u4e49\u5173\u7cfb\u7406\u89e3\u4e0a\u7684\u4e0d\u8db3\uff0c\u663e\u8457\u63d0\u5347\u4eba\u624d\u7ba1\u7406\u6587\u6863\u7684\u67e5\u8be2\u51c6\u786e\u7387\u3002", "motivation": "\u4f20\u7edf\u8868\u683c\u63d0\u53d6\u65b9\u6cd5\u5728\u5904\u7406\u590d\u6742\u8868\u683c\u65f6\u4e22\u5931\u8bed\u4e49\u5173\u7cfb\uff0c\u5bfc\u81f4\u4fe1\u606f\u68c0\u7d22\u548c\u51b3\u7b56\u652f\u6301\u6548\u679c\u4e0d\u4f73\uff0c\u4e9f\u9700\u6539\u8fdb\u3002", "method": "\u5f15\u5165TalentMine\u6846\u67b6\uff0c\u7ed3\u5408\u591a\u6a21\u6001\u63a8\u7406\u751f\u6210\u8bed\u4e49\u4e30\u5bcc\u7684\u8868\u683c\u8868\u793a\uff0c\u66ff\u4ee3\u4f20\u7edf\u7684CSV\u6216\u6587\u672c\u7ebf\u6027\u5316\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u663e\u793aTalentMine\u5728\u67e5\u8be2\u4efb\u52a1\u4e2d\u8fbe\u5230100%\u51c6\u786e\u7387\uff0c\u8fdc\u8d85AWS Textract\uff080%\uff09\u548c\u5176\u89c6\u89c9\u95ee\u7b54\u80fd\u529b\uff0840%\uff09\u3002", "conclusion": "TalentMine\u901a\u8fc7\u4fdd\u7559\u8868\u683c\u7ed3\u6784\u548c\u8bed\u4e49\u5173\u7cfb\uff0c\u663e\u8457\u63d0\u5347\u4eba\u624d\u7ba1\u7406\u7cfb\u7edf\u7684\u4fe1\u606f\u68c0\u7d22\u6027\u80fd\uff0c\u4e3a\u7aef\u5230\u7aef\u7cfb\u7edf\u63d0\u4f9b\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.00048", "categories": ["cs.AI", "cond-mat.mtrl-sci", "cs.CE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.00048", "abs": "https://arxiv.org/abs/2507.00048", "authors": ["Thomas M. Deucher", "Juan C. Verduzco", "Michael Titus", "Alejandro Strachan"], "title": "A collaborative digital twin built on FAIR data and compute infrastructure", "comment": "10 pages, 5 figures", "summary": "The integration of machine learning with automated experimentation in\nself-driving laboratories (SDL) offers a powerful approach to accelerate\ndiscovery and optimization tasks in science and engineering applications. When\nsupported by findable, accessible, interoperable, and reusable (FAIR) data\ninfrastructure, SDLs with overlapping interests can collaborate more\neffectively. This work presents a distributed SDL implementation built on\nnanoHUB services for online simulation and FAIR data management. In this\nframework, geographically dispersed collaborators conducting independent\noptimization tasks contribute raw experimental data to a shared central\ndatabase. These researchers can then benefit from analysis tools and machine\nlearning models that automatically update as additional data become available.\nNew data points are submitted through a simple web interface and automatically\nprocessed using a nanoHUB Sim2L, which extracts derived quantities and indexes\nall inputs and outputs in a FAIR data repository called ResultsDB. A separate\nnanoHUB workflow enables sequential optimization using active learning, where\nresearchers define the optimization objective, and machine learning models are\ntrained on-the-fly with all existing data, guiding the selection of future\nexperiments. Inspired by the concept of ``frugal twin\", the optimization task\nseeks to find the optimal recipe to combine food dyes to achieve the desired\ntarget color. With easily accessible and inexpensive materials, researchers and\nstudents can set up their own experiments, share data with collaborators, and\nexplore the combination of FAIR data, predictive ML models, and sequential\noptimization. The tools introduced are generally applicable and can easily be\nextended to other optimization problems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eFAIR\u6570\u636e\u57fa\u7840\u8bbe\u65bd\u7684\u5206\u5e03\u5f0f\u81ea\u9a71\u52a8\u5b9e\u9a8c\u5ba4\uff08SDL\uff09\u6846\u67b6\uff0c\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u548c\u81ea\u52a8\u5316\u5b9e\u9a8c\uff0c\u52a0\u901f\u79d1\u5b66\u548c\u5de5\u7a0b\u4e2d\u7684\u53d1\u73b0\u4e0e\u4f18\u5316\u4efb\u52a1\u3002", "motivation": "\u901a\u8fc7\u6574\u5408FAIR\u6570\u636e\u57fa\u7840\u8bbe\u65bd\u548cSDL\uff0c\u4fc3\u8fdb\u5730\u7406\u5206\u6563\u7684\u7814\u7a76\u8005\u534f\u4f5c\uff0c\u5171\u4eab\u6570\u636e\u5e76\u5229\u7528\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u4f18\u5316\u3002", "method": "\u5229\u7528nanoHUB\u670d\u52a1\u5b9e\u73b0\u5728\u7ebf\u6a21\u62df\u548cFAIR\u6570\u636e\u7ba1\u7406\uff0c\u7814\u7a76\u8005\u901a\u8fc7\u7b80\u5355\u754c\u9762\u63d0\u4ea4\u6570\u636e\uff0c\u7cfb\u7edf\u81ea\u52a8\u5904\u7406\u5e76\u66f4\u65b0\u673a\u5668\u5b66\u4e60\u6a21\u578b\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u901a\u7528\u7684\u5de5\u5177\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u98df\u54c1\u67d3\u6599\u914d\u65b9\u7684\u6848\u4f8b\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u79d1\u5b66\u548c\u5de5\u7a0b\u4e2d\u7684\u4f18\u5316\u4efb\u52a1\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u534f\u4f5c\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2507.00050", "categories": ["cs.AI", "cs.HC", "cs.LG", "I.2.0"], "pdf": "https://arxiv.org/pdf/2507.00050", "abs": "https://arxiv.org/abs/2507.00050", "authors": ["Devin Y. De Silva", "Sandareka Wickramanayake", "Dulani Meedeniya", "Sanka Rasnayaka"], "title": "SEZ-HARN: Self-Explainable Zero-shot Human Activity Recognition Network", "comment": null, "summary": "Human Activity Recognition (HAR), which uses data from Inertial Measurement\nUnit (IMU) sensors, has many practical applications in healthcare and assisted\nliving environments. However, its use in real-world scenarios has been limited\nby the lack of comprehensive IMU-based HAR datasets that cover a wide range of\nactivities and the lack of transparency in existing HAR models. Zero-shot HAR\n(ZS-HAR) overcomes the data limitations, but current models struggle to explain\ntheir decisions, making them less transparent. This paper introduces a novel\nIMU-based ZS-HAR model called the Self-Explainable Zero-shot Human Activity\nRecognition Network (SEZ-HARN). It can recognize activities not encountered\nduring training and provide skeleton videos to explain its decision-making\nprocess. We evaluate the effectiveness of the proposed SEZ-HARN on four\nbenchmark datasets PAMAP2, DaLiAc, HTD-MHAD and MHealth and compare its\nperformance against three state-of-the-art black-box ZS-HAR models. The\nexperiment results demonstrate that SEZ-HARN produces realistic and\nunderstandable explanations while achieving competitive Zero-shot recognition\naccuracy. SEZ-HARN achieves a Zero-shot prediction accuracy within 3\\% of the\nbest-performing black-box model on PAMAP2 while maintaining comparable\nperformance on the other three datasets.", "AI": {"tldr": "SEZ-HARN\u662f\u4e00\u79cd\u65b0\u578b\u7684\u96f6\u6837\u672c\u4eba\u7c7b\u6d3b\u52a8\u8bc6\u522b\u6a21\u578b\uff0c\u80fd\u591f\u8bc6\u522b\u672a\u8bad\u7ec3\u8fc7\u7684\u6d3b\u52a8\u5e76\u901a\u8fc7\u9aa8\u67b6\u89c6\u9891\u89e3\u91ca\u5176\u51b3\u7b56\u8fc7\u7a0b\uff0c\u6027\u80fd\u63a5\u8fd1\u73b0\u6709\u9ed1\u76d2\u6a21\u578b\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709IMU\u4f20\u611f\u5668\u6570\u636e\u5728HAR\u4e2d\u7f3a\u4e4f\u5168\u9762\u6570\u636e\u96c6\u548c\u6a21\u578b\u900f\u660e\u5ea6\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u81ea\u89e3\u91ca\u7684\u96f6\u6837\u672cHAR\u6a21\u578bSEZ-HARN\uff0c\u751f\u6210\u9aa8\u67b6\u89c6\u9891\u4ee5\u89e3\u91ca\u51b3\u7b56\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u63a5\u8fd1\u6700\u4f73\u9ed1\u76d2\u6a21\u578b\uff0c\u540c\u65f6\u63d0\u4f9b\u53ef\u7406\u89e3\u7684\u89e3\u91ca\u3002", "conclusion": "SEZ-HARN\u5728\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u7684\u540c\u65f6\u63d0\u5347\u4e86\u6a21\u578b\u900f\u660e\u5ea6\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2507.00054", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.00054", "abs": "https://arxiv.org/abs/2507.00054", "authors": ["Shreyansh Padarha"], "title": "Enhancing Reasoning Capabilities in SLMs with Reward Guided Dataset Distillation", "comment": "17 Pages, 7 figures", "summary": "The push to compress and impart the proficiency of Large Language Models\n(LLMs) into more deployable and efficient Small Language Models (SLMs) has\nbenefited from improvements in knowledge distillation (KD) techniques. These\ntechniques allow a smaller student model to learn from a more capable and\nlarger teacher model's responses. However, distillation often revolves around\nthe student model merely copying the teacher's in-distribution responses,\nlimiting its generalisability. This limitation is amplified on reasoning tasks\nand can be computationally expensive. In this study, we propose AdvDistill, a\nreward-guided dataset distillation framework. We utilise multiple generations\n(responses) from a teacher for each prompt and assign rewards based on\nrule-based verifiers. These varying and normally distributed rewards serve as\nweights when training student models. Our methods and their subsequent\nbehavioural analysis demonstrate a significant improvement in student model\nperformance for mathematical and complex reasoning tasks, showcasing the\nefficacy and benefits of incorporating a rewarding mechanism in dataset\ndistillation processes.", "AI": {"tldr": "AdvDistill\u662f\u4e00\u79cd\u57fa\u4e8e\u5956\u52b1\u7684\u6570\u636e\u96c6\u84b8\u998f\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u4ee3\u6559\u5e08\u6a21\u578b\u54cd\u5e94\u548c\u89c4\u5219\u9a8c\u8bc1\u5668\u5206\u914d\u5956\u52b1\uff0c\u663e\u8457\u63d0\u5347\u5c0f\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u548c\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u77e5\u8bc6\u84b8\u998f\u65b9\u6cd5\u4e2d\u5b66\u751f\u6a21\u578b\u4ec5\u6a21\u4eff\u6559\u5e08\u6a21\u578b\u7684\u5206\u5e03\u5185\u54cd\u5e94\uff0c\u9650\u5236\u4e86\u5176\u6cdb\u5316\u80fd\u529b\uff0c\u5c24\u5176\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\u4e14\u8ba1\u7b97\u6210\u672c\u9ad8\u3002", "method": "AdvDistill\u5229\u7528\u6559\u5e08\u6a21\u578b\u5bf9\u6bcf\u4e2a\u63d0\u793a\u7684\u591a\u4ee3\u54cd\u5e94\uff0c\u5e76\u901a\u8fc7\u89c4\u5219\u9a8c\u8bc1\u5668\u5206\u914d\u5956\u52b1\uff0c\u5c06\u8fd9\u4e9b\u5956\u52b1\u4f5c\u4e3a\u8bad\u7ec3\u5b66\u751f\u6a21\u578b\u7684\u6743\u91cd\u3002", "result": "AdvDistill\u663e\u8457\u63d0\u5347\u4e86\u5b66\u751f\u6a21\u578b\u5728\u6570\u5b66\u548c\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002", "conclusion": "\u5f15\u5165\u5956\u52b1\u673a\u5236\u7684\u6570\u636e\u96c6\u84b8\u998f\u8fc7\u7a0b\u6709\u6548\u4e14\u6709\u76ca\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u5c0f\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\u3002"}}
{"id": "2507.00079", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.00079", "abs": "https://arxiv.org/abs/2507.00079", "authors": ["Ethan Smyth", "Alessandro Suglia"], "title": "VoyagerVision: Investigating the Role of Multi-modal Information for Open-ended Learning Systems", "comment": "website: https://esmyth-dev.github.io/VoyagerVision.github.io/", "summary": "Open-endedness is an active field of research in the pursuit of capable\nArtificial General Intelligence (AGI), allowing models to pursue tasks of their\nown choosing. Simultaneously, recent advancements in Large Language Models\n(LLMs) such as GPT-4o [9] have allowed such models to be capable of\ninterpreting image inputs. Implementations such as OMNI-EPIC [4] have made use\nof such features, providing an LLM with pixel data of an agent's POV to parse\nthe environment and allow it to solve tasks. This paper proposes that providing\nthese visual inputs to a model gives it greater ability to interpret spatial\nenvironments, and as such, can increase the number of tasks it can successfully\nperform, extending its open-ended potential. To this aim, this paper proposes\nVoyagerVision -- a multi-modal model capable of creating structures within\nMinecraft using screenshots as a form of visual feedback, building on the\nfoundation of Voyager. VoyagerVision was capable of creating an average of 2.75\nunique structures within fifty iterations of the system, as Voyager was\nincapable of this, it is an extension in an entirely new direction.\nAdditionally, in a set of building unit tests VoyagerVision was successful in\nhalf of all attempts in flat worlds, with most failures arising in more complex\nstructures. Project website is available at\nhttps://esmyth-dev.github.io/VoyagerVision.github.io/", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faVoyagerVision\uff0c\u4e00\u79cd\u591a\u6a21\u6001\u6a21\u578b\uff0c\u901a\u8fc7\u89c6\u89c9\u53cd\u9988\u5728Minecraft\u4e2d\u521b\u5efa\u7ed3\u6784\uff0c\u6269\u5c55\u4e86Voyager\u7684\u80fd\u529b\u3002", "motivation": "\u7814\u7a76\u89c6\u89c9\u8f93\u5165\u5982\u4f55\u589e\u5f3a\u6a21\u578b\u5bf9\u7a7a\u95f4\u73af\u5883\u7684\u7406\u89e3\uff0c\u4ece\u800c\u63d0\u5347\u5176\u4efb\u52a1\u6267\u884c\u80fd\u529b\u548c\u5f00\u653e\u6027\u3002", "method": "\u57fa\u4e8eVoyager\uff0c\u5f00\u53d1\u591a\u6a21\u6001\u6a21\u578bVoyagerVision\uff0c\u5229\u7528\u622a\u56fe\u4f5c\u4e3a\u89c6\u89c9\u53cd\u9988\u5728Minecraft\u4e2d\u521b\u5efa\u7ed3\u6784\u3002", "result": "VoyagerVision\u5e73\u5747\u572850\u6b21\u8fed\u4ee3\u4e2d\u521b\u5efa2.75\u4e2a\u72ec\u7279\u7ed3\u6784\uff0c\u4e14\u5728\u5e73\u5766\u4e16\u754c\u4e2d\u6210\u529f\u7387\u4e3a50%\u3002", "conclusion": "\u89c6\u89c9\u8f93\u5165\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u7684\u4efb\u52a1\u6267\u884c\u80fd\u529b\uff0c\u4e3a\u5f00\u653e\u6027\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2507.00092", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.00092", "abs": "https://arxiv.org/abs/2507.00092", "authors": ["Basab Jha", "Firoj Paudel", "Ujjwal Puri", "Zhang Yuting", "Choi Donghyuk", "Wang Junhao"], "title": "Thinking About Thinking: SAGE-nano's Inverse Reasoning for Self-Aware Language Models", "comment": "19 pages, 2 figures, 9 tables", "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities at\nsolving complex reasoning tasks with Chain-of-Thought (CoT) prompting, but\ntheir decision-making processes remain somewhat blackbox. We introduce\ntextbfinverse reasoning, a novel paradigm enabling LLMs to decompose and\nexplain their own reasoning chains post-hoc. Our approach, used in SAGE-nano, a\n4-billion-parameter reasoning model, employs a metacognitive structure that\nreflects back via attention processes to identify major decision points and\ngenerate explanations of reasoning choices. While typical CoT approaches are\ndirected towards forward reasoning generation, inverse reasoning provides\ninsight into why specific reasoning chains were selected over others. Through\nthorough testing of logical reasoning puzzles, math problems and ethical\ndilemmas from AQUA-RAT, CommonsenseQA, and customized benchmarks, we\ndemonstrate that SAGE-nano is at the cutting edge both on reasoning accuracy\n(74.6% on AQUA-RAT) and explanation quality (92.1% human preference score) for\nits task, and offers performance almost on par with models like Claude-3.5\nSonnet or GPT-4o. Our contributions are: (i) the first rigorous framework for\nLLM self-reflection via inverse reasoning, (ii) a novel metalearning framework\nto reverse the attention flow, (iii) comprehensive evaluation frameworks for\nreasoning transparency, and (iv) evidence that increasing reasoning using\ninverse reasoning improves interpretability along with reasoning performance.\nOur work creates new avenues for transparent AI systems and closes significant\ngaps in AI safety, education, and scientific discovery.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201c\u9006\u5411\u63a8\u7406\u201d\u7684\u65b0\u8303\u5f0f\uff0c\u901a\u8fc7SAGE-nano\u6a21\u578b\u5b9e\u73b0LLM\u7684\u81ea\u6211\u89e3\u91ca\uff0c\u63d0\u5347\u63a8\u7406\u900f\u660e\u5ea6\u548c\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3LLM\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u51b3\u7b56\u8fc7\u7a0b\u4e0d\u900f\u660e\u7684\u95ee\u9898\uff0c\u589e\u5f3a\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u548c\u5b89\u5168\u6027\u3002", "method": "\u91c7\u7528\u9006\u5411\u63a8\u7406\u8303\u5f0f\uff0c\u901a\u8fc7\u5143\u8ba4\u77e5\u7ed3\u6784\u548c\u6ce8\u610f\u529b\u673a\u5236\u5206\u89e3\u548c\u89e3\u91ca\u63a8\u7406\u94fe\u3002", "result": "SAGE-nano\u5728AQUA-RAT\u7b49\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff08\u63a8\u7406\u51c6\u786e\u738774.6%\uff0c\u89e3\u91ca\u8d28\u91cf92.1%\uff09\uff0c\u6027\u80fd\u63a5\u8fd1Claude-3.5 Sonnet\u6216GPT-4o\u3002", "conclusion": "\u9006\u5411\u63a8\u7406\u6846\u67b6\u4e3a\u900f\u660eAI\u7cfb\u7edf\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\uff0c\u586b\u8865\u4e86AI\u5b89\u5168\u3001\u6559\u80b2\u548c\u79d1\u5b66\u53d1\u73b0\u4e2d\u7684\u7a7a\u767d\u3002"}}
{"id": "2507.00180", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.00180", "abs": "https://arxiv.org/abs/2507.00180", "authors": ["Vidhi Rathore"], "title": "BlackBoxToBlueprint: Extracting Interpretable Logic from Legacy Systems using Reinforcement Learning and Counterfactual Analysis", "comment": null, "summary": "Modernizing legacy software systems is a critical but challenging task, often\nhampered by a lack of documentation and understanding of the original system's\nintricate decision logic. Traditional approaches like behavioral cloning merely\nreplicate input-output behavior without capturing the underlying intent. This\npaper proposes a novel pipeline to automatically extract interpretable decision\nlogic from legacy systems treated as black boxes. The approach uses a\nReinforcement Learning (RL) agent to explore the input space and identify\ncritical decision boundaries by rewarding actions that cause meaningful changes\nin the system's output. These counterfactual state transitions, where the\noutput changes, are collected and clustered using K-Means. Decision trees are\nthen trained on these clusters to extract human-readable rules that approximate\nthe system's decision logic near the identified boundaries. I demonstrated the\npipeline's effectiveness on three dummy legacy systems with varying complexity,\nincluding threshold-based, combined-conditional, and non-linear range logic.\nResults show that the RL agent successfully focuses exploration on relevant\nboundary regions, and the extracted rules accurately reflect the core logic of\nthe underlying dummy systems, providing a promising foundation for generating\nspecifications and test cases during legacy migration.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u65b0\u65b9\u6cd5\uff0c\u4ece\u9ed1\u76d2\u9057\u7559\u7cfb\u7edf\u4e2d\u63d0\u53d6\u53ef\u89e3\u91ca\u7684\u51b3\u7b56\u903b\u8f91\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\uff08\u5982\u884c\u4e3a\u514b\u9686\uff09\u4ec5\u590d\u5236\u8f93\u5165\u8f93\u51fa\u884c\u4e3a\uff0c\u65e0\u6cd5\u6355\u6349\u5e95\u5c42\u610f\u56fe\uff0c\u800c\u9057\u7559\u7cfb\u7edf\u901a\u5e38\u7f3a\u4e4f\u6587\u6863\u548c\u7406\u89e3\u3002", "method": "\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u63a2\u7d22\u8f93\u5165\u7a7a\u95f4\uff0c\u8bc6\u522b\u5173\u952e\u51b3\u7b56\u8fb9\u754c\uff0c\u5e76\u901a\u8fc7K-Means\u805a\u7c7b\u548c\u51b3\u7b56\u6811\u63d0\u53d6\u4eba\u7c7b\u53ef\u8bfb\u89c4\u5219\u3002", "result": "\u5728\u4e09\u79cd\u4e0d\u540c\u590d\u6742\u5ea6\u7684\u9057\u7559\u7cfb\u7edf\u4e0a\u9a8c\u8bc1\uff0c\u63d0\u53d6\u7684\u89c4\u5219\u51c6\u786e\u53cd\u6620\u4e86\u6838\u5fc3\u903b\u8f91\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u9057\u7559\u7cfb\u7edf\u8fc1\u79fb\u4e2d\u7684\u89c4\u8303\u548c\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u57fa\u7840\u3002"}}
{"id": "2507.00181", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.00181", "abs": "https://arxiv.org/abs/2507.00181", "authors": ["Georgios P. Georgiou"], "title": "ChatGPT produces more \"lazy\" thinkers: Evidence of cognitive engagement decline", "comment": null, "summary": "Despite the increasing use of large language models (LLMs) in education,\nconcerns have emerged about their potential to reduce deep thinking and active\nlearning. This study investigates the impact of generative artificial\nintelligence (AI) tools, specifically ChatGPT, on the cognitive engagement of\nstudents during academic writing tasks. The study employed an experimental\ndesign with participants randomly assigned to either an AI-assisted (ChatGPT)\nor a non-assisted (control) condition. Participants completed a structured\nargumentative writing task followed by a cognitive engagement scale (CES), the\nCES-AI, developed to assess mental effort, attention, deep processing, and\nstrategic thinking. The results revealed significantly lower cognitive\nengagement scores in the ChatGPT group compared to the control group. These\nfindings suggest that AI assistance may lead to cognitive offloading. The study\ncontributes to the growing body of literature on the psychological implications\nof AI in education and raises important questions about the integration of such\ntools into academic practice. It calls for pedagogical strategies that promote\nactive, reflective engagement with AI-generated content to avoid compromising\nself-regulated learning and deep cognitive involvement of students.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8ChatGPT\u5bf9\u5b66\u751f\u5199\u4f5c\u4efb\u52a1\u4e2d\u8ba4\u77e5\u6295\u5165\u7684\u5f71\u54cd\uff0c\u53d1\u73b0AI\u8f85\u52a9\u5bfc\u81f4\u8ba4\u77e5\u6295\u5165\u964d\u4f4e\u3002", "motivation": "\u63a2\u7a76\u751f\u6210\u5f0fAI\u5de5\u5177\uff08\u5982ChatGPT\uff09\u662f\u5426\u5f71\u54cd\u5b66\u751f\u7684\u6df1\u5ea6\u601d\u8003\u548c\u4e3b\u52a8\u5b66\u4e60\u3002", "method": "\u5b9e\u9a8c\u8bbe\u8ba1\uff0c\u968f\u673a\u5206\u914d\u5b66\u751f\u81f3AI\u8f85\u52a9\u7ec4\u6216\u5bf9\u7167\u7ec4\uff0c\u5b8c\u6210\u5199\u4f5c\u4efb\u52a1\u5e76\u8bc4\u4f30\u8ba4\u77e5\u6295\u5165\u3002", "result": "ChatGPT\u7ec4\u7684\u8ba4\u77e5\u6295\u5165\u663e\u8457\u4f4e\u4e8e\u5bf9\u7167\u7ec4\uff0c\u8868\u660eAI\u53ef\u80fd\u5bfc\u81f4\u8ba4\u77e5\u5378\u8f7d\u3002", "conclusion": "\u9700\u5236\u5b9a\u6559\u5b66\u7b56\u7565\uff0c\u786e\u4fdd\u5b66\u751f\u4e3b\u52a8\u53cd\u601dAI\u751f\u6210\u5185\u5bb9\uff0c\u907f\u514d\u5f71\u54cd\u81ea\u4e3b\u5b66\u4e60\u548c\u6df1\u5ea6\u8ba4\u77e5\u6295\u5165\u3002"}}
{"id": "2507.00205", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.00205", "abs": "https://arxiv.org/abs/2507.00205", "authors": ["Periklis Petridis", "Georgios Margaritis", "Vasiliki Stoumpou", "Dimitris Bertsimas"], "title": "Holistic Artificial Intelligence in Medicine; improved performance and explainability", "comment": "Submitted to npj Digital Medicine", "summary": "With the increasing interest in deploying Artificial Intelligence in\nmedicine, we previously introduced HAIM (Holistic AI in Medicine), a framework\nthat fuses multimodal data to solve downstream clinical tasks. However, HAIM\nuses data in a task-agnostic manner and lacks explainability. To address these\nlimitations, we introduce xHAIM (Explainable HAIM), a novel framework\nleveraging Generative AI to enhance both prediction and explainability through\nfour structured steps: (1) automatically identifying task-relevant patient data\nacross modalities, (2) generating comprehensive patient summaries, (3) using\nthese summaries for improved predictive modeling, and (4) providing clinical\nexplanations by linking predictions to patient-specific medical knowledge.\nEvaluated on the HAIM-MIMIC-MM dataset, xHAIM improves average AUC from 79.9%\nto 90.3% across chest pathology and operative tasks. Importantly, xHAIM\ntransforms AI from a black-box predictor into an explainable decision support\nsystem, enabling clinicians to interactively trace predictions back to relevant\npatient data, bridging AI advancements with clinical utility.", "AI": {"tldr": "xHAIM\u662f\u4e00\u4e2a\u57fa\u4e8e\u751f\u6210\u5f0fAI\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u6b65\u9aa4\u63d0\u5347\u533b\u5b66AI\u7684\u9884\u6d4b\u80fd\u529b\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u89e3\u51b3HAIM\u6846\u67b6\u5728\u4efb\u52a1\u65e0\u5173\u6027\u548c\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002", "method": "\u901a\u8fc7\u56db\u4e2a\u6b65\u9aa4\uff1a\u8bc6\u522b\u4efb\u52a1\u76f8\u5173\u6570\u636e\u3001\u751f\u6210\u60a3\u8005\u6458\u8981\u3001\u6539\u8fdb\u9884\u6d4b\u6a21\u578b\u3001\u63d0\u4f9b\u4e34\u5e8a\u89e3\u91ca\u3002", "result": "\u5728HAIM-MIMIC-MM\u6570\u636e\u96c6\u4e0a\uff0cAUC\u4ece79.9%\u63d0\u5347\u81f390.3%\u3002", "conclusion": "xHAIM\u5c06AI\u4ece\u9ed1\u76d2\u9884\u6d4b\u5668\u8f6c\u53d8\u4e3a\u53ef\u89e3\u91ca\u7684\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\uff0c\u589e\u5f3a\u4e34\u5e8a\u5b9e\u7528\u6027\u3002"}}
{"id": "2507.00218", "categories": ["cs.AI", "math.OC"], "pdf": "https://arxiv.org/pdf/2507.00218", "abs": "https://arxiv.org/abs/2507.00218", "authors": ["Fangting Zhou", "Attila Lischka", "Balazs Kulcsar", "Jiaming Wu", "Morteza Haghir Chehreghani", "Gilbert Laporte"], "title": "Learning for routing: A guided review of recent developments and future directions", "comment": "Accepted for publication in Transportation Research Part E: Logistics\n  and Transportation Review", "summary": "This paper reviews the current progress in applying machine learning (ML)\ntools to solve NP-hard combinatorial optimization problems, with a focus on\nrouting problems such as the traveling salesman problem (TSP) and the vehicle\nrouting problem (VRP). Due to the inherent complexity of these problems, exact\nalgorithms often require excessive computational time to find optimal\nsolutions, while heuristics can only provide approximate solutions without\nguaranteeing optimality. With the recent success of machine learning models,\nthere is a growing trend in proposing and implementing diverse ML techniques to\nenhance the resolution of these challenging routing problems. We propose a\ntaxonomy categorizing ML-based routing methods into construction-based and\nimprovement-based approaches, highlighting their applicability to various\nproblem characteristics. This review aims to integrate traditional OR methods\nwith state-of-the-art ML techniques, providing a structured framework to guide\nfuture research and address emerging VRP variants.", "AI": {"tldr": "\u7efc\u8ff0\u4e86\u673a\u5668\u5b66\u4e60\u5728\u89e3\u51b3NP\u96be\u7ec4\u5408\u4f18\u5316\u95ee\u9898\uff08\u5982TSP\u548cVRP\uff09\u4e2d\u7684\u5e94\u7528\u8fdb\u5c55\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u7c7b\u65b9\u6cd5\uff0c\u65e8\u5728\u6574\u5408\u4f20\u7edf\u8fd0\u7b79\u5b66\u65b9\u6cd5\u4e0e\u73b0\u4ee3ML\u6280\u672f\u3002", "motivation": "\u7531\u4e8eNP\u96be\u95ee\u9898\u7684\u590d\u6742\u6027\uff0c\u4f20\u7edf\u7cbe\u786e\u7b97\u6cd5\u8017\u65f6\u8fc7\u957f\uff0c\u800c\u542f\u53d1\u5f0f\u65b9\u6cd5\u65e0\u6cd5\u4fdd\u8bc1\u6700\u4f18\u6027\uff0c\u673a\u5668\u5b66\u4e60\u4e3a\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u7c7b\u6cd5\uff0c\u5c06\u57fa\u4e8eML\u7684\u8def\u7531\u65b9\u6cd5\u5206\u4e3a\u6784\u9020\u578b\u548c\u6539\u8fdb\u578b\uff0c\u5e76\u5206\u6790\u4e86\u5176\u9002\u7528\u6027\u3002", "result": "\u7efc\u8ff0\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u6846\u67b6\uff0c\u5e76\u63a2\u8ba8\u4e86\u5982\u4f55\u5e94\u5bf9\u65b0\u5174VRP\u53d8\u4f53\u3002", "conclusion": "\u673a\u5668\u5b66\u4e60\u4e0e\u4f20\u7edf\u8fd0\u7b79\u5b66\u65b9\u6cd5\u7684\u7ed3\u5408\u4e3a\u89e3\u51b3\u590d\u6742\u8def\u7531\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2507.00417", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.00417", "abs": "https://arxiv.org/abs/2507.00417", "authors": ["Joongwon Kim", "Anirudh Goyal", "Liang Tan", "Hannaneh Hajishirzi", "Srinivasan Iyer", "Tianlu Wang"], "title": "ASTRO: Teaching Language Models to Reason by Reflecting and Backtracking In-Context", "comment": "36 pages, 23 figures", "summary": "We introduce ASTRO, the \"Autoregressive Search-Taught Reasoner\", a framework\nfor training language models to reason like search algorithms, explicitly\nleveraging self-reflection, backtracking, and exploration in their outputs.\nRecently, training large language models (LLMs) via reinforcement learning (RL)\nhas led to the advent of reasoning models with greatly enhanced reasoning\ncapabilities. Open-source replications of reasoning models, while successful,\nbuild upon models that already exhibit strong reasoning capabilities along with\nsearch behavior observed even before RL. As a result, it is yet unclear how to\nboost the reasoning capabilities of other non-reasoner models including Llama\n3. ASTRO teaches such models to internalize structured search behavior through\na synthetic dataset derived from Monte Carlo Tree Search (MCTS) over\nmathematical problem-solving trajectories. By converting search traces into\nnatural language chain-of-thoughts that capture both successes and recoveries\nfrom failure, ASTRO bootstraps models with a rich prior for exploration during\nRL. We finetune our models on these search-derived traces and further improve\nperformance via RL with verifiable rewards. We apply ASTRO to the Llama 3\nfamily of models and achieve absolute performance gains of 16.0% on MATH-500,\n26.9% on AMC 2023, and 20.0% on AIME 2024, especially improving upon\nchallenging problems that require iterative correction. Our results demonstrate\nthat search-inspired training offers a principled way to instill robust\nreasoning capabilities into open LLMs.", "AI": {"tldr": "ASTRO\u6846\u67b6\u901a\u8fc7\u81ea\u56de\u5f52\u641c\u7d22\u6559\u5b66\uff0c\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u7ed3\u5408\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u751f\u6210\u7684\u6570\u636e\u96c6\u548c\u5f3a\u5316\u5b66\u4e60\uff0c\u663e\u8457\u63d0\u9ad8\u4e86Llama 3\u5728\u6570\u5b66\u95ee\u9898\u4e0a\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u5f00\u6e90\u63a8\u7406\u6a21\u578b\u4f9d\u8d56\u5df2\u6709\u5f3a\u63a8\u7406\u80fd\u529b\u7684\u6a21\u578b\uff0c\u800cASTRO\u65e8\u5728\u63d0\u5347\u975e\u63a8\u7406\u6a21\u578b\uff08\u5982Llama 3\uff09\u7684\u63a8\u7406\u80fd\u529b\u3002", "method": "\u5229\u7528\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u751f\u6210\u81ea\u7136\u8bed\u8a00\u94fe\u5f0f\u601d\u7ef4\u6570\u636e\u96c6\uff0c\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u6a21\u578b\u3002", "result": "\u5728MATH-500\u3001AMC 2023\u548cAIME 2024\u4e0a\u5206\u522b\u53d6\u5f9716.0%\u300126.9%\u548c20.0%\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u641c\u7d22\u542f\u53d1\u7684\u8bad\u7ec3\u65b9\u6cd5\u4e3a\u5f00\u653eLLM\u63d0\u4f9b\u4e86\u7a33\u5065\u7684\u63a8\u7406\u80fd\u529b\u63d0\u5347\u9014\u5f84\u3002"}}
{"id": "2507.00432", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.00432", "abs": "https://arxiv.org/abs/2507.00432", "authors": ["Maggie Huan", "Yuetai Li", "Tuney Zheng", "Xiaoyu Xu", "Seungone Kim", "Minxin Du", "Radha Poovendran", "Graham Neubig", "Xiang Yue"], "title": "Does Math Reasoning Improve General LLM Capabilities? Understanding Transferability of LLM Reasoning", "comment": null, "summary": "Math reasoning has become the poster child of progress in large language\nmodels (LLMs), with new models rapidly surpassing human-level performance on\nbenchmarks like MATH and AIME. But as math leaderboards improve week by week,\nit is worth asking: do these gains reflect broader problem-solving ability or\njust narrow overfitting? To answer this question, we evaluate over 20\nopen-weight reasoning-tuned models across a broad suite of tasks, including\nmath, scientific QA, agent planning, coding, and standard\ninstruction-following. We surprisingly find that most models that succeed in\nmath fail to transfer their gains to other domains. To rigorously study this\nphenomenon, we conduct controlled experiments on Qwen3-14B models using\nmath-only data but different tuning methods. We find that reinforcement\nlearning (RL)-tuned models generalize well across domains, while supervised\nfine-tuning (SFT)-tuned models often forget general capabilities. Latent-space\nrepresentation and token-space distribution shift analyses reveal that SFT\ninduces substantial representation and output drift, while RL preserves\ngeneral-domain structure. Our results suggest a need to rethink standard\npost-training recipes, particularly the reliance on SFT-distilled data for\nadvancing reasoning models.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u5c3d\u7ba1\u6570\u5b66\u63a8\u7406\u80fd\u529b\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u663e\u8457\u63d0\u5347\uff0c\u4f46\u8fd9\u79cd\u80fd\u529b\u5e76\u672a\u5e7f\u6cdb\u8fc1\u79fb\u5230\u5176\u4ed6\u9886\u57df\u3002\u5f3a\u5316\u5b66\u4e60\u8c03\u4f18\u7684\u6a21\u578b\u8868\u73b0\u66f4\u597d\uff0c\u800c\u76d1\u7763\u5fae\u8c03\u5219\u5bfc\u81f4\u80fd\u529b\u9057\u5fd8\u3002", "motivation": "\u63a2\u8ba8\u6570\u5b66\u63a8\u7406\u80fd\u529b\u7684\u63d0\u5347\u662f\u5426\u53cd\u6620\u4e86\u66f4\u5e7f\u6cdb\u7684\u89e3\u51b3\u95ee\u9898\u7684\u80fd\u529b\uff0c\u8fd8\u662f\u4ec5\u4ec5\u662f\u72ed\u9698\u7684\u8fc7\u62df\u5408\u3002", "method": "\u8bc4\u4f3020\u591a\u4e2a\u5f00\u653e\u6743\u91cd\u7684\u63a8\u7406\u8c03\u4f18\u6a21\u578b\uff0c\u5e76\u5728\u6570\u5b66\u3001\u79d1\u5b66\u95ee\u7b54\u3001\u4ee3\u7406\u89c4\u5212\u3001\u7f16\u7801\u548c\u6307\u4ee4\u9075\u5faa\u7b49\u4efb\u52a1\u4e0a\u8fdb\u884c\u6d4b\u8bd5\u3002\u901a\u8fc7Qwen3-14B\u6a21\u578b\u8fdb\u884c\u5bf9\u7167\u5b9e\u9a8c\uff0c\u6bd4\u8f83\u4e0d\u540c\u8c03\u4f18\u65b9\u6cd5\u7684\u6548\u679c\u3002", "result": "\u5927\u591a\u6570\u5728\u6570\u5b66\u4e0a\u6210\u529f\u7684\u6a21\u578b\u672a\u80fd\u5c06\u80fd\u529b\u8fc1\u79fb\u5230\u5176\u4ed6\u9886\u57df\u3002\u5f3a\u5316\u5b66\u4e60\u8c03\u4f18\u7684\u6a21\u578b\u8868\u73b0\u66f4\u4f18\uff0c\u76d1\u7763\u5fae\u8c03\u5bfc\u81f4\u80fd\u529b\u9057\u5fd8\u3002\u6f5c\u5728\u7a7a\u95f4\u548c\u6807\u8bb0\u7a7a\u95f4\u5206\u6790\u63ed\u793a\u4e86\u76d1\u7763\u5fae\u8c03\u5f15\u8d77\u7684\u8868\u793a\u548c\u8f93\u51fa\u6f02\u79fb\u3002", "conclusion": "\u9700\u8981\u91cd\u65b0\u601d\u8003\u540e\u8bad\u7ec3\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u4f9d\u8d56\u76d1\u7763\u5fae\u8c03\u84b8\u998f\u6570\u636e\u6765\u63d0\u5347\u63a8\u7406\u6a21\u578b\u7684\u7b56\u7565\u3002"}}
{"id": "2507.00557", "categories": ["cs.AI", "cs.LO", "cs.SC"], "pdf": "https://arxiv.org/pdf/2507.00557", "abs": "https://arxiv.org/abs/2507.00557", "authors": ["Tianyi Ding", "Haokun Li", "Xinpeng Ni", "Bican Xia", "Tianqi Zhao"], "title": "Advancing Local Search in SMT-NRA with MCSAT Integration", "comment": null, "summary": "In this paper, we advance local search for Satisfiability Modulo the Theory\nof Nonlinear Real Arithmetic (SMT-NRA for short). First, we introduce a\ntwo-dimensional cell-jump move, called \\emph{$2d$-cell-jump}, generalizing the\nkey operation, cell-jump, of the local search method for SMT-NRA. Then, we\npropose an extended local search framework, named \\emph{$2d$-LS} (following the\nlocal search framework, LS, for SMT-NRA), integrating the model constructing\nsatisfiability calculus (MCSAT) framework to improve search efficiency. To\nfurther improve the efficiency of MCSAT, we implement a recently proposed\ntechnique called \\emph{sample-cell projection operator} for MCSAT, which is\nwell suited for CDCL-style search in the real domain and helps guide the search\naway from conflicting states. Finally, we design a hybrid framework for SMT-NRA\ncombining MCSAT, $2d$-LS and OpenCAD, to improve search efficiency through\ninformation exchange. The experimental results demonstrate improvements in\nlocal search performance, highlighting the effectiveness of the proposed\nmethods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a$2d$-cell-jump\u7684\u4e8c\u7ef4\u5355\u5143\u8df3\u8dc3\u64cd\u4f5c\uff0c\u6269\u5c55\u4e86SMT-NRA\u7684\u5c40\u90e8\u641c\u7d22\u65b9\u6cd5\uff0c\u5e76\u7ed3\u5408MCSAT\u6846\u67b6\u548csample-cell\u6295\u5f71\u7b97\u5b50\u63d0\u5347\u641c\u7d22\u6548\u7387\u3002", "motivation": "\u63d0\u5347SMT-NRA\uff08\u975e\u7ebf\u6027\u5b9e\u6570\u7b97\u672f\u7684\u53ef\u6ee1\u8db3\u6027\u6a21\u7406\u8bba\uff09\u7684\u5c40\u90e8\u641c\u7d22\u6548\u7387\u3002", "method": "\u5f15\u5165$2d$-cell-jump\u64cd\u4f5c\uff0c\u6269\u5c55$2d$-LS\u6846\u67b6\uff0c\u7ed3\u5408MCSAT\u548csample-cell\u6295\u5f71\u7b97\u5b50\uff0c\u8bbe\u8ba1\u6df7\u5408\u6846\u67b6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u5c40\u90e8\u641c\u7d22\u6027\u80fd\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86SMT-NRA\u7684\u641c\u7d22\u6548\u7387\u3002"}}
{"id": "2507.00726", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.00726", "abs": "https://arxiv.org/abs/2507.00726", "authors": ["Dongyoon Hwang", "Hojoon Lee", "Jaegul Choo", "Dongmin Park", "Jongho Park"], "title": "Can Large Language Models Develop Strategic Reasoning? Post-training Insights from Learning Chess", "comment": "27 pages", "summary": "While reinforcement learning (RL) for large language models (LLMs) has shown\npromise in mathematical reasoning, strategic reasoning for LLMs using RL\nremains largely unexplored. We investigate whether LLMs can develop strategic\nreasoning capabilities through RL in chess. To this end, we leverage a\nchess-pretrained action-value network to provide dense reward on the LLM's\noutput move quality, which can be seen as a form of knowledge distillation. Our\nexperiments show that our distillation-based dense rewards often outperform\nsparse binary rewards. However, surprisingly, all models plateau far below\nexpert levels. We provide SFT and RL ablations on chess reasoning training and\nfind evidence that this limitation stems from a deficit in the pretrained\nmodels' internal understanding of chess--a deficit which RL alone may not be\nable to fully overcome.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u8ba9\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u8c61\u68cb\u4e2d\u53d1\u5c55\u7b56\u7565\u63a8\u7406\u80fd\u529b\uff0c\u53d1\u73b0\u57fa\u4e8e\u77e5\u8bc6\u84b8\u998f\u7684\u5bc6\u96c6\u5956\u52b1\u4f18\u4e8e\u7a00\u758f\u5956\u52b1\uff0c\u4f46\u6a21\u578b\u8868\u73b0\u8fdc\u4f4e\u4e8e\u4e13\u5bb6\u6c34\u5e73\uff0c\u539f\u56e0\u53ef\u80fd\u662f\u9884\u8bad\u7ec3\u6a21\u578b\u5bf9\u8c61\u68cb\u7684\u7406\u89e3\u4e0d\u8db3\u3002", "motivation": "\u63a2\u7d22LLM\u662f\u5426\u53ef\u4ee5\u901a\u8fc7RL\u5728\u8c61\u68cb\u4e2d\u53d1\u5c55\u7b56\u7565\u63a8\u7406\u80fd\u529b\uff0c\u586b\u8865\u8fd9\u4e00\u9886\u57df\u7684\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u5229\u7528\u8c61\u68cb\u9884\u8bad\u7ec3\u7684\u52a8\u4f5c\u4ef7\u503c\u7f51\u7edc\u4e3aLLM\u7684\u8f93\u51fa\u52a8\u4f5c\u8d28\u91cf\u63d0\u4f9b\u5bc6\u96c6\u5956\u52b1\uff08\u77e5\u8bc6\u84b8\u998f\uff09\uff0c\u5e76\u4e0e\u7a00\u758f\u5956\u52b1\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u5bc6\u96c6\u5956\u52b1\u901a\u5e38\u4f18\u4e8e\u7a00\u758f\u5956\u52b1\uff0c\u4f46\u6240\u6709\u6a21\u578b\u8868\u73b0\u8fdc\u4f4e\u4e8e\u4e13\u5bb6\u6c34\u5e73\uff0cRL\u53ef\u80fd\u65e0\u6cd5\u5b8c\u5168\u514b\u670d\u9884\u8bad\u7ec3\u6a21\u578b\u5bf9\u8c61\u68cb\u7406\u89e3\u7684\u4e0d\u8db3\u3002", "conclusion": "\u9884\u8bad\u7ec3\u6a21\u578b\u5bf9\u8c61\u68cb\u7684\u5185\u90e8\u7406\u89e3\u4e0d\u8db3\u662f\u6027\u80fd\u74f6\u9888\uff0c\u4ec5\u9760RL\u53ef\u80fd\u65e0\u6cd5\u5b8c\u5168\u89e3\u51b3\u3002"}}
{"id": "2507.00810", "categories": ["cs.AI", "math.OC"], "pdf": "https://arxiv.org/pdf/2507.00810", "abs": "https://arxiv.org/abs/2507.00810", "authors": ["Qing Xu", "Xiaohua Xuan"], "title": "A Robust Algorithm for Non-IID Machine Learning Problems with Convergence Analysis", "comment": null, "summary": "In this paper, we propose an improved numerical algorithm for solving minimax\nproblems based on nonsmooth optimization, quadratic programming and iterative\nprocess. We also provide a rigorous proof of convergence for our algorithm\nunder some mild assumptions, such as gradient continuity and boundedness. Such\nan algorithm can be widely applied in various fields such as robust\noptimization, imbalanced learning, etc.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u975e\u5149\u6ed1\u4f18\u5316\u3001\u4e8c\u6b21\u89c4\u5212\u548c\u8fed\u4ee3\u8fc7\u7a0b\u7684\u6539\u8fdb\u6570\u503c\u7b97\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u6781\u5c0f\u6781\u5927\u95ee\u9898\uff0c\u5e76\u63d0\u4f9b\u4e86\u6536\u655b\u6027\u8bc1\u660e\u3002", "motivation": "\u89e3\u51b3\u6781\u5c0f\u6781\u5927\u95ee\u9898\u5728\u9c81\u68d2\u4f18\u5316\u548c\u4e0d\u5e73\u8861\u5b66\u4e60\u7b49\u9886\u57df\u7684\u5e7f\u6cdb\u5e94\u7528\u9700\u6c42\u3002", "method": "\u7ed3\u5408\u975e\u5149\u6ed1\u4f18\u5316\u3001\u4e8c\u6b21\u89c4\u5212\u548c\u8fed\u4ee3\u8fc7\u7a0b\u8bbe\u8ba1\u6539\u8fdb\u7b97\u6cd5\u3002", "result": "\u5728\u68af\u5ea6\u8fde\u7eed\u6027\u548c\u6709\u754c\u6027\u7b49\u6e29\u548c\u5047\u8bbe\u4e0b\uff0c\u7b97\u6cd5\u5177\u6709\u6536\u655b\u6027\u3002", "conclusion": "\u8be5\u7b97\u6cd5\u5728\u591a\u79cd\u9886\u57df\u5177\u6709\u6f5c\u5728\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2507.00841", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2507.00841", "abs": "https://arxiv.org/abs/2507.00841", "authors": ["Siyuan Liang", "Tianmeng Fang", "Zhe Liu", "Aishan Liu", "Yan Xiao", "Jinyuan He", "Ee-Chien Chang", "Xiaochun Cao"], "title": "SafeMobile: Chain-level Jailbreak Detection and Automated Evaluation for Multimodal Mobile Agents", "comment": "12 pages", "summary": "With the wide application of multimodal foundation models in intelligent\nagent systems, scenarios such as mobile device control, intelligent assistant\ninteraction, and multimodal task execution are gradually relying on such large\nmodel-driven agents. However, the related systems are also increasingly exposed\nto potential jailbreak risks. Attackers may induce the agents to bypass the\noriginal behavioral constraints through specific inputs, and then trigger\ncertain risky and sensitive operations, such as modifying settings, executing\nunauthorized commands, or impersonating user identities, which brings new\nchallenges to system security. Existing security measures for intelligent\nagents still have limitations when facing complex interactions, especially in\ndetecting potentially risky behaviors across multiple rounds of conversations\nor sequences of tasks. In addition, an efficient and consistent automated\nmethodology to assist in assessing and determining the impact of such risks is\ncurrently lacking. This work explores the security issues surrounding mobile\nmultimodal agents, attempts to construct a risk discrimination mechanism by\nincorporating behavioral sequence information, and designs an automated\nassisted assessment scheme based on a large language model. Through preliminary\nvalidation in several representative high-risk tasks, the results show that the\nmethod can improve the recognition of risky behaviors to some extent and assist\nin reducing the probability of agents being jailbroken. We hope that this study\ncan provide some valuable references for the security risk modeling and\nprotection of multimodal intelligent agent systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u5728\u667a\u80fd\u4ee3\u7406\u7cfb\u7edf\u4e2d\u7684\u5b89\u5168\u98ce\u9669\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u884c\u4e3a\u5e8f\u5217\u4fe1\u606f\u7684\u98ce\u9669\u8bc6\u522b\u673a\u5236\uff0c\u5e76\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u8bbe\u8ba1\u4e86\u81ea\u52a8\u5316\u8f85\u52a9\u8bc4\u4f30\u65b9\u6848\uff0c\u521d\u6b65\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u968f\u7740\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u5728\u667a\u80fd\u4ee3\u7406\u7cfb\u7edf\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u7cfb\u7edf\u9762\u4e34\u6f5c\u5728\u7684\u8d8a\u72f1\u98ce\u9669\uff0c\u73b0\u6709\u5b89\u5168\u63aa\u65bd\u5728\u590d\u6742\u4ea4\u4e92\u4e2d\u4ecd\u6709\u5c40\u9650\uff0c\u7f3a\u4e4f\u9ad8\u6548\u7684\u98ce\u9669\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u6784\u5efa\u4e86\u7ed3\u5408\u884c\u4e3a\u5e8f\u5217\u4fe1\u606f\u7684\u98ce\u9669\u8bc6\u522b\u673a\u5236\uff0c\u5e76\u8bbe\u8ba1\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u5316\u8f85\u52a9\u8bc4\u4f30\u65b9\u6848\u3002", "result": "\u521d\u6b65\u9a8c\u8bc1\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u63d0\u5347\u98ce\u9669\u884c\u4e3a\u8bc6\u522b\u80fd\u529b\uff0c\u964d\u4f4e\u4ee3\u7406\u88ab\u8d8a\u72f1\u7684\u6982\u7387\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u591a\u6a21\u6001\u667a\u80fd\u4ee3\u7406\u7cfb\u7edf\u7684\u5b89\u5168\u98ce\u9669\u5efa\u6a21\u4e0e\u9632\u62a4\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u53c2\u8003\u3002"}}
{"id": "2507.00951", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.00951", "abs": "https://arxiv.org/abs/2507.00951", "authors": ["Rizwan Qureshi", "Ranjan Sapkota", "Abbas Shah", "Amgad Muneer", "Anas Zafar", "Ashmal Vayani", "Maged Shoman", "Abdelrahman B. M. Eldaly", "Kai Zhang", "Ferhat Sadak", "Shaina Raza", "Xinqi Fan", "Ravid Shwartz-Ziv", "Hong Yan", "Vinjia Jain", "Aman Chadha", "Manoj Karkee", "Jia Wu", "Philip Torr", "Seyedali Mirjalili"], "title": "Thinking Beyond Tokens: From Brain-Inspired Intelligence to Cognitive Foundations for Artificial General Intelligence and its Societal Impact", "comment": null, "summary": "Can machines truly think, reason and act in domains like humans? This\nenduring question continues to shape the pursuit of Artificial General\nIntelligence (AGI). Despite the growing capabilities of models such as GPT-4.5,\nDeepSeek, Claude 3.5 Sonnet, Phi-4, and Grok 3, which exhibit multimodal\nfluency and partial reasoning, these systems remain fundamentally limited by\ntheir reliance on token-level prediction and lack of grounded agency. This\npaper offers a cross-disciplinary synthesis of AGI development, spanning\nartificial intelligence, cognitive neuroscience, psychology, generative models,\nand agent-based systems. We analyze the architectural and cognitive foundations\nof general intelligence, highlighting the role of modular reasoning, persistent\nmemory, and multi-agent coordination. In particular, we emphasize the rise of\nAgentic RAG frameworks that combine retrieval, planning, and dynamic tool use\nto enable more adaptive behavior. We discuss generalization strategies,\nincluding information compression, test-time adaptation, and training-free\nmethods, as critical pathways toward flexible, domain-agnostic intelligence.\nVision-Language Models (VLMs) are reexamined not just as perception modules but\nas evolving interfaces for embodied understanding and collaborative task\ncompletion. We also argue that true intelligence arises not from scale alone\nbut from the integration of memory and reasoning: an orchestration of modular,\ninteractive, and self-improving components where compression enables adaptive\nbehavior. Drawing on advances in neurosymbolic systems, reinforcement learning,\nand cognitive scaffolding, we explore how recent architectures begin to bridge\nthe gap between statistical learning and goal-directed cognition. Finally, we\nidentify key scientific, technical, and ethical challenges on the path to AGI.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u673a\u5668\u662f\u5426\u80fd\u50cf\u4eba\u7c7b\u4e00\u6837\u601d\u8003\u3001\u63a8\u7406\u548c\u884c\u52a8\uff0c\u5206\u6790\u4e86\u5f53\u524dAI\u6a21\u578b\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u591a\u5b66\u79d1\u878d\u5408\u7684AGI\u53d1\u5c55\u8def\u5f84\uff0c\u5f3a\u8c03\u6a21\u5757\u5316\u63a8\u7406\u3001\u8bb0\u5fc6\u548c\u591a\u667a\u80fd\u4f53\u534f\u8c03\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u63a2\u7d22\u5982\u4f55\u514b\u670d\u5f53\u524dAI\u6a21\u578b\uff08\u5982GPT-4.5\u7b49\uff09\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u771f\u6b63\u7684\u901a\u7528\u4eba\u5de5\u667a\u80fd\uff08AGI\uff09\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u8de8\u5b66\u79d1\u7efc\u5408\uff08AI\u3001\u8ba4\u77e5\u795e\u7ecf\u79d1\u5b66\u3001\u5fc3\u7406\u5b66\u7b49\uff09\uff0c\u5206\u6790\u901a\u7528\u667a\u80fd\u7684\u67b6\u6784\u548c\u8ba4\u77e5\u57fa\u7840\uff0c\u63d0\u51faAgentic RAG\u6846\u67b6\u548c\u901a\u7528\u5316\u7b56\u7565\u3002", "result": "\u7ed3\u679c\u6307\u51fa\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u3001\u8bb0\u5fc6\u4e0e\u63a8\u7406\u7684\u6574\u5408\u4ee5\u53ca\u795e\u7ecf\u7b26\u53f7\u7cfb\u7edf\u7b49\u65b9\u6cd5\uff0c\u53ef\u4ee5\u7f29\u5c0f\u7edf\u8ba1\u5b66\u4e60\u4e0e\u76ee\u6807\u5bfc\u5411\u8ba4\u77e5\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "conclusion": "\u7ed3\u8bba\u5f3a\u8c03\uff0cAGI\u7684\u5b9e\u73b0\u9700\u8981\u89e3\u51b3\u79d1\u5b66\u3001\u6280\u672f\u548c\u4f26\u7406\u6311\u6218\uff0c\u5e76\u4f9d\u8d56\u4e8e\u6a21\u5757\u5316\u3001\u4ea4\u4e92\u5f0f\u548c\u81ea\u6211\u6539\u8fdb\u7ec4\u4ef6\u7684\u6574\u5408\u3002"}}
{"id": "2507.00979", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.00979", "abs": "https://arxiv.org/abs/2507.00979", "authors": ["Dongyoon Hahm", "Woogyeol Jin", "June Suk Choi", "Sungsoo Ahn", "Kimin Lee"], "title": "Enhancing LLM Agent Safety via Causal Influence Prompting", "comment": "Accepted at ACL 2025 Findings, Source code:\n  https://github.com/HahmDY/causal_influence_prompting.git", "summary": "As autonomous agents powered by large language models (LLMs) continue to\ndemonstrate potential across various assistive tasks, ensuring their safe and\nreliable behavior is crucial for preventing unintended consequences. In this\nwork, we introduce CIP, a novel technique that leverages causal influence\ndiagrams (CIDs) to identify and mitigate risks arising from agent\ndecision-making. CIDs provide a structured representation of cause-and-effect\nrelationships, enabling agents to anticipate harmful outcomes and make safer\ndecisions. Our approach consists of three key steps: (1) initializing a CID\nbased on task specifications to outline the decision-making process, (2)\nguiding agent interactions with the environment using the CID, and (3)\niteratively refining the CID based on observed behaviors and outcomes.\nExperimental results demonstrate that our method effectively enhances safety in\nboth code execution and mobile device control tasks.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCIP\u7684\u65b0\u6280\u672f\uff0c\u5229\u7528\u56e0\u679c\u5f71\u54cd\u56fe\uff08CID\uff09\u6765\u8bc6\u522b\u548c\u51cf\u8f7b\u81ea\u4e3b\u4ee3\u7406\u51b3\u7b56\u4e2d\u7684\u98ce\u9669\uff0c\u4ece\u800c\u63d0\u5347\u5b89\u5168\u6027\u3002", "motivation": "\u968f\u7740\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u81ea\u4e3b\u4ee3\u7406\u5728\u5404\u79cd\u8f85\u52a9\u4efb\u52a1\u4e2d\u5c55\u73b0\u6f5c\u529b\uff0c\u786e\u4fdd\u5176\u884c\u4e3a\u5b89\u5168\u53ef\u9760\u81f3\u5173\u91cd\u8981\uff0c\u4ee5\u907f\u514d\u610f\u5916\u540e\u679c\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u4e09\u4e2a\u6b65\u9aa4\uff1a1) \u57fa\u4e8e\u4efb\u52a1\u89c4\u8303\u521d\u59cb\u5316CID\u4ee5\u63cf\u8ff0\u51b3\u7b56\u8fc7\u7a0b\uff1b2) \u4f7f\u7528CID\u6307\u5bfc\u4ee3\u7406\u4e0e\u73af\u5883\u4ea4\u4e92\uff1b3) \u6839\u636e\u89c2\u5bdf\u5230\u7684\u884c\u4e3a\u548c\u7ed3\u679c\u8fed\u4ee3\u4f18\u5316CID\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4ee3\u7801\u6267\u884c\u548c\u79fb\u52a8\u8bbe\u5907\u63a7\u5236\u4efb\u52a1\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u5b89\u5168\u6027\u3002", "conclusion": "CIP\u6280\u672f\u901a\u8fc7\u56e0\u679c\u5f71\u54cd\u56fe\u6709\u6548\u589e\u5f3a\u4e86\u81ea\u4e3b\u4ee3\u7406\u7684\u5b89\u5168\u6027\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u5b9e\u7528\u6846\u67b6\u3002"}}
