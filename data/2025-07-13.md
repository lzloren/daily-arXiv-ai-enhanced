<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 26]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Autonomous Control Leveraging LLMs: An Agentic Framework for Next-Generation Industrial Automation](https://arxiv.org/abs/2507.07115)
*Javal Vyas,Mehmet Mercangoz*

Main category: cs.AI

TL;DR: 论文提出了一种结合符号推理与自适应控制的统一代理框架，利用大语言模型（LLMs）同时处理离散故障恢复规划和连续过程控制，并通过案例研究验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现代化学过程日益复杂，劳动力短缺和故障场景多样化，需要新的自动化范式来结合符号推理与自适应控制。

Method: 采用有限状态机（FSMs）作为可解释的操作框架，通过LLM驱动的规划代理提出恢复序列，模拟代理执行和检查每个转换，并通过验证-重新提示循环迭代优化无效计划。

Result: 在案例研究中，GPT-4o和GPT-4o-mini在180个随机生成的FSMs中实现了100%的有效路径成功率，并在实验室平台上展示了与经典PID控制相当的性能。

Conclusion: 研究表明，通过结构化反馈和模块化代理，LLMs可以统一高级符号规划和低级连续控制，为化学工程中的语言驱动自动化铺平道路。

Abstract: The increasing complexity of modern chemical processes, coupled with
workforce shortages and intricate fault scenarios, demands novel automation
paradigms that blend symbolic reasoning with adaptive control. In this work, we
introduce a unified agentic framework that leverages large language models
(LLMs) for both discrete fault-recovery planning and continuous process control
within a single architecture. We adopt Finite State Machines (FSMs) as
interpretable operating envelopes: an LLM-driven planning agent proposes
recovery sequences through the FSM, a Simulation Agent executes and checks each
transition, and a Validator-Reprompting loop iteratively refines invalid plans.
In Case Study 1, across 180 randomly generated FSMs of varying sizes (4-25
states, 4-300 transitions), GPT-4o and GPT-4o-mini achieve 100% valid-path
success within five reprompts-outperforming open-source LLMs in both accuracy
and latency. In Case Study 2, the same framework modulates dual-heater inputs
on a laboratory TCLab platform (and its digital twin) to maintain a target
average temperature under persistent asymmetric disturbances. Compared to
classical PID control, our LLM-based controller attains similar performance,
while ablation of the prompting loop reveals its critical role in handling
nonlinear dynamics. We analyze key failure modes-such as instruction following
lapses and coarse ODE approximations. Our results demonstrate that, with
structured feedback and modular agents, LLMs can unify high-level symbolic
planningand low-level continuous control, paving the way towards resilient,
language-driven automation in chemical engineering.

</details>


### [2] [BOOST: Out-of-Distribution-Informed Adaptive Sampling for Bias Mitigation in Stylistic Convolutional Neural Networks](https://arxiv.org/abs/2507.07134)
*Mridula Vijendran,Shuang Chen,Jingjing Deng,Hubert P. H. Shum*

Main category: cs.AI

TL;DR: 论文提出了一种名为BOOST的新方法，通过动态调整温度缩放和采样概率，解决AI模型在艺术分类中的偏见问题，并在KaoKore和PACS数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: AI模型在艺术分类中存在偏见问题，尤其是面对分布外数据时，现有方法未能有效解决这一挑战。

Method: 提出BOOST方法，动态调整温度缩放和采样概率，并引入新指标SODC评估类别分离和偏见减少。

Result: BOOST在KaoKore和PACS数据集上表现出色，平衡了性能与公平性。

Conclusion: BOOST是一种有效的解决方案，适用于艺术领域中的AI模型去偏见化。

Abstract: The pervasive issue of bias in AI presents a significant challenge to
painting classification, and is getting more serious as these systems become
increasingly integrated into tasks like art curation and restoration. Biases,
often arising from imbalanced datasets where certain artistic styles dominate,
compromise the fairness and accuracy of model predictions, i.e., classifiers
are less accurate on rarely seen paintings. While prior research has made
strides in improving classification performance, it has largely overlooked the
critical need to address these underlying biases, that is, when dealing with
out-of-distribution (OOD) data. Our insight highlights the necessity of a more
robust approach to bias mitigation in AI models for art classification on
biased training data. We propose a novel OOD-informed model bias adaptive
sampling method called BOOST (Bias-Oriented OOD Sampling and Tuning). It
addresses these challenges by dynamically adjusting temperature scaling and
sampling probabilities, thereby promoting a more equitable representation of
all classes. We evaluate our proposed approach to the KaoKore and PACS
datasets, focusing on the model's ability to reduce class-wise bias. We further
propose a new metric, Same-Dataset OOD Detection Score (SODC), designed to
assess class-wise separation and per-class bias reduction. Our method
demonstrates the ability to balance high performance with fairness, making it a
robust solution for unbiasing AI models in the art domain.

</details>


### [3] [State-Inference-Based Prompting for Natural Language Trading with Game NPCs](https://arxiv.org/abs/2507.07203)
*Minkyung Kim,Junsik Kim,Hwidong Bae,Woongcheol Yang,Sangdon Park,Sohee Bae*

Main category: cs.AI

TL;DR: SIBP方法通过状态推断和规则遵守，解决了大语言模型在游戏交易系统中的规则违反问题，显著提升了准确性和信任度。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在动态游戏交互中表现良好，但在规则驱动的交易系统中容易出现规则违反（如物品幻觉和计算错误），影响玩家信任。

Method: 提出State-Inference-Based Prompting (SIBP)，将交易分解为六个状态，通过上下文感知的物品引用和占位符价格计算实现规则遵守。

Result: 在100次交易对话中，SIBP实现了>97%的状态合规性、>95%的引用准确性和99.7%的计算精度，计算效率优于基线方法。

Conclusion: SIBP为商业游戏中可信赖的NPC交互提供了实用基础。

Abstract: Large Language Models enable dynamic game interactions but struggle with
rule-governed trading systems. Current implementations suffer from rule
violations, such as item hallucinations and calculation errors, that erode
player trust. Here, State-Inference-Based Prompting (SIBP) enables reliable
trading through autonomous dialogue state inference and context-specific rule
adherence. The approach decomposes trading into six states within a unified
prompt framework, implementing context-aware item referencing and
placeholder-based price calculations. Evaluation across 100 trading dialogues
demonstrates >97% state compliance, >95% referencing accuracy, and 99.7%
calculation precision. SIBP maintains computational efficiency while
outperforming baseline approaches, establishing a practical foundation for
trustworthy NPC interactions in commercial games.

</details>


### [4] [Neurosymbolic Feature Extraction for Identifying Forced Labor in Supply Chains](https://arxiv.org/abs/2507.07217)
*Zili Wang,Frank Montabon,Kristin Yvonne Rozier*

Main category: cs.AI

TL;DR: 论文探讨了如何利用神经符号方法在稀疏且不可靠的数据中检测供应链中的非法活动，并比较了人工与自动特征提取的效果。


<details>
  <summary>Details</summary>
Motivation: 供应链网络复杂且常涉及非法活动，传统机器学习方法需要大量训练数据，但非法供应链数据稀疏且不可靠，因此需要新方法。

Method: 采用神经符号方法，结合问题树方法查询大型语言模型（LLM），以识别和量化新闻文章的相关性。

Result: 系统评估了人工与机器分类在供应链强迫劳动相关新闻文章中的差异。

Conclusion: 神经符号方法在稀疏数据中检测非法活动具有潜力，问题树方法能有效辅助分类。

Abstract: Supply chain networks are complex systems that are challenging to analyze;
this problem is exacerbated when there are illicit activities involved in the
supply chain, such as counterfeit parts, forced labor, or human trafficking.
While machine learning (ML) can find patterns in complex systems like supply
chains, traditional ML techniques require large training data sets. However,
illicit supply chains are characterized by very sparse data, and the data that
is available is often (purposely) corrupted or unreliable in order to hide the
nature of the activities. We need to be able to automatically detect new
patterns that correlate with such illegal activity over complex, even temporal
data, without requiring large training data sets. We explore neurosymbolic
methods for identifying instances of illicit activity in supply chains and
compare the effectiveness of manual and automated feature extraction from news
articles accurately describing illicit activities uncovered by authorities. We
propose a question tree approach for querying a large language model (LLM) to
identify and quantify the relevance of articles. This enables a systematic
evaluation of the differences between human and machine classification of news
articles related to forced labor in supply chains.

</details>


### [5] [Open Source Planning & Control System with Language Agents for Autonomous Scientific Discovery](https://arxiv.org/abs/2507.07257)
*Licong Xu,Milind Sarkar,Anto I. Lonappan,Íñigo Zubeldia,Pablo Villanueva-Domingo,Santiago Casas,Christian Fidler,Chetana Amancharla,Ujjwal Tiwari,Adrian Bayer,Chadi Ait Ekiou,Miles Cranmer,Adrian Dimitrov,James Fergusson,Kahaan Gandhi,Sven Krippendorf,Andrew Laverick,Julien Lesgourgues,Antony Lewis,Thomas Meier,Blake Sherwin,Kristen Surrao,Francisco Villaescusa-Navarro,Chi Wang,Xueqing Xu,Boris Bolliet*

Main category: cs.AI

TL;DR: 介绍了一个名为cmbagent的多智能体系统，用于自动化科学研究任务，由约30个LLM智能体组成，采用Planning & Control策略协调工作流，无需人工干预。


<details>
  <summary>Details</summary>
Motivation: 旨在通过多智能体系统实现科学研究的自动化，减少人工干预，提高效率。

Method: 系统由多个专门化LLM智能体组成，采用Planning & Control策略协调任务，支持本地代码执行。

Result: 成功应用于博士级宇宙学任务，性能优于当前最先进的LLM。

Conclusion: cmbagent展示了多智能体系统在科学研究自动化中的潜力，代码和演示已公开。

Abstract: We present a multi-agent system for automation of scientific research tasks,
cmbagent. The system is formed by about 30 Large Language Model (LLM) agents
and implements a Planning & Control strategy to orchestrate the agentic
workflow, with no human-in-the-loop at any point. Each agent specializes in a
different task (performing retrieval on scientific papers and codebases,
writing code, interpreting results, critiquing the output of other agents) and
the system is able to execute code locally. We successfully apply cmbagent to
carry out a PhD level cosmology task (the measurement of cosmological
parameters using supernova data) and evaluate its performance on two benchmark
sets, finding superior performance over state-of-the-art LLMs. The source code
is available on GitHub, demonstration videos are also available, and the system
is deployed on HuggingFace and will be available on the cloud.

</details>


### [6] [Application of LLMs to Multi-Robot Path Planning and Task Allocation](https://arxiv.org/abs/2507.07302)
*Ashish Kumar*

Main category: cs.AI

TL;DR: 本文研究了在多智能体强化学习中，利用大型语言模型作为专家规划器以提升探索效率的方法。


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习中的探索效率问题因算法复杂性而加剧，需要更高效的探索方法。

Method: 提出使用大型语言模型作为专家规划器，指导多智能体在基于规划的任务中进行探索。

Result: 研究表明，大型语言模型能够有效提升多智能体在复杂任务中的探索效率。

Conclusion: 利用大型语言模型作为专家规划器是一种有前景的多智能体探索方法。

Abstract: Efficient exploration is a well known problem in deep reinforcement learning
and this problem is exacerbated in multi-agent reinforcement learning due the
intrinsic complexities of such algorithms. There are several approaches to
efficiently explore an environment to learn to solve tasks by multi-agent
operating in that environment, of which, the idea of expert exploration is
investigated in this work. More specifically, this work investigates the
application of large-language models as expert planners for efficient
exploration in planning based tasks for multiple agents.

</details>


### [7] [ViDove: A Translation Agent System with Multimodal Context and Memory-Augmented Reasoning](https://arxiv.org/abs/2507.07306)
*Yichen Lu,Wei Dai,Jiaen Liu,Ching Wing Kwok,Zongheng Wu,Xudong Xiao,Ao Sun,Sheng Fu,Jianyuan Zhan,Yian Wang,Takatomo Saito,Sicheng Lai*

Main category: cs.AI

TL;DR: ViDove是一种基于LLM的多模态翻译代理系统，通过结合视觉和上下文背景信息提升翻译质量，并在字幕生成和通用翻译任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有LLM翻译代理通常仅支持文本输入，无法利用多模态信息，ViDove旨在解决这一问题。

Method: ViDove结合视觉和上下文信息，采用多模态记忆系统和长短时记忆模块，融入领域知识。

Result: ViDove在BLEU分数和SubER上分别提升28%和15%，并推出新基准DoveBench。

Conclusion: ViDove显著提升多模态翻译质量，为实际场景提供更准确的翻译解决方案。

Abstract: LLM-based translation agents have achieved highly human-like translation
results and are capable of handling longer and more complex contexts with
greater efficiency. However, they are typically limited to text-only inputs. In
this paper, we introduce ViDove, a translation agent system designed for
multimodal input. Inspired by the workflow of human translators, ViDove
leverages visual and contextual background information to enhance the
translation process. Additionally, we integrate a multimodal memory system and
long-short term memory modules enriched with domain-specific knowledge,
enabling the agent to perform more accurately and adaptively in real-world
scenarios. As a result, ViDove achieves significantly higher translation
quality in both subtitle generation and general translation tasks, with a 28%
improvement in BLEU scores and a 15% improvement in SubER compared to previous
state-of-the-art baselines. Moreover, we introduce DoveBench, a new benchmark
for long-form automatic video subtitling and translation, featuring 17 hours of
high-quality, human-annotated data. Our code is available here:
https://github.com/pigeonai-org/ViDove

</details>


### [8] [On the Impossibility of Separating Intelligence from Judgment: The Computational Intractability of Filtering for AI Alignment](https://arxiv.org/abs/2507.07341)
*Sarah Ball,Greg Gluch,Shafi Goldwasser,Frauke Kreuter,Omer Reingold,Guy N. Rothblum*

Main category: cs.AI

TL;DR: 论文研究大型语言模型（LLM）生成有害内容的过滤问题，发现输入和输出过滤均存在计算难题，并指出外部过滤器无法确保安全，需将判断力融入模型内部。


<details>
  <summary>Details</summary>
Motivation: 随着LLM的广泛应用，其可能被滥用于生成有害内容，研究旨在解决这一对齐挑战，特别是过滤器的有效性。

Method: 研究输入提示和输出内容的过滤，通过计算复杂性理论分析其可行性，并基于密码学假设提出分离结果。

Result: 证明高效输入过滤器不存在，且输出过滤在特定情况下计算不可行，外部过滤器无法确保安全。

Conclusion: 安全需通过模型内部设计实现，而非外部过滤器，智能与判断力不可分割。

Abstract: With the increased deployment of large language models (LLMs), one concern is
their potential misuse for generating harmful content. Our work studies the
alignment challenge, with a focus on filters to prevent the generation of
unsafe information. Two natural points of intervention are the filtering of the
input prompt before it reaches the model, and filtering the output after
generation. Our main results demonstrate computational challenges in filtering
both prompts and outputs. First, we show that there exist LLMs for which there
are no efficient prompt filters: adversarial prompts that elicit harmful
behavior can be easily constructed, which are computationally indistinguishable
from benign prompts for any efficient filter. Our second main result identifies
a natural setting in which output filtering is computationally intractable. All
of our separation results are under cryptographic hardness assumptions. In
addition to these core findings, we also formalize and study relaxed mitigation
approaches, demonstrating further computational barriers. We conclude that
safety cannot be achieved by designing filters external to the LLM internals
(architecture and weights); in particular, black-box access to the LLM will not
suffice. Based on our technical results, we argue that an aligned AI system's
intelligence cannot be separated from its judgment.

</details>


### [9] [Supply Chain Optimization via Generative Simulation and Iterative Decision Policies](https://arxiv.org/abs/2507.07355)
*Haoyue Bai,Haoyu Wang,Nanxu Gong,Xinyuan Wang,Wangyang Ying,Haifeng Chen,Yanjie Fu*

Main category: cs.AI

TL;DR: Sim-to-Dec框架结合生成模拟和智能决策，显著提升供应链运输的响应速度和经济效率。


<details>
  <summary>Details</summary>
Motivation: 供应链运输中的高响应性和经济效率是关键目标，受运输模式战略决策影响。

Method: 提出Sim-to-Dec框架，包括生成模拟模块（利用自回归建模）和双感知决策模型（历史与未来结合），通过端到端优化迭代改进。

Result: 在三个真实数据集上的实验表明，Sim-to-Dec显著提高了及时交付率和利润。

Conclusion: Sim-to-Dec为运输策略设计提供了可观察、低风险的环境，满足泛化性、动态性、历史与预测结合及反馈紧密集成的需求。

Abstract: High responsiveness and economic efficiency are critical objectives in supply
chain transportation, both of which are influenced by strategic decisions on
shipping mode. An integrated framework combining an efficient simulator with an
intelligent decision-making algorithm can provide an observable, low-risk
environment for transportation strategy design. An ideal simulation-decision
framework must (1) generalize effectively across various settings, (2) reflect
fine-grained transportation dynamics, (3) integrate historical experience with
predictive insights, and (4) maintain tight integration between simulation
feedback and policy refinement. We propose Sim-to-Dec framework to satisfy
these requirements. Specifically, Sim-to-Dec consists of a generative
simulation module, which leverages autoregressive modeling to simulate
continuous state changes, reducing dependence on handcrafted domain-specific
rules and enhancing robustness against data fluctuations; and a history-future
dual-aware decision model, refined iteratively through end-to-end optimization
with simulator interactions. Extensive experiments conducted on three
real-world datasets demonstrate that Sim-to-Dec significantly improves timely
delivery rates and profit.

</details>


### [10] [DrugMCTS: a drug repurposing framework combining multi-agent, RAG and Monte Carlo Tree Search](https://arxiv.org/abs/2507.07426)
*Zerui Yang,Yuwei Wan,Yinqiao Li,Yudai Matsuda,Tong Xie,Linqi Song*

Main category: cs.AI

TL;DR: DrugMCTS框架结合RAG、多智能体协作和蒙特卡洛树搜索，显著提升药物重定向任务的性能，无需领域微调即可超越现有模型。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在科学领域中推理能力受限的问题，避免传统方法的高计算成本或数据利用不足的缺陷。

Method: 提出DrugMCTS框架，整合检索增强生成、多智能体协作和蒙特卡洛树搜索，通过五个专业智能体实现结构化推理。

Result: 在DrugBank和KIBA数据集上，DrugMCTS的召回率和鲁棒性显著优于通用大语言模型和深度学习基线。

Conclusion: 结构化推理、智能体协作和反馈驱动搜索机制对药物发现中的大语言模型应用至关重要。

Abstract: Recent advances in large language models have demonstrated considerable
potential in scientific domains such as drug discovery. However, their
effectiveness remains constrained when reasoning extends beyond the knowledge
acquired during pretraining. Conventional approaches, such as fine-tuning or
retrieval-augmented generation, face limitations in either imposing high
computational overhead or failing to fully exploit structured scientific data.
To overcome these challenges, we propose DrugMCTS, a novel framework that
synergistically integrates RAG, multi-agent collaboration, and Monte Carlo Tree
Search for drug repurposing. The framework employs five specialized agents
tasked with retrieving and analyzing molecular and protein information, thereby
enabling structured and iterative reasoning. Without requiring domain-specific
fine-tuning, DrugMCTS empowers Qwen2.5-7B-Instruct to outperform Deepseek-R1 by
over 20\%. Extensive experiments on the DrugBank and KIBA datasets demonstrate
that DrugMCTS achieves substantially higher recall and robustness compared to
both general-purpose LLMs and deep learning baselines. Our results highlight
the importance of structured reasoning, agent-based collaboration, and
feedback-driven search mechanisms in advancing LLM applications for drug
discovery.

</details>


### [11] [StarDojo: Benchmarking Open-Ended Behaviors of Agentic Multimodal LLMs in Production-Living Simulations with Stardew Valley](https://arxiv.org/abs/2507.07445)
*Weihao Tan,Changjiu Jiang,Yu Duan,Mingcong Lei,Jiageng Li,Yitian Hong,Xinrun Wang,Bo An*

Main category: cs.AI

TL;DR: StarDojo是一个基于《星露谷物语》的新基准测试，用于评估AI代理在开放式生产生活模拟中的表现，涵盖农业、手工艺、探索、战斗和社交互动五大领域。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试很少同时评估生产活动与社交互动能力，StarDojo旨在填补这一空白。

Method: StarDojo包含1000个任务，分为五大领域，并提供100个代表性任务子集。其统一界面支持多操作系统和并行执行，适合评估多模态大语言模型（MLLMs）代理。

Result: 评估显示，当前最先进的MLLMs代理（如GPT-4.1）成功率仅为12.7%，主要因视觉理解、多模态推理和低级操作能力不足。

Conclusion: StarDojo为复杂生产生活环境中开放式代理的研究提供了用户友好的平台，推动更鲁棒代理的发展。

Abstract: Autonomous agents navigating human society must master both production
activities and social interactions, yet existing benchmarks rarely evaluate
these skills simultaneously. To bridge this gap, we introduce StarDojo, a novel
benchmark based on Stardew Valley, designed to assess AI agents in open-ended
production-living simulations. In StarDojo, agents are tasked to perform
essential livelihood activities such as farming and crafting, while
simultaneously engaging in social interactions to establish relationships
within a vibrant community. StarDojo features 1,000 meticulously curated tasks
across five key domains: farming, crafting, exploration, combat, and social
interactions. Additionally, we provide a compact subset of 100 representative
tasks for efficient model evaluation. The benchmark offers a unified,
user-friendly interface that eliminates the need for keyboard and mouse
control, supports all major operating systems, and enables the parallel
execution of multiple environment instances, making it particularly well-suited
for evaluating the most capable foundation agents, powered by multimodal large
language models (MLLMs). Extensive evaluations of state-of-the-art MLLMs agents
demonstrate substantial limitations, with the best-performing model, GPT-4.1,
achieving only a 12.7% success rate, primarily due to challenges in visual
understanding, multimodal reasoning and low-level manipulation. As a
user-friendly environment and benchmark, StarDojo aims to facilitate further
research towards robust, open-ended agents in complex production-living
environments.

</details>


### [12] [Position: We Need An Algorithmic Understanding of Generative AI](https://arxiv.org/abs/2507.07544)
*Oliver Eberle,Thomas McGee,Hamza Giaffar,Taylor Webb,Ida Momennejad*

Main category: cs.AI

TL;DR: 论文提出AlgEval框架，旨在系统研究LLM学习与使用的算法，填补理论空白，并通过案例研究验证假设。


<details>
  <summary>Details</summary>
Motivation: 当前研究多关注通过规模提升性能，缺乏对LLM学习算法的理论理解，AlgEval试图填补这一空白。

Method: 提出AlgEval框架，结合自上而下的假设与自下而上的电路级分析，研究LLM的算法组成。

Result: 案例研究表明AlgEval能揭示LLM的算法行为，为理解模型推理提供新视角。

Conclusion: AlgEval为LLM的算法解释提供系统方法，有望推动更高效的训练与架构设计。

Abstract: What algorithms do LLMs actually learn and use to solve problems? Studies
addressing this question are sparse, as research priorities are focused on
improving performance through scale, leaving a theoretical and empirical gap in
understanding emergent algorithms. This position paper proposes AlgEval: a
framework for systematic research into the algorithms that LLMs learn and use.
AlgEval aims to uncover algorithmic primitives, reflected in latent
representations, attention, and inference-time compute, and their algorithmic
composition to solve task-specific problems. We highlight potential
methodological paths and a case study toward this goal, focusing on emergent
search algorithms. Our case study illustrates both the formation of top-down
hypotheses about candidate algorithms, and bottom-up tests of these hypotheses
via circuit-level analysis of attention patterns and hidden states. The
rigorous, systematic evaluation of how LLMs actually solve tasks provides an
alternative to resource-intensive scaling, reorienting the field toward a
principled understanding of underlying computations. Such algorithmic
explanations offer a pathway to human-understandable interpretability, enabling
comprehension of the model's internal reasoning performance measures. This can
in turn lead to more sample-efficient methods for training and improving
performance, as well as novel architectures for end-to-end and multi-agent
systems.

</details>


### [13] [On Trustworthy Rule-Based Models and Explanations](https://arxiv.org/abs/2507.07576)
*Mohamed Siala,Jordi Planes,Joao Marques-Silva*

Main category: cs.AI

TL;DR: 论文探讨了机器学习中解释预测的重要性，特别是在高风险领域，分析了基于规则的模型中的负面问题，并提出了相关算法。


<details>
  <summary>Details</summary>
Motivation: 高风险领域中，错误的解释会误导决策者，因此需要严格的解释方法。尽管可解释性难以定义，基于规则的模型仍被广泛使用。

Method: 开发了算法来分析基于规则模型中的负面问题，如负重叠和冗余。

Result: 研究发现，广泛使用的基于规则模型学习工具会导致规则集出现负面问题。

Conclusion: 基于规则的模型在高风险应用中存在潜在问题，需进一步优化工具以减少负面影响。

Abstract: A task of interest in machine learning (ML) is that of ascribing explanations
to the predictions made by ML models. Furthermore, in domains deemed high risk,
the rigor of explanations is paramount. Indeed, incorrect explanations can and
will mislead human decision makers. As a result, and even if interpretability
is acknowledged as an elusive concept, so-called interpretable models are
employed ubiquitously in high-risk uses of ML and data mining (DM). This is the
case for rule-based ML models, which encompass decision trees, diagrams, sets
and lists. This paper relates explanations with well-known undesired facets of
rule-based ML models, which include negative overlap and several forms of
redundancy. The paper develops algorithms for the analysis of these undesired
facets of rule-based systems, and concludes that well-known and widely used
tools for learning rule-based ML models will induce rule sets that exhibit one
or more negative facets.

</details>


### [14] [Context Pooling: Query-specific Graph Pooling for Generic Inductive Link Prediction in Knowledge Graphs](https://arxiv.org/abs/2507.07595)
*Zhixiang Su,Di Wang,Chunyan Miao*

Main category: cs.AI

TL;DR: 论文提出了一种名为Context Pooling的新方法，用于提升基于GNN的知识图谱链接预测模型性能，首次在KG中应用图池化，并在42/48的测试中达到SOTA表现。


<details>
  <summary>Details</summary>
Motivation: 现有GNN模型在知识图谱链接预测中，普通聚合方法对性能提升有限，因此需要更有效的方法。

Method: 提出Context Pooling方法，通过设计邻居精度和邻居召回率两个指标，筛选逻辑相关的邻居用于链接预测。

Result: 在三个公开数据集上应用于两个SOTA模型，42/48的测试中达到SOTA性能。

Conclusion: Context Pooling是一种通用且高效的方法，显著提升了GNN在知识图谱链接预测中的表现。

Abstract: Recent investigations on the effectiveness of Graph Neural Network
(GNN)-based models for link prediction in Knowledge Graphs (KGs) show that
vanilla aggregation does not significantly impact the model performance. In
this paper, we introduce a novel method, named Context Pooling, to enhance
GNN-based models' efficacy for link predictions in KGs. To our best of
knowledge, Context Pooling is the first methodology that applies graph pooling
in KGs. Additionally, Context Pooling is first-of-its-kind to enable the
generation of query-specific graphs for inductive settings, where testing
entities are unseen during training. Specifically, we devise two metrics,
namely neighborhood precision and neighborhood recall, to assess the neighbors'
logical relevance regarding the given queries, thereby enabling the subsequent
comprehensive identification of only the logically relevant neighbors for link
prediction. Our method is generic and assessed by being applied to two
state-of-the-art (SOTA) models on three public transductive and inductive
datasets, achieving SOTA performance in 42 out of 48 settings.

</details>


### [15] [Enhancing Vaccine Safety Surveillance: Extracting Vaccine Mentions from Emergency Department Triage Notes Using Fine-Tuned Large Language Models](https://arxiv.org/abs/2507.07599)
*Sedigh Khademi,Jim Black,Christopher Palmer,Muhammad Javed,Hazel Clothier,Jim Buttery,Gerardo Luis Dimaguila*

Main category: cs.AI

TL;DR: 研究评估了微调的Llama 3.2模型从急诊分诊笔记中提取疫苗相关信息的能力，支持近实时疫苗安全监测。


<details>
  <summary>Details</summary>
Motivation: 支持高效的疫苗安全监测和早期发现免疫后不良事件。

Method: 使用提示工程创建标注数据集，比较提示工程模型、微调模型和基于规则的方法。

Result: 微调的Llama 3B参数模型在提取疫苗名称准确性上优于其他模型，量化技术实现高效部署。

Conclusion: 大语言模型在自动化数据提取中潜力显著，支持疫苗安全监测。

Abstract: This study evaluates fine-tuned Llama 3.2 models for extracting
vaccine-related information from emergency department triage notes to support
near real-time vaccine safety surveillance. Prompt engineering was used to
initially create a labeled dataset, which was then confirmed by human
annotators. The performance of prompt-engineered models, fine-tuned models, and
a rule-based approach was compared. The fine-tuned Llama 3 billion parameter
model outperformed other models in its accuracy of extracting vaccine names.
Model quantization enabled efficient deployment in resource-constrained
environments. Findings demonstrate the potential of large language models in
automating data extraction from emergency department notes, supporting
efficient vaccine safety surveillance and early detection of emerging adverse
events following immunization issues.

</details>


### [16] [Towards conservative inference in credal networks using belief functions: the case of credal chains](https://arxiv.org/abs/2507.07619)
*Marco Sangalli,Thomas Krak,Cassio de Campos*

Main category: cs.AI

TL;DR: 本文提出了一种基于Dempster-Shafer理论的新框架，用于在信用网络（特别是链式结构）中传播不确定性，并通过置信和似然函数高效生成保守区间。


<details>
  <summary>Details</summary>
Motivation: 探索如何在信用网络中利用Dempster-Shafer理论进行信念推断，以结合计算速度和鲁棒的不确定性表示。

Method: 提出了一种新颖的框架，用于在链式信用网络中传播不确定性，并利用置信和似然函数生成保守区间。

Result: 数值结果表明了该框架的优势和局限性，为链式及一般信用网络的实际应用提供了见解。

Conclusion: 该框架在信用网络中具有实用价值，尤其是在链式结构中，但需进一步研究其扩展性和适用性。

Abstract: This paper explores belief inference in credal networks using Dempster-Shafer
theory. By building on previous work, we propose a novel framework for
propagating uncertainty through a subclass of credal networks, namely chains.
The proposed approach efficiently yields conservative intervals through belief
and plausibility functions, combining computational speed with robust
uncertainty representation. Key contributions include formalizing belief-based
inference methods and comparing belief-based inference against classical
sensitivity analysis. Numerical results highlight the advantages and
limitations of applying belief inference within this framework, providing
insights into its practical utility for chains and for credal networks in
general.

</details>


### [17] [PlanQA: A Benchmark for Spatial Reasoning in LLMs using Structured Representations](https://arxiv.org/abs/2507.07644)
*Fedor Rodionov,Abdelrahman Eldesokey,Michael Birsak,John Femiani,Bernard Ghanem,Peter Wonka*

Main category: cs.AI

TL;DR: PlanQA是一个用于评估大型语言模型（LLMs）几何和空间推理能力的诊断基准，基于结构化室内场景表示，揭示了LLMs在真实世界布局推理中的盲点。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在几何和空间推理方面存在不足，尤其是模拟物理约束、保持空间一致性和布局扰动下的泛化能力。PlanQA旨在填补这一空白，推动相关研究。

Method: PlanQA基于符号化格式（如JSON、XML）的室内场景结构化表示，设计多样化问题类型，测试度量、拓扑推理及设计约束。

Result: 测试显示，LLMs在浅层查询中表现良好，但在模拟物理约束、空间一致性和布局扰动泛化方面表现不佳。

Conclusion: PlanQA揭示了LLMs在真实世界布局推理中的盲点，为未来研究提供了方向。

Abstract: We introduce PlanQA, a diagnostic benchmark for evaluating geometric and
spatial reasoning in large-language models (LLMs). PlanQA is grounded in
structured representations of indoor scenes, such as kitchens, living rooms,
and bedrooms, encoded in a symbolic format (e.g., JSON, XML layouts). The
benchmark includes diverse question types that test not only metric and
topological reasoning (e.g., distance, visibility, shortest paths) but also
interior design constraints such as affordance, clearance, balance, and
usability. Our results across a variety of frontier open-source and commercial
LLMs show that while models may succeed in shallow queries, they often fail to
simulate physical constraints, preserve spatial coherence, or generalize under
layout perturbation. PlanQA uncovers a clear blind spot in today's LLMs: they
do not consistently reason about real-world layouts. We hope that this
benchmark inspires new work on language models that can accurately infer and
manipulate spatial and geometric properties in practical settings.

</details>


### [18] [Stable Preference Optimization for LLMs: A Bilevel Approach Beyond Direct Preference Optimization](https://arxiv.org/abs/2507.07723)
*Chengtao Jian,Kai Yang,Ye Ouyang,Xiaozhou Ye*

Main category: cs.AI

TL;DR: 本文分析了直接偏好优化（DPO）的理论局限性，并提出了一种双层优化框架——稳定偏好优化（Stable Preference Optimization），以改进DPO的稳定性和对齐效果。


<details>
  <summary>Details</summary>
Motivation: DPO虽然在实际应用中表现良好，但其理论性质和内在局限性尚未充分研究。本文旨在揭示DPO的敏感性和概率分配问题，并提出改进方法。

Method: 通过概率演化视角分析DPO的动态特性，提出一种双层优化框架，结合监督微调和增强的DPO目标，引入正则化机制以稳定优化过程。

Result: 实验表明，该方法在推理和摘要任务中表现优于标准DPO，提高了推理准确性并更好地对齐输出分布。

Conclusion: 稳定偏好优化为偏好对齐目标的设计提供了新思路，有助于实现更可靠和可解释的语言模型对齐。

Abstract: Direct Preference Optimization (DPO) has emerged as a popular and efficient
alternative to reward modeling and reinforcement learning for aligning language
models with human preferences. Despite its empirical success, the theoretical
properties and intrinsic limitations of DPO remain underexplored. In this work,
we first present a comprehensive analysis of DPO's dynamics from a probability
evolution perspective. Our analysis reveals that DPO is highly sensitive to
initialization. It also tends to misallocate probability mass, which can
inadvertently shift probability toward irrelevant or undesired responses. This
misallocation may unintentionally reinforce model bias, thereby compromising
both the stability of model alignment and the consistency with intended
preferences. Motivated by these theoretical findings, we propose a
theoretically grounded bilevel optimization framework that tightly integrate
supervised fine-tuning with an enhanced DPO objective a.k.a. stable preference
optimization. Our approach introduces a principled regularization scheme to
explicitly encourage absolute probability improvement for preferred outputs,
while maintaining stable optimization dynamics. Experiments on challenging
reasoning and summarization benchmarks elucidate that our method consistently
improves reasoning accuracy and better aligns output distributions with
intended preferences, outperforming standard DPO. Stable preference
optimization provides new insights into the design of preference-based
alignment objectives and opens up new avenues towards more reliable and
interpretable language model alignment.

</details>


### [19] [Identification of Violin Reduction via Contour Lines Classification](https://arxiv.org/abs/2507.07743)
*Philémon Beghin,Anne-Emmanuelle Ceulemans,François Glineur*

Main category: cs.AI

TL;DR: 本文提出了一种基于轮廓线分类小提琴是否经过尺寸缩减的方法，通过几何特征分析，发现区分缩减与非缩减乐器具有一定可行性。


<details>
  <summary>Details</summary>
Motivation: 研究小提琴制作中尺寸缩减对轮廓线的影响，填补专家观察与定量研究之间的空白。

Method: 使用摄影测量获取25把小提琴的3D几何网格，提取轮廓线并拟合抛物线曲线，计算参数特征，应用分类方法。

Result: 发现几何特征可以一定程度上预测尺寸缩减，其中参数beta最具预测性。

Conclusion: 尺寸缩减对小提琴轮廓线有可量化的影响，但存在一定难度，尤其是对部分变形的乐器。

Abstract: The first violins appeared in late 16th-century Italy. Over the next 200
years, they spread across Europe and luthiers of various royal courts, eager to
experiment with new techniques, created a highly diverse family of instruments.
Around 1750, size standards were introduced to unify violin making for
orchestras and conservatories. Instruments that fell between two standards were
then reduced to a smaller size by luthiers. These reductions have an impact on
several characteristics of violins, in particular on the contour lines, i.e.
lines of constant altitude, which look more like a U for non reduced
instruments and a V for reduced ones. While such differences are observed by
experts, they have not been studied quantitatively.
  This paper presents a method for classifying violins as reduced or
non-reduced based on their contour lines. We study a corpus of 25 instruments
whose 3D geometric meshes were acquired via photogrammetry. For each
instrument, we extract 10-20 contour lines regularly spaced every millimetre.
Each line is fitted with a parabola-like curve (with an equation of the type y
= alpha*abs(x)**beta) depending on two parameters, describing how open (beta)
and how vertically stretched (alpha) the curve is. We compute additional
features from those parameters, using regressions and counting how many values
fall under some threshold. We also deal with outliers and non equal numbers of
levels, and eventually obtain a numerical profile for each instrument.
  We then apply classification methods to assess whether geometry alone can
predict size reduction. We find that distinguishing between reduced and non
reduced instruments is feasible to some degree, taking into account that a
whole spectrum of more or less transformed violins exists, for which it is more
difficult to quantify the reduction. We also find the opening parameter beta to
be the most predictive.

</details>


### [20] [Measuring AI Alignment with Human Flourishing](https://arxiv.org/abs/2507.07787)
*Elizabeth Hilliard,Akshaya Jagadeesh,Alex Cook,Steele Billings,Nicholas Skytland,Alicia Llewellyn,Jackson Paull,Nathan Paull,Nolan Kurylo,Keatra Nesbitt,Robert Gruenewald,Anthony Jantzi,Omar Chavez*

Main category: cs.AI

TL;DR: FAI Benchmark评估AI对人类繁荣的贡献，涵盖七个维度，发现现有模型在多个维度上表现不足。


<details>
  <summary>Details</summary>
Motivation: 传统AI评估仅关注技术能力或危害预防，而FAI Benchmark旨在衡量AI对人类全面繁荣的贡献。

Method: 通过1,229个主客观问题，结合专家LLM和几何平均评分，评估AI在七个维度的表现。

Result: 测试28个领先语言模型，最高得分72/100，但无模型在所有维度上表现良好，尤其在信仰与灵性、品格与美德、意义与目的方面。

Conclusion: FAI Benchmark为开发支持人类繁荣的AI系统提供了框架，对AI发展、伦理和评估有重要意义。

Abstract: This paper introduces the Flourishing AI Benchmark (FAI Benchmark), a novel
evaluation framework that assesses AI alignment with human flourishing across
seven dimensions: Character and Virtue, Close Social Relationships, Happiness
and Life Satisfaction, Meaning and Purpose, Mental and Physical Health,
Financial and Material Stability, and Faith and Spirituality. Unlike
traditional benchmarks that focus on technical capabilities or harm prevention,
the FAI Benchmark measures AI performance on how effectively models contribute
to the flourishing of a person across these dimensions. The benchmark evaluates
how effectively LLM AI systems align with current research models of holistic
human well-being through a comprehensive methodology that incorporates 1,229
objective and subjective questions. Using specialized judge Large Language
Models (LLMs) and cross-dimensional evaluation, the FAI Benchmark employs
geometric mean scoring to ensure balanced performance across all flourishing
dimensions. Initial testing of 28 leading language models reveals that while
some models approach holistic alignment (with the highest-scoring models
achieving 72/100), none are acceptably aligned across all dimensions,
particularly in Faith and Spirituality, Character and Virtue, and Meaning and
Purpose. This research establishes a framework for developing AI systems that
actively support human flourishing rather than merely avoiding harm, offering
significant implications for AI development, ethics, and evaluation.

</details>


### [21] [MoSE: Skill-by-Skill Mixture-of-Expert Learning for Autonomous Driving](https://arxiv.org/abs/2507.07818)
*Lu Xu,Jiaqian Yu,Xiongfeng Peng,Yiwei Chen,Weiming Li,Jaewook Yoo,Sunghyun Chunag,Dongwook Lee,Daehyun Ji,Chao Zhang*

Main category: cs.AI

TL;DR: 论文提出了一种技能导向的混合专家模型MoSE，模仿人类驾驶员的学习和推理过程，通过技能分步学习，显著提升了自动驾驶系统的性能，同时减少了计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有的混合专家模型（MoE）需要大量训练数据和复杂优化，而MoSE通过模仿人类驾驶员的学习过程，提出技能导向的路由机制，以更高效的方式实现性能提升。

Method: MoSE通过定义和标注特定技能，构建分层技能数据集，并预训练路由器，实现技能分步学习和推理。模型在单次前向过程中整合辅助任务，无需额外计算成本。

Result: MoSE在CODA AD极端案例推理任务中表现优于多个8B+参数模型，激活参数量少于3B，性能达到SOTA，且激活模型规模减少了至少62.5%。

Conclusion: MoSE通过技能导向的学习和推理机制，显著提升了自动驾驶系统的效率和性能，为未来研究提供了新的方向。

Abstract: Recent studies show large language models (LLMs) and vision language models
(VLMs) trained using web-scale data can empower end-to-end autonomous driving
systems for a better generalization and interpretation. Specifically, by
dynamically routing inputs to specialized subsets of parameters, the
Mixture-of-Experts (MoE) technique enables general LLMs or VLMs to achieve
substantial performance improvements while maintaining computational
efficiency. However, general MoE models usually demands extensive training data
and complex optimization. In this work, inspired by the learning process of
human drivers, we propose a skill-oriented MoE, called MoSE, which mimics human
drivers' learning process and reasoning process, skill-by-skill and
step-by-step. We propose a skill-oriented routing mechanism that begins with
defining and annotating specific skills, enabling experts to identify the
necessary driving competencies for various scenarios and reasoning tasks,
thereby facilitating skill-by-skill learning. Further align the driving process
to multi-step planning in human reasoning and end-to-end driving models, we
build a hierarchical skill dataset and pretrain the router to encourage the
model to think step-by-step. Unlike multi-round dialogs, MoSE integrates
valuable auxiliary tasks (e.g.\ description, reasoning, planning) in one single
forward process without introducing any extra computational cost. With less
than 3B sparsely activated parameters, our model outperforms several 8B+
parameters on CODA AD corner case reasoning task. Compared to existing methods
based on open-source models and data, our approach achieves state-of-the-art
performance with significantly reduced activated model size (at least by
$62.5\%$) with a single-turn conversation.

</details>


### [22] [AI Should Sense Better, Not Just Scale Bigger: Adaptive Sensing as a Paradigm Shift](https://arxiv.org/abs/2507.07820)
*Eunsu Baek,Keondo Park,Jeonggil Ko,Min-hwan Oh,Taesik Gong,Hyung-Sin Kim*

Main category: cs.AI

TL;DR: 论文提出自适应感知作为AI领域的基础性转变，通过动态调整传感器参数提高效率，减少环境和经济成本，并展示了小模型超越大模型的潜力。


<details>
  <summary>Details</summary>
Motivation: 当前AI依赖大规模模型和数据集，导致环境、经济和伦理成本高昂，限制了可持续性和公平性。受生物感官系统启发，提出自适应感知作为解决方案。

Method: 通过动态调整传感器参数（如曝光、灵敏度、多模态配置）来主动缓解协变量偏移，提高效率。

Result: 实证研究表明，自适应感知使小模型（如EfficientNet-B0）超越更大模型（如OpenCLIP-H）。

Conclusion: 论文提出将自适应感知整合到实际应用中，并探讨了技术和伦理挑战，旨在推动AI向可持续、鲁棒和公平的方向发展。

Abstract: Current AI advances largely rely on scaling neural models and expanding
training datasets to achieve generalization and robustness. Despite notable
successes, this paradigm incurs significant environmental, economic, and
ethical costs, limiting sustainability and equitable access. Inspired by
biological sensory systems, where adaptation occurs dynamically at the input
(e.g., adjusting pupil size, refocusing vision)--we advocate for adaptive
sensing as a necessary and foundational shift. Adaptive sensing proactively
modulates sensor parameters (e.g., exposure, sensitivity, multimodal
configurations) at the input level, significantly mitigating covariate shifts
and improving efficiency. Empirical evidence from recent studies demonstrates
that adaptive sensing enables small models (e.g., EfficientNet-B0) to surpass
substantially larger models (e.g., OpenCLIP-H) trained with significantly more
data and compute. We (i) outline a roadmap for broadly integrating adaptive
sensing into real-world applications spanning humanoid, healthcare, autonomous
systems, agriculture, and environmental monitoring, (ii) critically assess
technical and ethical integration challenges, and (iii) propose targeted
research directions, such as standardized benchmarks, real-time adaptive
algorithms, multimodal integration, and privacy-preserving methods.
Collectively, these efforts aim to transition the AI community toward
sustainable, robust, and equitable artificial intelligence systems.

</details>


### [23] [Searching for actual causes: Approximate algorithms with adjustable precision](https://arxiv.org/abs/2507.07857)
*Samuel Reyd,Ada Diaconescu,Jean-Louis Dessalles*

Main category: cs.AI

TL;DR: 论文提出了一种多项式复杂度的算法，用于识别实际原因，解决了现有方法无法处理的非布尔、黑盒和随机系统问题。


<details>
  <summary>Details</summary>
Motivation: 现有可解释人工智能（XAI）和因果性研究未能满足非专家用户对实际原因的需求，且识别实际原因是NP完全问题，缺乏实用解决方案。

Method: 提出一组多项式复杂度的算法，可调整精度和完备性，适用于非布尔、黑盒和随机系统。

Result: 实验表明，算法能识别现有方法无法处理的系统类别的原因，且可通过增加计算时间提高精度和完备性。

Conclusion: 该算法为解决实际原因识别问题提供了实用且灵活的解决方案。

Abstract: Causality has gained popularity in recent years. It has helped improve the
performance, reliability, and interpretability of machine learning models.
However, recent literature on explainable artificial intelligence (XAI) has
faced criticism. The classical XAI and causality literature focuses on
understanding which factors contribute to which consequences. While such
knowledge is valuable for researchers and engineers, it is not what non-expert
users expect as explanations. Instead, these users often await facts that cause
the target consequences, i.e., actual causes. Formalizing this notion is still
an open problem. Additionally, identifying actual causes is reportedly an
NP-complete problem, and there are too few practical solutions to approximate
formal definitions. We propose a set of algorithms to identify actual causes
with a polynomial complexity and an adjustable level of precision and
exhaustiveness. Our experiments indicate that the algorithms (1) identify
causes for different categories of systems that are not handled by existing
approaches (i.e., non-boolean, black-box, and stochastic systems), (2) can be
adjusted to gain more precision and exhaustiveness with more computation time.

</details>


### [24] [An Integrated Framework of Prompt Engineering and Multidimensional Knowledge Graphs for Legal Dispute Analysis](https://arxiv.org/abs/2507.07893)
*Mingda Zhang,Na Zhao,Jianglong Qing,Qing xu,Kaiwen Pan,Ting luo*

Main category: cs.AI

TL;DR: 论文提出了一种结合提示工程和多维知识图谱的增强框架，以解决大语言模型在法律纠纷分析中的局限性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在法律纠纷分析中存在法律知识表示不足、概念理解有限和推理缺陷等问题，需要改进。

Method: 采用三阶段分层提示结构（任务定义、知识背景、推理指导）和三层次知识图谱架构（法律分类本体、表示层、实例层），结合四种法律概念检索方法。

Result: 实验结果显示，该框架显著提升了法律纠纷分析的性能，能准确分析复杂案件的法律适用。

Conclusion: 该研究为智能法律辅助系统的实现提供了新的技术途径。

Abstract: The rapid development of artificial intelligence has positioned large
language models as fundamental components of intelligent legal systems.
However, these models face significant limitations in legal dispute analysis,
including insufficient legal knowledge representation, limited concept
understanding, and reasoning deficiencies. This research proposes an enhanced
framework integrating prompt engineering with multidimensional knowledge
graphs. The framework introduces a three-stage hierarchical prompt structure
comprising task definition, knowledge background, and reasoning guidance,
supplemented by legal-specific reasoning templates and dynamic optimization
mechanisms. A three-layer knowledge graph architecture is constructed with
legal classification ontology, representation, and instance layers. Four
complementary methods enable precise legal concept retrieval: direct legal norm
code matching, domain-specific semantic vector similarity, ontology-based path
reasoning, and specialized lexical segmentation. These components integrate
with web search technology to establish a knowledge-enhanced framework for
legal decision-making. Experimental results demonstrate significant performance
improvements in legal dispute analysis, enabling accurate legal application
analysis for complex cases while exhibiting nuanced understanding of judicial
decision-making logic, providing a novel technical approach for implementing
intelligent legal assistance systems.

</details>


### [25] [Meek Models Shall Inherit the Earth](https://arxiv.org/abs/2507.07931)
*Hans Gundlach,Jayson Lynch,Neil Thompson*

Main category: cs.AI

TL;DR: 论文认为，随着计算资源投入的边际效益递减，AI模型性能将趋于收敛，小型模型（计算资源有限）将逐渐接近顶级模型的性能。


<details>
  <summary>Details</summary>
Motivation: 探讨AI模型性能不平等现象，并分析计算资源投入的边际效益递减对模型性能收敛的影响。

Method: 通过模型分析和实证数据，研究计算资源投入与模型性能的关系，并验证训练损失差异等指标的重要性。

Result: 计算资源的边际效益递减将导致模型性能收敛，小型模型性能接近顶级模型。

Conclusion: AI战略和政策需重新审视，以适应小型模型性能提升的趋势。

Abstract: The past decade has seen incredible scaling of AI systems by a few companies,
leading to inequality in AI model performance. This paper argues that, contrary
to prevailing intuition, the diminishing returns to compute scaling will lead
to a convergence of AI model capabilities. In other words, meek models (those
with limited computation budget) shall inherit the earth, approaching the
performance level of the best models overall. We develop a model illustrating
that under a fixed-distribution next-token objective, the marginal capability
returns to raw compute shrink substantially. Given current scaling practices,
we argue that these diminishing returns are strong enough that even companies
that can scale their models exponentially faster than other organizations will
eventually have little advantage in capabilities. As part of our argument, we
give several reasons that proxies like training loss differences capture
important capability measures using evidence from benchmark data and
theoretical performance models. In addition, we analyze empirical data on the
capability difference of AI models over time. Finally, in light of the
increasing ability of meek models, we argue that AI strategy and policy require
reexamination, and we outline the areas this shift will affect.

</details>


### [26] [Working with AI: Measuring the Occupational Implications of Generative AI](https://arxiv.org/abs/2507.07935)
*Kiran Tomlinson,Sonia Jaffe,Will Wang,Scott Counts,Siddharth Suri*

Main category: cs.AI

TL;DR: 论文分析了生成式AI对经济的影响，通过研究用户与AI的互动数据，发现AI主要应用于信息收集、写作等活动，并计算了各职业的AI适用性得分。


<details>
  <summary>Details</summary>
Motivation: 理解生成式AI对经济的广泛影响是社会的关键问题。

Method: 分析了20万条用户与Microsoft Bing Copilot的匿名对话数据，结合职业活动分类和任务成功度量。

Result: AI适用性得分最高的职业包括计算机、数学、行政支持和销售等知识型工作。

Conclusion: 研究揭示了AI在职业活动中的实际应用情况及其与工资、教育的关系。

Abstract: Given the rapid adoption of generative AI and its potential to impact a wide
range of tasks, understanding the effects of AI on the economy is one of
society's most important questions. In this work, we take a step toward that
goal by analyzing the work activities people do with AI, how successfully and
broadly those activities are done, and combine that with data on what
occupations do those activities. We analyze a dataset of 200k anonymized and
privacy-scrubbed conversations between users and Microsoft Bing Copilot, a
publicly available generative AI system. We find the most common work
activities people seek AI assistance for involve gathering information and
writing, while the most common activities that AI itself is performing are
providing information and assistance, writing, teaching, and advising.
Combining these activity classifications with measurements of task success and
scope of impact, we compute an AI applicability score for each occupation. We
find the highest AI applicability scores for knowledge work occupation groups
such as computer and mathematical, and office and administrative support, as
well as occupations such as sales whose work activities involve providing and
communicating information. Additionally, we characterize the types of work
activities performed most successfully, how wage and education correlate with
AI applicability, and how real-world usage compares to predictions of
occupational AI impact.

</details>
