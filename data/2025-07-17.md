<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 13]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [A Study on the Application of Artificial Intelligence in Ecological Design](https://arxiv.org/abs/2507.11595)
*Hengyue Zhao*

Main category: cs.AI

TL;DR: 探讨AI是否能促进人类与自然的共生关系，并通过案例研究展示AI在生态设计中的应用。


<details>
  <summary>Details</summary>
Motivation: 研究人类与自然关系从支配转向共生的可能性，以及AI在此过程中的作用。

Method: 通过案例研究分析AI在数据、图像识别和生态修复中的应用，并提出结合强化学习与植物修复的设计路径。

Result: AI不仅扩展了创意方法，还重构了生态设计的理论与实践，展示了其在科学、艺术和环保中的潜力。

Conclusion: AI为可持续技术生态系统提供了研究方向，未来可进一步探索其在生态设计中的应用。

Abstract: This paper asks whether our relationship with nature can move from human
dominance to genuine interdependence, and whether artificial intelligence (AI)
can mediate that shift. We examine a new ecological-design paradigm in which AI
interacts with non-human life forms. Through case studies we show how artists
and designers apply AI for data analysis, image recognition, and ecological
restoration, producing results that differ from conventional media. We argue
that AI not only expands creative methods but also reframes the theory and
practice of ecological design. Building on the author's prototype for
AI-assisted water remediation, the study proposes design pathways that couple
reinforcement learning with plant-based phytoremediation. The findings
highlight AI's potential to link scientific insight, artistic practice, and
environmental stewardship, offering a roadmap for future research on
sustainable, technology-enabled ecosystems.

</details>


### [2] [General Modular Harness for LLM Agents in Multi-Turn Gaming Environments](https://arxiv.org/abs/2507.11633)
*Yuxuan Zhang,Haoyang Yu,Lanxiang Hu,Haojian Jin,Hao Zhang*

Main category: cs.AI

TL;DR: 提出了一种模块化设计的LLM代理框架，包含感知、记忆和推理组件，适用于多轮游戏环境，无需领域特定工程。


<details>
  <summary>Details</summary>
Motivation: 通过模块化设计提升通用代理在多轮游戏环境中的性能，利用游戏作为多样化测试平台。

Method: 采用经典和现代游戏套件作为测试平台，分析各模块在动态交互环境中的影响。

Result: 实验表明该框架显著提升游戏性能，并揭示不同模块的贡献模式（如记忆在长时谜题中占主导，感知在视觉噪声环境中关键）。

Conclusion: 模块化设计有效推进通用代理的发展，游戏作为测试平台的熟悉性和普遍性进一步验证了其价值。

Abstract: We introduce a modular harness design for LLM agents that composes of
perception, memory, and reasoning components, enabling a single LLM or VLM
backbone to tackle a wide spectrum of multi turn gaming environments without
domain-specific engineering. Using classic and modern game suites as
low-barrier, high-diversity testbeds, our framework provides a unified workflow
for analyzing how each module affects performance across dynamic interactive
settings. Extensive experiments demonstrate that the harness lifts gameplay
performance consistently over un-harnessed baselines and reveals distinct
contribution patterns, for example, memory dominates in long-horizon puzzles
while perception is critical in vision noisy arcades. These findings highlight
the effectiveness of our modular harness design in advancing general-purpose
agent, given the familiarity and ubiquity of games in everyday human
experience.

</details>


### [3] [Let's Think in Two Steps: Mitigating Agreement Bias in MLLMs with Self-Grounded Verification](https://arxiv.org/abs/2507.11662)
*Moises Andrade,Joonhyuk Cha,Brandon Ho,Vriksha Srihari,Karmesh Yadav,Zsolt Kira*

Main category: cs.AI

TL;DR: 多模态大语言模型（MLLMs）作为验证器在复杂任务中表现有限，存在一致性偏差问题。提出的自接地验证（SGV）方法显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 在缺乏明确成功标准的领域（如计算机使用）扩展AI验证器的应用是一个挑战，MLLMs因其知识和推理能力被视为潜在解决方案。

Method: 提出自接地验证（SGV），通过无条件与条件生成结合，利用MLLMs的采样机制，分两步检索任务先验并评估候选轨迹。

Result: SGV使MLLM验证器在准确性和故障检测率上提升高达20点，并在多个任务中实现实时监督，性能超越之前最佳48%。

Conclusion: SGV有效解决了MLLMs作为验证器时的一致性偏差问题，显著提升了其在复杂任务中的表现。

Abstract: Verifiers -- functions assigning rewards to agent behavior -- have been key
for AI progress in domains like math and board games. However, extending these
gains to domains without clear-cut success criteria (e.g.,computer use) remains
a challenge: while humans can recognize suitable outcomes, translating this
intuition into scalable rules is non-trivial. Multimodal Large Language
Models(MLLMs) emerge as a promising solution, given their world knowledge,
human-preference alignment, and reasoning skills. We evaluate MLLMs as
verifiers of agent trajectories across web navigation, computer use, and
robotic manipulation, and identify a critical limitation: agreement bias, a
strong tendency for MLLMs to favor information in their context window, often
generating chains of thought to rationalize flawed behavior. This bias is
pervasive across models, resilient to test-time scaling, and can impact several
methods using MLLMs as evaluators (e.g.,data filtering). Notably, it occurs
despite MLLMs showing strong, human-aligned priors on desired behavior. To
address this, we propose Self-Grounded Verification (SGV), a lightweight method
that enables more effective use of MLLMs' knowledge and reasoning by harnessing
their own sampling mechanisms via unconditional and conditional generation. SGV
operates in two steps: first, the MLLM is elicited to retrieve broad priors
about task completion, independent of the data under evaluation. Then,
conditioned on self-generated priors, it reasons over and evaluates a candidate
trajectory. Enhanced with SGV, MLLM verifiers show gains of up to 20 points in
accuracy and failure detection rates, and can perform real-time supervision of
heterogeneous agents, boosting task completion of a GUI specialist in OSWorld,
a diffusion policy in robomimic, and a ReAct agent in VisualWebArena -- setting
a new state of the art on the benchmark, surpassing the previous best by 48%.

</details>


### [4] [ClarifAI: Enhancing AI Interpretability and Transparency through Case-Based Reasoning and Ontology-Driven Approach for Improved Decision-Making](https://arxiv.org/abs/2507.11733)
*Srikanth Vemula*

Main category: cs.AI

TL;DR: ClarifAI是一种结合案例推理（CBR）和本体驱动方法的新型AI透明性与可解释性增强工具，旨在满足不同利益相关者对AI决策解释的需求。


<details>
  <summary>Details</summary>
Motivation: 提升AI系统的透明性和可解释性，以满足高利害环境中的决策需求。

Method: 结合案例推理（CBR）和本体驱动方法，设计ClarifAI的理论基础和架构。

Result: ClarifAI能够增强AI的可解释性，适用于多领域和高风险环境。

Conclusion: ClarifAI为AI系统的可解释性提供了重要支持，有望在关键决策中发挥作用。

Abstract: This Study introduces Clarity and Reasoning Interface for Artificial
Intelligence(ClarifAI), a novel approach designed to augment the transparency
and interpretability of artificial intelligence (AI) in the realm of improved
decision making. Leveraging the Case-Based Reasoning (CBR) methodology and
integrating an ontology-driven approach, ClarifAI aims to meet the intricate
explanatory demands of various stakeholders involved in AI-powered
applications. The paper elaborates on ClarifAI's theoretical foundations,
combining CBR and ontologies to furnish exhaustive explanation mechanisms. It
further elaborates on the design principles and architectural blueprint,
highlighting ClarifAI's potential to enhance AI interpretability across
different sectors and its applicability in high-stake environments. This
research delineates the significant role of ClariAI in advancing the
interpretability of AI systems, paving the way for its deployment in critical
decision-making processes.

</details>


### [5] [Auto-Formulating Dynamic Programming Problems with Large Language Models](https://arxiv.org/abs/2507.11737)
*Chenyu Zhou,Jingyuan Yang,Linwei Xin,Yitian Chen,Ziyan He,Dongdong Ge*

Main category: cs.AI

TL;DR: 论文介绍了DP-Bench基准和DPLM模型，用于自动化动态规划问题建模，通过DualReflect数据生成方法在低数据和高数据场景下优化性能。


<details>
  <summary>Details</summary>
Motivation: 动态规划建模传统上依赖专家知识，LLMs有潜力自动化这一过程，但面临数据稀缺和随机性挑战。

Method: 提出DPLM模型和DualReflect数据生成方法，结合前向和后向生成以提升数据多样性和可靠性。

Result: DPLM在性能上媲美顶尖LLMs，并在难题上超越它们，DualReflect方法在低数据和高数据场景下均表现优异。

Conclusion: 前向和后向生成方法互补，结合使用能有效提升动态规划问题的自动化建模能力。

Abstract: Dynamic programming (DP) is a fundamental method in operations research, but
formulating DP models has traditionally required expert knowledge of both the
problem context and DP techniques. Large Language Models (LLMs) offer the
potential to automate this process. However, DP problems pose unique challenges
due to their inherently stochastic transitions and the limited availability of
training data. These factors make it difficult to directly apply existing
LLM-based models or frameworks developed for other optimization problems, such
as linear or integer programming. We introduce DP-Bench, the first benchmark
covering a wide range of textbook-level DP problems to enable systematic
evaluation. We present Dynamic Programming Language Model (DPLM), a
7B-parameter specialized model that achieves performance comparable to
state-of-the-art LLMs like OpenAI's o1 and DeepSeek-R1, and surpasses them on
hard problems. Central to DPLM's effectiveness is DualReflect, our novel
synthetic data generation pipeline, designed to scale up training data from a
limited set of initial examples. DualReflect combines forward generation for
diversity and backward generation for reliability. Our results reveal a key
insight: backward generation is favored in low-data regimes for its strong
correctness guarantees, while forward generation, though lacking such
guarantees, becomes increasingly valuable at scale for introducing diverse
formulations. This trade-off highlights the complementary strengths of both
approaches and the importance of combining them.

</details>


### [6] [Survey of Swarm Intelligence Approaches to Search Documents Based On Semantic Similarity](https://arxiv.org/abs/2507.11787)
*Chandrashekar Muniyappa,Eunjin Kim*

Main category: cs.AI

TL;DR: 本文综述了基于群体智能算法的语义相似性文档搜索的最新进展，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 群体智能（SI）因其在解决现实问题中的有效性而受到广泛关注，尤其是在计算机优化问题中的应用。本文旨在总结其在语义相似性文档搜索领域的最新发展。

Method: 通过观察动物和昆虫的自然行为，将其转化为计算机算法（群体计算），并应用于文档搜索问题。

Result: 综述了群体智能在语义相似性文档搜索中的应用，展示了其有效性和潜力。

Conclusion: 群体智能在语义相似性文档搜索中表现出色，未来研究应进一步探索其优化和应用扩展。

Abstract: Swarm Intelligence (SI) is gaining a lot of popularity in artificial
intelligence, where the natural behavior of animals and insects is observed and
translated into computer algorithms called swarm computing to solve real-world
problems. Due to their effectiveness, they are applied in solving various
computer optimization problems. This survey will review all the latest
developments in Searching for documents based on semantic similarity using
Swarm Intelligence algorithms and recommend future research directions.

</details>


### [7] [A Parallel CPU-GPU Framework for Cost-Bounded DFS with Applications to IDA* and BTS](https://arxiv.org/abs/2507.11916)
*Ehsan Futuhi,Nathan R. Sturtevant*

Main category: cs.AI

TL;DR: 提出了一种在深度优先搜索（DFS）中批量处理GPU计算的方法，结合CPU和GPU的并行能力，扩展了IDA*和BTS算法，并在实验中验证了其高效性。


<details>
  <summary>Details</summary>
Motivation: 利用GPU的强大并行处理能力改进经典搜索算法，填补了GPU在搜索算法中应用的研究空白。

Method: 提出了一种成本受限的深度优先搜索（CB-DFS）方法，结合CPU和GPU的并行性，扩展了Batch IDA*和Batch BTS算法。

Result: 在3x3魔方和4x4滑块拼图（STP）上验证了方法的有效性，并分析了超参数、启发式神经网络大小和硬件资源对性能的影响。

Conclusion: 该方法成功地将GPU并行计算引入DFS，保持了最优性保证，并在实验中展示了高效性。

Abstract: The rapid advancement of GPU technology has unlocked powerful parallel
processing capabilities, creating new opportunities to enhance classic search
algorithms. A recent successful application of GPUs is in compressing large
pattern database (PDB) heuristics using neural networks while preserving
heuristic admissibility. However, very few algorithms have been designed to
exploit GPUs during search. Several variants of A* exist that batch GPU
computations. In this paper we introduce a method for batching GPU computations
in depth first search. In particular, we describe a new cost-bounded
depth-first search (CB-DFS) method that leverages the combined parallelism of
modern CPUs and GPUs. This is used to create algorithms like \emph{Batch IDA*},
an extension of the Iterative Deepening A* (IDA*) algorithm, or Batch BTS, an
extensions of Budgeted Tree Search. Our approach builds on the general approach
used by Asynchronous Parallel IDA* (AIDA*), while maintaining optimality
guarantees. We evaluate the approach on the 3x3 Rubik's Cube and 4x4 sliding
tile puzzle (STP), showing that GPU operations can be efficiently batched in
DFS. Additionally, we conduct extensive experiments to analyze the effects of
hyperparameters, neural network heuristic size, and hardware resources on
performance.

</details>


### [8] [Aime: Towards Fully-Autonomous Multi-Agent Framework](https://arxiv.org/abs/2507.11988)
*Yexuan Shi,Mingyu Wang,Yunxiang Cao,Hongjie Lai,Junjian Lan,Xin Han,Yu Wang,Jie Geng,Zhenan Li,Zihao Xia,Xiang Chen,Chen Li,Jian Xu,Wenbo Duan,Yuanshuo Zhu*

Main category: cs.AI

TL;DR: Aime是一个新型多智能体框架，通过动态反应式规划和执行解决传统框架的局限性，显著提升了适应性和任务成功率。


<details>
  <summary>Details</summary>
Motivation: 传统多智能体系统的规划和执行框架存在刚性执行、静态能力和低效通信等问题，限制了其在动态环境中的适应性和鲁棒性。

Method: Aime采用动态规划器、动态执行器工厂和集中式进度管理模块，实现实时策略调整、按需组装智能体和全局状态感知。

Result: 在多个基准测试中，Aime表现优于领域内最先进的专用智能体，展示了更高的适应性和任务成功率。

Conclusion: Aime为多智能体协作提供了更灵活、高效的框架，适用于复杂动态环境。

Abstract: Multi-Agent Systems (MAS) powered by Large Language Models (LLMs) are
emerging as a powerful paradigm for solving complex, multifaceted problems.
However, the potential of these systems is often constrained by the prevalent
plan-and-execute framework, which suffers from critical limitations: rigid plan
execution, static agent capabilities, and inefficient communication. These
weaknesses hinder their adaptability and robustness in dynamic environments.
This paper introduces Aime, a novel multi-agent framework designed to overcome
these challenges through dynamic, reactive planning and execution. Aime
replaces the conventional static workflow with a fluid and adaptive
architecture. Its core innovations include: (1) a Dynamic Planner that
continuously refines the overall strategy based on real-time execution
feedback; (2) an Actor Factory that implements Dynamic Actor instantiation,
assembling specialized agents on-demand with tailored tools and knowledge; and
(3) a centralized Progress Management Module that serves as a single source of
truth for coherent, system-wide state awareness. We empirically evaluated Aime
on a diverse suite of benchmarks spanning general reasoning (GAIA), software
engineering (SWE-bench Verified), and live web navigation (WebVoyager). The
results demonstrate that Aime consistently outperforms even highly specialized
state-of-the-art agents in their respective domains. Its superior adaptability
and task success rate establish Aime as a more resilient and effective
foundation for multi-agent collaboration.

</details>


### [9] [Understanding visual attention beehind bee-inspired UAV navigation](https://arxiv.org/abs/2507.11992)
*Pranav Rajbhandari,Abhi Veda,Matthew Garratt,Mandayam Srinivasan,Sridhar Ravi*

Main category: cs.AI

TL;DR: 论文通过强化学习训练无人机仅使用光流输入导航，发现其注意力集中在光流不连续区域和大光流区域，行为类似昆虫飞行。


<details>
  <summary>Details</summary>
Motivation: 生物系统（如蜜蜂）利用有限感官和计算能力实现飞行和避障，启发无人机导航研究。

Method: 训练强化学习代理仅用光流输入在障碍隧道中导航，分析其注意力模式。

Result: 代理主要关注光流不连续和大光流区域，行为类似昆虫飞行，且独立训练代理表现一致。

Conclusion: 该策略可用于开发简单明确的无人机控制法则。

Abstract: Bio-inspired design is often used in autonomous UAV navigation due to the
capacity of biological systems for flight and obstacle avoidance despite
limited sensory and computational capabilities. In particular, honeybees mainly
use the sensory input of optic flow, the apparent motion of objects in their
visual field, to navigate cluttered environments. In our work, we train a
Reinforcement Learning agent to navigate a tunnel with obstacles using only
optic flow as sensory input. We inspect the attention patterns of trained
agents to determine the regions of optic flow on which they primarily base
their motor decisions. We find that agents trained in this way pay most
attention to regions of discontinuity in optic flow, as well as regions with
large optic flow magnitude. The trained agents appear to navigate a cluttered
tunnel by avoiding the obstacles that produce large optic flow, while
maintaining a centered position in their environment, which resembles the
behavior seen in flying insects. This pattern persists across independently
trained agents, which suggests that this could be a good strategy for
developing a simple explicit control law for physical UAVs.

</details>


### [10] [Topology Enhanced MARL for Multi-Vehicle Cooperative Decision-Making of CAVs](https://arxiv.org/abs/2507.12110)
*Ye Han,Lijun Zhang,Dejian Meng,Zhuang Zhang*

Main category: cs.AI

TL;DR: 论文提出了一种基于拓扑增强的多智能体强化学习方法（TPE-MARL），用于优化混合交通中联网自动驾驶车辆（CAVs）的协同决策，通过压缩高维状态空间和改进探索-利用平衡，显著提升了交通效率和安全性。


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习（MARL）在联合状态-动作空间指数增长的情况下，探索-利用的权衡问题尤为突出，尤其是在混合交通中CAVs的协同决策优化中。

Method: 1. 构建动态交通流的博弈拓扑张量，压缩高维交通状态信息；2. 基于拓扑张量和QMIX算法，设计包含访问计数和智能体互信息的拓扑增强MARL框架。

Result: 在不同交通密度和CAV渗透率下的仿真表明，TPE-MARL在交通效率、安全性、决策平滑性和任务完成度上表现优越，且决策合理性接近或超过人类驾驶员。

Conclusion: TPE-MARL通过拓扑增强和探索-利用平衡优化，有效解决了MARL在混合交通中的挑战，为CAVs的协同决策提供了高效解决方案。

Abstract: The exploration-exploitation trade-off constitutes one of the fundamental
challenges in reinforcement learning (RL), which is exacerbated in multi-agent
reinforcement learning (MARL) due to the exponential growth of joint
state-action spaces. This paper proposes a topology-enhanced MARL (TPE-MARL)
method for optimizing cooperative decision-making of connected and autonomous
vehicles (CAVs) in mixed traffic. This work presents two primary contributions:
First, we construct a game topology tensor for dynamic traffic flow,
effectively compressing high-dimensional traffic state information and decrease
the search space for MARL algorithms. Second, building upon the designed game
topology tensor and using QMIX as the backbone RL algorithm, we establish a
topology-enhanced MARL framework incorporating visit counts and agent mutual
information. Extensive simulations across varying traffic densities and CAV
penetration rates demonstrate the effectiveness of TPE-MARL. Evaluations
encompassing training dynamics, exploration patterns, macroscopic traffic
performance metrics, and microscopic vehicle behaviors reveal that TPE-MARL
successfully balances exploration and exploitation. Consequently, it exhibits
superior performance in terms of traffic efficiency, safety, decision
smoothness, and task completion. Furthermore, the algorithm demonstrates
decision-making rationality comparable to or exceeding that of human drivers in
both mixed-autonomy and fully autonomous traffic scenarios. Code of our work is
available at
\href{https://github.com/leoPub/tpemarl}{https://github.com/leoPub/tpemarl}.

</details>


### [11] [Partially Observable Reference Policy Programming: Solving POMDPs Sans Numerical Optimisation](https://arxiv.org/abs/2507.12186)
*Edward Kim,Hanna Kurniawati*

Main category: cs.AI

TL;DR: 提出了一种新的在线近似POMDP求解器，通过深度采样未来历史并逐步更新策略，性能损失由采样误差的平均值而非最大值决定。


<details>
  <summary>Details</summary>
Motivation: 解决在线规划中采样稀疏性带来的性能损失问题，适用于动态变化的大规模环境。

Method: 提出Partially Observable Reference Policy Programming，通过深度采样未来历史并强制逐步策略更新。

Result: 理论保证性能损失由采样误差平均值决定，实验表明在直升机紧急场景等大规模问题中优于现有在线基准。

Conclusion: 该求解器在动态环境中表现优异，理论支持其性能优势。

Abstract: This paper proposes Partially Observable Reference Policy Programming, a
novel anytime online approximate POMDP solver which samples meaningful future
histories very deeply while simultaneously forcing a gradual policy update. We
provide theoretical guarantees for the algorithm's underlying scheme which say
that the performance loss is bounded by the average of the sampling
approximation errors rather than the usual maximum, a crucial requirement given
the sampling sparsity of online planning. Empirical evaluations on two
large-scale problems with dynamically evolving environments -- including a
helicopter emergency scenario in the Corsica region requiring approximately 150
planning steps -- corroborate the theoretical results and indicate that our
solver considerably outperforms current online benchmarks.

</details>


### [12] [BuildEvo: Designing Building Energy Consumption Forecasting Heuristics via LLM-driven Evolution](https://arxiv.org/abs/2507.12207)
*Subin Lin,Chuanbo Hua*

Main category: cs.AI

TL;DR: BuildEvo框架利用大型语言模型（LLMs）自动设计高效且可解释的建筑能耗预测启发式方法，结合物理原理和数据，实现卓越性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统启发式方法精度不足，而高级模型缺乏透明性和泛化能力，因此需要一种结合物理原理和自动化的新方法。

Method: 通过进化过程引导LLMs构建和优化启发式方法，结合建筑特性和操作数据的物理洞察。

Result: BuildEvo在基准测试中表现优异，具有更好的泛化能力和透明性。

Conclusion: 该工作推动了自动化设计稳健、基于物理的启发式方法的发展，为复杂能源系统提供了可信赖的模型。

Abstract: Accurate building energy forecasting is essential, yet traditional heuristics
often lack precision, while advanced models can be opaque and struggle with
generalization by neglecting physical principles. This paper introduces
BuildEvo, a novel framework that uses Large Language Models (LLMs) to
automatically design effective and interpretable energy prediction heuristics.
Within an evolutionary process, BuildEvo guides LLMs to construct and enhance
heuristics by systematically incorporating physical insights from building
characteristics and operational data (e.g., from the Building Data Genome
Project 2). Evaluations show BuildEvo achieves state-of-the-art performance on
benchmarks, offering improved generalization and transparent prediction logic.
This work advances the automated design of robust, physically grounded
heuristics, promoting trustworthy models for complex energy systems.

</details>


### [13] [Xiangqi-R1: Enhancing Spatial Strategic Reasoning in LLMs for Chinese Chess via Reinforcement Learning](https://arxiv.org/abs/2507.12215)
*Yuhao Chen,Shuochen Liu,Yuanjie Lyu,Chao Zhang,Jiayao Shi,Tong Xu*

Main category: cs.AI

TL;DR: 论文探讨了大型语言模型（LLMs）在空间战略推理（如中国象棋）中的不足，并提出了一种针对中国象棋的训练框架Xiangqi-R1，显著提升了模型表现。


<details>
  <summary>Details</summary>
Motivation: 中国象棋因其复杂规则和空间特性成为评估LLMs战略推理能力的理想测试平台，填补了LLMs在此领域的空白。

Method: 采用多阶段训练：1) 微调合法移动预测；2) 加入战略注释；3) 通过GRPO强化学习优化推理稳定性。

Result: Xiangqi-R1相比通用LLMs，移动合法性和分析准确性分别提升18%和22%。

Conclusion: 研究为在空间复杂领域开发通用战略智能提供了可行路径。

Abstract: Game playing has long served as a fundamental benchmark for evaluating
Artificial General Intelligence (AGI). While Large Language Models (LLMs) have
demonstrated impressive capabilities in general reasoning, their effectiveness
in spatial strategic reasoning, which is critical for complex and fully
observable board games, remains insufficiently explored. In this work, we adopt
Chinese Chess (Xiangqi) as a challenging and rich testbed due to its intricate
rules and spatial complexity. To advance LLMs' strategic competence in such
environments, we propose a training framework tailored to Xiangqi, built upon a
large-scale dataset of five million board-move pairs enhanced with expert
annotations and engine evaluations. Building on this foundation, we introduce
Xiangqi-R1, a 7B-parameter model trained in multi-stage manner: (1) fine-tuning
for legal move prediction to capture basic spatial rules, (2) incorporating
strategic annotations to improve decision-making, and (3) applying
reinforcement learning via Group Relative Policy Optimization (GRPO) with
multi-dimensional reward signals to enhance reasoning stability. Our
Experimental results indicate that, despite their size and power,
general-purpose LLMs struggle to achieve satisfactory performance in these
tasks. Compared to general-purpose LLMs, Xiangqi-R1 greatly advances with an
18% rise in move legality and a 22% boost in analysis accuracy. Our results
point to a promising path for creating general strategic intelligence in
spatially complex areas.

</details>
