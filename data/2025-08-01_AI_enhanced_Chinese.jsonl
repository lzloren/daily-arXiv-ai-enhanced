{"id": "2507.22951", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.22951", "abs": "https://arxiv.org/abs/2507.22951", "authors": ["Alessandro Lonardi", "Samy Badreddine", "Tarek R. Besold", "Pablo Sanchez Martin"], "title": "Unifying Post-hoc Explanations of Knowledge Graph Completions", "comment": null, "summary": "Post-hoc explainability for Knowledge Graph Completion (KGC) lacks\nformalization and consistent evaluations, hindering reproducibility and\ncross-study comparisons. This paper argues for a unified approach to post-hoc\nexplainability in KGC. First, we propose a general framework to characterize\npost-hoc explanations via multi-objective optimization, balancing their\neffectiveness and conciseness. This unifies existing post-hoc explainability\nalgorithms in KGC and the explanations they produce. Next, we suggest and\nempirically support improved evaluation protocols using popular metrics like\nMean Reciprocal Rank and Hits@$k$. Finally, we stress the importance of\ninterpretability as the ability of explanations to address queries meaningful\nto end-users. By unifying methods and refining evaluation standards, this work\naims to make research in KGC explainability more reproducible and impactful.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\uff08KGC\uff09\u4e8b\u540e\u89e3\u91ca\u6027\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u76ee\u6807\u4f18\u5316\u5e73\u8861\u89e3\u91ca\u7684\u6709\u6548\u6027\u548c\u7b80\u6d01\u6027\uff0c\u5e76\u6539\u8fdb\u4e86\u8bc4\u4f30\u534f\u8bae\u3002", "motivation": "\u5f53\u524dKGC\u7684\u4e8b\u540e\u89e3\u91ca\u6027\u7f3a\u4e4f\u5f62\u5f0f\u5316\u548c\u4e00\u81f4\u7684\u8bc4\u4ef7\u6807\u51c6\uff0c\u5f71\u54cd\u4e86\u7814\u7a76\u7684\u53ef\u91cd\u590d\u6027\u548c\u8de8\u7814\u7a76\u6bd4\u8f83\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u901a\u7528\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u76ee\u6807\u4f18\u5316\u7edf\u4e00\u73b0\u6709\u7684\u4e8b\u540e\u89e3\u91ca\u6027\u7b97\u6cd5\uff0c\u5e76\u6539\u8fdb\u8bc4\u4f30\u534f\u8bae\uff08\u5982\u4f7f\u7528Mean Reciprocal Rank\u548cHits@k\uff09\u3002", "result": "\u6846\u67b6\u7edf\u4e00\u4e86\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u6539\u8fdb\u7684\u8bc4\u4f30\u6807\u51c6\u63d0\u5347\u4e86\u7814\u7a76\u7684\u53ef\u91cd\u590d\u6027\u548c\u5f71\u54cd\u529b\u3002", "conclusion": "\u901a\u8fc7\u7edf\u4e00\u65b9\u6cd5\u548c\u4f18\u5316\u8bc4\u4f30\u6807\u51c6\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63d0\u5347KGC\u89e3\u91ca\u6027\u7814\u7a76\u7684\u53ef\u91cd\u590d\u6027\u548c\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2507.23018", "categories": ["cs.AI", "cs.CE", "cs.DC", "cs.LG", "I.2.6"], "pdf": "https://arxiv.org/pdf/2507.23018", "abs": "https://arxiv.org/abs/2507.23018", "authors": ["Wesley Brewer", "Patrick Widener", "Valentine Anantharaj", "Feiyi Wang", "Tom Beck", "Arjun Shankar", "Sarp Oral"], "title": "Data Readiness for Scientific AI at Scale", "comment": "10 pages, 1 figure, 2 tables", "summary": "This paper examines how Data Readiness for AI (DRAI) principles apply to\nleadership-scale scientific datasets used to train foundation models. We\nanalyze archetypal workflows across four representative domains - climate,\nnuclear fusion, bio/health, and materials - to identify common preprocessing\npatterns and domain-specific constraints. We introduce a two-dimensional\nreadiness framework composed of Data Readiness Levels (raw to AI-ready) and\nData Processing Stages (ingest to shard), both tailored to high performance\ncomputing (HPC) environments. This framework outlines key challenges in\ntransforming scientific data for scalable AI training, emphasizing\ntransformer-based generative models. Together, these dimensions form a\nconceptual maturity matrix that characterizes scientific data readiness and\nguides infrastructure development toward standardized, cross-domain support for\nscalable and reproducible AI for science.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u6570\u636e\u51c6\u5907\uff08DRAI\uff09\u539f\u5219\u5728\u9886\u5bfc\u7ea7\u79d1\u5b66\u6570\u636e\u96c6\u4e2d\u7684\u5e94\u7528\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e8c\u7ef4\u51c6\u5907\u6846\u67b6\uff0c\u7528\u4e8e\u6307\u5bfcAI\u8bad\u7ec3\u7684\u6570\u636e\u8f6c\u6362\u548c\u57fa\u7840\u8bbe\u65bd\u5f00\u53d1\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u89e3\u51b3\u79d1\u5b66\u6570\u636e\u5728AI\u8bad\u7ec3\u4e2d\u7684\u9884\u5904\u7406\u6311\u6218\uff0c\u7279\u522b\u662f\u9488\u5bf9\u9ad8\u6027\u80fd\u8ba1\u7b97\u73af\u5883\u4e2d\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u5206\u6790\u56db\u4e2a\u5178\u578b\u9886\u57df\u7684\u5de5\u4f5c\u6d41\u7a0b\uff0c\u5e76\u63d0\u51fa\u4e00\u4e2a\u7531\u6570\u636e\u51c6\u5907\u7ea7\u522b\u548c\u5904\u7406\u9636\u6bb5\u7ec4\u6210\u7684\u4e8c\u7ef4\u6846\u67b6\u3002", "result": "\u7ed3\u679c\u662f\u4e00\u4e2a\u6982\u5ff5\u6027\u7684\u6210\u719f\u5ea6\u77e9\u9635\uff0c\u7528\u4e8e\u8bc4\u4f30\u79d1\u5b66\u6570\u636e\u7684\u51c6\u5907\u72b6\u6001\uff0c\u5e76\u652f\u6301\u8de8\u9886\u57df\u7684\u6807\u51c6\u5316AI\u8bad\u7ec3\u3002", "conclusion": "\u7ed3\u8bba\u5f3a\u8c03\u4e86\u8be5\u6846\u67b6\u5bf9\u53ef\u6269\u5c55\u548c\u53ef\u590d\u73b0\u7684\u79d1\u5b66AI\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2507.23067", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23067", "abs": "https://arxiv.org/abs/2507.23067", "authors": ["Zhenyu Pan", "Yutong Zhang", "Jianshu Zhang", "Haoran Lu", "Haozheng Luo", "Yuwei Han", "Philip S. Yu", "Manling Li", "Han Liu"], "title": "FairReason: Balancing Reasoning and Social Bias in MLLMs", "comment": null, "summary": "Multimodal Large Language Models (MLLMs) already achieve state-of-the-art\nresults across a wide range of tasks and modalities. To push their reasoning\nability further, recent studies explore advanced prompting schemes and\npost-training fine-tuning. Although these techniques improve logical accuracy,\nthey frequently leave the models' outputs burdened with pronounced social\nbiases. Clarifying how reasoning gains interact with bias mitigation-and\nwhether the two objectives inherently trade off-therefore remains an open and\npressing research problem. Our study begins by benchmarking three\nbias-mitigation strategies-supervised fine-uning (SFT), knowledge distillation\n(KD), and rule-based reinforcement learning (RL)-under identical conditions,\nestablishing their baseline strengths and weaknesses. Building on these\nresults, we vary the proportion of debias-focused and reasoning-centric samples\nwithin each paradigm to chart the reasoning-versus-bias trade-off. Our sweeps\nreveal a consistent sweet spot: a roughly 1:4 mix trained with reinforcement\nlearning cuts stereotype scores by 10% while retaining 88% of the model's\noriginal reasoning accuracy, offering concrete guidance for balancing fairness\nand capability in MLLMs.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u76841:4\u6df7\u5408\u6837\u672c\u6bd4\u4f8b\u53ef\u4ee5\u5728\u51cf\u5c1110%\u504f\u89c1\u7684\u540c\u65f6\u4fdd\u755988%\u7684\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u63a2\u7d22\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u5728\u63a8\u7406\u80fd\u529b\u63d0\u5347\u4e0e\u504f\u89c1\u7f13\u89e3\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\u3002", "method": "\u6bd4\u8f83\u4e09\u79cd\u504f\u89c1\u7f13\u89e3\u7b56\u7565\uff08SFT\u3001KD\u3001RL\uff09\uff0c\u5e76\u901a\u8fc7\u8c03\u6574\u6837\u672c\u6bd4\u4f8b\u5206\u6790\u63a8\u7406\u4e0e\u504f\u89c1\u7684\u6743\u8861\u3002", "result": "1:4\u7684\u6df7\u5408\u6837\u672c\u6bd4\u4f8b\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u80fd\u51cf\u5c1110%\u504f\u89c1\u5e76\u4fdd\u755988%\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u4e0b\u7684\u7279\u5b9a\u6837\u672c\u6bd4\u4f8b\u53ef\u6709\u6548\u5e73\u8861MLLMs\u7684\u516c\u5e73\u6027\u4e0e\u80fd\u529b\u3002"}}
{"id": "2507.23091", "categories": ["cs.AI", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2507.23091", "abs": "https://arxiv.org/abs/2507.23091", "authors": ["David Noever", "Forrest McKee"], "title": "Moravec's Paradox: Towards an Auditory Turing Test", "comment": null, "summary": "This research work demonstrates that current AI systems fail catastrophically\non auditory tasks that humans perform effortlessly. Drawing inspiration from\nMoravec's paradox (i.e., tasks simple for humans often prove difficult for\nmachines, and vice versa), we introduce an auditory Turing test comprising 917\nchallenges across seven categories: overlapping speech, speech in noise,\ntemporal distortion, spatial audio, coffee-shop noise, phone distortion, and\nperceptual illusions. Our evaluation of state-of-the-art audio models including\nGPT-4's audio capabilities and OpenAI's Whisper reveals a striking failure rate\nexceeding 93%, with even the best-performing model achieving only 6.9% accuracy\non tasks that humans solved at 7.5 times higher success (52%). These results\nexpose focusing failures in how AI systems process complex auditory scenes,\nparticularly in selective attention, noise robustness, and contextual\nadaptation. Our benchmark not only quantifies the human-machine auditory gap\nbut also provides insights into why these failures occur, suggesting that\ncurrent architectures lack fundamental mechanisms for human-like auditory scene\nanalysis. The traditional design of audio CAPTCHAs highlights common filters\nthat humans evolved but machines fail to select in multimodal language models.\nThis work establishes a diagnostic framework for measuring progress toward\nhuman-level machine listening and highlights the need for novel approaches\nintegrating selective attention, physics-based audio understanding, and\ncontext-aware perception into multimodal AI systems.", "AI": {"tldr": "\u5f53\u524dAI\u7cfb\u7edf\u5728\u4eba\u7c7b\u8f7b\u677e\u5b8c\u6210\u7684\u542c\u89c9\u4efb\u52a1\u4e0a\u8868\u73b0\u6781\u5dee\uff0c\u5931\u8d25\u7387\u8d85\u8fc793%\u3002\u7814\u7a76\u901a\u8fc7\u542c\u89c9\u56fe\u7075\u6d4b\u8bd5\u63ed\u793a\u4e86AI\u5728\u9009\u62e9\u6027\u6ce8\u610f\u529b\u3001\u566a\u58f0\u9c81\u68d2\u6027\u548c\u4e0a\u4e0b\u6587\u9002\u5e94\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "motivation": "\u53d7Moravec\u6096\u8bba\u542f\u53d1\uff0c\u7814\u7a76\u65e8\u5728\u91cf\u5316AI\u4e0e\u4eba\u7c7b\u5728\u542c\u89c9\u4efb\u52a1\u4e0a\u7684\u5dee\u8ddd\uff0c\u5e76\u63ed\u793a\u5931\u8d25\u539f\u56e0\u3002", "method": "\u5f15\u5165\u5305\u542b917\u4e2a\u6311\u6218\u7684\u542c\u89c9\u56fe\u7075\u6d4b\u8bd5\uff0c\u8bc4\u4f30GPT-4\u548cWhisper\u7b49\u5148\u8fdb\u97f3\u9891\u6a21\u578b\u3002", "result": "AI\u6a21\u578b\u5e73\u5747\u51c6\u786e\u7387\u4ec56.9%\uff0c\u8fdc\u4f4e\u4e8e\u4eba\u7c7b\u768452%\uff0c\u66b4\u9732\u4e86\u5176\u5728\u590d\u6742\u542c\u89c9\u573a\u666f\u4e2d\u7684\u7f3a\u9677\u3002", "conclusion": "\u7814\u7a76\u4e3a\u8861\u91cfAI\u542c\u89c9\u8fdb\u6b65\u63d0\u4f9b\u4e86\u8bca\u65ad\u6846\u67b6\uff0c\u5e76\u6307\u51fa\u9700\u6574\u5408\u9009\u62e9\u6027\u6ce8\u610f\u529b\u3001\u7269\u7406\u97f3\u9891\u7406\u89e3\u548c\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2507.22910", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22910", "abs": "https://arxiv.org/abs/2507.22910", "authors": ["Sergio Di Meglio", "Aniello Somma", "Luigi Libero Lucio Starace", "Fabio Scippacercola", "Giancarlo Sperl\u00ec", "Sergio Di Martino"], "title": "Large Language Models in the Travel Domain: An Industrial Experience", "comment": "Manuscript accepted to the International Conference on Software\n  Engineering and Knowledge Engineering (SEKE) 2025", "summary": "Online property booking platforms are widely used and rely heavily on\nconsistent, up-to-date information about accommodation facilities, often\nsourced from third-party providers. However, these external data sources are\nfrequently affected by incomplete or inconsistent details, which can frustrate\nusers and result in a loss of market. In response to these challenges, we\npresent an industrial case study involving the integration of Large Language\nModels (LLMs) into CALEIDOHOTELS, a property reservation platform developed by\nFERVENTO. We evaluate two well-known LLMs in this context: Mistral 7B,\nfine-tuned with QLoRA, and Mixtral 8x7B, utilized with a refined system prompt.\nBoth models were assessed based on their ability to generate consistent and\nhomogeneous descriptions while minimizing hallucinations. Mixtral 8x7B\noutperformed Mistral 7B in terms of completeness (99.6% vs. 93%), precision\n(98.8% vs. 96%), and hallucination rate (1.2% vs. 4%), producing shorter yet\nmore concise content (249 vs. 277 words on average). However, this came at a\nsignificantly higher computational cost: 50GB VRAM and $1.61/hour versus 5GB\nand $0.16/hour for Mistral 7B. Our findings provide practical insights into the\ntrade-offs between model quality and resource efficiency, offering guidance for\ndeploying LLMs in production environments and demonstrating their effectiveness\nin enhancing the consistency and reliability of accommodation data.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5728\u5728\u7ebf\u623f\u4ea7\u9884\u8ba2\u5e73\u53f0\u4e2d\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u63d0\u5347\u6570\u636e\u4e00\u81f4\u6027\u7684\u6548\u679c\uff0c\u6bd4\u8f83\u4e86Mistral 7B\u548cMixtral 8x7B\u7684\u6027\u80fd\u4e0e\u8d44\u6e90\u6d88\u8017\u3002", "motivation": "\u89e3\u51b3\u7b2c\u4e09\u65b9\u6570\u636e\u6e90\u7684\u4e0d\u5b8c\u6574\u548c\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u63d0\u5347\u7528\u6237\u4f53\u9a8c\u548c\u5e73\u53f0\u5e02\u573a\u7ade\u4e89\u529b\u3002", "method": "\u5728CALEIDOHOTELS\u5e73\u53f0\u4e0a\u96c6\u6210\u5e76\u8bc4\u4f30Mistral 7B\uff08QLoRA\u5fae\u8c03\uff09\u548cMixtral 8x7B\uff08\u4f18\u5316\u7cfb\u7edf\u63d0\u793a\uff09\u7684\u6027\u80fd\u3002", "result": "Mixtral 8x7B\u5728\u5b8c\u6574\u6027\uff0899.6%\uff09\u3001\u7cbe\u786e\u5ea6\uff0898.8%\uff09\u548c\u5e7b\u89c9\u7387\uff081.2%\uff09\u4e0a\u4f18\u4e8eMistral 7B\uff0c\u4f46\u8ba1\u7b97\u6210\u672c\u66f4\u9ad8\uff0850GB VRAM\u548c$1.61/\u5c0f\u65f6\uff09\u3002", "conclusion": "\u7814\u7a76\u4e3a\u751f\u4ea7\u73af\u5883\u4e2d\u90e8\u7f72LLMs\u63d0\u4f9b\u4e86\u8d28\u91cf\u4e0e\u8d44\u6e90\u6548\u7387\u7684\u6743\u8861\u6307\u5bfc\uff0c\u8bc1\u660e\u4e86LLMs\u5728\u63d0\u5347\u6570\u636e\u4e00\u81f4\u6027\u65b9\u9762\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2507.23163", "categories": ["cs.AI", "I.2.7"], "pdf": "https://arxiv.org/pdf/2507.23163", "abs": "https://arxiv.org/abs/2507.23163", "authors": ["Deniz Gorur", "Antonio Rago", "Francesca Toni"], "title": "Argumentatively Coherent Judgmental Forecasting", "comment": "17 pages, 18 figures, ECAI 2025", "summary": "Judgmental forecasting employs human opinions to make predictions about\nfuture events, rather than exclusively historical data as in quantitative\nforecasting. When these opinions form an argumentative structure around\nforecasts, it is useful to study the properties of the forecasts from an\nargumentative perspective. In this paper, we advocate and formally define a\nproperty of argumentative coherence, which, in essence, requires that a\nforecaster's reasoning is coherent with their forecast. We then conduct three\nevaluations with our notion of coherence. First, we assess the impact of\nenforcing coherence on human forecasters as well as on Large Language Model\n(LLM)-based forecasters, given that they have recently shown to be competitive\nwith human forecasters. In both cases, we show that filtering out incoherent\npredictions improves forecasting accuracy consistently, supporting the\npractical value of coherence in both human and LLM-based forecasting. Then, via\ncrowd-sourced user experiments, we show that, despite its apparent\nintuitiveness and usefulness, users do not generally align with this coherence\nproperty. This points to the need to integrate, within argumentation-based\njudgmental forecasting, mechanisms to filter out incoherent opinions before\nobtaining group forecasting predictions.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5224\u65ad\u6027\u9884\u6d4b\u4e2d\u7684\u8bba\u8bc1\u8fde\u8d2f\u6027\uff0c\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86\u8fde\u8d2f\u6027\u5bf9\u9884\u6d4b\u51c6\u786e\u6027\u7684\u79ef\u6781\u5f71\u54cd\uff0c\u5e76\u6307\u51fa\u7528\u6237\u5bf9\u6b64\u5c5e\u6027\u7684\u8ba4\u77e5\u4e0d\u8db3\u3002", "motivation": "\u7814\u7a76\u5224\u65ad\u6027\u9884\u6d4b\u4e2d\u8bba\u8bc1\u8fde\u8d2f\u6027\u7684\u4f5c\u7528\uff0c\u4ee5\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u3002", "method": "\u5b9a\u4e49\u8bba\u8bc1\u8fde\u8d2f\u6027\uff0c\u5e76\u901a\u8fc7\u4eba\u7c7b\u548cLLM\u9884\u6d4b\u8005\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6548\u679c\uff0c\u540c\u65f6\u8fdb\u884c\u7528\u6237\u5b9e\u9a8c\u3002", "result": "\u8fc7\u6ee4\u4e0d\u8fde\u8d2f\u9884\u6d4b\u663e\u8457\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\uff0c\u4f46\u7528\u6237\u666e\u904d\u672a\u610f\u8bc6\u5230\u8fde\u8d2f\u6027\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u9700\u8981\u5728\u57fa\u4e8e\u8bba\u8bc1\u7684\u5224\u65ad\u6027\u9884\u6d4b\u4e2d\u5f15\u5165\u673a\u5236\u8fc7\u6ee4\u4e0d\u8fde\u8d2f\u610f\u89c1\uff0c\u4ee5\u63d0\u9ad8\u7fa4\u4f53\u9884\u6d4b\u8d28\u91cf\u3002"}}
{"id": "2507.22911", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22911", "abs": "https://arxiv.org/abs/2507.22911", "authors": ["Jinzhi Wang", "Qingke Peng", "Haozhou Li", "Zeyuan Zeng", "Qinfeng Song", "Kaixuan Yang", "Jiangbo Zhang", "Yaoying Wang", "Ruimeng Li", "Biyi Zhou"], "title": "ElectriQ: A Benchmark for Assessing the Response Capability of Large Language Models in Power Marketing", "comment": null, "summary": "Electric power marketing customer service plays a critical role in addressing\ninquiries, complaints, and service requests. However, current systems, such as\nChina's 95598 hotline, often struggle with slow response times, inflexible\nprocedures, and limited accuracy in domain-specific tasks. While large language\nmodels (LLMs) like GPT-4o and Claude 3 demonstrate strong general capabilities,\nthey lack the domain expertise and empathy required in this field. To bridge\nthis gap, we introduce ElectriQ, the first benchmark designed to evaluate and\nenhance LLMs in electric power marketing scenarios. ElectriQ consists of a\ndialogue dataset covering six key service categories and introduces four\nevaluation metrics: professionalism, popularity, readability, and\nuser-friendliness. We further incorporate a domain-specific knowledge base and\npropose a knowledge augmentation method to boost model performance. Experiments\non 13 LLMs reveal that smaller models such as LLama3-8B, when fine-tuned and\naugmented, can surpass GPT-4o in terms of professionalism and\nuser-friendliness. ElectriQ establishes a comprehensive foundation for\ndeveloping LLMs tailored to the needs of power marketing services.", "AI": {"tldr": "ElectriQ\u662f\u4e00\u4e2a\u4e13\u4e3a\u7535\u529b\u8425\u9500\u5ba2\u670d\u573a\u666f\u8bbe\u8ba1\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u65e8\u5728\u8bc4\u4f30\u548c\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u8be5\u9886\u57df\u7684\u8868\u73b0\u3002\u901a\u8fc7\u5f15\u5165\u9886\u57df\u77e5\u8bc6\u5e93\u548c\u77e5\u8bc6\u589e\u5f3a\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u8868\u660e\u8f83\u5c0f\u7684\u6a21\u578b\uff08\u5982LLama3-8B\uff09\u5728\u4e13\u4e1a\u6027\u548c\u7528\u6237\u53cb\u597d\u6027\u4e0a\u53ef\u4ee5\u8d85\u8d8aGPT-4o\u3002", "motivation": "\u5f53\u524d\u7535\u529b\u8425\u9500\u5ba2\u670d\u7cfb\u7edf\uff08\u5982\u4e2d\u56fd95598\u70ed\u7ebf\uff09\u5b58\u5728\u54cd\u5e94\u6162\u3001\u6d41\u7a0b\u50f5\u5316\u7b49\u95ee\u9898\uff0c\u901a\u7528LLMs\u7f3a\u4e4f\u9886\u57df\u4e13\u4e1a\u6027\u548c\u540c\u7406\u5fc3\u3002ElectriQ\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u6784\u5efa\u5305\u542b\u516d\u4e2a\u670d\u52a1\u7c7b\u522b\u7684\u5bf9\u8bdd\u6570\u636e\u96c6\uff0c\u63d0\u51fa\u56db\u9879\u8bc4\u4f30\u6307\u6807\uff08\u4e13\u4e1a\u6027\u3001\u53d7\u6b22\u8fce\u5ea6\u3001\u53ef\u8bfb\u6027\u3001\u7528\u6237\u53cb\u597d\u6027\uff09\uff0c\u5e76\u5f15\u5165\u9886\u57df\u77e5\u8bc6\u5e93\u548c\u77e5\u8bc6\u589e\u5f3a\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u7ecf\u8fc7\u5fae\u8c03\u548c\u77e5\u8bc6\u589e\u5f3a\u7684\u5c0f\u578b\u6a21\u578b\uff08\u5982LLama3-8B\uff09\u5728\u4e13\u4e1a\u6027\u548c\u7528\u6237\u53cb\u597d\u6027\u4e0a\u4f18\u4e8eGPT-4o\u3002", "conclusion": "ElectriQ\u4e3a\u5f00\u53d1\u9002\u5408\u7535\u529b\u8425\u9500\u670d\u52a1\u7684LLMs\u63d0\u4f9b\u4e86\u5168\u9762\u57fa\u7840\u3002"}}
{"id": "2507.23191", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23191", "abs": "https://arxiv.org/abs/2507.23191", "authors": ["Meghyn Bienvenu", "Diego Figueira", "Pierre Lafourcade"], "title": "Tractable Responsibility Measures for Ontology-Mediated Query Answering", "comment": "Long version of a paper to appear at KR 2025, which contains further\n  proof details in the appendix", "summary": "Recent work on quantitative approaches to explaining query answers employs\nresponsibility measures to assign scores to facts in order to quantify their\nrespective contributions to obtaining a given answer. In this paper, we study\nthe complexity of computing such responsibility scores in the setting of\nontology-mediated query answering, focusing on a very recently introduced\nfamily of Shapley-value-based responsibility measures defined in terms of\nweighted sums of minimal supports (WSMS). By exploiting results from the\ndatabase setting, we can show that such measures enjoy polynomial data\ncomplexity for classes of ontology-mediated queries that are\nfirst-order-rewritable, whereas the problem becomes \"shP\"-hard when the\nontology language can encode reachability queries (via axioms like $\\exists R.\nA \\sqsubseteq A$). To better understand the tractability frontier, we next\nexplore the combined complexity of WSMS computation. We prove that\nintractability applies already to atomic queries if the ontology language\nsupports conjunction, as well as to unions of `well-behaved' conjunctive\nqueries, even in the absence of an ontology. By contrast, our study yields\npositive results for common DL-Lite dialects: by means of careful analysis, we\nidentify classes of structurally restricted conjunctive queries (which\nintuitively disallow undesirable interactions between query atoms) that admit\ntractable WSMS computation.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u57fa\u4e8eShapley\u503c\u7684\u8d23\u4efb\u8bc4\u5206\u5728ontology-mediated\u67e5\u8be2\u4e2d\u7684\u8ba1\u7b97\u590d\u6742\u6027\uff0c\u53d1\u73b0\u5176\u5728\u67d0\u4e9b\u67e5\u8be2\u7c7b\u578b\u4e0b\u5177\u6709\u591a\u9879\u5f0f\u6570\u636e\u590d\u6742\u6027\uff0c\u800c\u5728\u5176\u4ed6\u60c5\u51b5\u4e0b\u5219\u53d8\u5f97\u56f0\u96be\u3002", "motivation": "\u91cf\u5316\u67e5\u8be2\u7b54\u6848\u4e2d\u5404\u4e8b\u5b9e\u7684\u8d21\u732e\u662f\u91cd\u8981\u95ee\u9898\uff0c\u7814\u7a76\u5176\u8ba1\u7b97\u590d\u6742\u6027\u6709\u52a9\u4e8e\u7406\u89e3\u5b9e\u9645\u5e94\u7528\u7684\u53ef\u884c\u6027\u3002", "method": "\u5229\u7528\u6570\u636e\u5e93\u8bbe\u7f6e\u7684\u7ed3\u679c\uff0c\u5206\u6790\u4e0d\u540contology-mediated\u67e5\u8be2\u7c7b\u7684WSMS\u8d23\u4efb\u8bc4\u5206\u8ba1\u7b97\u590d\u6742\u6027\u3002", "result": "\u5bf9\u4e8efirst-order-rewritable\u67e5\u8be2\u7c7b\uff0cWSMS\u5177\u6709\u591a\u9879\u5f0f\u6570\u636e\u590d\u6742\u6027\uff1b\u800c\u5bf9\u4e8e\u652f\u6301\u53ef\u8fbe\u6027\u67e5\u8be2\u7684ontology\u8bed\u8a00\uff0c\u95ee\u9898\u53d8\u5f97\u56f0\u96be\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86WSMS\u8ba1\u7b97\u590d\u6742\u6027\u7684\u8fb9\u754c\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002"}}
{"id": "2507.22912", "categories": ["cs.CL", "cs.AI", "cs.LG", "68T07, 68T50"], "pdf": "https://arxiv.org/pdf/2507.22912", "abs": "https://arxiv.org/abs/2507.22912", "authors": ["Navid Yazdanjue", "Morteza Rakhshaninejad", "Hossein Yazdanjouei", "Mohammad Sadegh Khorshidi", "Mikko S. Niemela", "Fang Chen", "Amir H. Gandomi"], "title": "A Language Model-Driven Semi-Supervised Ensemble Framework for Illicit Market Detection Across Deep/Dark Web and Social Platforms", "comment": "16 pages, 5 figures, 9 tables", "summary": "Illegal marketplaces have increasingly shifted to concealed parts of the\ninternet, including the deep and dark web, as well as platforms such as\nTelegram, Reddit, and Pastebin. These channels enable the anonymous trade of\nillicit goods including drugs, weapons, and stolen credentials. Detecting and\ncategorizing such content remains challenging due to limited labeled data, the\nevolving nature of illicit language, and the structural heterogeneity of online\nsources. This paper presents a hierarchical classification framework that\ncombines fine-tuned language models with a semi-supervised ensemble learning\nstrategy to detect and classify illicit marketplace content across diverse\nplatforms. We extract semantic representations using ModernBERT, a transformer\nmodel for long documents, finetuned on domain-specific data from deep and dark\nweb pages, Telegram channels, Subreddits, and Pastebin pastes to capture\nspecialized jargon and ambiguous linguistic patterns. In addition, we\nincorporate manually engineered features such as document structure, embedded\npatterns including Bitcoin addresses, emails, and IPs, and metadata, which\ncomplement language model embeddings. The classification pipeline operates in\ntwo stages. The first stage uses a semi-supervised ensemble of XGBoost, Random\nForest, and SVM with entropy-based weighted voting to detect sales-related\ndocuments. The second stage further classifies these into drug, weapon, or\ncredential sales. Experiments on three datasets, including our multi-source\ncorpus, DUTA, and CoDA, show that our model outperforms several baselines,\nincluding BERT, ModernBERT, DarkBERT, ALBERT, Longformer, and BigBird. The\nmodel achieves an accuracy of 0.96489, an F1-score of 0.93467, and a TMCC of\n0.95388, demonstrating strong generalization, robustness under limited\nsupervision, and effectiveness in real-world illicit content detection.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5fae\u8c03\u8bed\u8a00\u6a21\u578b\u548c\u534a\u76d1\u7763\u96c6\u6210\u5b66\u4e60\u7684\u5c42\u6b21\u5206\u7c7b\u6846\u67b6\uff0c\u7528\u4e8e\u68c0\u6d4b\u548c\u5206\u7c7b\u975e\u6cd5\u5e02\u573a\u5185\u5bb9\u3002", "motivation": "\u975e\u6cd5\u5e02\u573a\u8f6c\u5411\u9690\u853d\u7684\u7f51\u7edc\u5e73\u53f0\uff0c\u5982\u6697\u7f51\u3001Telegram\u7b49\uff0c\u73b0\u6709\u65b9\u6cd5\u56e0\u6570\u636e\u6709\u9650\u548c\u8bed\u8a00\u590d\u6742\u6027\u96be\u4ee5\u6709\u6548\u68c0\u6d4b\u3002", "method": "\u91c7\u7528ModernBERT\u63d0\u53d6\u8bed\u4e49\u8868\u793a\uff0c\u7ed3\u5408\u624b\u5de5\u7279\u5f81\uff0c\u5206\u4e24\u9636\u6bb5\u5206\u7c7b\uff1a\u534a\u76d1\u7763\u96c6\u6210\u5b66\u4e60\u68c0\u6d4b\u9500\u552e\u5185\u5bb9\uff0c\u518d\u7ec6\u5206\u7c7b\u522b\u3002", "result": "\u6a21\u578b\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u51c6\u786e\u73870.96489\uff0cF1\u5206\u65700.93467\uff0c\u4f18\u4e8e\u591a\u79cd\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "\u8be5\u6846\u67b6\u5728\u6709\u9650\u76d1\u7763\u4e0b\u8868\u73b0\u51fa\u5f3a\u6cdb\u5316\u80fd\u529b\u548c\u9c81\u68d2\u6027\uff0c\u9002\u7528\u4e8e\u73b0\u5b9e\u4e16\u754c\u7684\u975e\u6cd5\u5185\u5bb9\u68c0\u6d4b\u3002"}}
{"id": "2507.23197", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23197", "abs": "https://arxiv.org/abs/2507.23197", "authors": ["Yuke Liao", "Blaise Genest", "Kuldeep Meel", "Shaan Aryaman"], "title": "Solution-aware vs global ReLU selection: partial MILP strikes back for DNN verification", "comment": null, "summary": "To handle complex instances, we revisit a divide-and-conquer approach to\nbreak down the complexity: instead of few complex BaB calls, we rely on many\nsmall {\\em partial} MILP calls. The crucial step is to select very few but very\nimportant ReLUs to treat using (costly) binary variables. The previous attempts\nwere suboptimal in that respect. To select these important ReLU variables, we\npropose a novel {\\em solution-aware} ReLU scoring ({\\sf SAS}), as well as adapt\nthe BaB-SR and BaB-FSB branching functions as {\\em global} ReLU scoring ({\\sf\nGS}) functions. We compare them theoretically as well as experimentally, and\n{\\sf SAS} is more efficient at selecting a set of variables to open using\nbinary variables. Compared with previous attempts, SAS reduces the number of\nbinary variables by around 6 times, while maintaining the same level of\naccuracy. Implemented in {\\em Hybrid MILP}, calling first $\\alpha,\\beta$-CROWN\nwith a short time-out to solve easier instances, and then partial MILP,\nproduces a very accurate yet efficient verifier, reducing by up to $40\\%$ the\nnumber of undecided instances to low levels ($8-15\\%$), while keeping a\nreasonable runtime ($46s-417s$ on average per instance), even for fairly large\nCNNs with 2 million parameters.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u611f\u77e5ReLU\u8bc4\u5206\u65b9\u6cd5\uff08SAS\uff09\uff0c\u901a\u8fc7\u51cf\u5c11\u4e8c\u8fdb\u5236\u53d8\u91cf\u6570\u91cf\u5e76\u4fdd\u6301\u51c6\u786e\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9a8c\u8bc1\u6548\u7387\u3002", "motivation": "\u5904\u7406\u590d\u6742\u5b9e\u4f8b\u65f6\uff0c\u4f20\u7edf\u65b9\u6cd5\u6548\u7387\u4f4e\u4e0b\uff0c\u9700\u6539\u8fdbReLU\u53d8\u91cf\u9009\u62e9\u7b56\u7565\u4ee5\u4f18\u5316\u9a8c\u8bc1\u8fc7\u7a0b\u3002", "method": "\u91c7\u7528\u89e3\u51b3\u65b9\u6848\u611f\u77e5ReLU\u8bc4\u5206\uff08SAS\uff09\u548c\u5168\u5c40ReLU\u8bc4\u5206\uff08GS\uff09\uff0c\u7ed3\u5408Hybrid MILP\u65b9\u6cd5\uff0c\u5148\u8c03\u7528\u03b1,\u03b2-CROWN\u5904\u7406\u7b80\u5355\u5b9e\u4f8b\uff0c\u518d\u4f7f\u7528\u90e8\u5206MILP\u3002", "result": "SAS\u5c06\u4e8c\u8fdb\u5236\u53d8\u91cf\u6570\u91cf\u51cf\u5c11\u7ea66\u500d\uff0c\u9a8c\u8bc1\u5668\u6548\u7387\u63d0\u534740%\uff0c\u672a\u89e3\u51b3\u5b9e\u4f8b\u6bd4\u4f8b\u964d\u81f38-15%\uff0c\u5e73\u5747\u8fd0\u884c\u65f6\u95f4\u4e3a46-417\u79d2\u3002", "conclusion": "SAS\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u9a8c\u8bc1\u5668\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u795e\u7ecf\u7f51\u7edc\u3002"}}
{"id": "2507.22913", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22913", "abs": "https://arxiv.org/abs/2507.22913", "authors": ["Jinyu Liu", "Xiaoying Song", "Diana Zhang", "Jason Thomale", "Daqing He", "Lingzi Hong"], "title": "A Hybrid Framework for Subject Analysis: Integrating Embedding-Based Regression Models with Large Language Models", "comment": "13 pages, 2 figures, accepted by ASIST 2025", "summary": "Providing subject access to information resources is an essential function of\nany library management system. Large language models (LLMs) have been widely\nused in classification and summarization tasks, but their capability to perform\nsubject analysis is underexplored. Multi-label classification with traditional\nmachine learning (ML) models has been used for subject analysis but struggles\nwith unseen cases. LLMs offer an alternative but often over-generate and\nhallucinate. Therefore, we propose a hybrid framework that integrates\nembedding-based ML models with LLMs. This approach uses ML models to (1)\npredict the optimal number of LCSH labels to guide LLM predictions and (2)\npost-edit the predicted terms with actual LCSH terms to mitigate\nhallucinations. We experimented with LLMs and the hybrid framework to predict\nthe subject terms of books using the Library of Congress Subject Headings\n(LCSH). Experiment results show that providing initial predictions to guide LLM\ngenerations and imposing post-edits result in more controlled and\nvocabulary-aligned outputs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5d4c\u5165\u5f0f\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u6df7\u5408\u6846\u67b6\uff0c\u7528\u4e8e\u4f18\u5316\u4e3b\u9898\u5206\u6790\u4efb\u52a1\uff0c\u51cf\u5c11\u5e7b\u89c9\u5e76\u63d0\u9ad8\u51c6\u786e\u6027\u3002", "motivation": "\u4e3b\u9898\u5206\u6790\u662f\u56fe\u4e66\u9986\u7ba1\u7406\u7cfb\u7edf\u7684\u6838\u5fc3\u529f\u80fd\uff0c\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u5904\u7406\u672a\u89c1\u6848\u4f8b\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u800cLLM\u5bb9\u6613\u8fc7\u5ea6\u751f\u6210\u548c\u4ea7\u751f\u5e7b\u89c9\u3002", "method": "\u91c7\u7528\u6df7\u5408\u6846\u67b6\uff0c\u5229\u7528ML\u6a21\u578b\u9884\u6d4bLCSH\u6807\u7b7e\u6570\u91cf\u4ee5\u6307\u5bfcLLM\u751f\u6210\uff0c\u5e76\u901a\u8fc7\u540e\u7f16\u8f91\u5c06\u9884\u6d4b\u672f\u8bed\u4e0e\u5b9e\u9645LCSH\u672f\u8bed\u5bf9\u9f50\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6df7\u5408\u6846\u67b6\u80fd\u751f\u6210\u66f4\u53d7\u63a7\u4e14\u4e0e\u8bcd\u6c47\u8868\u5bf9\u9f50\u7684\u8f93\u51fa\u3002", "conclusion": "\u6df7\u5408\u6846\u67b6\u7ed3\u5408\u4e86ML\u4e0eLLM\u7684\u4f18\u52bf\uff0c\u6709\u6548\u63d0\u5347\u4e86\u4e3b\u9898\u5206\u6790\u7684\u51c6\u786e\u6027\u548c\u53ef\u63a7\u6027\u3002"}}
{"id": "2507.23276", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23276", "abs": "https://arxiv.org/abs/2507.23276", "authors": ["Qiujie Xie", "Yixuan Weng", "Minjun Zhu", "Fuchen Shen", "Shulin Huang", "Zhen Lin", "Jiahui Zhou", "Zilan Mao", "Zijie Yang", "Linyi Yang", "Jian Wu", "Yue Zhang"], "title": "How Far Are AI Scientists from Changing the World?", "comment": null, "summary": "The emergence of large language models (LLMs) is propelling automated\nscientific discovery to the next level, with LLM-based Artificial Intelligence\n(AI) Scientist systems now taking the lead in scientific research. Several\ninfluential works have already appeared in the field of AI Scientist systems,\nwith AI-generated research papers having been accepted at the ICLR 2025\nworkshop, suggesting that a human-level AI Scientist capable of uncovering\nphenomena previously unknown to humans, may soon become a reality. In this\nsurvey, we focus on the central question: How far are AI scientists from\nchanging the world and reshaping the scientific research paradigm? To answer\nthis question, we provide a prospect-driven review that comprehensively\nanalyzes the current achievements of AI Scientist systems, identifying key\nbottlenecks and the critical components required for the emergence of a\nscientific agent capable of producing ground-breaking discoveries that solve\ngrand challenges. We hope this survey will contribute to a clearer\nunderstanding of limitations of current AI Scientist systems, showing where we\nare, what is missing, and what the ultimate goals for scientific AI should be.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684AI\u79d1\u5b66\u5bb6\u7cfb\u7edf\u5728\u79d1\u5b66\u53d1\u73b0\u4e2d\u7684\u6f5c\u529b\uff0c\u5206\u6790\u4e86\u5176\u5f53\u524d\u6210\u5c31\u3001\u74f6\u9888\u53ca\u672a\u6765\u76ee\u6807\u3002", "motivation": "\u7814\u7a76AI\u79d1\u5b66\u5bb6\u7cfb\u7edf\u5982\u4f55\u63a8\u52a8\u79d1\u5b66\u7814\u7a76\u7684\u8303\u5f0f\u8f6c\u53d8\uff0c\u5e76\u8bc4\u4f30\u5176\u5b9e\u73b0\u7a81\u7834\u6027\u53d1\u73b0\u7684\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u524d\u77bb\u6027\u7efc\u8ff0\uff0c\u5168\u9762\u5206\u6790AI\u79d1\u5b66\u5bb6\u7cfb\u7edf\u7684\u73b0\u72b6\uff0c\u8bc6\u522b\u5173\u952e\u74f6\u9888\u548c\u5fc5\u8981\u7ec4\u4ef6\u3002", "result": "\u6307\u51faAI\u79d1\u5b66\u5bb6\u7cfb\u7edf\u5df2\u53d6\u5f97\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u4ecd\u9700\u89e3\u51b3\u5173\u952e\u95ee\u9898\u4ee5\u5b9e\u73b0\u7a81\u7834\u6027\u79d1\u5b66\u53d1\u73b0\u3002", "conclusion": "\u672c\u6587\u65e8\u5728\u660e\u786e\u5f53\u524dAI\u79d1\u5b66\u5bb6\u7cfb\u7edf\u7684\u5c40\u9650\u6027\uff0c\u5e76\u4e3a\u5176\u672a\u6765\u53d1\u5c55\u63d0\u4f9b\u65b9\u5411\u3002"}}
{"id": "2507.22914", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.22914", "abs": "https://arxiv.org/abs/2507.22914", "authors": ["Victor Eiti Yamamoto", "Hideaki Takeda"], "title": "Full Triple Matcher: Integrating all triple elements between heterogeneous Knowledge Graphs", "comment": null, "summary": "Knowledge graphs (KGs) are powerful tools for representing and reasoning over\nstructured information. Their main components include schema, identity, and\ncontext. While schema and identity matching are well-established in ontology\nand entity matching research, context matching remains largely unexplored. This\nis particularly important because real-world KGs often vary significantly in\nsource, size, and information density - factors not typically represented in\nthe datasets on which current entity matching methods are evaluated. As a\nresult, existing approaches may fall short in scenarios where diverse and\ncomplex contexts need to be integrated.\n  To address this gap, we propose a novel KG integration method consisting of\nlabel matching and triple matching. We use string manipulation, fuzzy matching,\nand vector similarity techniques to align entity and predicate labels. Next, we\nidentify mappings between triples that convey comparable information, using\nthese mappings to improve entity-matching accuracy. Our approach demonstrates\ncompetitive performance compared to leading systems in the OAEI competition and\nagainst supervised methods, achieving high accuracy across diverse test cases.\nAdditionally, we introduce a new dataset derived from the benchmark dataset to\nevaluate the triple-matching step more comprehensively.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u77e5\u8bc6\u56fe\u8c31\u96c6\u6210\u65b9\u6cd5\uff0c\u7ed3\u5408\u6807\u7b7e\u5339\u914d\u548c\u4e09\u91cd\u5339\u914d\uff0c\u4ee5\u89e3\u51b3\u4e0a\u4e0b\u6587\u5339\u914d\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u5b9e\u4f53\u5339\u914d\u65b9\u6cd5\u5728\u591a\u6837\u5316\u548c\u590d\u6742\u4e0a\u4e0b\u6587\u96c6\u6210\u573a\u666f\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u7f3a\u4e4f\u5bf9\u4e0a\u4e0b\u6587\u5339\u914d\u7684\u63a2\u7d22\u3002", "method": "\u91c7\u7528\u5b57\u7b26\u4e32\u64cd\u4f5c\u3001\u6a21\u7cca\u5339\u914d\u548c\u5411\u91cf\u76f8\u4f3c\u6027\u6280\u672f\u5bf9\u9f50\u6807\u7b7e\uff0c\u5e76\u901a\u8fc7\u4e09\u91cd\u5339\u914d\u63d0\u9ad8\u5b9e\u4f53\u5339\u914d\u51c6\u786e\u6027\u3002", "result": "\u5728OAEI\u7ade\u8d5b\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4e14\u5728\u591a\u6837\u6d4b\u8bd5\u6848\u4f8b\u4e2d\u5b9e\u73b0\u9ad8\u51c6\u786e\u7387\u3002", "conclusion": "\u65b0\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u4e0a\u4e0b\u6587\u5339\u914d\u95ee\u9898\uff0c\u5e76\u5f15\u5165\u65b0\u6570\u636e\u96c6\u4ee5\u66f4\u5168\u9762\u8bc4\u4f30\u4e09\u91cd\u5339\u914d\u3002"}}
{"id": "2507.23330", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23330", "abs": "https://arxiv.org/abs/2507.23330", "authors": ["Tosin Adewumi", "Lama Alkhaled", "Florent Imbert", "Hui Han", "Nudrat Habib", "Karl L\u00f6wenmark"], "title": "AI Must not be Fully Autonomous", "comment": "11 pages, 1 figure", "summary": "Autonomous Artificial Intelligence (AI) has many benefits. It also has many\nrisks. In this work, we identify the 3 levels of autonomous AI. We are of the\nposition that AI must not be fully autonomous because of the many risks,\nespecially as artificial superintelligence (ASI) is speculated to be just\ndecades away. Fully autonomous AI, which can develop its own objectives, is at\nlevel 3 and without responsible human oversight. However, responsible human\noversight is crucial for mitigating the risks. To ague for our position, we\ndiscuss theories of autonomy, AI and agents. Then, we offer 12 distinct\narguments and 6 counterarguments with rebuttals to the counterarguments. We\nalso present 15 pieces of recent evidence of AI misaligned values and other\nrisks in the appendix.", "AI": {"tldr": "\u8bba\u6587\u4e3b\u5f20AI\u4e0d\u5e94\u5b8c\u5168\u81ea\u4e3b\uff0c\u63d0\u51fa3\u7ea7\u81ea\u4e3bAI\u5206\u7c7b\uff0c\u5f3a\u8c03\u4eba\u7c7b\u76d1\u7763\u7684\u91cd\u8981\u6027\uff0c\u5e76\u63d0\u4f9b\u8bba\u636e\u548c\u53cd\u9a73\u3002", "motivation": "\u63a2\u8ba8AI\u5b8c\u5168\u81ea\u4e3b\u7684\u98ce\u9669\uff0c\u5c24\u5176\u662f\u8d85\u7ea7\u667a\u80fd\uff08ASI\uff09\u53ef\u80fd\u5e26\u6765\u7684\u5a01\u80c1\u3002", "method": "\u5206\u6790\u81ea\u4e3b\u6027\u7406\u8bba\u3001AI\u548c\u4ee3\u7406\uff0c\u63d0\u51fa12\u4e2a\u8bba\u70b9\u548c6\u4e2a\u53cd\u9a73\uff0c\u5e76\u63d0\u4f9b15\u4e2aAI\u4ef7\u503c\u89c2\u9519\u4f4d\u7684\u8bc1\u636e\u3002", "result": "\u652f\u6301\u4eba\u7c7b\u76d1\u7763\u7684\u5fc5\u8981\u6027\uff0c\u53cd\u5bf9\u5b8c\u5168\u81ea\u4e3b\u7684AI\u3002", "conclusion": "\u4e3a\u907f\u514d\u98ce\u9669\uff0cAI\u9700\u5728\u4eba\u7c7b\u76d1\u7763\u4e0b\u8fd0\u884c\uff0c\u4e0d\u5e94\u8fbe\u5230\u5b8c\u5168\u81ea\u4e3b\u7684\u7b2c\u4e09\u7ea7\u3002"}}
{"id": "2507.22915", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22915", "abs": "https://arxiv.org/abs/2507.22915", "authors": ["Esmail Gumaan"], "title": "Theoretical Foundations and Mitigation of Hallucination in Large Language Models", "comment": "12 pages", "summary": "Hallucination in Large Language Models (LLMs) refers to the generation of\ncontent that is not faithful to the input or the real-world facts. This paper\nprovides a rigorous treatment of hallucination in LLMs, including formal\ndefinitions and theoretical analyses. We distinguish between intrinsic and\nextrinsic hallucinations, and define a \\textit{hallucination risk} for models.\nWe derive bounds on this risk using learning-theoretic frameworks (PAC-Bayes\nand Rademacher complexity). We then survey detection strategies for\nhallucinations, such as token-level uncertainty estimation, confidence\ncalibration, and attention alignment checks. On the mitigation side, we discuss\napproaches including retrieval-augmented generation, hallucination-aware\nfine-tuning, logit calibration, and the incorporation of fact-verification\nmodules. We propose a unified detection and mitigation workflow, illustrated\nwith a diagram, to integrate these strategies. Finally, we outline evaluation\nprotocols for hallucination, recommending datasets, metrics, and experimental\nsetups to quantify and reduce hallucinations. Our work lays a theoretical\nfoundation and practical guidelines for addressing the crucial challenge of\nhallucination in LLMs.", "AI": {"tldr": "\u8bba\u6587\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e2d\u7684\u5e7b\u89c9\u73b0\u8c61\u8fdb\u884c\u4e86\u7cfb\u7edf\u7814\u7a76\uff0c\u5305\u62ec\u5b9a\u4e49\u3001\u7406\u8bba\u5206\u6790\u3001\u68c0\u6d4b\u4e0e\u7f13\u89e3\u7b56\u7565\uff0c\u5e76\u63d0\u51fa\u7edf\u4e00\u7684\u68c0\u6d4b\u4e0e\u7f13\u89e3\u6d41\u7a0b\u3002", "motivation": "\u89e3\u51b3LLM\u751f\u6210\u5185\u5bb9\u4e0d\u5fe0\u5b9e\u4e8e\u8f93\u5165\u6216\u4e8b\u5b9e\u7684\u95ee\u9898\uff0c\u4e3a\u5e7b\u89c9\u73b0\u8c61\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u8df5\u6307\u5bfc\u3002", "method": "\u533a\u5206\u5185\u5728\u548c\u5916\u5728\u5e7b\u89c9\uff0c\u5b9a\u4e49\u5e7b\u89c9\u98ce\u9669\uff0c\u5229\u7528\u5b66\u4e60\u7406\u8bba\u6846\u67b6\uff08\u5982PAC-Bayes\u548cRademacher\u590d\u6742\u5ea6\uff09\u63a8\u5bfc\u98ce\u9669\u754c\u9650\uff0c\u5e76\u8c03\u67e5\u68c0\u6d4b\u4e0e\u7f13\u89e3\u7b56\u7565\u3002", "result": "\u63d0\u51fa\u7edf\u4e00\u7684\u68c0\u6d4b\u4e0e\u7f13\u89e3\u6d41\u7a0b\uff0c\u5e76\u63a8\u8350\u8bc4\u4f30\u5e7b\u89c9\u7684\u6570\u636e\u96c6\u3001\u6307\u6807\u548c\u5b9e\u9a8c\u8bbe\u7f6e\u3002", "conclusion": "\u8bba\u6587\u4e3aLLM\u4e2d\u7684\u5e7b\u89c9\u95ee\u9898\u5960\u5b9a\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u5e76\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u6307\u5357\u3002"}}
{"id": "2507.23336", "categories": ["cs.AI", "cs.CL", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.23336", "abs": "https://arxiv.org/abs/2507.23336", "authors": ["Ram Mohan Rao Kadiyala", "Siddhant Gupta", "Jebish Purbey", "Giulio Martini", "Suman Debnath", "Hamza Farooq"], "title": "DSBC : Data Science task Benchmarking with Context engineering", "comment": "32 pages", "summary": "Recent advances in large language models (LLMs) have significantly impacted\ndata science workflows, giving rise to specialized data science agents designed\nto automate analytical tasks. Despite rapid adoption, systematic benchmarks\nevaluating the efficacy and limitations of these agents remain scarce. In this\npaper, we introduce a comprehensive benchmark specifically crafted to reflect\nreal-world user interactions with data science agents by observing usage of our\ncommercial applications. We evaluate three LLMs: Claude-4.0-Sonnet,\nGemini-2.5-Flash, and OpenAI-o4-Mini across three approaches: zero-shot with\ncontext engineering, multi-step with context engineering, and with SmolAgent.\nOur benchmark assesses performance across a diverse set of eight data science\ntask categories, additionally exploring the sensitivity of models to common\nprompting issues, such as data leakage and slightly ambiguous instructions. We\nfurther investigate the influence of temperature parameters on overall and\ntask-specific outcomes for each model and approach. Our findings reveal\ndistinct performance disparities among the evaluated models and methodologies,\nhighlighting critical factors that affect practical deployment. The benchmark\ndataset and evaluation framework introduced herein aim to provide a foundation\nfor future research of more robust and effective data science agents.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u9488\u5bf9\u6570\u636e\u79d1\u5b66\u4ee3\u7406\u7684\u5168\u9762\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u4e86\u4e09\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u540c\u65b9\u6cd5\u4e0b\u7684\u6027\u80fd\u8868\u73b0\uff0c\u63ed\u793a\u4e86\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u5173\u952e\u56e0\u7d20\u3002", "motivation": "\u5c3d\u7ba1\u6570\u636e\u79d1\u5b66\u4ee3\u7406\u5728\u81ea\u52a8\u5316\u5206\u6790\u4efb\u52a1\u4e2d\u8fc5\u901f\u666e\u53ca\uff0c\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u6027\u8bc4\u4f30\u5176\u6548\u80fd\u548c\u5c40\u9650\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002", "method": "\u901a\u8fc7\u5546\u4e1a\u5e94\u7528\u89c2\u5bdf\u7528\u6237\u4ea4\u4e92\uff0c\u8bc4\u4f30\u4e09\u79cdLLM\uff08Claude-4.0-Sonnet\u3001Gemini-2.5-Flash\u3001OpenAI-o4-Mini\uff09\u5728\u4e09\u79cd\u65b9\u6cd5\u4e0b\u7684\u8868\u73b0\uff0c\u5305\u62ec\u96f6\u6837\u672c\u4e0a\u4e0b\u6587\u5de5\u7a0b\u3001\u591a\u6b65\u4e0a\u4e0b\u6587\u5de5\u7a0b\u548cSmolAgent\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4e0d\u540c\u6a21\u578b\u548c\u65b9\u6cd5\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u5e76\u63a2\u8ba8\u4e86\u6e29\u5ea6\u53c2\u6570\u5bf9\u4efb\u52a1\u8868\u73b0\u7684\u5f71\u54cd\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u51c6\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u6846\u67b6\u4e3a\u672a\u6765\u7814\u7a76\u66f4\u9c81\u68d2\u548c\u9ad8\u6548\u7684\u6570\u636e\u79d1\u5b66\u4ee3\u7406\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2507.22917", "categories": ["cs.CL", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2507.22917", "abs": "https://arxiv.org/abs/2507.22917", "authors": ["Kwun Hang Lau", "Ruiyuan Zhang", "Weijie Shi", "Xiaofang Zhou", "Xiaojun Cheng"], "title": "Reading Between the Timelines: RAG for Answering Diachronic Questions", "comment": null, "summary": "While Retrieval-Augmented Generation (RAG) excels at injecting static,\nfactual knowledge into Large Language Models (LLMs), it exhibits a critical\ndeficit in handling longitudinal queries that require tracking entities and\nphenomena across time. This blind spot arises because conventional,\nsemantically-driven retrieval methods are not equipped to gather evidence that\nis both topically relevant and temporally coherent for a specified duration. We\naddress this challenge by proposing a new framework that fundamentally\nredesigns the RAG pipeline to infuse temporal logic. Our methodology begins by\ndisentangling a user's query into its core subject and its temporal window. It\nthen employs a specialized retriever that calibrates semantic matching against\ntemporal relevance, ensuring the collection of a contiguous evidence set that\nspans the entire queried period. To enable rigorous evaluation of this\ncapability, we also introduce the Analytical Diachronic Question Answering\nBenchmark (ADQAB), a challenging evaluation suite grounded in a hybrid corpus\nof real and synthetic financial news. Empirical results on ADQAB show that our\napproach yields substantial gains in answer accuracy, surpassing standard RAG\nimplementations by 13% to 27%. This work provides a validated pathway toward\nRAG systems capable of performing the nuanced, evolutionary analysis required\nfor complex, real-world questions. The dataset and code for this study are\npublicly available at https://github.com/kwunhang/TA-RAG.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684RAG\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\u65f6\u95f4\u903b\u8f91\u6765\u89e3\u51b3\u4f20\u7edfRAG\u5728\u5904\u7406\u65f6\u95f4\u76f8\u5173\u67e5\u8be2\u65f6\u7684\u4e0d\u8db3\uff0c\u5e76\u5728\u65b0\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u4f20\u7edfRAG\u5728\u5904\u7406\u9700\u8981\u8de8\u65f6\u95f4\u8ffd\u8e2a\u5b9e\u4f53\u548c\u73b0\u8c61\u7684\u67e5\u8be2\u65f6\u5b58\u5728\u4e0d\u8db3\uff0c\u56e0\u4e3a\u5176\u68c0\u7d22\u65b9\u6cd5\u7f3a\u4e4f\u65f6\u95f4\u8fde\u8d2f\u6027\u3002", "method": "\u63d0\u51fa\u65b0\u6846\u67b6\uff0c\u5c06\u67e5\u8be2\u5206\u89e3\u4e3a\u4e3b\u9898\u548c\u65f6\u95f4\u7a97\u53e3\uff0c\u4f7f\u7528\u4e13\u95e8\u68c0\u7d22\u5668\u7ed3\u5408\u8bed\u4e49\u5339\u914d\u548c\u65f6\u95f4\u76f8\u5173\u6027\uff0c\u786e\u4fdd\u8bc1\u636e\u7684\u65f6\u95f4\u8fde\u8d2f\u6027\u3002", "result": "\u5728\u65b0\u57fa\u51c6\u6d4b\u8bd5ADQAB\u4e0a\uff0c\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u6807\u51c6RAG\uff0c\u51c6\u786e\u7387\u63d0\u534713%\u81f327%\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3aRAG\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5904\u7406\u590d\u6742\u65f6\u95f4\u76f8\u5173\u95ee\u9898\u7684\u6709\u6548\u9014\u5f84\uff0c\u4ee3\u7801\u548c\u6570\u636e\u96c6\u5df2\u516c\u5f00\u3002"}}
{"id": "2507.23377", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23377", "abs": "https://arxiv.org/abs/2507.23377", "authors": ["Zhuo Li", "Xianghuai Deng", "Chiwei Feng", "Hanmeng Li", "Shenjie Wang", "Haichao Zhang", "Teng Jia", "Conlin Chen", "Louis Linchun Wu", "Jia Wang"], "title": "LLM4Rail: An LLM-Augmented Railway Service Consulting Platform", "comment": null, "summary": "Large language models (LLMs) have significantly reshaped different walks of\nbusiness. To meet the increasing demands for individualized railway service, we\ndevelop LLM4Rail - a novel LLM-augmented railway service consulting platform.\nEmpowered by LLM, LLM4Rail can provide custom modules for ticketing, railway\nfood & drink recommendations, weather information, and chitchat. In LLM4Rail,\nwe propose the iterative \"Question-Thought-Action-Observation (QTAO)\" prompting\nframework. It meticulously integrates verbal reasoning with task-oriented\nactions, that is, reasoning to guide action selection, to effectively retrieve\nexternal observations relevant to railway operation and service to generate\naccurate responses. To provide personalized onboard dining services, we first\nconstruct the Chinese Railway Food and Drink (CRFD-25) - a publicly accessible\ntakeout dataset tailored for railway services. CRFD-25 covers a wide range of\nsignature dishes categorized by cities, cuisines, age groups, and spiciness\nlevels. We further introduce an LLM-based zero-shot conversational recommender\nfor railway catering. To address the unconstrained nature of open\nrecommendations, the feature similarity-based post-processing step is\nintroduced to ensure all the recommended items are aligned with CRFD-25\ndataset.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faLLM4Rail\u5e73\u53f0\uff0c\u5229\u7528LLM\u589e\u5f3a\u94c1\u8def\u670d\u52a1\u54a8\u8be2\uff0c\u91c7\u7528QTAO\u63d0\u793a\u6846\u67b6\u6574\u5408\u63a8\u7406\u4e0e\u4efb\u52a1\u5bfc\u5411\u884c\u52a8\uff0c\u5e76\u5f15\u5165CRFD-25\u6570\u636e\u96c6\u548c\u96f6\u6837\u672c\u63a8\u8350\u7cfb\u7edf\u3002", "motivation": "\u6ee1\u8db3\u4e2a\u6027\u5316\u94c1\u8def\u670d\u52a1\u9700\u6c42\uff0c\u63d0\u5347\u94c1\u8def\u54a8\u8be2\u7684\u51c6\u786e\u6027\u548c\u4e2a\u6027\u5316\u3002", "method": "\u63d0\u51faQTAO\u63d0\u793a\u6846\u67b6\uff0c\u7ed3\u5408\u63a8\u7406\u4e0e\u884c\u52a8\uff1b\u6784\u5efaCRFD-25\u6570\u636e\u96c6\uff1b\u5f00\u53d1\u57fa\u4e8eLLM\u7684\u96f6\u6837\u672c\u63a8\u8350\u7cfb\u7edf\u3002", "result": "LLM4Rail\u80fd\u63d0\u4f9b\u4e2a\u6027\u5316\u94c1\u8def\u670d\u52a1\uff0c\u5982\u7968\u52a1\u3001\u9910\u996e\u63a8\u8350\u7b49\uff1bCRFD-25\u6570\u636e\u96c6\u652f\u6301\u7cbe\u51c6\u63a8\u8350\u3002", "conclusion": "LLM4Rail\u548cQTAO\u6846\u67b6\u6709\u6548\u63d0\u5347\u94c1\u8def\u670d\u52a1\u4e2a\u6027\u5316\uff0cCRFD-25\u6570\u636e\u96c6\u4e3a\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u57fa\u7840\u3002"}}
{"id": "2507.22918", "categories": ["cs.CL", "cs.LG", "68T50", "I.2.6; I.2.7"], "pdf": "https://arxiv.org/pdf/2507.22918", "abs": "https://arxiv.org/abs/2507.22918", "authors": ["Daniel Son", "Sanjana Rathore", "Andrew Rufail", "Adrian Simon", "Daniel Zhang", "Soham Dave", "Cole Blondin", "Kevin Zhu", "Sean O'Brien"], "title": "Semantic Convergence: Investigating Shared Representations Across Scaled LLMs", "comment": "Submitted to ACL 2025 Student Research Workshop (poster)", "summary": "We investigate feature universality in Gemma-2 language models (Gemma-2-2B\nand Gemma-2-9B), asking whether models with a four-fold difference in scale\nstill converge on comparable internal concepts. Using the Sparse Autoencoder\n(SAE) dictionary-learning pipeline, we utilize SAEs on each model's\nresidual-stream activations, align the resulting monosemantic features via\nactivation correlation, and compare the matched feature spaces with SVCCA and\nRSA. Middle layers yield the strongest overlap, while early and late layers\nshow far less similarity. Preliminary experiments extend the analysis from\nsingle tokens to multi-token subspaces, showing that semantically similar\nsubspaces interact similarly with language models. These results strengthen the\ncase that large language models carve the world into broadly similar,\ninterpretable features despite size differences, reinforcing universality as a\nfoundation for cross-model interpretability.", "AI": {"tldr": "\u7814\u7a76Gemma-2\u8bed\u8a00\u6a21\u578b\uff082B\u548c9B\uff09\u7684\u7279\u5f81\u666e\u904d\u6027\uff0c\u53d1\u73b0\u4e0d\u540c\u89c4\u6a21\u7684\u6a21\u578b\u5728\u5185\u90e8\u6982\u5ff5\u4e0a\u4ecd\u5177\u6709\u53ef\u6bd4\u6027\u3002", "motivation": "\u63a2\u7a76\u4e0d\u540c\u89c4\u6a21\u7684\u8bed\u8a00\u6a21\u578b\u662f\u5426\u6536\u655b\u4e8e\u76f8\u4f3c\u7684\u5185\u90e8\u6982\u5ff5\uff0c\u4ee5\u9a8c\u8bc1\u7279\u5f81\u666e\u904d\u6027\u4f5c\u4e3a\u8de8\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u7684\u57fa\u7840\u3002", "method": "\u4f7f\u7528\u7a00\u758f\u81ea\u7f16\u7801\u5668\uff08SAE\uff09\u5206\u6790\u6a21\u578b\u7684\u6b8b\u5dee\u6d41\u6fc0\u6d3b\uff0c\u901a\u8fc7\u6fc0\u6d3b\u76f8\u5173\u6027\u5bf9\u9f50\u7279\u5f81\uff0c\u5e76\u7528SVCCA\u548cRSA\u6bd4\u8f83\u5339\u914d\u7279\u5f81\u7a7a\u95f4\u3002", "result": "\u4e2d\u95f4\u5c42\u7684\u7279\u5f81\u91cd\u53e0\u6700\u5f3a\uff0c\u65e9\u671f\u548c\u665a\u671f\u5c42\u76f8\u4f3c\u6027\u8f83\u4f4e\uff1b\u591a\u6807\u8bb0\u5b50\u7a7a\u95f4\u5b9e\u9a8c\u663e\u793a\u8bed\u4e49\u76f8\u4f3c\u7684\u5b50\u7a7a\u95f4\u4e0e\u6a21\u578b\u4ea4\u4e92\u65b9\u5f0f\u7c7b\u4f3c\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u540c\u89c4\u6a21\u4e0b\u4ecd\u80fd\u5f62\u6210\u76f8\u4f3c\u7684\u3001\u53ef\u89e3\u91ca\u7684\u7279\u5f81\uff0c\u652f\u6301\u7279\u5f81\u666e\u904d\u6027\u4f5c\u4e3a\u8de8\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u7684\u57fa\u7840\u3002"}}
{"id": "2507.23429", "categories": ["cs.AI", "cs.DB", "cs.ET", "cs.HC", "cs.MA", "68T50, 68P20", "I.2.7; H.2.5; H.2.8; H.5.m"], "pdf": "https://arxiv.org/pdf/2507.23429", "abs": "https://arxiv.org/abs/2507.23429", "authors": ["Jorge Ruiz G\u00f3mez", "Lidia Andr\u00e9s Susinos", "Jorge Alamo Oliv\u00e9", "Sonia Rey Osorno", "Manuel Luis Gonzalez Hern\u00e1ndez"], "title": "Chatting with your ERP: A Recipe", "comment": "11 pages, includes 3 tables summarizing schema and model performance.\n  Submitted on July 31, 2025. Targets integration of LLM agents with ERP\n  systems using open-weight models and Ollama deployment", "summary": "This paper presents the design, implementation, and evaluation behind a Large\nLanguage Model (LLM) agent that chats with an industrial production-grade ERP\nsystem. The agent is capable of interpreting natural language queries and\ntranslating them into executable SQL statements, leveraging open-weight LLMs. A\nnovel dual-agent architecture combining reasoning and critique stages was\nproposed to improve query generation reliability.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u4ee3\u7406\uff0c\u80fd\u591f\u4e0e\u5de5\u4e1a\u7ea7ERP\u7cfb\u7edf\u4ea4\u4e92\uff0c\u5c06\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u8f6c\u6362\u4e3a\u53ef\u6267\u884c\u7684SQL\u8bed\u53e5\uff0c\u5e76\u91c7\u7528\u53cc\u4ee3\u7406\u67b6\u6784\u63d0\u9ad8\u53ef\u9760\u6027\u3002", "motivation": "\u89e3\u51b3\u5de5\u4e1a\u7ea7ERP\u7cfb\u7edf\u4e2d\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u8f6c\u6362\u4e3aSQL\u8bed\u53e5\u7684\u53ef\u9760\u6027\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u53cc\u4ee3\u7406\u67b6\u6784\uff0c\u7ed3\u5408\u63a8\u7406\u548c\u6279\u5224\u9636\u6bb5\uff0c\u5229\u7528\u5f00\u6e90\u6743\u91cdLLM\u3002", "result": "\u4ee3\u7406\u80fd\u591f\u53ef\u9760\u5730\u5c06\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u8f6c\u6362\u4e3aSQL\u8bed\u53e5\u3002", "conclusion": "\u53cc\u4ee3\u7406\u67b6\u6784\u663e\u8457\u63d0\u9ad8\u4e86\u67e5\u8be2\u751f\u6210\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2507.22919", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22919", "abs": "https://arxiv.org/abs/2507.22919", "authors": ["Qixuan Hu", "Xumou Zhang", "Jinman Kim", "Florence Bourgeois", "Adam G. Dunn"], "title": "A novel language model for predicting serious adverse event results in clinical trials from their prospective registrations", "comment": null, "summary": "Objectives: With accurate estimates of expected safety results, clinical\ntrials could be designed to avoid terminations and limit exposing participants\nto unnecessary risks. We evaluated methods for predicting serious adverse event\n(SAE) results in clinical trials using information only from their\nregistrations prior to the trial. Material and Methods: We analysed 22,107\ntwo-arm parallel interventional clinical trials from ClinicalTrials.gov with\nstructured summary results. Two prediction models were developed: a classifier\npredicting will experimental arm have higher SAE rates (area under the receiver\noperating characteristic curve; AUC) than control arm, and a regression model\nto predict the proportion of SAEs in control arms (root mean squared error;\nRMSE). A transfer learning approach using pretrained language models (e.g.,\nClinicalT5, BioBERT) was used for feature extraction, combined with downstream\nmodel for prediction. To maintain semantic representation in long trial texts\nexceeding localised language model input limits, a sliding window method was\ndeveloped for embedding extraction. Results: The best model\n(ClinicalT5+Transformer+MLP) had 77.6% AUC predicting which trial arm has a\nhigher proportion of patients with SAEs. When predicting proportion of\nparticipants experiencing SAE in the control arm, the same model achieved RMSE\nof 18.6%. The sliding window approach consistently outperformed methods without\nit. Across 12 classifiers, the average absolute AUC increase was 2.00%; across\n12 regressors, the average absolute RMSE reduction was 1.58%. Discussion:\nSummary results data available at ClinicalTrials.gov remains underutilised. The\npotential to estimate results of trials before they start is an opportunity to\nimprove trial design and flag discrepancies between expected and reported\nsafety results.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5229\u7528\u4e34\u5e8a\u8bd5\u9a8c\u6ce8\u518c\u4fe1\u606f\u9884\u6d4b\u4e25\u91cd\u4e0d\u826f\u4e8b\u4ef6\uff08SAE\uff09\u7ed3\u679c\u7684\u65b9\u6cd5\uff0c\u5f00\u53d1\u4e86\u5206\u7c7b\u548c\u56de\u5f52\u6a21\u578b\uff0c\u5e76\u91c7\u7528\u6ed1\u52a8\u7a97\u53e3\u65b9\u6cd5\u4f18\u5316\u957f\u6587\u672c\u5904\u7406\u3002", "motivation": "\u901a\u8fc7\u51c6\u786e\u9884\u6d4bSAE\u7ed3\u679c\uff0c\u4f18\u5316\u4e34\u5e8a\u8bd5\u9a8c\u8bbe\u8ba1\uff0c\u51cf\u5c11\u8bd5\u9a8c\u7ec8\u6b62\u548c\u53c2\u4e0e\u8005\u98ce\u9669\u3002", "method": "\u5206\u6790\u4e8622,107\u9879\u4e34\u5e8a\u8bd5\u9a8c\u6570\u636e\uff0c\u5f00\u53d1\u4e86\u5206\u7c7b\u548c\u56de\u5f52\u6a21\u578b\uff0c\u91c7\u7528\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff08\u5982ClinicalT5\u3001BioBERT\uff09\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u5e76\u7ed3\u5408\u6ed1\u52a8\u7a97\u53e3\u65b9\u6cd5\u5904\u7406\u957f\u6587\u672c\u3002", "result": "\u6700\u4f73\u6a21\u578b\uff08ClinicalT5+Transformer+MLP\uff09\u5728\u9884\u6d4bSAE\u6bd4\u4f8b\u65f6AUC\u4e3a77.6%\uff0c\u63a7\u5236\u7ec4SAE\u6bd4\u4f8b\u7684RMSE\u4e3a18.6%\u3002\u6ed1\u52a8\u7a97\u53e3\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "conclusion": "\u4e34\u5e8a\u8bd5\u9a8c\u6ce8\u518c\u6570\u636e\u672a\u88ab\u5145\u5206\u5229\u7528\uff0c\u9884\u6d4bSAE\u7ed3\u679c\u6709\u52a9\u4e8e\u4f18\u5316\u8bd5\u9a8c\u8bbe\u8ba1\u548c\u53d1\u73b0\u9884\u671f\u4e0e\u62a5\u544a\u7ed3\u679c\u95f4\u7684\u5dee\u5f02\u3002"}}
{"id": "2507.23440", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23440", "abs": "https://arxiv.org/abs/2507.23440", "authors": ["Mingzhe Li", "Xin Lu", "Yanyan Zhao"], "title": "Self-Foveate: Enhancing Diversity and Difficulty of Synthesized Instructions from Unsupervised Text via Multi-Level Foveation", "comment": "Accepted by Findings of ACL 2025", "summary": "Large language models (LLMs) with instruction following capabilities have\ndemonstrated impressive problem-solving abilities. While synthesizing\ninstructional data from unsupervised text has become a common approach for\ntraining such models, conventional methods rely heavily on human effort for\ndata annotation. Although existing automated synthesis paradigms have\nalleviated this constraint, they still exhibit significant limitations in\nensuring adequate diversity and difficulty of synthesized instructions. To\naddress these challenges, we propose Self-Foveate, an innovative LLM-driven\nmethod for instruction synthesis. This approach introduces a\n\"Micro-Scatter-Macro\" multi-level foveation methodology that effectively guides\nthe LLM to deeply excavate fine-grained information embedded in unsupervised\ntext, thereby enhancing both the diversity and difficulty of synthesized\ninstructions. Comprehensive experiments across multiple unsupervised corpora\nand diverse model architectures validate the effectiveness and superiority of\nour proposed method. We publicly release our data and codes:\nhttps://github.com/Mubuky/Self-Foveate", "AI": {"tldr": "Self-Foveate\u662f\u4e00\u79cd\u521b\u65b0\u7684LLM\u9a71\u52a8\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u7ea7\u6ce8\u89c6\u6280\u672f\u63d0\u5347\u6307\u4ee4\u5408\u6210\u7684\u591a\u6837\u6027\u548c\u96be\u5ea6\u3002", "motivation": "\u4f20\u7edf\u6307\u4ee4\u5408\u6210\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u6807\u6ce8\u4e14\u81ea\u52a8\u5316\u65b9\u6cd5\u5728\u591a\u6837\u6027\u548c\u96be\u5ea6\u4e0a\u5b58\u5728\u5c40\u9650\u3002", "method": "\u63d0\u51faMicro-Scatter-Macro\u591a\u7ea7\u6ce8\u89c6\u65b9\u6cd5\uff0c\u6307\u5bfcLLM\u4ece\u65e0\u76d1\u7763\u6587\u672c\u4e2d\u6316\u6398\u7ec6\u7c92\u5ea6\u4fe1\u606f\u3002", "result": "\u5728\u591a\u4e2a\u65e0\u76d1\u7763\u8bed\u6599\u5e93\u548c\u6a21\u578b\u67b6\u6784\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u4f18\u8d8a\u6027\u3002", "conclusion": "Self-Foveate\u663e\u8457\u63d0\u5347\u4e86\u6307\u4ee4\u5408\u6210\u7684\u591a\u6837\u6027\u548c\u96be\u5ea6\uff0c\u4ee3\u7801\u548c\u6570\u636e\u5df2\u516c\u5f00\u3002"}}
{"id": "2507.22920", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22920", "abs": "https://arxiv.org/abs/2507.22920", "authors": ["Jindong Li", "Yali Fu", "Jiahong Liu", "Linxiao Cao", "Wei Ji", "Menglin Yang", "Irwin King", "Ming-Hsuan Yang"], "title": "Discrete Tokenization for Multimodal LLMs: A Comprehensive Survey", "comment": null, "summary": "The rapid advancement of large language models (LLMs) has intensified the\nneed for effective mechanisms to transform continuous multimodal data into\ndiscrete representations suitable for language-based processing. Discrete\ntokenization, with vector quantization (VQ) as a central approach, offers both\ncomputational efficiency and compatibility with LLM architectures. Despite its\ngrowing importance, there is a lack of a comprehensive survey that\nsystematically examines VQ techniques in the context of LLM-based systems. This\nwork fills this gap by presenting the first structured taxonomy and analysis of\ndiscrete tokenization methods designed for LLMs. We categorize 8 representative\nVQ variants that span classical and modern paradigms and analyze their\nalgorithmic principles, training dynamics, and integration challenges with LLM\npipelines. Beyond algorithm-level investigation, we discuss existing research\nin terms of classical applications without LLMs, LLM-based single-modality\nsystems, and LLM-based multimodal systems, highlighting how quantization\nstrategies influence alignment, reasoning, and generation performance. In\naddition, we identify key challenges including codebook collapse, unstable\ngradient estimation, and modality-specific encoding constraints. Finally, we\ndiscuss emerging research directions such as dynamic and task-adaptive\nquantization, unified tokenization frameworks, and biologically inspired\ncodebook learning. This survey bridges the gap between traditional vector\nquantization and modern LLM applications, serving as a foundational reference\nfor the development of efficient and generalizable multimodal systems. A\ncontinuously updated version is available at:\nhttps://github.com/jindongli-Ai/LLM-Discrete-Tokenization-Survey.", "AI": {"tldr": "\u8be5\u8bba\u6587\u586b\u8865\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e2d\u79bb\u6563\u6807\u8bb0\u5316\u65b9\u6cd5\u7684\u7efc\u8ff0\u7a7a\u767d\uff0c\u63d0\u51fa\u4e868\u79cd\u5411\u91cf\u91cf\u5316\uff08VQ\uff09\u53d8\u4f53\u7684\u5206\u7c7b\u4e0e\u5206\u6790\uff0c\u5e76\u63a2\u8ba8\u4e86\u5176\u5728LLM\u4e2d\u7684\u5e94\u7528\u4e0e\u6311\u6218\u3002", "motivation": "\u968f\u7740LLM\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u9700\u8981\u5c06\u8fde\u7eed\u591a\u6a21\u6001\u6570\u636e\u8f6c\u6362\u4e3a\u9002\u5408\u8bed\u8a00\u5904\u7406\u7684\u79bb\u6563\u8868\u793a\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u5bf9VQ\u6280\u672f\u5728LLM\u4e2d\u5e94\u7528\u7684\u5168\u9762\u7efc\u8ff0\u3002", "method": "\u63d0\u51fa\u4e86\u9996\u4e2a\u9488\u5bf9LLM\u7684\u79bb\u6563\u6807\u8bb0\u5316\u65b9\u6cd5\u7684\u7ed3\u6784\u5316\u5206\u7c7b\u4e0e\u5206\u6790\uff0c\u6db5\u76d68\u79cdVQ\u53d8\u4f53\uff0c\u5e76\u7814\u7a76\u4e86\u5176\u7b97\u6cd5\u539f\u7406\u3001\u8bad\u7ec3\u52a8\u6001\u53ca\u4e0eLLM\u7684\u96c6\u6210\u6311\u6218\u3002", "result": "\u5206\u6790\u4e86VQ\u5728LLM\u4e2d\u7684\u5f71\u54cd\uff0c\u5305\u62ec\u5bf9\u9f50\u3001\u63a8\u7406\u548c\u751f\u6210\u6027\u80fd\uff0c\u5e76\u6307\u51fa\u4e86\u4ee3\u7801\u672c\u5d29\u6e83\u3001\u68af\u5ea6\u4f30\u8ba1\u4e0d\u7a33\u5b9a\u7b49\u5173\u952e\u6311\u6218\u3002", "conclusion": "\u8be5\u7efc\u8ff0\u4e3a\u9ad8\u6548\u4e14\u901a\u7528\u7684\u591a\u6a21\u6001\u7cfb\u7edf\u5f00\u53d1\u63d0\u4f9b\u4e86\u57fa\u7840\u53c2\u8003\uff0c\u5e76\u63d0\u51fa\u4e86\u52a8\u6001\u91cf\u5316\u3001\u7edf\u4e00\u6807\u8bb0\u5316\u6846\u67b6\u7b49\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2507.23488", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23488", "abs": "https://arxiv.org/abs/2507.23488", "authors": ["Kacper Kadziolka", "Saber Salehkaleybar"], "title": "Causal Reasoning in Pieces: Modular In-Context Learning for Causal Discovery", "comment": null, "summary": "Causal inference remains a fundamental challenge for large language models.\nRecent advances in internal reasoning with large language models have sparked\ninterest in whether state-of-the-art reasoning models can robustly perform\ncausal discovery-a task where conventional models often suffer from severe\noverfitting and near-random performance under data perturbations. We study\ncausal discovery on the Corr2Cause benchmark using the emergent OpenAI's\no-series and DeepSeek-R model families and find that these reasoning-first\narchitectures achieve significantly greater native gains than prior approaches.\nTo capitalize on these strengths, we introduce a modular in-context pipeline\ninspired by the Tree-of-Thoughts and Chain-of-Thoughts methodologies, yielding\nnearly three-fold improvements over conventional baselines. We further probe\nthe pipeline's impact by analyzing reasoning chain length, complexity, and\nconducting qualitative and quantitative comparisons between conventional and\nreasoning models. Our findings suggest that while advanced reasoning models\nrepresent a substantial leap forward, carefully structured in-context\nframeworks are essential to maximize their capabilities and offer a\ngeneralizable blueprint for causal discovery across diverse domains.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u57fa\u4e8e\u63a8\u7406\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5728\u56e0\u679c\u53d1\u73b0\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u6a21\u5757\u5316\u4e0a\u4e0b\u6587\u7ba1\u9053\uff0c\u6027\u80fd\u63d0\u5347\u663e\u8457\u3002", "motivation": "\u63a2\u7d22\u5927\u8bed\u8a00\u6a21\u578b\u5728\u56e0\u679c\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\uff0c\u89e3\u51b3\u4f20\u7edf\u6a21\u578b\u5728\u6570\u636e\u6270\u52a8\u4e0b\u7684\u8fc7\u62df\u5408\u548c\u6027\u80fd\u4f4e\u4e0b\u95ee\u9898\u3002", "method": "\u4f7f\u7528OpenAI\u7684o\u7cfb\u5217\u548cDeepSeek-R\u6a21\u578b\uff0c\u7ed3\u5408Tree-of-Thoughts\u548cChain-of-Thoughts\u65b9\u6cd5\uff0c\u6784\u5efa\u6a21\u5757\u5316\u4e0a\u4e0b\u6587\u7ba1\u9053\u3002", "result": "\u63a8\u7406\u6a21\u578b\u6027\u80fd\u663e\u8457\u63d0\u5347\uff0c\u7ba1\u9053\u65b9\u6cd5\u6bd4\u4f20\u7edf\u57fa\u7ebf\u63d0\u9ad8\u4e86\u8fd1\u4e09\u500d\u3002", "conclusion": "\u9ad8\u7ea7\u63a8\u7406\u6a21\u578b\u7ed3\u5408\u7ed3\u6784\u5316\u4e0a\u4e0b\u6587\u6846\u67b6\u662f\u56e0\u679c\u53d1\u73b0\u4efb\u52a1\u7684\u5173\u952e\uff0c\u4e3a\u8de8\u9886\u57df\u5e94\u7528\u63d0\u4f9b\u4e86\u901a\u7528\u84dd\u56fe\u3002"}}
{"id": "2507.22921", "categories": ["cs.CL", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2507.22921", "abs": "https://arxiv.org/abs/2507.22921", "authors": ["Lee Harris"], "title": "Fast and Accurate Contextual Knowledge Extraction Using Cascading Language Model Chains and Candidate Answers", "comment": null, "summary": "Language models can capture complex relationships in given text, but these\nare notorious for being costly and for producing information that does not\nexist (i.e., hallucinations). Furthermore, the resources invested into\nproducing this information would be wasted if it were incorrect. We address\nthese issues by proposing, implementing, and applying the Language Model Chain\n(LMC) algorithm. In this, a language model's response to a given prompt about\ngiven text is only correct if it exists in the collection of possible (i.e.,\ncandidate) answers, and text corresponding to incorrect responses is fed into a\nmore predictive (but slower) language model. This process is repeated for a\ncollection of language models, or until all predictions about the text are\ncorrect. We used the LMC algorithm to extract patient dates of birth from\nmedical documents, and combining a collection of language models in a\nmulti-stage cascade significantly increased prediction speed and accuracy over\nindividual language models, while greatly reducing the number of corresponding\nhallucinations. We believe that the novel LMC algorithm significantly\ncontributes to the knowledge extraction field, and that this should be explored\nmuch further in the future.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u8bed\u8a00\u6a21\u578b\u94fe\uff08LMC\uff09\u7684\u7b97\u6cd5\uff0c\u901a\u8fc7\u591a\u9636\u6bb5\u7ea7\u8054\u8bed\u8a00\u6a21\u578b\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u9884\u6d4b\u901f\u5ea6\u548c\u51c6\u786e\u6027\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u5e7b\u89c9\u73b0\u8c61\u3002", "motivation": "\u89e3\u51b3\u8bed\u8a00\u6a21\u578b\u5728\u6587\u672c\u5904\u7406\u4e2d\u7684\u9ad8\u6210\u672c\u548c\u5e7b\u89c9\u95ee\u9898\uff0c\u907f\u514d\u8d44\u6e90\u6d6a\u8d39\u3002", "method": "\u63d0\u51faLMC\u7b97\u6cd5\uff0c\u901a\u8fc7\u7ea7\u8054\u591a\u4e2a\u8bed\u8a00\u6a21\u578b\uff0c\u4ec5\u63a5\u53d7\u5b58\u5728\u4e8e\u5019\u9009\u7b54\u6848\u4e2d\u7684\u6b63\u786e\u54cd\u5e94\uff0c\u5e76\u5c06\u9519\u8bef\u54cd\u5e94\u8f93\u5165\u66f4\u6162\u4f46\u66f4\u51c6\u786e\u7684\u6a21\u578b\u3002", "result": "\u5728\u533b\u7597\u6587\u6863\u4e2d\u63d0\u53d6\u60a3\u8005\u51fa\u751f\u65e5\u671f\u7684\u5b9e\u9a8c\u4e2d\uff0cLMC\u663e\u8457\u63d0\u9ad8\u4e86\u901f\u5ea6\u548c\u51c6\u786e\u6027\uff0c\u51cf\u5c11\u4e86\u5e7b\u89c9\u3002", "conclusion": "LMC\u7b97\u6cd5\u4e3a\u77e5\u8bc6\u63d0\u53d6\u9886\u57df\u505a\u51fa\u4e86\u91cd\u8981\u8d21\u732e\uff0c\u503c\u5f97\u8fdb\u4e00\u6b65\u63a2\u7d22\u3002"}}
{"id": "2507.23497", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.23497", "abs": "https://arxiv.org/abs/2507.23497", "authors": ["David A Kelly", "Hana Chockler"], "title": "Causal Identification of Sufficient, Contrastive and Complete Feature Sets in Image Classification", "comment": "13 pages, 13 figures, appendix included", "summary": "Existing algorithms for explaining the outputs of image classifiers are based\non a variety of approaches and produce explanations that lack formal rigor. On\nthe other hand, logic-based explanations are formally and rigorously defined\nbut their computability relies on strict assumptions about the model that do\nnot hold on image classifiers.\n  In this paper, we show that causal explanations, in addition to being\nformally and rigorously defined, enjoy the same formal properties as\nlogic-based ones, while still lending themselves to black-box algorithms and\nbeing a natural fit for image classifiers. We prove formal properties of causal\nexplanations and introduce contrastive causal explanations for image\nclassifiers. Moreover, we augment the definition of explanation with confidence\nawareness and introduce complete causal explanations: explanations that are\nclassified with exactly the same confidence as the original image.\n  We implement our definitions, and our experimental results demonstrate that\ndifferent models have different patterns of sufficiency, contrastiveness, and\ncompleteness. Our algorithms are efficiently computable, taking on average 6s\nper image on a ResNet50 model to compute all types of explanations, and are\ntotally black-box, needing no knowledge of the model, no access to model\ninternals, no access to gradient, nor requiring any properties, such as\nmonotonicity, of the model.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u56e0\u679c\u89e3\u91ca\u65b9\u6cd5\uff0c\u7ed3\u5408\u5f62\u5f0f\u4e25\u8c28\u6027\u548c\u5b9e\u7528\u6027\uff0c\u9002\u7528\u4e8e\u56fe\u50cf\u5206\u7c7b\u5668\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u9ad8\u6548\u6027\u548c\u9ed1\u76d2\u7279\u6027\u3002", "motivation": "\u73b0\u6709\u56fe\u50cf\u5206\u7c7b\u5668\u89e3\u91ca\u65b9\u6cd5\u7f3a\u4e4f\u5f62\u5f0f\u4e25\u8c28\u6027\uff0c\u800c\u903b\u8f91\u89e3\u91ca\u867d\u4e25\u8c28\u4f46\u5047\u8bbe\u4e25\u683c\uff0c\u4e0d\u9002\u7528\u4e8e\u56fe\u50cf\u5206\u7c7b\u5668\u3002", "method": "\u5f15\u5165\u56e0\u679c\u89e3\u91ca\uff0c\u8bc1\u660e\u5176\u5f62\u5f0f\u6027\u8d28\uff0c\u63d0\u51fa\u5bf9\u6bd4\u56e0\u679c\u89e3\u91ca\u548c\u7f6e\u4fe1\u611f\u77e5\u7684\u5b8c\u6574\u56e0\u679c\u89e3\u91ca\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u4e0d\u540c\u6a21\u578b\u5728\u5145\u5206\u6027\u3001\u5bf9\u6bd4\u6027\u548c\u5b8c\u6574\u6027\u4e0a\u6709\u4e0d\u540c\u6a21\u5f0f\uff0c\u7b97\u6cd5\u9ad8\u6548\u4e14\u5b8c\u5168\u9ed1\u76d2\u3002", "conclusion": "\u56e0\u679c\u89e3\u91ca\u517c\u5177\u5f62\u5f0f\u4e25\u8c28\u6027\u548c\u5b9e\u7528\u6027\uff0c\u9002\u7528\u4e8e\u56fe\u50cf\u5206\u7c7b\u5668\uff0c\u4e14\u8ba1\u7b97\u9ad8\u6548\u3002"}}
{"id": "2507.22922", "categories": ["cs.CL", "cs.AI", "cs.SI"], "pdf": "https://arxiv.org/pdf/2507.22922", "abs": "https://arxiv.org/abs/2507.22922", "authors": ["Mateusz Kmak", "Kamil Chmurzy\u0144ski", "Kamil Matejuk", "Pawe\u0142 Kotzbach", "Jan Koco\u0144"], "title": "Predicting stock prices with ChatGPT-annotated Reddit sentiment", "comment": "International Conference on Computational Science 2025", "summary": "The surge of retail investor activity on social media, exemplified by the\n2021 GameStop short squeeze, raised questions about the influence of online\nsentiment on stock prices. This paper explores whether sentiment derived from\nsocial media discussions can meaningfully predict stock market movements. We\nfocus on Reddit's r/wallstreetbets and analyze sentiment related to two\ncompanies: GameStop (GME) and AMC Entertainment (AMC). To assess sentiment's\nrole, we employ two existing text-based sentiment analysis methods and\nintroduce a third, a ChatGPT-annotated and fine-tuned RoBERTa-based model\ndesigned to better interpret the informal language and emojis prevalent in\nsocial media discussions. We use correlation and causality metrics to determine\nthese models' predictive power. Surprisingly, our findings suggest that social\nmedia sentiment has only a weak correlation with stock prices. At the same\ntime, simpler metrics, such as the volume of comments and Google search trends,\nexhibit stronger predictive signals. These results highlight the complexity of\nretail investor behavior and suggest that traditional sentiment analysis may\nnot fully capture the nuances of market-moving online discussions.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u793e\u4ea4\u5a92\u4f53\u60c5\u7eea\u5bf9\u80a1\u4ef7\u9884\u6d4b\u80fd\u529b\u8f83\u5f31\uff0c\u800c\u8bc4\u8bba\u91cf\u548c\u641c\u7d22\u8d8b\u52bf\u66f4\u5177\u9884\u6d4b\u6027\u3002", "motivation": "\u63a2\u8ba8\u793e\u4ea4\u5a92\u4f53\u60c5\u7eea\uff08\u5982Reddit\u7684r/wallstreetbets\uff09\u662f\u5426\u80fd\u6709\u6548\u9884\u6d4b\u80a1\u4ef7\u53d8\u52a8\u3002", "method": "\u4f7f\u7528\u4e24\u79cd\u73b0\u6709\u6587\u672c\u60c5\u7eea\u5206\u6790\u65b9\u6cd5\uff0c\u5e76\u5f15\u5165\u57fa\u4e8eChatGPT\u6807\u6ce8\u548c\u5fae\u8c03\u7684RoBERTa\u6a21\u578b\uff0c\u5206\u6790GameStop\u548cAMC\u7684\u8ba8\u8bba\u3002", "result": "\u793e\u4ea4\u5a92\u4f53\u60c5\u7eea\u4e0e\u80a1\u4ef7\u76f8\u5173\u6027\u8f83\u5f31\uff0c\u8bc4\u8bba\u91cf\u548c\u641c\u7d22\u8d8b\u52bf\u66f4\u5177\u9884\u6d4b\u6027\u3002", "conclusion": "\u4f20\u7edf\u60c5\u7eea\u5206\u6790\u65b9\u6cd5\u53ef\u80fd\u65e0\u6cd5\u5b8c\u5168\u6355\u6349\u5728\u7ebf\u8ba8\u8bba\u5bf9\u5e02\u573a\u7684\u5f71\u54cd\uff0c\u96f6\u552e\u6295\u8d44\u8005\u884c\u4e3a\u590d\u6742\u3002"}}
{"id": "2507.23554", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23554", "abs": "https://arxiv.org/abs/2507.23554", "authors": ["Ruoyu Wang", "Junda Wu", "Yu Xia", "Tong Yu", "Ryan A. Rossi", "Julian McAuley", "Lina Yao"], "title": "DICE: Dynamic In-Context Example Selection in LLM Agents via Efficient Knowledge Transfer", "comment": null, "summary": "Large language model-based agents, empowered by in-context learning (ICL),\nhave demonstrated strong capabilities in complex reasoning and tool-use tasks.\nHowever, existing works have shown that the effectiveness of ICL is highly\nsensitive to the choice of demonstrations, with suboptimal examples often\nleading to unstable or degraded performance. While prior work has explored\nexample selection, including in some agentic or multi-step settings, existing\napproaches typically rely on heuristics or task-specific designs and lack a\ngeneral, theoretically grounded criterion for what constitutes an effective\ndemonstration across reasoning steps. Therefore, it is non-trivial to develop a\nprincipled, general-purpose method for selecting demonstrations that\nconsistently benefit agent performance. In this paper, we address this\nchallenge with DICE, Dynamic In-Context Example Selection for LLM Agents, a\ntheoretically grounded ICL framework for agentic tasks that selects the most\nrelevant demonstrations at each step of reasoning. Our approach decomposes\ndemonstration knowledge into transferable and non-transferable components\nthrough a causal lens, showing how the latter can introduce spurious\ndependencies that impair generalization. We further propose a stepwise\nselection criterion with a formal guarantee of improved agent performance.\nImportantly, DICE is a general, framework-agnostic solution that can be\nintegrated as a plug-in module into existing agentic frameworks without any\nadditional training cost. Extensive experiments across diverse domains\ndemonstrate our method's effectiveness and generality, highlighting the\nimportance of principled, context-aware demo selection for robust and efficient\nLLM agents.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faDICE\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u9009\u62e9\u4e0a\u4e0b\u6587\u793a\u4f8b\u63d0\u5347LLM\u4ee3\u7406\u7684\u6027\u80fd\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u542f\u53d1\u5f0f\u6216\u4efb\u52a1\u7279\u5b9a\u8bbe\u8ba1\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u4e0a\u4e0b\u6587\u5b66\u4e60\u7684LLM\u4ee3\u7406\u6027\u80fd\u5bf9\u793a\u4f8b\u9009\u62e9\u654f\u611f\uff0c\u7f3a\u4e4f\u901a\u7528\u4e14\u7406\u8bba\u652f\u6301\u7684\u9009\u62e9\u6807\u51c6\u3002", "method": "\u63d0\u51faDICE\u6846\u67b6\uff0c\u901a\u8fc7\u56e0\u679c\u89c6\u89d2\u5206\u89e3\u793a\u4f8b\u77e5\u8bc6\uff0c\u63d0\u51fa\u9010\u6b65\u9009\u62e9\u6807\u51c6\uff0c\u5e76\u4fdd\u8bc1\u6027\u80fd\u63d0\u5347\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eDICE\u5728\u591a\u4e2a\u9886\u57df\u6709\u6548\u4e14\u901a\u7528\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u6210\u672c\u3002", "conclusion": "DICE\u4e3aLLM\u4ee3\u7406\u63d0\u4f9b\u4e86\u4e00\u79cd\u901a\u7528\u3001\u7406\u8bba\u652f\u6301\u7684\u793a\u4f8b\u9009\u62e9\u65b9\u6cd5\uff0c\u63d0\u5347\u4e86\u6027\u80fd\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2507.22923", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22923", "abs": "https://arxiv.org/abs/2507.22923", "authors": ["Aman Gupta", "Yingying Zhuang", "Zhou Yu", "Ziji Zhang", "Anurag Beniwal"], "title": "How and Where to Translate? The Impact of Translation Strategies in Cross-lingual LLM Prompting", "comment": "Accepted at Prompt Optimization KDD '25", "summary": "Despite advances in the multilingual capabilities of Large Language Models\n(LLMs), their performance varies substantially across different languages and\ntasks. In multilingual retrieval-augmented generation (RAG)-based systems,\nknowledge bases (KB) are often shared from high-resource languages (such as\nEnglish) to low-resource ones, resulting in retrieved information from the KB\nbeing in a different language than the rest of the context. In such scenarios,\ntwo common practices are pre-translation to create a mono-lingual prompt and\ncross-lingual prompting for direct inference. However, the impact of these\nchoices remains unclear. In this paper, we systematically evaluate the impact\nof different prompt translation strategies for classification tasks with\nRAG-enhanced LLMs in multilingual systems. Experimental results show that an\noptimized prompting strategy can significantly improve knowledge sharing across\nlanguages, therefore improve the performance on the downstream classification\ntask. The findings advocate for a broader utilization of multilingual resource\nsharing and cross-lingual prompt optimization for non-English languages,\nespecially the low-resource ones.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u591a\u8bed\u8a00\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7cfb\u7edf\u4e2d\u63d0\u793a\u7ffb\u8bd1\u7b56\u7565\u5bf9\u5206\u7c7b\u4efb\u52a1\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u4f18\u5316\u7b56\u7565\u80fd\u663e\u8457\u63d0\u5347\u8de8\u8bed\u8a00\u77e5\u8bc6\u5171\u4eab\u548c\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u591a\u8bed\u8a00\u80fd\u529b\u4e0a\u6709\u6240\u8fdb\u6b65\uff0c\u4f46\u5176\u5728\u4e0d\u540c\u8bed\u8a00\u548c\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u5dee\u5f02\u663e\u8457\u3002\u591a\u8bed\u8a00RAG\u7cfb\u7edf\u4e2d\uff0c\u77e5\u8bc6\u5e93\uff08KB\uff09\u5e38\u4ece\u9ad8\u8d44\u6e90\u8bed\u8a00\uff08\u5982\u82f1\u8bed\uff09\u5171\u4eab\u5230\u4f4e\u8d44\u6e90\u8bed\u8a00\uff0c\u5bfc\u81f4\u68c0\u7d22\u4fe1\u606f\u4e0e\u4e0a\u4e0b\u6587\u8bed\u8a00\u4e0d\u4e00\u81f4\u3002", "method": "\u7cfb\u7edf\u8bc4\u4f30\u4e86RAG\u589e\u5f3aLLMs\u5728\u591a\u8bed\u8a00\u7cfb\u7edf\u4e2d\u4e0d\u540c\u63d0\u793a\u7ffb\u8bd1\u7b56\u7565\u5bf9\u5206\u7c7b\u4efb\u52a1\u7684\u5f71\u54cd\uff0c\u6bd4\u8f83\u4e86\u9884\u7ffb\u8bd1\u548c\u8de8\u8bed\u8a00\u63d0\u793a\u4e24\u79cd\u5e38\u89c1\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4f18\u5316\u7684\u63d0\u793a\u7b56\u7565\u80fd\u663e\u8457\u63d0\u5347\u8de8\u8bed\u8a00\u77e5\u8bc6\u5171\u4eab\uff0c\u4ece\u800c\u6539\u5584\u4e0b\u6e38\u5206\u7c7b\u4efb\u52a1\u7684\u6027\u80fd\u3002", "conclusion": "\u7814\u7a76\u4e3b\u5f20\u66f4\u5e7f\u6cdb\u5730\u5229\u7528\u591a\u8bed\u8a00\u8d44\u6e90\u5171\u4eab\u548c\u8de8\u8bed\u8a00\u63d0\u793a\u4f18\u5316\uff0c\u5c24\u5176\u662f\u5bf9\u4f4e\u8d44\u6e90\u8bed\u8a00\u3002"}}
{"id": "2507.23565", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23565", "abs": "https://arxiv.org/abs/2507.23565", "authors": ["Botao Zhu", "Xianbin Wang", "Dusit Niyato"], "title": "Semantic Chain-of-Trust: Autonomous Trust Orchestration for Collaborator Selection via Hypergraph-Aided Agentic AI", "comment": null, "summary": "In collaborative systems, the effective completion of tasks hinges on\ntask-specific trust evaluations of potential devices for distributed\ncollaboration. However, the complexity of tasks, the spatiotemporal dynamism of\ndistributed device resources, and the inevitable assessment overhead\ndramatically increase the complexity and resource consumption of the trust\nevaluation process. As a result, ill-timed or overly frequent trust evaluations\ncan reduce utilization rate of constrained resources, negatively affecting\ncollaborative task execution. To address this challenge, this paper proposes an\nautonomous trust orchestration method based on a new concept of semantic\nchain-of-trust. Our technique employs agentic AI and hypergraph to establish\nand maintain trust relationships among devices. By leveraging its strengths in\nautonomous perception, task decomposition, and semantic reasoning, we propose\nagentic AI to perceive device states and autonomously perform trust evaluations\nof collaborators based on historical performance data only during device idle\nperiods, thereby enabling efficient utilization of distributed resources. In\naddition, agentic AI performs task-specific trust evaluations on collaborator\nresources by analyzing the alignment between resource capabilities and task\nrequirements. Moreover, by maintaining a trust hypergraph embedded with trust\nsemantics for each device, agentic AI enables hierarchical management of\ncollaborators and identifies collaborators requiring trust evaluation based on\ntrust semantics, thereby achieving a balance between overhead and trust\naccuracy. Furthermore, local trust hypergraphs from multiple devices can be\nchained together to support multi-hop collaboration, enabling efficient\ncoordination in large-scale systems. Experimental results demonstrate that the\nproposed method achieves resource-efficient trust evaluation.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u8bed\u4e49\u4fe1\u4efb\u94fe\u7684\u81ea\u4e3b\u4fe1\u4efb\u7f16\u6392\u65b9\u6cd5\uff0c\u5229\u7528\u667a\u80fd\u4ee3\u7406\u548c\u8d85\u56fe\u6280\u672f\u4f18\u5316\u5206\u5e03\u5f0f\u534f\u4f5c\u4e2d\u7684\u4fe1\u4efb\u8bc4\u4f30\uff0c\u63d0\u9ad8\u8d44\u6e90\u5229\u7528\u7387\u3002", "motivation": "\u5206\u5e03\u5f0f\u534f\u4f5c\u4e2d\uff0c\u4efb\u52a1\u590d\u6742\u6027\u3001\u8bbe\u5907\u8d44\u6e90\u52a8\u6001\u6027\u53ca\u8bc4\u4f30\u5f00\u9500\u589e\u52a0\u4e86\u4fe1\u4efb\u8bc4\u4f30\u7684\u590d\u6742\u5ea6\uff0c\u5f71\u54cd\u8d44\u6e90\u5229\u7528\u548c\u4efb\u52a1\u6267\u884c\u6548\u7387\u3002", "method": "\u91c7\u7528\u667a\u80fd\u4ee3\u7406\u548c\u8d85\u56fe\u6280\u672f\uff0c\u57fa\u4e8e\u5386\u53f2\u6570\u636e\u548c\u8bbe\u5907\u7a7a\u95f2\u671f\u8fdb\u884c\u81ea\u4e3b\u4fe1\u4efb\u8bc4\u4f30\uff0c\u5e76\u901a\u8fc7\u4fe1\u4efb\u8bed\u4e49\u8d85\u56fe\u5b9e\u73b0\u5206\u5c42\u7ba1\u7406\u548c\u591a\u8df3\u534f\u4f5c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u8d44\u6e90\u9ad8\u6548\u7684\u4fe1\u4efb\u8bc4\u4f30\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u6548\u5e73\u8861\u4e86\u8bc4\u4f30\u5f00\u9500\u4e0e\u4fe1\u4efb\u51c6\u786e\u6027\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u5206\u5e03\u5f0f\u7cfb\u7edf\u3002"}}
{"id": "2507.22924", "categories": ["cs.CL", "I.2.7; K.3.1"], "pdf": "https://arxiv.org/pdf/2507.22924", "abs": "https://arxiv.org/abs/2507.22924", "authors": ["Brittney Exline", "Melanie Duffin", "Brittany Harbison", "Chrissa da Gomez", "David Joyner"], "title": "Using Sentiment Analysis to Investigate Peer Feedback by Native and Non-Native English Speakers", "comment": null, "summary": "Graduate-level CS programs in the U.S. increasingly enroll international\nstudents, with 60.2 percent of master's degrees in 2023 awarded to non-U.S.\nstudents. Many of these students take online courses, where peer feedback is\nused to engage students and improve pedagogy in a scalable manner. Since these\ncourses are conducted in English, many students study in a language other than\ntheir first. This paper examines how native versus non-native English speaker\nstatus affects three metrics of peer feedback experience in online U.S.-based\ncomputing courses. Using the Twitter-roBERTa-based model, we analyze the\nsentiment of peer reviews written by and to a random sample of 500 students. We\nthen relate sentiment scores and peer feedback ratings to students' language\nbackground. Results show that native English speakers rate feedback less\nfavorably, while non-native speakers write more positively but receive less\npositive sentiment in return. When controlling for sex and age, significant\ninteractions emerge, suggesting that language background plays a modest but\ncomplex role in shaping peer feedback experiences.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u5728\u7f8e\u56fd\u5728\u7ebf\u8ba1\u7b97\u673a\u8bfe\u7a0b\u4e2d\uff0c\u82f1\u8bed\u6bcd\u8bed\u4e0e\u975e\u6bcd\u8bed\u5b66\u751f\u5728\u540c\u4f34\u53cd\u9988\u4f53\u9a8c\u4e2d\u7684\u5dee\u5f02\u3002", "motivation": "\u968f\u7740\u7f8e\u56fd\u7814\u7a76\u751f\u8ba1\u7b97\u673a\u8bfe\u7a0b\u4e2d\u56fd\u9645\u5b66\u751f\u6bd4\u4f8b\u589e\u52a0\uff082023\u5e7460.2%\u7855\u58eb\u6388\u4e88\u975e\u7f8e\u56fd\u5b66\u751f\uff09\uff0c\u4e86\u89e3\u8bed\u8a00\u80cc\u666f\u5bf9\u540c\u4f34\u53cd\u9988\u7684\u5f71\u54cd\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u4f7f\u7528Twitter-roBERTa\u6a21\u578b\u5206\u6790500\u540d\u5b66\u751f\u7684\u540c\u4f34\u53cd\u9988\u60c5\u611f\uff0c\u5e76\u7ed3\u5408\u8bed\u8a00\u80cc\u666f\u3001\u6027\u522b\u548c\u5e74\u9f84\u8fdb\u884c\u7edf\u8ba1\u3002", "result": "\u82f1\u8bed\u6bcd\u8bed\u5b66\u751f\u5bf9\u53cd\u9988\u8bc4\u4ef7\u8f83\u4f4e\uff0c\u975e\u6bcd\u8bed\u5b66\u751f\u53cd\u9988\u66f4\u79ef\u6781\u4f46\u6536\u5230\u7684\u60c5\u611f\u66f4\u6d88\u6781\u3002\u8bed\u8a00\u80cc\u666f\u4e0e\u6027\u522b\u3001\u5e74\u9f84\u4ea4\u4e92\u4f5c\u7528\u663e\u8457\u3002", "conclusion": "\u8bed\u8a00\u80cc\u666f\u5bf9\u540c\u4f34\u53cd\u9988\u4f53\u9a8c\u6709\u590d\u6742\u4f46\u9002\u5ea6\u7684\u5f71\u54cd\uff0c\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2507.23633", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23633", "abs": "https://arxiv.org/abs/2507.23633", "authors": ["Qian Zhao", "Zhuo Sun", "Bin Guo", "Zhiwen Yu"], "title": "MemoCue: Empowering LLM-Based Agents for Human Memory Recall via Strategy-Guided Querying", "comment": null, "summary": "Agent-assisted memory recall is one critical research problem in the field of\nhuman-computer interaction. In conventional methods, the agent can retrieve\ninformation from its equipped memory module to help the person recall\nincomplete or vague memories. The limited size of memory module hinders the\nacquisition of complete memories and impacts the memory recall performance in\npractice. Memory theories suggest that the person's relevant memory can be\nproactively activated through some effective cues. Inspired by this, we propose\na novel strategy-guided agent-assisted memory recall method, allowing the agent\nto transform an original query into a cue-rich one via the judiciously designed\nstrategy to help the person recall memories. To this end, there are two key\nchallenges. (1) How to choose the appropriate recall strategy for diverse\nforgetting scenarios with distinct memory-recall characteristics? (2) How to\nobtain the high-quality responses leveraging recall strategies, given only\nabstract and sparsely annotated strategy patterns? To address the challenges,\nwe propose a Recall Router framework. Specifically, we design a 5W Recall Map\nto classify memory queries into five typical scenarios and define fifteen\nrecall strategy patterns across the corresponding scenarios. We then propose a\nhierarchical recall tree combined with the Monte Carlo Tree Search algorithm to\noptimize the selection of strategy and the generation of strategy responses. We\nconstruct an instruction tuning dataset and fine-tune multiple open-source\nlarge language models (LLMs) to develop MemoCue, an agent that excels in\nproviding memory-inspired responses. Experiments on three representative\ndatasets show that MemoCue surpasses LLM-based methods by 17.74% in recall\ninspiration. Further human evaluation highlights its advantages in\nmemory-recall applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7b56\u7565\u5f15\u5bfc\u7684\u4ee3\u7406\u8f85\u52a9\u8bb0\u5fc6\u56de\u5fc6\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bbe\u8ba1\u7b56\u7565\u5c06\u539f\u59cb\u67e5\u8be2\u8f6c\u5316\u4e3a\u7ebf\u7d22\u4e30\u5bcc\u7684\u67e5\u8be2\uff0c\u63d0\u5347\u8bb0\u5fc6\u56de\u5fc6\u6548\u679c\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u4e2d\u4ee3\u7406\u7684\u8bb0\u5fc6\u6a21\u5757\u5bb9\u91cf\u6709\u9650\uff0c\u5f71\u54cd\u8bb0\u5fc6\u56de\u5fc6\u6027\u80fd\u3002\u53d7\u8bb0\u5fc6\u7406\u8bba\u542f\u53d1\uff0c\u901a\u8fc7\u6709\u6548\u7ebf\u7d22\u4e3b\u52a8\u6fc0\u6d3b\u76f8\u5173\u8bb0\u5fc6\u3002", "method": "\u8bbe\u8ba1\u4e865W\u56de\u5fc6\u5730\u56fe\u5206\u7c7b\u8bb0\u5fc6\u67e5\u8be2\uff0c\u5b9a\u4e4915\u79cd\u7b56\u7565\u6a21\u5f0f\uff0c\u7ed3\u5408\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u7b97\u6cd5\u4f18\u5316\u7b56\u7565\u9009\u62e9\u548c\u54cd\u5e94\u751f\u6210\u3002", "result": "\u5b9e\u9a8c\u8868\u660eMemoCue\u5728\u56de\u5fc6\u7075\u611f\u4e0a\u4f18\u4e8e\u57fa\u4e8eLLM\u7684\u65b9\u6cd517.74%\uff0c\u4eba\u7c7b\u8bc4\u4f30\u4e5f\u663e\u793a\u5176\u4f18\u52bf\u3002", "conclusion": "MemoCue\u5728\u8bb0\u5fc6\u56de\u5fc6\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u4ee3\u7406\u8f85\u52a9\u8bb0\u5fc6\u56de\u5fc6\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2507.22925", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22925", "abs": "https://arxiv.org/abs/2507.22925", "authors": ["Haoran Sun", "Shaoning Zeng"], "title": "Hierarchical Memory for High-Efficiency Long-Term Reasoning in LLM Agents", "comment": null, "summary": "Long-term memory is one of the key factors influencing the reasoning\ncapabilities of Large Language Model Agents (LLM Agents). Incorporating a\nmemory mechanism that effectively integrates past interactions can\nsignificantly enhance decision-making and contextual coherence of LLM Agents.\nWhile recent works have made progress in memory storage and retrieval, such as\nencoding memory into dense vectors for similarity-based search or organizing\nknowledge in the form of graph, these approaches often fall short in structured\nmemory organization and efficient retrieval. To address these limitations, we\npropose a Hierarchical Memory (H-MEM) architecture for LLM Agents that\norganizes and updates memory in a multi-level fashion based on the degree of\nsemantic abstraction. Each memory vector is embedded with a positional index\nencoding pointing to its semantically related sub-memories in the next layer.\nDuring the reasoning phase, an index-based routing mechanism enables efficient,\nlayer-by-layer retrieval without performing exhaustive similarity computations.\nWe evaluate our method on five task settings from the LoCoMo dataset.\nExperimental results show that our approach consistently outperforms five\nbaseline methods, demonstrating its effectiveness in long-term dialogue\nscenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5c42\u8bb0\u5fc6\u67b6\u6784\uff08H-MEM\uff09\u7528\u4e8eLLM Agents\uff0c\u901a\u8fc7\u591a\u7ea7\u8bed\u4e49\u62bd\u8c61\u7ec4\u7ec7\u8bb0\u5fc6\uff0c\u63d0\u9ad8\u4e86\u68c0\u7d22\u6548\u7387\u548c\u51b3\u7b56\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u8bb0\u5fc6\u5b58\u50a8\u4e0e\u68c0\u7d22\u65b9\u6cd5\u5728\u7ed3\u6784\u5316\u7ec4\u7ec7\u548c\u9ad8\u6548\u68c0\u7d22\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u9650\u5236\u4e86LLM Agents\u7684\u957f\u671f\u63a8\u7406\u80fd\u529b\u3002", "method": "\u91c7\u7528\u5206\u5c42\u8bb0\u5fc6\u67b6\u6784\uff0c\u901a\u8fc7\u4f4d\u7f6e\u7d22\u5f15\u7f16\u7801\u548c\u57fa\u4e8e\u7d22\u5f15\u7684\u8def\u7531\u673a\u5236\u5b9e\u73b0\u9ad8\u6548\u68c0\u7d22\u3002", "result": "\u5728LoCoMo\u6570\u636e\u96c6\u7684\u4e94\u4e2a\u4efb\u52a1\u4e2d\uff0cH-MEM\u4f18\u4e8e\u4e94\u79cd\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "H-MEM\u663e\u8457\u63d0\u5347\u4e86LLM Agents\u5728\u957f\u671f\u5bf9\u8bdd\u573a\u666f\u4e2d\u7684\u8868\u73b0\u3002"}}
{"id": "2507.23664", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2507.23664", "abs": "https://arxiv.org/abs/2507.23664", "authors": ["Haipeng Liu", "Yuxuan Liu", "Ting Long"], "title": "Personalized Education with Ranking Alignment Recommendation", "comment": null, "summary": "Personalized question recommendation aims to guide individual students\nthrough questions to enhance their mastery of learning targets. Most previous\nmethods model this task as a Markov Decision Process and use reinforcement\nlearning to solve, but they struggle with efficient exploration, failing to\nidentify the best questions for each student during training. To address this,\nwe propose Ranking Alignment Recommendation (RAR), which incorporates\ncollaborative ideas into the exploration mechanism, enabling more efficient\nexploration within limited training episodes. Experiments show that RAR\neffectively improves recommendation performance, and our framework can be\napplied to any RL-based question recommender. Our code is available in\nhttps://github.com/wuming29/RAR.git.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aRAR\u7684\u4e2a\u6027\u5316\u95ee\u9898\u63a8\u8350\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u534f\u4f5c\u601d\u60f3\u878d\u5165\u63a2\u7d22\u673a\u5236\uff0c\u63d0\u5347\u4e86\u63a8\u8350\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u65b9\u6cd5\u5728\u63a2\u7d22\u6548\u7387\u4e0a\u5b58\u5728\u4e0d\u8db3\uff0c\u96be\u4ee5\u5728\u8bad\u7ec3\u4e2d\u4e3a\u6bcf\u4e2a\u5b66\u751f\u627e\u5230\u6700\u4f73\u95ee\u9898\u3002", "method": "\u63d0\u51faRanking Alignment Recommendation (RAR)\uff0c\u5c06\u534f\u4f5c\u601d\u60f3\u6574\u5408\u5230\u63a2\u7d22\u673a\u5236\u4e2d\uff0c\u4f18\u5316\u8bad\u7ec3\u8fc7\u7a0b\u3002", "result": "\u5b9e\u9a8c\u8868\u660eRAR\u663e\u8457\u63d0\u5347\u4e86\u63a8\u8350\u6027\u80fd\uff0c\u4e14\u6846\u67b6\u9002\u7528\u4e8e\u4efb\u4f55\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u63a8\u8350\u7cfb\u7edf\u3002", "conclusion": "RAR\u901a\u8fc7\u6539\u8fdb\u63a2\u7d22\u673a\u5236\uff0c\u4e3a\u4e2a\u6027\u5316\u95ee\u9898\u63a8\u8350\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.22926", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2507.22926", "abs": "https://arxiv.org/abs/2507.22926", "authors": ["Nilesh", "Atul Gupta", "Avinash C Panday"], "title": "Multi-Relation Extraction in Entity Pairs using Global Context", "comment": "11 pages, 9 figures", "summary": "In document-level relation extraction, entities may appear multiple times in\na document, and their relationships can shift from one context to another.\nAccurate prediction of the relationship between two entities across an entire\ndocument requires building a global context spanning all relevant sentences.\nPrevious approaches have focused only on the sentences where entities are\nmentioned, which fails to capture the complete document context necessary for\naccurate relation extraction. Therefore, this paper introduces a novel input\nembedding approach to capture the positions of mentioned entities throughout\nthe document rather than focusing solely on the span where they appear. The\nproposed input encoding approach leverages global relationships and\nmulti-sentence reasoning by representing entities as standalone segments,\nindependent of their positions within the document. The performance of the\nproposed method has been tested on three benchmark relation extraction\ndatasets, namely DocRED, Re-DocRED, and REBEL. The experimental results\ndemonstrated that the proposed method accurately predicts relationships between\nentities in a document-level setting. The proposed research also has\ntheoretical and practical implications. Theoretically, it advances global\ncontext modeling and multi-sentence reasoning in document-level relation\nextraction. Practically, it enhances relationship detection, enabling improved\nperformance in real-world NLP applications requiring comprehensive entity-level\ninsights and interpretability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8f93\u5165\u5d4c\u5165\u65b9\u6cd5\uff0c\u7528\u4e8e\u6587\u6863\u7ea7\u5173\u7cfb\u62bd\u53d6\uff0c\u901a\u8fc7\u5168\u5c40\u4e0a\u4e0b\u6587\u5efa\u6a21\u548c\u591a\u53e5\u5b50\u63a8\u7406\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5173\u7cfb\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4ec5\u5173\u6ce8\u5b9e\u4f53\u51fa\u73b0\u7684\u53e5\u5b50\uff0c\u65e0\u6cd5\u6355\u6349\u5b8c\u6574\u7684\u6587\u6863\u4e0a\u4e0b\u6587\uff0c\u5bfc\u81f4\u5173\u7cfb\u62bd\u53d6\u4e0d\u51c6\u786e\u3002", "method": "\u5f15\u5165\u4e00\u79cd\u65b0\u7684\u8f93\u5165\u5d4c\u5165\u65b9\u6cd5\uff0c\u5c06\u5b9e\u4f53\u8868\u793a\u4e3a\u72ec\u7acb\u7247\u6bb5\uff0c\u72ec\u7acb\u4e8e\u5176\u5728\u6587\u6863\u4e2d\u7684\u4f4d\u7f6e\uff0c\u4ee5\u6355\u83b7\u5168\u5c40\u5173\u7cfb\u548c\u591a\u53e5\u5b50\u63a8\u7406\u3002", "result": "\u5728DocRED\u3001Re-DocRED\u548cREBEL\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\uff0c\u8bc1\u660e\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u7406\u8bba\u548c\u5b9e\u8df5\u4e0a\u5747\u6709\u91cd\u8981\u610f\u4e49\uff0c\u63a8\u52a8\u4e86\u5168\u5c40\u4e0a\u4e0b\u6587\u5efa\u6a21\u548c\u591a\u53e5\u5b50\u63a8\u7406\u7684\u7814\u7a76\uff0c\u5e76\u63d0\u5347\u4e86\u5b9e\u9645NLP\u5e94\u7528\u4e2d\u7684\u5173\u7cfb\u68c0\u6d4b\u6027\u80fd\u3002"}}
{"id": "2507.23701", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.23701", "abs": "https://arxiv.org/abs/2507.23701", "authors": ["Long Phan", "Mantas Mazeika", "Andy Zou", "Dan Hendrycks"], "title": "TextQuests: How Good are LLMs at Text-Based Video Games?", "comment": null, "summary": "Evaluating AI agents within complex, interactive environments that mirror\nreal-world challenges is critical for understanding their practical\ncapabilities. While existing agent benchmarks effectively assess skills like\ntool use or performance on structured tasks, they often do not fully capture an\nagent's ability to operate autonomously in exploratory environments that demand\nsustained, self-directed reasoning over a long and growing context. To spur the\ndevelopment of agents capable of more robust intrinsic reasoning over long\nhorizons, we introduce TextQuests, a benchmark based on the Infocom suite of\ninteractive fiction games. These text-based adventures, which can take human\nplayers over 30 hours and require hundreds of precise actions to solve, serve\nas an effective proxy for evaluating AI agents on focused, stateful tasks. The\nbenchmark is specifically designed to assess an LLM agent's capacity for\nself-contained problem-solving by precluding the use of external tools, thereby\nfocusing on intrinsic long-context reasoning capabilities in an exploratory\nenvironment characterized by the need for trial-and-error learning and\nsustained problem-solving within a single interactive session. We release\nTextQuests at https://textquests.ai.", "AI": {"tldr": "TextQuests\u662f\u4e00\u4e2a\u57fa\u4e8eInfocom\u4e92\u52a8\u5c0f\u8bf4\u6e38\u620f\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u65e8\u5728\u8bc4\u4f30AI\u4ee3\u7406\u5728\u63a2\u7d22\u6027\u73af\u5883\u4e2d\u7684\u81ea\u4e3b\u63a8\u7406\u80fd\u529b\uff0c\u91cd\u70b9\u5173\u6ce8\u957f\u671f\u4e0a\u4e0b\u6587\u63a8\u7406\u548c\u81ea\u4e3b\u95ee\u9898\u89e3\u51b3\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u672a\u80fd\u5168\u9762\u8bc4\u4f30AI\u4ee3\u7406\u5728\u9700\u8981\u957f\u671f\u81ea\u4e3b\u63a8\u7406\u7684\u63a2\u7d22\u6027\u73af\u5883\u4e2d\u7684\u80fd\u529b\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u65b0\u7684\u6d4b\u8bd5\u5e73\u53f0\u3002", "method": "\u901a\u8fc7\u57fa\u4e8eInfocom\u4e92\u52a8\u5c0f\u8bf4\u6e38\u620f\u7684TextQuests\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7981\u6b62\u4f7f\u7528\u5916\u90e8\u5de5\u5177\uff0c\u4e13\u6ce8\u4e8e\u8bc4\u4f30\u4ee3\u7406\u7684\u957f\u671f\u4e0a\u4e0b\u6587\u63a8\u7406\u548c\u81ea\u4e3b\u95ee\u9898\u89e3\u51b3\u80fd\u529b\u3002", "result": "TextQuests\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u6d4b\u8bd5\u5e73\u53f0\uff0c\u80fd\u591f\u8bc4\u4f30AI\u4ee3\u7406\u5728\u590d\u6742\u3001\u63a2\u7d22\u6027\u73af\u5883\u4e2d\u7684\u81ea\u4e3b\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "TextQuests\u4e3a\u5f00\u53d1\u5177\u5907\u957f\u671f\u81ea\u4e3b\u63a8\u7406\u80fd\u529b\u7684AI\u4ee3\u7406\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\uff0c\u5e76\u63a8\u52a8\u4e86\u76f8\u5173\u7814\u7a76\u7684\u53d1\u5c55\u3002"}}
{"id": "2507.22927", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.22927", "abs": "https://arxiv.org/abs/2507.22927", "authors": ["Zhehao Tan", "Yihan Jiao", "Dan Yang", "Lei Liu", "Jie Feng", "Duolin Sun", "Yue Shen", "Jian Wang", "Peng Wei", "Jinjie Gu"], "title": "PRGB Benchmark: A Robust Placeholder-Assisted Algorithm for Benchmarking Retrieval-Augmented Generation", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by\nintegrating external knowledge, where the LLM's ability to generate responses\nbased on the combination of a given query and retrieved documents is crucial.\nHowever, most benchmarks focus on overall RAG system performance, rarely\nassessing LLM-specific capabilities. Current benchmarks emphasize broad aspects\nsuch as noise robustness, but lack a systematic and granular evaluation\nframework on document utilization. To this end, we introduce\n\\textit{Placeholder-RAG-Benchmark}, a multi-level fine-grained benchmark,\nemphasizing the following progressive dimensions: (1) multi-level filtering\nabilities, (2) combination abilities, and (3) reference reasoning. To provide a\nmore nuanced understanding of LLMs' roles in RAG systems, we formulate an\ninnovative placeholder-based approach to decouple the contributions of the\nLLM's parametric knowledge and the external knowledge. Experiments demonstrate\nthe limitations of representative LLMs in the RAG system's generation\ncapabilities, particularly in error resilience and context faithfulness. Our\nbenchmark provides a reproducible framework for developing more reliable and\nefficient RAG systems. Our code is available in\nhttps://github.com/Alipay-Med/PRGB.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aPlaceholder-RAG-Benchmark\u7684\u591a\u5c42\u6b21\u7ec6\u7c92\u5ea6\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7cfb\u7edf\u4e2d\u7684\u8868\u73b0\uff0c\u91cd\u70b9\u5173\u6ce8\u6587\u6863\u5229\u7528\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u5173\u6ce8RAG\u7cfb\u7edf\u7684\u6574\u4f53\u6027\u80fd\uff0c\u800c\u7f3a\u4e4f\u5bf9LLM\u7279\u5b9a\u80fd\u529b\u7684\u7cfb\u7edf\u6027\u548c\u7ec6\u7c92\u5ea6\u8bc4\u4f30\u3002", "method": "\u901a\u8fc7\u521b\u65b0\u7684\u57fa\u4e8e\u5360\u4f4d\u7b26\u7684\u65b9\u6cd5\uff0c\u5206\u79bbLLM\u7684\u53c2\u6570\u5316\u77e5\u8bc6\u548c\u5916\u90e8\u77e5\u8bc6\u7684\u8d21\u732e\uff0c\u5e76\u8bbe\u8ba1\u4e86\u591a\u5c42\u6b21\u7684\u8bc4\u4f30\u7ef4\u5ea6\uff08\u8fc7\u6ee4\u80fd\u529b\u3001\u7ec4\u5408\u80fd\u529b\u548c\u53c2\u8003\u63a8\u7406\uff09\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4ee3\u8868\u6027LLM\u5728RAG\u7cfb\u7edf\u4e2d\u7684\u751f\u6210\u80fd\u529b\u5b58\u5728\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u5728\u9519\u8bef\u6062\u590d\u548c\u4e0a\u4e0b\u6587\u5fe0\u5b9e\u5ea6\u65b9\u9762\u3002", "conclusion": "\u8be5\u57fa\u51c6\u6d4b\u8bd5\u4e3a\u5f00\u53d1\u66f4\u53ef\u9760\u548c\u9ad8\u6548\u7684RAG\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u590d\u73b0\u7684\u6846\u67b6\u3002"}}
{"id": "2507.23726", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.23726", "abs": "https://arxiv.org/abs/2507.23726", "authors": ["Luoxin Chen", "Jinming Gu", "Liankai Huang", "Wenhao Huang", "Zhicheng Jiang", "Allan Jie", "Xiaoran Jin", "Xing Jin", "Chenggang Li", "Kaijing Ma", "Cheng Ren", "Jiawei Shen", "Wenlei Shi", "Tong Sun", "He Sun", "Jiahui Wang", "Siran Wang", "Zhihong Wang", "Chenrui Wei", "Shufa Wei", "Yonghui Wu", "Yuchen Wu", "Yihang Xia", "Huajian Xin", "Fan Yang", "Huaiyuan Ying", "Hongyi Yuan", "Zheng Yuan", "Tianyang Zhan", "Chi Zhang", "Yue Zhang", "Ge Zhang", "Tianyun Zhao", "Jianqiu Zhao", "Yichi Zhou", "Thomas Hanwen Zhu"], "title": "Seed-Prover: Deep and Broad Reasoning for Automated Theorem Proving", "comment": null, "summary": "LLMs have demonstrated strong mathematical reasoning abilities by leveraging\nreinforcement learning with long chain-of-thought, yet they continue to\nstruggle with theorem proving due to the lack of clear supervision signals when\nsolely using natural language. Dedicated domain-specific languages like Lean\nprovide clear supervision via formal verification of proofs, enabling effective\ntraining through reinforcement learning. In this work, we propose\n\\textbf{Seed-Prover}, a lemma-style whole-proof reasoning model. Seed-Prover\ncan iteratively refine its proof based on Lean feedback, proved lemmas, and\nself-summarization. To solve IMO-level contest problems, we design three\ntest-time inference strategies that enable both deep and broad reasoning.\nSeed-Prover proves $78.1\\%$ of formalized past IMO problems, saturates MiniF2F,\nand achieves over 50\\% on PutnamBench, outperforming the previous\nstate-of-the-art by a large margin. To address the lack of geometry support in\nLean, we introduce a geometry reasoning engine \\textbf{Seed-Geometry}, which\noutperforms previous formal geometry engines. We use these two systems to\nparticipate in IMO 2025 and fully prove 5 out of 6 problems. This work\nrepresents a significant advancement in automated mathematical reasoning,\ndemonstrating the effectiveness of formal verification with long\nchain-of-thought reasoning.", "AI": {"tldr": "Seed-Prover\u662f\u4e00\u79cd\u57fa\u4e8eLean\u53cd\u9988\u7684\u5b9a\u7406\u8bc1\u660e\u6a21\u578b\uff0c\u901a\u8fc7\u8fed\u4ee3\u4f18\u5316\u8bc1\u660e\u8fc7\u7a0b\uff0c\u663e\u8457\u63d0\u5347\u4e86IMO\u7ea7\u95ee\u9898\u7684\u89e3\u51b3\u80fd\u529b\u3002", "motivation": "\u73b0\u6709LLMs\u5728\u5b9a\u7406\u8bc1\u660e\u4e2d\u56e0\u7f3a\u4e4f\u660e\u786e\u76d1\u7763\u4fe1\u53f7\u800c\u8868\u73b0\u4e0d\u4f73\uff0c\u800c\u9886\u57df\u4e13\u7528\u8bed\u8a00\u5982Lean\u80fd\u63d0\u4f9b\u6e05\u6670\u7684\u9a8c\u8bc1\u4fe1\u53f7\u3002", "method": "\u63d0\u51faSeed-Prover\u6a21\u578b\uff0c\u7ed3\u5408Lean\u53cd\u9988\u3001\u5df2\u8bc1\u660e\u5f15\u7406\u548c\u81ea\u6211\u603b\u7ed3\u8fed\u4ee3\u4f18\u5316\u8bc1\u660e\uff1b\u8bbe\u8ba1\u4e09\u79cd\u63a8\u7406\u7b56\u7565\u4ee5\u652f\u6301\u6df1\u5ea6\u548c\u5e7f\u5ea6\u63a8\u7406\u3002", "result": "Seed-Prover\u5728IMO\u95ee\u9898\u4e2d\u8fbe\u523078.1%\u7684\u89e3\u51b3\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff1bSeed-Geometry\u5728\u51e0\u4f55\u63a8\u7406\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "Seed-Prover\u548cSeed-Geometry\u5c55\u793a\u4e86\u5f62\u5f0f\u5316\u9a8c\u8bc1\u4e0e\u957f\u94fe\u63a8\u7406\u7ed3\u5408\u5728\u81ea\u52a8\u6570\u5b66\u63a8\u7406\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2507.22928", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22928", "abs": "https://arxiv.org/abs/2507.22928", "authors": ["Xi Chen", "Aske Plaat", "Niki van Stein"], "title": "How does Chain of Thought Think? Mechanistic Interpretability of Chain-of-Thought Reasoning with Sparse Autoencoding", "comment": null, "summary": "Chain-of-thought (CoT) prompting boosts Large Language Models accuracy on\nmulti-step tasks, yet whether the generated \"thoughts\" reflect the true\ninternal reasoning process is unresolved. We present the first feature-level\ncausal study of CoT faithfulness. Combining sparse autoencoders with activation\npatching, we extract monosemantic features from Pythia-70M and Pythia-2.8B\nwhile they tackle GSM8K math problems under CoT and plain (noCoT) prompting.\nSwapping a small set of CoT-reasoning features into a noCoT run raises answer\nlog-probabilities significantly in the 2.8B model, but has no reliable effect\nin 70M, revealing a clear scale threshold. CoT also leads to significantly\nhigher activation sparsity and feature interpretability scores in the larger\nmodel, signalling more modular internal computation. For example, the model's\nconfidence in generating correct answers improves from 1.2 to 4.3. We introduce\npatch-curves and random-feature patching baselines, showing that useful CoT\ninformation is not only present in the top-K patches but widely distributed.\nOverall, our results indicate that CoT can induce more interpretable internal\nstructures in high-capacity LLMs, validating its role as a structured prompting\nmethod.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u7a00\u758f\u81ea\u7f16\u7801\u5668\u548c\u6fc0\u6d3b\u4fee\u8865\u6280\u672f\uff0c\u5206\u6790\u4e86CoT\u63d0\u793a\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5185\u90e8\u63a8\u7406\u8fc7\u7a0b\u7684\u5f71\u54cd\uff0c\u53d1\u73b0CoT\u5728\u9ad8\u5bb9\u91cf\u6a21\u578b\u4e2d\u80fd\u63d0\u5347\u7b54\u6848\u51c6\u786e\u6027\u548c\u6a21\u5757\u5316\u8ba1\u7b97\u3002", "motivation": "\u63a2\u7a76CoT\u63d0\u793a\u751f\u6210\u7684\u201c\u601d\u8003\u201d\u662f\u5426\u771f\u5b9e\u53cd\u6620\u6a21\u578b\u5185\u90e8\u63a8\u7406\u8fc7\u7a0b\uff0c\u9a8c\u8bc1CoT\u4f5c\u4e3a\u7ed3\u6784\u5316\u63d0\u793a\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "method": "\u7ed3\u5408\u7a00\u758f\u81ea\u7f16\u7801\u5668\u548c\u6fc0\u6d3b\u4fee\u8865\u6280\u672f\uff0c\u63d0\u53d6Pythia-70M\u548cPythia-2.8B\u5728GSM8K\u6570\u5b66\u95ee\u9898\u4e2d\u7684\u7279\u5f81\uff0c\u5bf9\u6bd4CoT\u548c\u65e0CoT\u63d0\u793a\u7684\u6548\u679c\u3002", "result": "\u57282.8B\u6a21\u578b\u4e2d\uff0cCoT\u663e\u8457\u63d0\u5347\u7b54\u6848\u5bf9\u6570\u6982\u7387\uff0c\u6fc0\u6d3b\u7a00\u758f\u6027\u548c\u7279\u5f81\u53ef\u89e3\u91ca\u6027\u66f4\u9ad8\uff1b70M\u6a21\u578b\u65e0\u663e\u8457\u53d8\u5316\u3002CoT\u4fe1\u606f\u5206\u5e03\u5e7f\u6cdb\u3002", "conclusion": "CoT\u80fd\u8bf1\u5bfc\u9ad8\u5bb9\u91cf\u6a21\u578b\u5f62\u6210\u66f4\u53ef\u89e3\u91ca\u7684\u5185\u90e8\u7ed3\u6784\uff0c\u9a8c\u8bc1\u5176\u4f5c\u4e3a\u7ed3\u6784\u5316\u63d0\u793a\u65b9\u6cd5\u7684\u4f5c\u7528\u3002"}}
{"id": "2507.23751", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.23751", "abs": "https://arxiv.org/abs/2507.23751", "authors": ["Ping Yu", "Jack Lanchantin", "Tianlu Wang", "Weizhe Yuan", "Olga Golovneva", "Ilia Kulikov", "Sainbayar Sukhbaatar", "Jason Weston", "Jing Xu"], "title": "CoT-Self-Instruct: Building high-quality synthetic prompts for reasoning and non-reasoning tasks", "comment": null, "summary": "We propose CoT-Self-Instruct, a synthetic data generation method that\ninstructs LLMs to first reason and plan via Chain-of-Thought (CoT) based on the\ngiven seed tasks, and then to generate a new synthetic prompt of similar\nquality and complexity for use in LLM training, followed by filtering for\nhigh-quality data with automatic metrics. In verifiable reasoning, our\nsynthetic data significantly outperforms existing training datasets, such as\ns1k and OpenMathReasoning, across MATH500, AMC23, AIME24 and GPQA-Diamond. For\nnon-verifiable instruction-following tasks, our method surpasses the\nperformance of human or standard self-instruct prompts on both AlpacaEval 2.0\nand Arena-Hard.", "AI": {"tldr": "CoT-Self-Instruct\u662f\u4e00\u79cd\u5408\u6210\u6570\u636e\u751f\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u94fe\u5f0f\u601d\u8003\uff08CoT\uff09\u6307\u5bfcLLMs\u751f\u6210\u9ad8\u8d28\u91cf\u5408\u6210\u63d0\u793a\uff0c\u663e\u8457\u63d0\u5347\u63a8\u7406\u548c\u6307\u4ee4\u8ddf\u968f\u4efb\u52a1\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u8bad\u7ec3\u6570\u636e\u96c6\u5728\u53ef\u9a8c\u8bc1\u63a8\u7406\u548c\u6307\u4ee4\u8ddf\u968f\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u8db3\uff0c\u9700\u8981\u66f4\u9ad8\u8d28\u91cf\u7684\u5408\u6210\u6570\u636e\u6765\u63d0\u5347LLM\u6027\u80fd\u3002", "method": "\u57fa\u4e8e\u79cd\u5b50\u4efb\u52a1\uff0c\u5229\u7528CoT\u5f15\u5bfcLLMs\u751f\u6210\u5408\u6210\u63d0\u793a\uff0c\u5e76\u901a\u8fc7\u81ea\u52a8\u6307\u6807\u8fc7\u6ee4\u9ad8\u8d28\u91cf\u6570\u636e\u3002", "result": "\u5728MATH500\u3001AMC23\u7b49\u53ef\u9a8c\u8bc1\u63a8\u7406\u4efb\u52a1\u4e0a\u4f18\u4e8e\u73b0\u6709\u6570\u636e\u96c6\uff1b\u5728AlpacaEval 2.0\u7b49\u6307\u4ee4\u8ddf\u968f\u4efb\u52a1\u4e0a\u8d85\u8d8a\u4eba\u7c7b\u6216\u6807\u51c6\u81ea\u63d0\u793a\u65b9\u6cd5\u3002", "conclusion": "CoT-Self-Instruct\u80fd\u6709\u6548\u751f\u6210\u9ad8\u8d28\u91cf\u5408\u6210\u6570\u636e\uff0c\u663e\u8457\u63d0\u5347LLM\u5728\u591a\u79cd\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002"}}
{"id": "2507.22929", "categories": ["cs.CL", "cs.CV", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.22929", "abs": "https://arxiv.org/abs/2507.22929", "authors": ["Xiaoyu Pan", "Yang Bai", "Ke Zou", "Yang Zhou", "Jun Zhou", "Huazhu Fu", "Yih-Chung Tham", "Yong Liu"], "title": "EH-Benchmark Ophthalmic Hallucination Benchmark and Agent-Driven Top-Down Traceable Reasoning Workflow", "comment": "9 figures, 5 tables. submit/6621751", "summary": "Medical Large Language Models (MLLMs) play a crucial role in ophthalmic\ndiagnosis, holding significant potential to address vision-threatening\ndiseases. However, their accuracy is constrained by hallucinations stemming\nfrom limited ophthalmic knowledge, insufficient visual localization and\nreasoning capabilities, and a scarcity of multimodal ophthalmic data, which\ncollectively impede precise lesion detection and disease diagnosis.\nFurthermore, existing medical benchmarks fail to effectively evaluate various\ntypes of hallucinations or provide actionable solutions to mitigate them. To\naddress the above challenges, we introduce EH-Benchmark, a novel ophthalmology\nbenchmark designed to evaluate hallucinations in MLLMs. We categorize MLLMs'\nhallucinations based on specific tasks and error types into two primary\nclasses: Visual Understanding and Logical Composition, each comprising multiple\nsubclasses. Given that MLLMs predominantly rely on language-based reasoning\nrather than visual processing, we propose an agent-centric, three-phase\nframework, including the Knowledge-Level Retrieval stage, the Task-Level Case\nStudies stage, and the Result-Level Validation stage. Experimental results show\nthat our multi-agent framework significantly mitigates both types of\nhallucinations, enhancing accuracy, interpretability, and reliability. Our\nproject is available at https://github.com/ppxy1/EH-Benchmark.", "AI": {"tldr": "EH-Benchmark\u662f\u4e00\u4e2a\u65b0\u7684\u773c\u79d1\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u533b\u5b66\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u4e2d\u7684\u5e7b\u89c9\u95ee\u9898\uff0c\u901a\u8fc7\u591a\u9636\u6bb5\u6846\u67b6\u663e\u8457\u51cf\u5c11\u5e7b\u89c9\u5e76\u63d0\u9ad8\u51c6\u786e\u6027\u3002", "motivation": "MLLMs\u5728\u773c\u79d1\u8bca\u65ad\u4e2d\u5b58\u5728\u5e7b\u89c9\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5176\u51c6\u786e\u6027\uff0c\u73b0\u6709\u57fa\u51c6\u65e0\u6cd5\u6709\u6548\u8bc4\u4f30\u6216\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u63d0\u51faEH-Benchmark\uff0c\u5c06\u5e7b\u89c9\u5206\u4e3a\u89c6\u89c9\u7406\u89e3\u548c\u903b\u8f91\u7ec4\u5408\u4e24\u7c7b\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u4e09\u9636\u6bb5\u7684\u591a\u4ee3\u7406\u6846\u67b6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u663e\u8457\u51cf\u5c11\u4e86\u5e7b\u89c9\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u51c6\u786e\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u9760\u6027\u3002", "conclusion": "EH-Benchmark\u4e3aMLLMs\u7684\u5e7b\u89c9\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u8bc4\u4f30\u548c\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.23773", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2507.23773", "abs": "https://arxiv.org/abs/2507.23773", "authors": ["Mingkai Deng", "Jinyu Hou", "Yilin Shen", "Hongxia Jin", "Graham Neubig", "Zhiting Hu", "Eric Xing"], "title": "SimuRA: Towards General Goal-Oriented Agent via Simulative Reasoning Architecture with LLM-Based World Model", "comment": null, "summary": "AI agents built on large language models (LLMs) hold enormous promise, but\ncurrent practice focuses on a one-task-one-agent approach, which not only falls\nshort of scalability and generality, but also suffers from the fundamental\nlimitations of autoregressive LLMs. On the other hand, humans are general\nagents who reason by mentally simulating the outcomes of their actions and\nplans. Moving towards a more general and powerful AI agent, we introduce\nSimuRA, a goal-oriented architecture for generalized agentic reasoning. Based\non a principled formulation of optimal agent in any environment, \\modelname\novercomes the limitations of autoregressive reasoning by introducing a world\nmodel for planning via simulation. The generalized world model is implemented\nusing LLM, which can flexibly plan in a wide range of environments using the\nconcept-rich latent space of natural language. Experiments on difficult web\nbrowsing tasks show that \\modelname improves the success of flight search from\n0\\% to 32.2\\%. World-model-based planning, in particular, shows consistent\nadvantage of up to 124\\% over autoregressive planning, demonstrating the\nadvantage of world model simulation as a reasoning paradigm. We are excited\nabout the possibility for training a single, general agent model based on LLMs\nthat can act superintelligently in all environments. To start, we make SimuRA,\na web-browsing agent built on \\modelname with pretrained LLMs, available as a\nresearch demo for public testing.", "AI": {"tldr": "SimuRA\u662f\u4e00\u79cd\u57fa\u4e8e\u4e16\u754c\u6a21\u578b\u7684\u76ee\u6807\u5bfc\u5411\u67b6\u6784\uff0c\u901a\u8fc7\u6a21\u62df\u89c4\u5212\u514b\u670d\u81ea\u56de\u5f52LLM\u7684\u9650\u5236\uff0c\u63d0\u5347\u901a\u7528AI\u4ee3\u7406\u7684\u80fd\u529b\u3002", "motivation": "\u5f53\u524dAI\u4ee3\u7406\u5c40\u9650\u4e8e\u5355\u4efb\u52a1\u5355\u4ee3\u7406\u6a21\u5f0f\uff0c\u7f3a\u4e4f\u53ef\u6269\u5c55\u6027\u548c\u901a\u7528\u6027\uff0c\u4e14\u53d7\u9650\u4e8e\u81ea\u56de\u5f52LLM\u7684\u56fa\u6709\u7f3a\u9677\u3002\u4eba\u7c7b\u901a\u8fc7\u5fc3\u7406\u6a21\u62df\u8fdb\u884c\u63a8\u7406\uff0c\u542f\u53d1SimuRA\u7684\u8bbe\u8ba1\u3002", "method": "SimuRA\u5f15\u5165\u4e16\u754c\u6a21\u578b\u8fdb\u884c\u6a21\u62df\u89c4\u5212\uff0c\u5229\u7528LLM\u7684\u4e30\u5bcc\u6982\u5ff5\u7a7a\u95f4\u7075\u6d3b\u9002\u5e94\u591a\u79cd\u73af\u5883\u3002", "result": "\u5728\u7f51\u9875\u6d4f\u89c8\u4efb\u52a1\u4e2d\uff0cSimuRA\u5c06\u822a\u73ed\u641c\u7d22\u6210\u529f\u7387\u4ece0%\u63d0\u5347\u81f332.2%\uff0c\u4e16\u754c\u6a21\u578b\u89c4\u5212\u6bd4\u81ea\u56de\u5f52\u89c4\u5212\u4f18\u52bf\u8fbe124%\u3002", "conclusion": "SimuRA\u5c55\u793a\u4e86\u4e16\u754c\u6a21\u578b\u6a21\u62df\u4f5c\u4e3a\u63a8\u7406\u8303\u5f0f\u7684\u4f18\u52bf\uff0c\u4e3a\u8bad\u7ec3\u901a\u7528LLM\u4ee3\u7406\u63d0\u4f9b\u4e86\u53ef\u80fd\u6027\u3002"}}
{"id": "2507.22930", "categories": ["cs.CL", "cs.SI"], "pdf": "https://arxiv.org/pdf/2507.22930", "abs": "https://arxiv.org/abs/2507.22930", "authors": ["Shalini Jangra", "Suparna De", "Nishanth Sastry", "Saeed Fadaei"], "title": "Protecting Vulnerable Voices: Synthetic Dataset Generation for Self-Disclosure Detection", "comment": "15 pages, 4 Figures, Accepted in \"The 17th International Conference\n  on Advances in Social Networks Analysis and Mining -ASONAM-2025\"", "summary": "Social platforms such as Reddit have a network of communities of shared\ninterests, with a prevalence of posts and comments from which one can infer\nusers' Personal Information Identifiers (PIIs). While such self-disclosures can\nlead to rewarding social interactions, they pose privacy risks and the threat\nof online harms. Research into the identification and retrieval of such risky\nself-disclosures of PIIs is hampered by the lack of open-source labeled\ndatasets. To foster reproducible research into PII-revealing text detection, we\ndevelop a novel methodology to create synthetic equivalents of PII-revealing\ndata that can be safely shared. Our contributions include creating a taxonomy\nof 19 PII-revealing categories for vulnerable populations and the creation and\nrelease of a synthetic PII-labeled multi-text span dataset generated from 3\ntext generation Large Language Models (LLMs), Llama2-7B, Llama3-8B, and\nzephyr-7b-beta, with sequential instruction prompting to resemble the original\nReddit posts. The utility of our methodology to generate this synthetic dataset\nis evaluated with three metrics: First, we require reproducibility equivalence,\ni.e., results from training a model on the synthetic data should be comparable\nto those obtained by training the same models on the original posts. Second, we\nrequire that the synthetic data be unlinkable to the original users, through\ncommon mechanisms such as Google Search. Third, we wish to ensure that the\nsynthetic data be indistinguishable from the original, i.e., trained humans\nshould not be able to tell them apart. We release our dataset and code at\nhttps://netsys.surrey.ac.uk/datasets/synthetic-self-disclosure/ to foster\nreproducible research into PII privacy risks in online social media.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u751f\u6210\u5408\u6210PII\u63ed\u793a\u6570\u636e\u7684\u65b9\u6cd5\uff0c\u4ee5\u4fc3\u8fdb\u9690\u79c1\u98ce\u9669\u7814\u7a76\uff0c\u5e76\u53d1\u5e03\u4e86\u57fa\u4e8eLLMs\u7684\u591a\u6587\u672c\u8de8\u5ea6\u6570\u636e\u96c6\u3002", "motivation": "\u793e\u4ea4\u5e73\u53f0\u4e0a\u7684PII\u63ed\u793a\u5b58\u5728\u9690\u79c1\u98ce\u9669\uff0c\u4f46\u7f3a\u4e4f\u5f00\u6e90\u6807\u6ce8\u6570\u636e\u96c6\u963b\u788d\u4e86\u76f8\u5173\u7814\u7a76\u3002", "method": "\u4f7f\u7528\u4e09\u79cdLLMs\u751f\u6210\u5408\u6210PII\u6570\u636e\uff0c\u5e76\u901a\u8fc7\u4e09\u4e2a\u6807\u51c6\u8bc4\u4f30\u5176\u6548\u7528\uff1a\u53ef\u91cd\u73b0\u6027\u3001\u4e0d\u53ef\u94fe\u63a5\u6027\u548c\u4e0d\u53ef\u533a\u5206\u6027\u3002", "result": "\u751f\u6210\u4e86\u4e00\u4e2a\u5408\u6210PII\u6570\u636e\u96c6\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u5728\u7814\u7a76\u4e2d\u7684\u5b9e\u7528\u6027\u3002", "conclusion": "\u5408\u6210\u6570\u636e\u65b9\u6cd5\u4e3a\u9690\u79c1\u98ce\u9669\u7814\u7a76\u63d0\u4f9b\u4e86\u53ef\u5171\u4eab\u4e14\u5b89\u5168\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2503.21813", "categories": ["cs.CL", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2503.21813", "abs": "https://arxiv.org/abs/2503.21813", "authors": ["Zhangcheng Qiang", "Kerry Taylor", "Weiqing Wang", "Jing Jiang"], "title": "OAEI-LLM-T: A TBox Benchmark Dataset for Understanding Large Language Model Hallucinations in Ontology Matching", "comment": "14 pages, 4 figures, 4 tables, 2 prompt templates", "summary": "Hallucinations are often inevitable in downstream tasks using large language\nmodels (LLMs). To tackle the substantial challenge of addressing hallucinations\nfor LLM-based ontology matching (OM) systems, we introduce a new benchmark\ndataset OAEI-LLM-T. The dataset evolves from seven TBox datasets in the\nOntology Alignment Evaluation Initiative (OAEI), capturing hallucinations of\nten different LLMs performing OM tasks. These OM-specific hallucinations are\norganised into two primary categories and six sub-categories. We showcase the\nusefulness of the dataset in constructing an LLM leaderboard for OM tasks and\nfor fine-tuning LLMs used in OM tasks.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aOAEI-LLM-T\u7684\u65b0\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u57fa\u4e8e\u672c\u4f53\u5339\u914d\uff08OM\uff09\u4efb\u52a1\u4e2d\u7684\u5e7b\u89c9\u95ee\u9898\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u5e38\u51fa\u73b0\u5e7b\u89c9\uff0c\u7279\u522b\u662f\u5728\u672c\u4f53\u5339\u914d\u4efb\u52a1\u4e2d\uff0c\u8fd9\u4e00\u95ee\u9898\u5c24\u4e3a\u7a81\u51fa\u3002", "method": "\u4eceOAEI\u7684\u4e03\u4e2aTBox\u6570\u636e\u96c6\u4e2d\u6f14\u5316\u51faOAEI-LLM-T\u6570\u636e\u96c6\uff0c\u6355\u83b7\u4e86\u5341\u79cd\u4e0d\u540cLLMs\u5728OM\u4efb\u52a1\u4e2d\u7684\u5e7b\u89c9\uff0c\u5e76\u5c06\u5176\u5206\u4e3a\u4e24\u5927\u7c7b\u548c\u516d\u5c0f\u7c7b\u3002", "result": "\u6570\u636e\u96c6\u53ef\u7528\u4e8e\u6784\u5efaOM\u4efb\u52a1\u7684LLM\u6392\u884c\u699c\uff0c\u5e76\u7528\u4e8e\u5fae\u8c03OM\u4efb\u52a1\u4e2d\u7684LLMs\u3002", "conclusion": "OAEI-LLM-T\u6570\u636e\u96c6\u4e3a\u89e3\u51b3LLMs\u5728OM\u4efb\u52a1\u4e2d\u7684\u5e7b\u89c9\u95ee\u9898\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2507.22931", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22931", "abs": "https://arxiv.org/abs/2507.22931", "authors": ["Shuyu Guo", "Zhaochun Ren"], "title": "Enhancing RAG Efficiency with Adaptive Context Compression", "comment": null, "summary": "Retrieval-augmented generation (RAG) enhances large language models (LLMs)\nwith external knowledge but incurs significant inference costs due to lengthy\nretrieved contexts. While context compression mitigates this issue, existing\nmethods apply fixed compression rates, over-compressing simple queries or\nunder-compressing complex ones. We propose Adaptive Context Compression for RAG\n(ACC-RAG), a framework that dynamically adjusts compression rates based on\ninput complexity, optimizing inference efficiency without sacrificing accuracy.\nACC-RAG combines a hierarchical compressor (for multi-granular embeddings) with\na context selector to retain minimal sufficient information, akin to human\nskimming. Evaluated on Wikipedia and five QA datasets, ACC-RAG outperforms\nfixed-rate methods and matches/unlocks over 4 times faster inference versus\nstandard RAG while maintaining or improving accuracy.", "AI": {"tldr": "ACC-RAG\u52a8\u6001\u8c03\u6574\u538b\u7f29\u7387\u4ee5\u4f18\u5316\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7684\u63a8\u7406\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u56fa\u5b9a\u538b\u7f29\u7387\u65b9\u6cd5\u5728\u5904\u7406\u7b80\u5355\u6216\u590d\u6742\u67e5\u8be2\u65f6\u6548\u7387\u4e0d\u8db3\uff0c\u9700\u52a8\u6001\u8c03\u6574\u538b\u7f29\u7387\u3002", "method": "\u7ed3\u5408\u5206\u5c42\u538b\u7f29\u5668\u548c\u4e0a\u4e0b\u6587\u9009\u62e9\u5668\uff0c\u52a8\u6001\u8c03\u6574\u538b\u7f29\u7387\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u56fa\u5b9a\u538b\u7f29\u7387\u65b9\u6cd5\uff0c\u63a8\u7406\u901f\u5ea6\u63d0\u53474\u500d\u4ee5\u4e0a\u3002", "conclusion": "ACC-RAG\u5728\u4fdd\u6301\u6216\u63d0\u5347\u51c6\u786e\u6027\u7684\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u4e86\u63a8\u7406\u6548\u7387\u3002"}}
{"id": "2507.22932", "categories": ["cs.CL", "q-fin.GN"], "pdf": "https://arxiv.org/pdf/2507.22932", "abs": "https://arxiv.org/abs/2507.22932", "authors": ["Baptiste Lefort", "Eric Benhamou", "Beatrice Guez", "Jean-Jacques Ohana", "Ethan Setrouk", "Alban Etienne"], "title": "FinMarBa: A Market-Informed Dataset for Financial Sentiment Classification", "comment": "8 pages", "summary": "This paper presents a novel hierarchical framework for portfolio\noptimization, integrating lightweight Large Language Models (LLMs) with Deep\nReinforcement Learning (DRL) to combine sentiment signals from financial news\nwith traditional market indicators. Our three-tier architecture employs base RL\nagents to process hybrid data, meta-agents to aggregate their decisions, and a\nsuper-agent to merge decisions based on market data and sentiment analysis.\nEvaluated on data from 2018 to 2024, after training on 2000-2017, the framework\nachieves a 26% annualized return and a Sharpe ratio of 1.2, outperforming\nequal-weighted and S&P 500 benchmarks. Key contributions include scalable\ncross-modal integration, a hierarchical RL structure for enhanced stability,\nand open-source reproducibility.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u5206\u5c42\u6846\u67b6\uff0c\u7ed3\u5408\u8f7b\u91cf\u7ea7\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u548c\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09\uff0c\u5c06\u91d1\u878d\u65b0\u95fb\u7684\u60c5\u611f\u4fe1\u53f7\u4e0e\u4f20\u7edf\u5e02\u573a\u6307\u6807\u6574\u5408\uff0c\u7528\u4e8e\u6295\u8d44\u7ec4\u5408\u4f18\u5316\u3002", "motivation": "\u4f20\u7edf\u6295\u8d44\u7ec4\u5408\u4f18\u5316\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u5229\u7528\u60c5\u611f\u4fe1\u53f7\u4e0e\u5e02\u573a\u6570\u636e\u7684\u7ed3\u5408\u6f5c\u529b\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u3001\u7a33\u5b9a\u7684\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u4e09\u5c42\u67b6\u6784\uff1a\u57fa\u7840RL\u4ee3\u7406\u5904\u7406\u6df7\u5408\u6570\u636e\uff0c\u5143\u4ee3\u7406\u805a\u5408\u51b3\u7b56\uff0c\u8d85\u7ea7\u4ee3\u7406\u7ed3\u5408\u5e02\u573a\u6570\u636e\u548c\u60c5\u611f\u5206\u6790\u505a\u51fa\u6700\u7ec8\u51b3\u7b56\u3002", "result": "\u57282018-2024\u5e74\u6570\u636e\u4e0a\u6d4b\u8bd5\uff08\u8bad\u7ec3\u6570\u636e\u4e3a2000-2017\u5e74\uff09\uff0c\u5e74\u5316\u6536\u76ca\u7387\u4e3a26%\uff0c\u590f\u666e\u6bd4\u7387\u4e3a1.2\uff0c\u4f18\u4e8e\u7b49\u6743\u91cd\u548c\u6807\u666e500\u57fa\u51c6\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u8de8\u6a21\u6001\u6574\u5408\u548c\u5206\u5c42RL\u7ed3\u6784\u63d0\u9ad8\u4e86\u7a33\u5b9a\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u5e76\u5177\u6709\u5f00\u6e90\u53ef\u590d\u73b0\u6027\u3002"}}
{"id": "2507.22933", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22933", "abs": "https://arxiv.org/abs/2507.22933", "authors": ["Anthony C Davis", "Burhan Sadiq", "Tianmin Shu", "Chien-Ming Huang"], "title": "Augmented Vision-Language Models: A Systematic Review", "comment": null, "summary": "Recent advances in visual-language machine learning models have demonstrated\nexceptional ability to use natural language and understand visual scenes by\ntraining on large, unstructured datasets. However, this training paradigm\ncannot produce interpretable explanations for its outputs, requires retraining\nto integrate new information, is highly resource-intensive, and struggles with\ncertain forms of logical reasoning. One promising solution involves integrating\nneural networks with external symbolic information systems, forming neural\nsymbolic systems that can enhance reasoning and memory abilities. These neural\nsymbolic systems provide more interpretable explanations to their outputs and\nthe capacity to assimilate new information without extensive retraining.\nUtilizing powerful pre-trained Vision-Language Models (VLMs) as the core neural\ncomponent, augmented by external systems, offers a pragmatic approach to\nrealizing the benefits of neural-symbolic integration. This systematic\nliterature review aims to categorize techniques through which visual-language\nunderstanding can be improved by interacting with external symbolic information\nsystems.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u901a\u8fc7\u7ed3\u5408\u795e\u7ecf\u7f51\u7edc\u4e0e\u5916\u90e8\u7b26\u53f7\u7cfb\u7edf\u63d0\u5347\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u89e3\u91ca\u6027\u548c\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u89e3\u91ca\u6027\u3001\u4fe1\u606f\u66f4\u65b0\u548c\u903b\u8f91\u63a8\u7406\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u6574\u5408\u9884\u8bad\u7ec3\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e0e\u5916\u90e8\u7b26\u53f7\u7cfb\u7edf\uff0c\u5f62\u6210\u795e\u7ecf\u7b26\u53f7\u7cfb\u7edf\u3002", "result": "\u795e\u7ecf\u7b26\u53f7\u7cfb\u7edf\u80fd\u63d0\u4f9b\u66f4\u53ef\u89e3\u91ca\u7684\u8f93\u51fa\uff0c\u5e76\u51cf\u5c11\u5bf9\u65b0\u4fe1\u606f\u91cd\u65b0\u8bad\u7ec3\u7684\u9700\u6c42\u3002", "conclusion": "\u7ed3\u5408\u5916\u90e8\u7b26\u53f7\u7cfb\u7edf\u662f\u63d0\u5347\u89c6\u89c9\u8bed\u8a00\u7406\u89e3\u7684\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2507.22934", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22934", "abs": "https://arxiv.org/abs/2507.22934", "authors": ["Jingwei Zhao", "Yuhua Wen", "Qifei Li", "Minchi Hu", "Yingying Zhou", "Jingyao Xue", "Junyang Wu", "Yingming Gao", "Zhengqi Wen", "Jianhua Tao", "Ya Li"], "title": "Deep Learning Approaches for Multimodal Intent Recognition: A Survey", "comment": "Submitted to ACM Computing Surveys", "summary": "Intent recognition aims to identify users' underlying intentions,\ntraditionally focusing on text in natural language processing. With growing\ndemands for natural human-computer interaction, the field has evolved through\ndeep learning and multimodal approaches, incorporating data from audio, vision,\nand physiological signals. Recently, the introduction of Transformer-based\nmodels has led to notable breakthroughs in this domain. This article surveys\ndeep learning methods for intent recognition, covering the shift from unimodal\nto multimodal techniques, relevant datasets, methodologies, applications, and\ncurrent challenges. It provides researchers with insights into the latest\ndevelopments in multimodal intent recognition (MIR) and directions for future\nresearch.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u610f\u56fe\u8bc6\u522b\u9886\u57df\u7684\u6700\u65b0\u53d1\u5c55\uff0c\u91cd\u70b9\u4ecb\u7ecd\u4e86\u4ece\u5355\u6a21\u6001\u5230\u591a\u6a21\u6001\u65b9\u6cd5\u7684\u8f6c\u53d8\uff0c\u4ee5\u53caTransformer\u6a21\u578b\u7684\u5e94\u7528\u3002", "motivation": "\u968f\u7740\u4eba\u673a\u4ea4\u4e92\u9700\u6c42\u7684\u589e\u957f\uff0c\u610f\u56fe\u8bc6\u522b\u9886\u57df\u9700\u8981\u66f4\u81ea\u7136\u3001\u591a\u6a21\u6001\u7684\u65b9\u6cd5\u3002", "method": "\u6587\u7ae0\u8c03\u67e5\u4e86\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u5305\u62ec\u5355\u6a21\u6001\u548c\u591a\u6a21\u6001\u6280\u672f\uff0c\u4ee5\u53caTransformer\u6a21\u578b\u7684\u5e94\u7528\u3002", "result": "\u603b\u7ed3\u4e86\u76f8\u5173\u6570\u636e\u96c6\u3001\u65b9\u6cd5\u3001\u5e94\u7528\u548c\u5f53\u524d\u6311\u6218\u3002", "conclusion": "\u4e3a\u7814\u7a76\u8005\u63d0\u4f9b\u4e86\u591a\u6a21\u6001\u610f\u56fe\u8bc6\u522b\u7684\u6700\u65b0\u8fdb\u5c55\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2507.22935", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22935", "abs": "https://arxiv.org/abs/2507.22935", "authors": ["Kathleen Mealey", "Jonathan A. Karr Jr.", "Priscila Saboia Moreira", "Paul R. Brenner", "Charles F. Vardeman II"], "title": "Trusted Knowledge Extraction for Operations and Maintenance Intelligence", "comment": null, "summary": "Deriving operational intelligence from organizational data repositories is a\nkey challenge due to the dichotomy of data confidentiality vs data integration\nobjectives, as well as the limitations of Natural Language Processing (NLP)\ntools relative to the specific knowledge structure of domains such as\noperations and maintenance. In this work, we discuss Knowledge Graph\nconstruction and break down the Knowledge Extraction process into its Named\nEntity Recognition, Coreference Resolution, Named Entity Linking, and Relation\nExtraction functional components. We then evaluate sixteen NLP tools in concert\nwith or in comparison to the rapidly advancing capabilities of Large Language\nModels (LLMs). We focus on the operational and maintenance intelligence use\ncase for trusted applications in the aircraft industry. A baseline dataset is\nderived from a rich public domain US Federal Aviation Administration dataset\nfocused on equipment failures or maintenance requirements. We assess the\nzero-shot performance of NLP and LLM tools that can be operated within a\ncontrolled, confidential environment (no data is sent to third parties). Based\non our observation of significant performance limitations, we discuss the\nchallenges related to trusted NLP and LLM tools as well as their Technical\nReadiness Level for wider use in mission-critical industries such as aviation.\nWe conclude with recommendations to enhance trust and provide our open-source\ncurated dataset to support further baseline testing and evaluation.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u4ece\u7ec4\u7ec7\u6570\u636e\u4e2d\u63d0\u53d6\u64cd\u4f5c\u60c5\u62a5\u7684\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u65b9\u6cd5\uff0c\u5e76\u8bc4\u4f30\u4e86NLP\u5de5\u5177\u548cLLM\u5728\u822a\u7a7a\u7ef4\u62a4\u9886\u57df\u7684\u6027\u80fd\u4e0e\u5c40\u9650\u6027\u3002", "motivation": "\u89e3\u51b3\u6570\u636e\u4fdd\u5bc6\u6027\u4e0e\u96c6\u6210\u76ee\u6807\u4e4b\u95f4\u7684\u77db\u76fe\uff0c\u4ee5\u53caNLP\u5de5\u5177\u5728\u7279\u5b9a\u9886\u57df\uff08\u5982\u822a\u7a7a\u7ef4\u62a4\uff09\u4e2d\u7684\u5c40\u9650\u6027\u3002", "method": "\u5c06\u77e5\u8bc6\u63d0\u53d6\u8fc7\u7a0b\u5206\u89e3\u4e3a\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u3001\u5171\u6307\u6d88\u89e3\u3001\u5b9e\u4f53\u94fe\u63a5\u548c\u5173\u7cfb\u63d0\u53d6\uff0c\u5e76\u8bc4\u4f3016\u79cdNLP\u5de5\u5177\u4e0eLLM\u7684\u6027\u80fd\u3002", "result": "\u53d1\u73b0\u73b0\u6709\u5de5\u5177\u5728\u96f6\u6837\u672c\u4efb\u52a1\u4e2d\u8868\u73b0\u6709\u9650\uff0c\u8ba8\u8bba\u4e86\u53ef\u4fe1NLP\u548cLLM\u5de5\u5177\u7684\u6311\u6218\u53ca\u5176\u6280\u672f\u6210\u719f\u5ea6\u3002", "conclusion": "\u63d0\u51fa\u4e86\u589e\u5f3a\u4fe1\u4efb\u7684\u5efa\u8bae\uff0c\u5e76\u5f00\u6e90\u4e86\u6570\u636e\u96c6\u4ee5\u652f\u6301\u8fdb\u4e00\u6b65\u6d4b\u8bd5\u4e0e\u8bc4\u4f30\u3002"}}
{"id": "2507.22936", "categories": ["cs.CL", "cs.AI", "cs.CE", "cs.HC", "q-fin.CP"], "pdf": "https://arxiv.org/pdf/2507.22936", "abs": "https://arxiv.org/abs/2507.22936", "authors": ["Md Talha Mohsin"], "title": "Evaluating Large Language Models (LLMs) in Financial NLP: A Comparative Study on Financial Report Analysis", "comment": "22 Pages, 6 Tables, 7 Figures", "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities across\na wide variety of Financial Natural Language Processing (FinNLP) tasks.\nHowever, systematic comparisons among widely used LLMs remain underexplored.\nGiven the rapid advancement and growing influence of LLMs in financial\nanalysis, this study conducts a thorough comparative evaluation of five leading\nLLMs, GPT, Claude, Perplexity, Gemini and DeepSeek, using 10-K filings from the\n'Magnificent Seven' technology companies. We create a set of domain-specific\nprompts and then use three methodologies to evaluate model performance: human\nannotation, automated lexical-semantic metrics (ROUGE, Cosine Similarity,\nJaccard), and model behavior diagnostics (prompt-level variance and\nacross-model similarity). The results show that GPT gives the most coherent,\nsemantically aligned, and contextually relevant answers; followed by Claude and\nPerplexity. Gemini and DeepSeek, on the other hand, have more variability and\nless agreement. Also, the similarity and stability of outputs change from\ncompany to company and over time, showing that they are sensitive to how\nprompts are written and what source material is used.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5bf9\u4e94\u79cd\u4e3b\u6d41\u5927\u8bed\u8a00\u6a21\u578b\uff08GPT\u3001Claude\u3001Perplexity\u3001Gemini\u548cDeepSeek\uff09\u5728\u91d1\u878d\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u8fdb\u884c\u4e86\u7cfb\u7edf\u6bd4\u8f83\uff0c\u53d1\u73b0GPT\u8868\u73b0\u6700\u4f73\uff0c\u800cGemini\u548cDeepSeek\u8868\u73b0\u8f83\u5dee\u3002", "motivation": "\u7531\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u5728\u91d1\u878d\u5206\u6790\u4e2d\u7684\u5feb\u901f\u53d1\u5c55\u548c\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u6bd4\u8f83\uff0c\u56e0\u6b64\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u7814\u7a76\u4f7f\u752810-K\u6587\u4ef6\uff0c\u8bbe\u8ba1\u9886\u57df\u7279\u5b9a\u63d0\u793a\uff0c\u5e76\u901a\u8fc7\u4eba\u5de5\u6807\u6ce8\u3001\u81ea\u52a8\u8bed\u4e49\u6307\u6807\uff08\u5982ROUGE\uff09\u548c\u6a21\u578b\u884c\u4e3a\u8bca\u65ad\u4e09\u79cd\u65b9\u6cd5\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\u3002", "result": "GPT\u5728\u8fde\u8d2f\u6027\u3001\u8bed\u4e49\u5bf9\u9f50\u548c\u4e0a\u4e0b\u6587\u76f8\u5173\u6027\u4e0a\u8868\u73b0\u6700\u4f73\uff0cClaude\u548cPerplexity\u6b21\u4e4b\uff0cGemini\u548cDeepSeek\u8868\u73b0\u4e0d\u7a33\u5b9a\u4e14\u4e00\u81f4\u6027\u8f83\u4f4e\u3002", "conclusion": "\u6a21\u578b\u8868\u73b0\u53d7\u63d0\u793a\u8bbe\u8ba1\u548c\u6e90\u6750\u6599\u5f71\u54cd\uff0c\u63d0\u793a\u4e86\u672a\u6765\u7814\u7a76\u4e2d\u4f18\u5316\u63d0\u793a\u548c\u6a21\u578b\u9009\u62e9\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2507.22937", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22937", "abs": "https://arxiv.org/abs/2507.22937", "authors": ["Jinkun Zhao", "Yuanshuai Wang", "Xingjian Zhang", "Ruibo Chen", "Xingchuang Liao", "Junle Wang", "Lei Huang", "Kui Zhang", "Wenjun Wu"], "title": "CoE-Ops: Collaboration of LLM-based Experts for AIOps Question-Answering", "comment": null, "summary": "With the rapid evolution of artificial intelligence, AIOps has emerged as a\nprominent paradigm in DevOps. Lots of work has been proposed to improve the\nperformance of different AIOps phases. However, constrained by domain-specific\nknowledge, a single model can only handle the operation requirement of a\nspecific task,such as log parser,root cause analysis. Meanwhile, combining\nmultiple models can achieve more efficient results, which have been proved in\nboth previous ensemble learning and the recent LLM training domain. Inspired by\nthese works,to address the similar challenges in AIOPS, this paper first\nproposes a collaboration-of-expert framework(CoE-Ops) incorporating a\ngeneral-purpose large language model task classifier. A retrieval-augmented\ngeneration mechanism is introduced to improve the framework's capability in\nhandling both Question-Answering tasks with high-level(Code,build,Test,etc.)\nand low-level(fault analysis,anomaly detection,etc.). Finally, the proposed\nmethod is implemented in the AIOps domain, and extensive experiments are\nconducted on the DevOps-EVAL dataset. Experimental results demonstrate that\nCoE-Ops achieves a 72% improvement in routing accuracy for high-level AIOps\ntasks compared to existing CoE methods, delivers up to 8% accuracy enhancement\nover single AIOps models in DevOps problem resolution, and outperforms\nlarger-scale Mixture-of-Experts (MoE) models by up to 14% in accuracy.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u534f\u4f5c\u4e13\u5bb6\u6846\u67b6\uff08CoE-Ops\uff09\uff0c\u7ed3\u5408\u901a\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4efb\u52a1\u5206\u7c7b\u5668\uff0c\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u673a\u5236\u63d0\u5347\u5904\u7406\u9ad8\u4f4e\u7ea7AIOps\u4efb\u52a1\u7684\u80fd\u529b\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6027\u80fd\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709AIOps\u6a21\u578b\u53d7\u9650\u4e8e\u9886\u57df\u77e5\u8bc6\uff0c\u53ea\u80fd\u5904\u7406\u7279\u5b9a\u4efb\u52a1\uff0c\u800c\u591a\u6a21\u578b\u534f\u4f5c\u5728\u96c6\u6210\u5b66\u4e60\u548cLLM\u8bad\u7ec3\u4e2d\u5df2\u8bc1\u660e\u66f4\u9ad8\u6548\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3AIOps\u4e2d\u7684\u7c7b\u4f3c\u6311\u6218\u3002", "method": "\u63d0\u51faCoE-Ops\u6846\u67b6\uff0c\u7ed3\u5408\u901a\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4efb\u52a1\u5206\u7c7b\u5668\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u673a\u5236\uff0c\u5904\u7406\u9ad8\u4f4e\u7ea7AIOps\u4efb\u52a1\u3002", "result": "\u5728DevOps-EVAL\u6570\u636e\u96c6\u4e0a\uff0cCoE-Ops\u5728\u9ad8\u9636\u4efb\u52a1\u8def\u7531\u51c6\u786e\u7387\u4e0a\u63d0\u534772%\uff0c\u5728\u95ee\u9898\u89e3\u51b3\u51c6\u786e\u7387\u4e0a\u6bd4\u5355\u6a21\u578b\u9ad88%\uff0c\u6bd4MoE\u6a21\u578b\u9ad814%\u3002", "conclusion": "CoE-Ops\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86AIOps\u4efb\u52a1\u7684\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u591a\u6a21\u578b\u534f\u4f5c\u5728AIOps\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2507.22938", "categories": ["cs.CL", "cs.AI", "68T50", "I.2.7"], "pdf": "https://arxiv.org/pdf/2507.22938", "abs": "https://arxiv.org/abs/2507.22938", "authors": ["Sumit Soman", "H. G. Ranjani", "Sujoy Roychowdhury", "Venkata Dharma Surya Narayana Sastry", "Akshat Jain", "Pranav Gangrade", "Ayaaz Khan"], "title": "A Graph-based Approach for Multi-Modal Question Answering from Flowcharts in Telecom Documents", "comment": "Accepted for publication at the KDD 2025 Workshop on Structured\n  Knowledge for Large Language Models", "summary": "Question-Answering (QA) from technical documents often involves questions\nwhose answers are present in figures, such as flowcharts or flow diagrams.\nText-based Retrieval Augmented Generation (RAG) systems may fail to answer such\nquestions. We leverage graph representations of flowcharts obtained from Visual\nlarge Language Models (VLMs) and incorporate them in a text-based RAG system to\nshow that this approach can enable image retrieval for QA in the telecom\ndomain. We present the end-to-end approach from processing technical documents,\nclassifying image types, building graph representations, and incorporating them\nwith the text embedding pipeline for efficient retrieval. We benchmark the same\non a QA dataset created based on proprietary telecom product information\ndocuments. Results show that the graph representations obtained using a\nfine-tuned VLM model have lower edit distance with respect to the ground truth,\nwhich illustrate the robustness of these representations for flowchart images.\nFurther, the approach for QA using these representations gives good retrieval\nperformance using text-based embedding models, including a telecom-domain\nadapted one. Our approach also alleviates the need for a VLM in inference,\nwhich is an important cost benefit for deployed QA systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u89c6\u89c9\u5927\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u751f\u6210\u7684\u6d41\u7a0b\u56fe\u56fe\u8868\u793a\u4e0e\u6587\u672c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7cfb\u7edf\u7684\u65b9\u6cd5\uff0c\u4ee5\u89e3\u51b3\u6280\u672f\u6587\u6863\u4e2d\u57fa\u4e8e\u56fe\u50cf\u7684\u95ee\u7b54\u95ee\u9898\u3002", "motivation": "\u6280\u672f\u6587\u6863\u4e2d\u7684\u95ee\u7b54\u5e38\u6d89\u53ca\u56fe\u8868\u5185\u5bb9\uff0c\u4f20\u7edf\u6587\u672cRAG\u7cfb\u7edf\u96be\u4ee5\u5904\u7406\u8fd9\u7c7b\u95ee\u9898\u3002", "method": "\u5229\u7528VLM\u4ece\u6d41\u7a0b\u56fe\u4e2d\u63d0\u53d6\u56fe\u8868\u793a\uff0c\u5e76\u5c06\u5176\u6574\u5408\u5230\u6587\u672cRAG\u7cfb\u7edf\u4e2d\uff0c\u5b9e\u73b0\u56fe\u50cf\u68c0\u7d22\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u7535\u4fe1\u9886\u57dfQA\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u56fe\u8868\u793a\u4e0e\u771f\u5b9e\u503c\u7f16\u8f91\u8ddd\u79bb\u66f4\u4f4e\uff0c\u68c0\u7d22\u6027\u80fd\u4f18\u8d8a\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u63d0\u5347\u4e86\u95ee\u7b54\u6027\u80fd\uff0c\u8fd8\u907f\u514d\u4e86\u63a8\u7406\u65f6\u4f7f\u7528VLM\uff0c\u964d\u4f4e\u4e86\u90e8\u7f72\u6210\u672c\u3002"}}
{"id": "2507.22939", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22939", "abs": "https://arxiv.org/abs/2507.22939", "authors": ["Bastien Le Guellec", "Kokou Adambounou", "Lisa C Adams", "Thibault Agripnidis", "Sung Soo Ahn", "Radhia Ait Chalal", "Tugba Akinci D Antonoli", "Philippe Amouyel", "Henrik Andersson", "Raphael Bentegeac", "Claudio Benzoni", "Antonino Andrea Blandino", "Felix Busch", "Elif Can", "Riccardo Cau", "Armando Ugo Cavallo", "Christelle Chavihot", "Erwin Chiquete", "Renato Cuocolo", "Eugen Divjak", "Gordana Ivanac", "Barbara Dziadkowiec Macek", "Armel Elogne", "Salvatore Claudio Fanni", "Carlos Ferrarotti", "Claudia Fossataro", "Federica Fossataro", "Katarzyna Fulek", "Michal Fulek", "Pawel Gac", "Martyna Gachowska", "Ignacio Garcia Juarez", "Marco Gatti", "Natalia Gorelik", "Alexia Maria Goulianou", "Aghiles Hamroun", "Nicolas Herinirina", "Krzysztof Kraik", "Dominik Krupka", "Quentin Holay", "Felipe Kitamura", "Michail E Klontzas", "Anna Kompanowska", "Rafal Kompanowski", "Alexandre Lefevre", "Tristan Lemke", "Maximilian Lindholz", "Lukas Muller", "Piotr Macek", "Marcus Makowski", "Luigi Mannacio", "Aymen Meddeb", "Antonio Natale", "Beatrice Nguema Edzang", "Adriana Ojeda", "Yae Won Park", "Federica Piccione", "Andrea Ponsiglione", "Malgorzata Poreba", "Rafal Poreba", "Philipp Prucker", "Jean Pierre Pruvo", "Rosa Alba Pugliesi", "Feno Hasina Rabemanorintsoa", "Vasileios Rafailidis", "Katarzyna Resler", "Jan Rotkegel", "Luca Saba", "Ezann Siebert", "Arnaldo Stanzione", "Ali Fuat Tekin", "Liz Toapanta Yanchapaxi", "Matthaios Triantafyllou", "Ekaterini Tsaoulia", "Evangelia Vassalou", "Federica Vernuccio", "Johan Wasselius", "Weilang Wang", "Szymon Urban", "Adrian Wlodarczak", "Szymon Wlodarczak", "Andrzej Wysocki", "Lina Xu", "Tomasz Zatonski", "Shuhang Zhang", "Sebastian Ziegelmayer", "Gregory Kuchcinski", "Keno K Bressem"], "title": "PARROT: An Open Multilingual Radiology Reports Dataset", "comment": null, "summary": "Rationale and Objectives: To develop and validate PARROT (Polyglottal\nAnnotated Radiology Reports for Open Testing), a large, multicentric,\nopen-access dataset of fictional radiology reports spanning multiple languages\nfor testing natural language processing applications in radiology. Materials\nand Methods: From May to September 2024, radiologists were invited to\ncontribute fictional radiology reports following their standard reporting\npractices. Contributors provided at least 20 reports with associated metadata\nincluding anatomical region, imaging modality, clinical context, and for\nnon-English reports, English translations. All reports were assigned ICD-10\ncodes. A human vs. AI report differentiation study was conducted with 154\nparticipants (radiologists, healthcare professionals, and non-healthcare\nprofessionals) assessing whether reports were human-authored or AI-generated.\nResults: The dataset comprises 2,658 radiology reports from 76 authors across\n21 countries and 13 languages. Reports cover multiple imaging modalities (CT:\n36.1%, MRI: 22.8%, radiography: 19.0%, ultrasound: 16.8%) and anatomical\nregions, with chest (19.9%), abdomen (18.6%), head (17.3%), and pelvis (14.1%)\nbeing most prevalent. In the differentiation study, participants achieved 53.9%\naccuracy (95% CI: 50.7%-57.1%) in distinguishing between human and AI-generated\nreports, with radiologists performing significantly better (56.9%, 95% CI:\n53.3%-60.6%, p<0.05) than other groups. Conclusion: PARROT represents the\nlargest open multilingual radiology report dataset, enabling development and\nvalidation of natural language processing applications across linguistic,\ngeographic, and clinical boundaries without privacy constraints.", "AI": {"tldr": "PARROT\u662f\u4e00\u4e2a\u591a\u8bed\u8a00\u3001\u5f00\u653e\u7684\u865a\u6784\u653e\u5c04\u5b66\u62a5\u544a\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u6d4b\u8bd5\u81ea\u7136\u8bed\u8a00\u5904\u7406\u5e94\u7528\u3002\u6570\u636e\u96c6\u5305\u542b2658\u4efd\u62a5\u544a\uff0c\u6db5\u76d6\u591a\u79cd\u8bed\u8a00\u548c\u5f71\u50cf\u6a21\u6001\u3002\u4eba\u7c7b\u4e0eAI\u62a5\u544a\u533a\u5206\u7814\u7a76\u4e2d\uff0c\u53c2\u4e0e\u8005\u51c6\u786e\u7387\u4e3a53.9%\uff0c\u653e\u5c04\u79d1\u533b\u751f\u8868\u73b0\u66f4\u597d\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u591a\u8bed\u8a00\u3001\u5f00\u653e\u7684\u653e\u5c04\u5b66\u62a5\u544a\u6570\u636e\u96c6\uff0c\u4ee5\u652f\u6301\u81ea\u7136\u8bed\u8a00\u5904\u7406\u5728\u653e\u5c04\u5b66\u4e2d\u7684\u5e94\u7528\uff0c\u540c\u65f6\u907f\u514d\u9690\u79c1\u95ee\u9898\u3002", "method": "\u9080\u8bf7\u653e\u5c04\u79d1\u533b\u751f\u8d21\u732e\u865a\u6784\u62a5\u544a\uff0c\u6536\u96c6\u62a5\u544a\u53ca\u76f8\u5173\u5143\u6570\u636e\uff0c\u5e76\u8fdb\u884c\u4eba\u7c7b\u4e0eAI\u62a5\u544a\u533a\u5206\u7814\u7a76\u3002", "result": "\u6570\u636e\u96c6\u5305\u542b2658\u4efd\u62a5\u544a\uff0c\u6db5\u76d613\u79cd\u8bed\u8a00\u548c\u591a\u79cd\u5f71\u50cf\u6a21\u6001\u3002\u533a\u5206\u7814\u7a76\u4e2d\uff0c\u53c2\u4e0e\u8005\u51c6\u786e\u7387\u4e3a53.9%\uff0c\u653e\u5c04\u79d1\u533b\u751f\u8868\u73b0\u663e\u8457\u66f4\u597d\u3002", "conclusion": "PARROT\u662f\u6700\u5927\u7684\u5f00\u653e\u591a\u8bed\u8a00\u653e\u5c04\u5b66\u62a5\u544a\u6570\u636e\u96c6\uff0c\u652f\u6301\u8de8\u8bed\u8a00\u3001\u5730\u7406\u548c\u4e34\u5e8a\u8fb9\u754c\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u5e94\u7528\u5f00\u53d1\u3002"}}
{"id": "2507.22940", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22940", "abs": "https://arxiv.org/abs/2507.22940", "authors": ["Rui Jiao", "Yue Zhang", "Jinku Li"], "title": "Trustworthy Reasoning: Evaluating and Enhancing Factual Accuracy in LLM Intermediate Thought Processes", "comment": null, "summary": "We present RELIANCE (Reasoning Evaluation with Logical Integrity and Accuracy\nfor Confidence Enhancement), a novel framework addressing a critical\nvulnerability in Large Language Models (LLMs): the prevalence of factual\ninaccuracies within intermediate reasoning steps despite correct final answers.\nThis phenomenon poses substantial risks in high-stakes domains including\nhealthcare, legal analysis, and scientific research, where erroneous yet\nconfidently presented reasoning can mislead users into dangerous decisions. Our\nframework integrates three core components: (1) a specialized fact-checking\nclassifier trained on counterfactually augmented data to detect subtle factual\ninconsistencies within reasoning chains; (2) a Group Relative Policy\nOptimization (GRPO) reinforcement learning approach that balances factuality,\ncoherence, and structural correctness through multi-dimensional rewards; and\n(3) a mechanistic interpretability module examining how factuality improvements\nmanifest in model activations during reasoning processes. Extensive evaluation\nacross ten state-of-the-art models reveals concerning patterns: even leading\nmodels like Claude-3.7 and GPT-o1 demonstrate reasoning factual accuracy of\nonly 81.93% and 82.57% respectively. RELIANCE significantly enhances factual\nrobustness (up to 49.90% improvement) while maintaining or improving\nperformance on challenging benchmarks including Math-500, AIME-2024, and GPQA.\nFurthermore, our activation-level analysis provides actionable insights into\nhow factual enhancements reshape reasoning trajectories within model\narchitectures, establishing foundations for future training methodologies that\nexplicitly target factual robustness through activation-guided optimization.", "AI": {"tldr": "RELIANCE\u6846\u67b6\u901a\u8fc7\u4e8b\u5b9e\u68c0\u67e5\u3001\u5f3a\u5316\u5b66\u4e60\u548c\u53ef\u89e3\u91ca\u6027\u6a21\u5757\u63d0\u5347LLM\u63a8\u7406\u6b65\u9aa4\u7684\u4e8b\u5b9e\u51c6\u786e\u6027\uff0c\u663e\u8457\u6539\u5584\u4e8b\u5b9e\u7a33\u5065\u6027\u3002", "motivation": "\u89e3\u51b3LLM\u5728\u63a8\u7406\u6b65\u9aa4\u4e2d\u4e8b\u5b9e\u9519\u8bef\u7684\u95ee\u9898\uff0c\u907f\u514d\u9ad8\u98ce\u9669\u9886\u57df\u7684\u8bef\u5bfc\u51b3\u7b56\u3002", "method": "\u7ed3\u5408\u4e8b\u5b9e\u68c0\u67e5\u5206\u7c7b\u5668\u3001GRPO\u5f3a\u5316\u5b66\u4e60\u548c\u53ef\u89e3\u91ca\u6027\u6a21\u5757\u3002", "result": "\u663e\u8457\u63d0\u5347\u4e8b\u5b9e\u51c6\u786e\u6027\uff08\u6700\u9ad849.9%\u6539\u8fdb\uff09\uff0c\u5e76\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4fdd\u6301\u6216\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "RELIANCE\u4e3a\u672a\u6765\u901a\u8fc7\u6fc0\u6d3b\u5f15\u5bfc\u4f18\u5316\u63d0\u5347\u4e8b\u5b9e\u7a33\u5065\u6027\u7684\u8bad\u7ec3\u65b9\u6cd5\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2507.22941", "categories": ["cs.CL", "cs.CY", "cs.LG", "stat.AP"], "pdf": "https://arxiv.org/pdf/2507.22941", "abs": "https://arxiv.org/abs/2507.22941", "authors": ["Paul Minchella", "Lo\u00efc Verlingue", "St\u00e9phane Chr\u00e9tien", "R\u00e9mi Vaucher", "Guillaume Metzler"], "title": "SigBERT: Combining Narrative Medical Reports and Rough Path Signature Theory for Survival Risk Estimation in Oncology", "comment": "12 pages, 2 figures, accepted for ECML PKDD 2025", "summary": "Electronic medical reports (EHR) contain a vast amount of information that\ncan be leveraged for machine learning applications in healthcare. However,\nexisting survival analysis methods often struggle to effectively handle the\ncomplexity of textual data, particularly in its sequential form. Here, we\npropose SigBERT, an innovative temporal survival analysis framework designed to\nefficiently process a large number of clinical reports per patient. SigBERT\nprocesses timestamped medical reports by extracting and averaging word\nembeddings into sentence embeddings. To capture temporal dynamics from the time\nseries of sentence embedding coordinates, we apply signature extraction from\nrough path theory to derive geometric features for each patient, which\nsignificantly enhance survival model performance by capturing complex temporal\ndynamics. These features are then integrated into a LASSO-penalized Cox model\nto estimate patient-specific risk scores. The model was trained and evaluated\non a real-world oncology dataset from the L\\'eon B\\'erard Center corpus, with a\nC-index score of 0.75 (sd 0.014) on the independent test cohort. SigBERT\nintegrates sequential medical data to enhance risk estimation, advancing\nnarrative-based survival analysis.", "AI": {"tldr": "SigBERT\u662f\u4e00\u4e2a\u521b\u65b0\u7684\u65f6\u5e8f\u751f\u5b58\u5206\u6790\u6846\u67b6\uff0c\u901a\u8fc7\u5904\u7406\u7535\u5b50\u533b\u7597\u62a5\u544a\u4e2d\u7684\u6587\u672c\u6570\u636e\uff0c\u7ed3\u5408\u7b7e\u540d\u63d0\u53d6\u548cLASSO\u60e9\u7f5a\u7684Cox\u6a21\u578b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u751f\u5b58\u5206\u6790\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u751f\u5b58\u5206\u6790\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u5904\u7406\u6587\u672c\u6570\u636e\u7684\u590d\u6742\u6027\uff0c\u5c24\u5176\u662f\u65f6\u5e8f\u5f62\u5f0f\u7684\u4e34\u5e8a\u62a5\u544a\u3002", "method": "SigBERT\u901a\u8fc7\u63d0\u53d6\u548c\u5e73\u5747\u8bcd\u5d4c\u5165\u4e3a\u53e5\u5b50\u5d4c\u5165\uff0c\u5229\u7528\u7c97\u7cd9\u8def\u5f84\u7406\u8bba\u7684\u7b7e\u540d\u63d0\u53d6\u6355\u83b7\u65f6\u5e8f\u52a8\u6001\uff0c\u5e76\u5c06\u51e0\u4f55\u7279\u5f81\u6574\u5408\u5230LASSO\u60e9\u7f5a\u7684Cox\u6a21\u578b\u4e2d\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u80bf\u7624\u6570\u636e\u96c6\u4e0a\uff0cSigBERT\u7684C-index\u5f97\u5206\u4e3a0.75\uff08\u6807\u51c6\u5dee0.014\uff09\u3002", "conclusion": "SigBERT\u901a\u8fc7\u6574\u5408\u65f6\u5e8f\u533b\u7597\u6570\u636e\uff0c\u63d0\u5347\u4e86\u98ce\u9669\u4f30\u8ba1\u80fd\u529b\uff0c\u63a8\u52a8\u4e86\u57fa\u4e8e\u53d9\u4e8b\u7684\u751f\u5b58\u5206\u6790\u3002"}}
{"id": "2507.22943", "categories": ["cs.CL", "stat.ME"], "pdf": "https://arxiv.org/pdf/2507.22943", "abs": "https://arxiv.org/abs/2507.22943", "authors": ["Shirley V Wang", "Georg Hahn", "Sushama Kattinakere Sreedhara", "Mufaddal Mahesri", "Haritha S. Pillai", "Rajendra Aldis", "Joyce Lii", "Sarah K. Dutcher", "Rhoda Eniafe", "Jamal T. Jones", "Keewan Kim", "Jiwei He", "Hana Lee", "Sengwee Toh", "Rishi J Desai", "Jie Yang"], "title": "A chart review process aided by natural language processing and multi-wave adaptive sampling to expedite validation of code-based algorithms for large database studies", "comment": null, "summary": "Background: One of the ways to enhance analyses conducted with large claims\ndatabases is by validating the measurement characteristics of code-based\nalgorithms used to identify health outcomes or other key study parameters of\ninterest. These metrics can be used in quantitative bias analyses to assess the\nrobustness of results for an inferential study given potential bias from\noutcome misclassification. However, extensive time and resource allocation are\ntypically re-quired to create reference-standard labels through manual chart\nreview of free-text notes from linked electronic health records. Methods: We\ndescribe an expedited process that introduces efficiency in a validation study\nus-ing two distinct mechanisms: 1) use of natural language processing (NLP) to\nreduce time spent by human reviewers to review each chart, and 2) a multi-wave\nadaptive sampling approach with pre-defined criteria to stop the validation\nstudy once performance characteristics are identified with sufficient\nprecision. We illustrate this process in a case study that validates the\nperformance of a claims-based outcome algorithm for intentional self-harm in\npatients with obesity. Results: We empirically demonstrate that the\nNLP-assisted annotation process reduced the time spent on review per chart by\n40% and use of the pre-defined stopping rule with multi-wave samples would have\nprevented review of 77% of patient charts with limited compromise to precision\nin derived measurement characteristics. Conclusion: This approach could\nfacilitate more routine validation of code-based algorithms used to define key\nstudy parameters, ultimately enhancing understanding of the reliability of\nfind-ings derived from database studies.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u548c\u591a\u6ce2\u81ea\u9002\u5e94\u91c7\u6837\u7684\u9ad8\u6548\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u7528\u4e8e\u9a8c\u8bc1\u57fa\u4e8e\u4ee3\u7801\u7684\u7b97\u6cd5\u5728\u5065\u5eb7\u7ed3\u679c\u8bc6\u522b\u4e2d\u7684\u6027\u80fd\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u65f6\u95f4\u548c\u8d44\u6e90\u6d88\u8017\u3002", "motivation": "\u5728\u5927\u89c4\u6a21\u7d22\u8d54\u6570\u636e\u5e93\u5206\u6790\u4e2d\uff0c\u9a8c\u8bc1\u57fa\u4e8e\u4ee3\u7801\u7684\u7b97\u6cd5\u7684\u6d4b\u91cf\u7279\u6027\u662f\u63d0\u9ad8\u7ed3\u679c\u53ef\u9760\u6027\u7684\u5173\u952e\uff0c\u4f46\u4f20\u7edf\u624b\u52a8\u56fe\u8868\u5ba1\u67e5\u8017\u65f6\u8017\u529b\u3002", "method": "\u91c7\u7528NLP\u51cf\u5c11\u4eba\u5de5\u5ba1\u67e5\u65f6\u95f4\uff0c\u5e76\u7ed3\u5408\u591a\u6ce2\u81ea\u9002\u5e94\u91c7\u6837\u548c\u9884\u5b9a\u4e49\u505c\u6b62\u89c4\u5219\uff0c\u4ee5\u9ad8\u6548\u5b8c\u6210\u9a8c\u8bc1\u3002", "result": "NLP\u8f85\u52a9\u5ba1\u67e5\u4f7f\u6bcf\u5f20\u56fe\u8868\u5ba1\u67e5\u65f6\u95f4\u51cf\u5c1140%\uff0c\u591a\u6ce2\u91c7\u6837\u65b9\u6cd5\u53ef\u907f\u514d77%\u7684\u56fe\u8868\u5ba1\u67e5\uff0c\u4e14\u4e0d\u5f71\u54cd\u6d4b\u91cf\u7cbe\u5ea6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u53ef\u4fc3\u8fdb\u66f4\u9891\u7e41\u7684\u7b97\u6cd5\u9a8c\u8bc1\uff0c\u63d0\u5347\u6570\u636e\u5e93\u7814\u7a76\u7ed3\u679c\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2507.22944", "categories": ["cs.CL", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2507.22944", "abs": "https://arxiv.org/abs/2507.22944", "authors": ["Naomi Omeonga wa Kayembe"], "title": "Opacity as Authority: Arbitrariness and the Preclusion of Contestation", "comment": null, "summary": "This article redefines arbitrariness not as a normative flaw or a symptom of\ndomination, but as a foundational functional mechanism structuring human\nsystems and interactions. Diverging from critical traditions that conflate\narbitrariness with injustice, it posits arbitrariness as a semiotic trait: a\nproperty enabling systems - linguistic, legal, or social - to operate\neffectively while withholding their internal rationale. Building on Ferdinand\nde Saussure's concept of l'arbitraire du signe, the analysis extends this\nprinciple beyond language to demonstrate its cross-domain applicability,\nparticularly in law and social dynamics. The paper introduces the \"Motivation\n-> Constatability -> Contestability\" chain, arguing that motivation functions\nas a crucial interface rendering an act's logic vulnerable to intersubjective\ncontestation. When this chain is broken through mechanisms like\n\"immotivization\" or \"Conflict Lateralization\" (exemplified by \"the blur of the\nwolf drowned in the fish\"), acts produce binding effects without exposing their\nrationale, thus precluding justiciability. This structural opacity, while\nappearing illogical, is a deliberate design protecting authority from\naccountability. Drawing on Shannon's entropy model, the paper formalizes\narbitrariness as A = H(L|M) (conditional entropy). It thereby proposes a modern\ntheory of arbitrariness as a neutral operator central to control as well as\ncare, an overlooked dimension of interpersonal relations. While primarily\ndeveloped through human social systems, this framework also illuminates a new\npathway for analyzing explainability in advanced artificial intelligence\nsystems.", "AI": {"tldr": "\u8bba\u6587\u91cd\u65b0\u5b9a\u4e49\u4efb\u610f\u6027\uff0c\u5c06\u5176\u89c6\u4e3a\u4eba\u7c7b\u7cfb\u7edf\u548c\u4e92\u52a8\u7684\u57fa\u7840\u529f\u80fd\u673a\u5236\uff0c\u800c\u975e\u89c4\u8303\u6027\u7f3a\u9677\u6216\u652f\u914d\u75c7\u72b6\u3002", "motivation": "\u6311\u6218\u4f20\u7edf\u6279\u5224\u89c2\u70b9\uff0c\u5c06\u4efb\u610f\u6027\u89c6\u4e3a\u7b26\u53f7\u5b66\u7279\u6027\uff0c\u652f\u6301\u7cfb\u7edf\u6709\u6548\u8fd0\u4f5c\u3002", "method": "\u57fa\u4e8e\u7d22\u7eea\u5c14\u7684\u7b26\u53f7\u4efb\u610f\u6027\u7406\u8bba\uff0c\u6269\u5c55\u81f3\u6cd5\u5f8b\u548c\u793e\u4f1a\u52a8\u6001\uff0c\u63d0\u51fa\u201c\u52a8\u673a\u2192\u53ef\u89c2\u5bdf\u6027\u2192\u53ef\u4e89\u8bae\u6027\u201d\u94fe\u3002", "result": "\u5f62\u5f0f\u5316\u4efb\u610f\u6027\u4e3a\u6761\u4ef6\u71b5A=H(L|M)\uff0c\u63ed\u793a\u5176\u4f5c\u4e3a\u63a7\u5236\u548c\u5173\u6000\u4e2d\u6027\u64cd\u4f5c\u8005\u7684\u4f5c\u7528\u3002", "conclusion": "\u4efb\u610f\u6027\u662f\u7ed3\u6784\u8bbe\u8ba1\u7684\u4e00\u90e8\u5206\uff0c\u4fdd\u62a4\u6743\u5a01\u514d\u4e8e\u95ee\u8d23\uff0c\u5e76\u4e3aAI\u7cfb\u7edf\u53ef\u89e3\u91ca\u6027\u63d0\u4f9b\u65b0\u89c6\u89d2\u3002"}}
{"id": "2507.22968", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22968", "abs": "https://arxiv.org/abs/2507.22968", "authors": ["Chengqian Ma", "Wei Tao", "Yiwen Guo"], "title": "C3: A Bilingual Benchmark for Spoken Dialogue Models Exploring Challenges in Complex Conversations", "comment": null, "summary": "Spoken Dialogue Models (SDMs) have recently attracted significant attention\nfor their ability to generate voice responses directly to users' spoken\nqueries. Despite their increasing popularity, there exists a gap in research\nfocused on comprehensively understanding their practical effectiveness in\ncomprehending and emulating human conversations. This is especially true\ncompared to text-based Large Language Models (LLMs), which benefit from\nextensive benchmarking. Human voice interactions are inherently more complex\nthan text due to characteristics unique to spoken dialogue. Ambiguity poses one\nchallenge, stemming from semantic factors like polysemy, as well as\nphonological aspects such as heterograph, heteronyms, and stress patterns.\nAdditionally, context-dependency, like omission, coreference, and multi-turn\ninteraction, adds further complexity to human conversational dynamics. To\nilluminate the current state of SDM development and to address these\nchallenges, we present a benchmark dataset in this paper, which comprises 1,079\ninstances in English and Chinese. Accompanied by an LLM-based evaluation method\nthat closely aligns with human judgment, this dataset facilitates a\ncomprehensive exploration of the performance of SDMs in tackling these\npractical challenges.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u53e3\u8bed\u5bf9\u8bdd\u6a21\u578b\uff08SDMs\uff09\u7684\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5305\u542b1079\u4e2a\u4e2d\u82f1\u6587\u5b9e\u4f8b\uff0c\u5e76\u91c7\u7528\u57fa\u4e8eLLM\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u4ee5\u89e3\u51b3SDMs\u5728\u7406\u89e3\u548c\u6a21\u62df\u4eba\u7c7b\u5bf9\u8bdd\u4e2d\u7684\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u5bf9SDMs\u5728\u5b9e\u9645\u5bf9\u8bdd\u4e2d\u8868\u73b0\u7684\u7cfb\u7edf\u8bc4\u4f30\uff0c\u5c24\u5176\u662f\u4e0e\u6587\u672c\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u76f8\u6bd4\u3002\u53e3\u8bed\u5bf9\u8bdd\u7684\u590d\u6742\u6027\uff08\u5982\u6b67\u4e49\u548c\u4e0a\u4e0b\u6587\u4f9d\u8d56\uff09\u589e\u52a0\u4e86\u8bc4\u4f30\u96be\u5ea6\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b1079\u4e2a\u4e2d\u82f1\u6587\u5b9e\u4f8b\u7684\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u4ee5\u6a21\u62df\u4eba\u7c7b\u5224\u65ad\u3002", "result": "\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u65b9\u6cd5\u4e3aSDMs\u7684\u6027\u80fd\u63d0\u4f9b\u4e86\u5168\u9762\u5206\u6790\u5de5\u5177\uff0c\u63ed\u793a\u4e86\u5176\u5728\u5904\u7406\u53e3\u8bed\u5bf9\u8bdd\u6311\u6218\u4e2d\u7684\u8868\u73b0\u3002", "conclusion": "\u8be5\u7814\u7a76\u586b\u8865\u4e86SDMs\u8bc4\u4f30\u7684\u7a7a\u767d\uff0c\u4e3a\u672a\u6765\u6539\u8fdbSDMs\u5728\u53e3\u8bed\u5bf9\u8bdd\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2507.23063", "categories": ["cs.CL", "68T50", "I.2.7"], "pdf": "https://arxiv.org/pdf/2507.23063", "abs": "https://arxiv.org/abs/2507.23063", "authors": ["Valeria de Paiva", "Qiyue Gao", "Hai Hu", "Pavel Kovalev", "Yikang Liu", "Lawrence S. Moss", "Zhiheng Qian"], "title": "Math Natural Language Inference: this should be easy!", "comment": "9 pages plus appendices", "summary": "We ask whether contemporary LLMs are able to perform natural language\ninference (NLI) tasks on mathematical texts. We call this the Math NLI problem.\nWe construct a corpus of Math NLI pairs whose premises are from extant\nmathematical text and whose hypotheses and gold labels were provided by people\nwith experience in both research-level mathematics and also in the NLI field.\nWe also investigate the quality of corpora using the same premises but whose\nhypotheses are provided by LLMs themselves. We not only investigate the\nperformance but also the inter-group consistency of the diverse group of LLMs.\nWe have both positive and negative findings. Among our positive findings: in\nsome settings, using a majority vote of LLMs is approximately equivalent to\nusing human-labeled data in the Math NLI area. On the negative side: LLMs still\nstruggle with mathematical language. They occasionally fail at even basic\ninferences. Current models are not as prone to hypothesis-only \"inference\" in\nour data the way the previous generation had been. In addition to our findings,\nwe also provide our corpora as data to support future work on Math NLI.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u5f53\u4ee3LLMs\u80fd\u5426\u5904\u7406\u6570\u5b66\u6587\u672c\u7684\u81ea\u7136\u8bed\u8a00\u63a8\u7406\uff08Math NLI\uff09\u4efb\u52a1\uff0c\u6784\u5efa\u4e86\u76f8\u5173\u8bed\u6599\u5e93\uff0c\u5e76\u8bc4\u4f30\u4e86LLMs\u7684\u8868\u73b0\u548c\u4e00\u81f4\u6027\u3002", "motivation": "\u63a2\u7d22LLMs\u5728\u6570\u5b66\u6587\u672c\u63a8\u7406\u4e2d\u7684\u80fd\u529b\uff0c\u586b\u8865Math NLI\u9886\u57df\u7684\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u6784\u5efa\u4eba\u5de5\u6807\u6ce8\u548cLLMs\u751f\u6210\u7684Math NLI\u8bed\u6599\u5e93\uff0c\u8bc4\u4f30LLMs\u7684\u8868\u73b0\u548c\u4e00\u81f4\u6027\u3002", "result": "LLMs\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u8868\u73b0\u63a5\u8fd1\u4eba\u7c7b\u6807\u6ce8\uff0c\u4f46\u5728\u6570\u5b66\u8bed\u8a00\u63a8\u7406\u4e0a\u4ecd\u6709\u56f0\u96be\u3002", "conclusion": "LLMs\u5728Math NLI\u4e2d\u6709\u6f5c\u529b\uff0c\u4f46\u9700\u6539\u8fdb\u6570\u5b66\u8bed\u8a00\u5904\u7406\u80fd\u529b\uff1b\u63d0\u4f9b\u8bed\u6599\u5e93\u652f\u6301\u672a\u6765\u7814\u7a76\u3002"}}
{"id": "2507.23082", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.23082", "abs": "https://arxiv.org/abs/2507.23082", "authors": ["Diego Garat", "Guillermo Moncecchi", "Dina Wonsever"], "title": "Exploring In-Context Learning for Frame-Semantic Parsing", "comment": null, "summary": "Frame Semantic Parsing (FSP) entails identifying predicates and labeling\ntheir arguments according to Frame Semantics. This paper investigates the use\nof In-Context Learning (ICL) with Large Language Models (LLMs) to perform FSP\nwithout model fine-tuning. We propose a method that automatically generates\ntask-specific prompts for the Frame Identification (FI) and Frame Semantic Role\nLabeling (FSRL) subtasks, relying solely on the FrameNet database. These\nprompts, constructed from frame definitions and annotated examples, are used to\nguide six different LLMs. Experiments are conducted on a subset of frames\nrelated to violent events. The method achieves competitive results, with F1\nscores of 94.3% for FI and 77.4% for FSRL. The findings suggest that ICL offers\na practical and effective alternative to traditional fine-tuning for\ndomain-specific FSP tasks.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08ICL\uff09\u8fdb\u884c\u6846\u67b6\u8bed\u4e49\u89e3\u6790\uff08FSP\uff09\uff0c\u65e0\u9700\u5fae\u8c03\u6a21\u578b\uff0c\u901a\u8fc7\u81ea\u52a8\u751f\u6210\u4efb\u52a1\u7279\u5b9a\u63d0\u793a\uff0c\u5728FrameNet\u6570\u636e\u5e93\u4e0a\u5b9e\u73b0\u4e86\u7ade\u4e89\u6027\u7ed3\u679c\u3002", "motivation": "\u63a2\u7d22\u65e0\u9700\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u4e0a\u4e0b\u6587\u5b66\u4e60\u5b8c\u6210\u6846\u67b6\u8bed\u4e49\u89e3\u6790\u4efb\u52a1\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u81ea\u52a8\u751f\u6210\u4efb\u52a1\u7279\u5b9a\u63d0\u793a\u7684\u65b9\u6cd5\uff0c\u57fa\u4e8eFrameNet\u6570\u636e\u5e93\u6784\u5efa\u63d0\u793a\uff0c\u7528\u4e8e\u6307\u5bfc\u516d\u79cd\u4e0d\u540c\u7684\u5927\u8bed\u8a00\u6a21\u578b\u3002", "result": "\u5728\u66b4\u529b\u4e8b\u4ef6\u76f8\u5173\u6846\u67b6\u5b50\u96c6\u4e0a\uff0cFI\u7684F1\u5f97\u5206\u4e3a94.3%\uff0cFSRL\u4e3a77.4%\u3002", "conclusion": "\u4e0a\u4e0b\u6587\u5b66\u4e60\u4e3a\u9886\u57df\u7279\u5b9aFSP\u4efb\u52a1\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u4e14\u6709\u6548\u7684\u66ff\u4ee3\u4f20\u7edf\u5fae\u8c03\u7684\u65b9\u6cd5\u3002"}}
{"id": "2507.23083", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.23083", "abs": "https://arxiv.org/abs/2507.23083", "authors": ["Ali Veisi", "Delaram Fartoot", "Hamidreza Amirzadeh"], "title": "Context-aware Rotary Position Embedding", "comment": "4 pages, 1 table", "summary": "Positional encoding is a vital component of Transformer architectures,\nenabling models to incorporate sequence order into self-attention mechanisms.\nRotary Positional Embeddings (RoPE) have become a widely adopted solution due\nto their compatibility with relative position encoding and computational\nefficiency. However, RoPE relies on static, input-independent sinusoidal\nfrequency patterns, limiting its ability to model context-sensitive\nrelationships. In this work, we propose CARoPE (Context-Aware Rotary Positional\nEmbedding), a novel generalization of RoPE that dynamically generates\nhead-specific frequency patterns conditioned on token embeddings. This design\nintroduces token- and context-sensitive positional representations while\npreserving RoPE efficiency and architectural simplicity. CARoPE computes\ninput-dependent phase shifts using a bounded transformation of token embeddings\nand integrates them into the rotary mechanism across attention heads. We\nevaluate CARoPE on the FineWeb-Edu-10B dataset using GPT-2 variants trained on\nnext-token prediction tasks. Experimental results show that CARoPE consistently\noutperforms RoPE and other common positional encoding baselines, achieving\nsignificantly lower perplexity, even at longer context lengths. Additionally,\nCARoPE enables faster training throughput without sacrificing model stability.\nThese findings demonstrate that CARoPE offers a scalable, expressive, and\nefficient upgrade to existing positional encoding strategies in Transformer\nmodels.", "AI": {"tldr": "CARoPE\u662f\u4e00\u79cd\u65b0\u578b\u7684\u4f4d\u7f6e\u7f16\u7801\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u751f\u6210\u4e0e\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u9891\u7387\u6a21\u5f0f\uff0c\u6539\u8fdb\u4e86\u4f20\u7edf\u7684RoPE\uff0c\u663e\u8457\u63d0\u5347\u4e86Transformer\u6a21\u578b\u7684\u6027\u80fd\u3002", "motivation": "RoPE\u867d\u7136\u9ad8\u6548\u4e14\u517c\u5bb9\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801\uff0c\u4f46\u5176\u9759\u6001\u7684\u9891\u7387\u6a21\u5f0f\u9650\u5236\u4e86\u4e0a\u4e0b\u6587\u654f\u611f\u5173\u7cfb\u7684\u5efa\u6a21\u80fd\u529b\u3002CARoPE\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "CARoPE\u901a\u8fc7\u52a8\u6001\u751f\u6210\u4e0etoken\u5d4c\u5165\u76f8\u5173\u7684\u9891\u7387\u6a21\u5f0f\uff0c\u5f15\u5165\u4e0a\u4e0b\u6587\u654f\u611f\u7684\u4f4d\u7f6e\u8868\u793a\uff0c\u540c\u65f6\u4fdd\u6301RoPE\u7684\u9ad8\u6548\u6027\u548c\u67b6\u6784\u7b80\u6d01\u6027\u3002", "result": "\u5728FineWeb-Edu-10B\u6570\u636e\u96c6\u4e0a\uff0cCARoPE\u663e\u8457\u964d\u4f4e\u4e86\u56f0\u60d1\u5ea6\uff0c\u5e76\u5728\u957f\u4e0a\u4e0b\u6587\u957f\u5ea6\u4e0b\u8868\u73b0\u66f4\u4f18\uff0c\u540c\u65f6\u8bad\u7ec3\u901f\u5ea6\u66f4\u5feb\u3002", "conclusion": "CARoPE\u4e3aTransformer\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u3001\u8868\u8fbe\u529b\u5f3a\u4e14\u9ad8\u6548\u7684\u4f4d\u7f6e\u7f16\u7801\u5347\u7ea7\u65b9\u6848\u3002"}}
{"id": "2507.23095", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23095", "abs": "https://arxiv.org/abs/2507.23095", "authors": ["Ishani Mondal", "Meera Bharadwaj", "Ayush Roy", "Aparna Garimella", "Jordan Lee Boyd-Graber"], "title": "SMART-Editor: A Multi-Agent Framework for Human-Like Design Editing with Structural Integrity", "comment": "Under Submission", "summary": "We present SMART-Editor, a framework for compositional layout and content\nediting across structured (posters, websites) and unstructured (natural images)\ndomains. Unlike prior models that perform local edits, SMART-Editor preserves\nglobal coherence through two strategies: Reward-Refine, an inference-time\nrewardguided refinement method, and RewardDPO, a training-time preference\noptimization approach using reward-aligned layout pairs. To evaluate model\nperformance, we introduce SMARTEdit-Bench, a benchmark covering multi-domain,\ncascading edit scenarios. SMART-Editor outperforms strong baselines like\nInstructPix2Pix and HIVE, with RewardDPO achieving up to 15% gains in\nstructured settings and Reward-Refine showing advantages on natural images.\nAutomatic and human evaluations confirm the value of reward-guided planning in\nproducing semantically consistent and visually aligned edits.", "AI": {"tldr": "SMART-Editor\u662f\u4e00\u4e2a\u652f\u6301\u7ed3\u6784\u5316\u4e0e\u975e\u7ed3\u6784\u5316\u9886\u57df\u5e03\u5c40\u548c\u5185\u5bb9\u7f16\u8f91\u7684\u6846\u67b6\uff0c\u901a\u8fc7Reward-Refine\u548cRewardDPO\u7b56\u7565\u4fdd\u6301\u5168\u5c40\u4e00\u81f4\u6027\uff0c\u5e76\u5728\u591a\u57df\u7f16\u8f91\u573a\u666f\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u6a21\u578b\u5728\u7f16\u8f91\u65f6\u7f3a\u4e4f\u5168\u5c40\u4e00\u81f4\u6027\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e00\u79cd\u80fd\u591f\u8de8\u9886\u57df\u4fdd\u6301\u8bed\u4e49\u548c\u89c6\u89c9\u5bf9\u9f50\u7684\u7f16\u8f91\u6846\u67b6\u3002", "method": "\u91c7\u7528Reward-Refine\uff08\u63a8\u7406\u65f6\u5956\u52b1\u5f15\u5bfc\u7ec6\u5316\uff09\u548cRewardDPO\uff08\u8bad\u7ec3\u65f6\u5956\u52b1\u5bf9\u9f50\u5e03\u5c40\u4f18\u5316\uff09\u4e24\u79cd\u7b56\u7565\u3002", "result": "\u5728SMARTEdit-Bench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSMART-Editor\u4f18\u4e8eInstructPix2Pix\u548cHIVE\uff0cRewardDPO\u5728\u7ed3\u6784\u5316\u573a\u666f\u4e2d\u63d0\u534715%\uff0cReward-Refine\u5728\u81ea\u7136\u56fe\u50cf\u4e2d\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "\u5956\u52b1\u5f15\u5bfc\u7684\u89c4\u5212\u80fd\u6709\u6548\u751f\u6210\u8bed\u4e49\u4e00\u81f4\u4e14\u89c6\u89c9\u5bf9\u9f50\u7684\u7f16\u8f91\u7ed3\u679c\uff0c\u81ea\u52a8\u548c\u4eba\u5de5\u8bc4\u4f30\u5747\u9a8c\u8bc1\u4e86\u5176\u4ef7\u503c\u3002"}}
{"id": "2507.23104", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.23104", "abs": "https://arxiv.org/abs/2507.23104", "authors": ["Jeffrey Eben", "Aitzaz Ahmad", "Stephen Lau"], "title": "RASL: Retrieval Augmented Schema Linking for Massive Database Text-to-SQL", "comment": null, "summary": "Despite advances in large language model (LLM)-based natural language\ninterfaces for databases, scaling to enterprise-level data catalogs remains an\nunder-explored challenge. Prior works addressing this challenge rely on\ndomain-specific fine-tuning - complicating deployment - and fail to leverage\nimportant semantic context contained within database metadata. To address these\nlimitations, we introduce a component-based retrieval architecture that\ndecomposes database schemas and metadata into discrete semantic units, each\nseparately indexed for targeted retrieval. Our approach prioritizes effective\ntable identification while leveraging column-level information, ensuring the\ntotal number of retrieved tables remains within a manageable context budget.\nExperiments demonstrate that our method maintains high recall and accuracy,\nwith our system outperforming baselines over massive databases with varying\nstructure and available metadata. Our solution enables practical text-to-SQL\nsystems deployable across diverse enterprise settings without specialized\nfine-tuning, addressing a critical scalability gap in natural language database\ninterfaces.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7ec4\u4ef6\u68c0\u7d22\u7684\u67b6\u6784\uff0c\u7528\u4e8e\u89e3\u51b3\u5927\u89c4\u6a21\u6570\u636e\u5e93\u81ea\u7136\u8bed\u8a00\u63a5\u53e3\u7684\u6269\u5c55\u6027\u95ee\u9898\uff0c\u65e0\u9700\u9886\u57df\u5fae\u8c03\u5373\u53ef\u9ad8\u6548\u68c0\u7d22\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u9886\u57df\u5fae\u8c03\u4e14\u672a\u80fd\u5145\u5206\u5229\u7528\u6570\u636e\u5e93\u5143\u6570\u636e\u7684\u8bed\u4e49\u4fe1\u606f\uff0c\u9650\u5236\u4e86\u5728\u5927\u578b\u4f01\u4e1a\u7ea7\u6570\u636e\u76ee\u5f55\u4e2d\u7684\u6269\u5c55\u6027\u3002", "method": "\u5c06\u6570\u636e\u5e93\u6a21\u5f0f\u548c\u5143\u6570\u636e\u5206\u89e3\u4e3a\u79bb\u6563\u8bed\u4e49\u5355\u5143\uff0c\u5206\u522b\u7d22\u5f15\u4ee5\u5b9e\u73b0\u9488\u5bf9\u6027\u68c0\u7d22\uff0c\u4f18\u5148\u8bc6\u522b\u6709\u6548\u8868\u5e76\u63a7\u5236\u68c0\u7d22\u8868\u7684\u6570\u91cf\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u9ad8\u53ec\u56de\u7387\u548c\u51c6\u786e\u6027\u4e0a\u4f18\u4e8e\u57fa\u7ebf\uff0c\u9002\u7528\u4e8e\u4e0d\u540c\u7ed3\u6784\u548c\u5143\u6570\u636e\u7684\u5927\u89c4\u6a21\u6570\u636e\u5e93\u3002", "conclusion": "\u8be5\u65b9\u6848\u89e3\u51b3\u4e86\u81ea\u7136\u8bed\u8a00\u6570\u636e\u5e93\u63a5\u53e3\u7684\u5173\u952e\u6269\u5c55\u6027\u95ee\u9898\uff0c\u9002\u7528\u4e8e\u591a\u6837\u5316\u4f01\u4e1a\u73af\u5883\u3002"}}
{"id": "2507.23121", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23121", "abs": "https://arxiv.org/abs/2507.23121", "authors": ["Xinwei Wu", "Haojie Li", "Hongyu Liu", "Xinyu Ji", "Ruohan Li", "Yule Chen", "Yigeng Zhang"], "title": "Uncovering the Fragility of Trustworthy LLMs through Chinese Textual Ambiguity", "comment": "Accepted at KDD workshop on Evaluation and Trustworthiness of Agentic\n  and Generative AI Models (Agentic & GenAI Evaluation Workshop KDD '25)", "summary": "In this work, we study a critical research problem regarding the\ntrustworthiness of large language models (LLMs): how LLMs behave when\nencountering ambiguous narrative text, with a particular focus on Chinese\ntextual ambiguity. We created a benchmark dataset by collecting and generating\nambiguous sentences with context and their corresponding disambiguated pairs,\nrepresenting multiple possible interpretations. These annotated examples are\nsystematically categorized into 3 main categories and 9 subcategories. Through\nexperiments, we discovered significant fragility in LLMs when handling\nambiguity, revealing behavior that differs substantially from humans.\nSpecifically, LLMs cannot reliably distinguish ambiguous text from unambiguous\ntext, show overconfidence in interpreting ambiguous text as having a single\nmeaning rather than multiple meanings, and exhibit overthinking when attempting\nto understand the various possible meanings. Our findings highlight a\nfundamental limitation in current LLMs that has significant implications for\ntheir deployment in real-world applications where linguistic ambiguity is\ncommon, calling for improved approaches to handle uncertainty in language\nunderstanding. The dataset and code are publicly available at this GitHub\nrepository: https://github.com/ictup/LLM-Chinese-Textual-Disambiguation.", "AI": {"tldr": "\u7814\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u4e2d\u6587\u6587\u672c\u6b67\u4e49\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5176\u5904\u7406\u6b67\u4e49\u65f6\u5b58\u5728\u663e\u8457\u8106\u5f31\u6027\uff0c\u4e0e\u4eba\u7c7b\u884c\u4e3a\u5dee\u5f02\u660e\u663e\u3002", "motivation": "\u63a2\u8ba8LLMs\u5728\u9047\u5230\u6b67\u4e49\u6587\u672c\u65f6\u7684\u53ef\u4fe1\u5ea6\u95ee\u9898\uff0c\u7279\u522b\u662f\u4e2d\u6587\u6587\u672c\u6b67\u4e49\u3002", "method": "\u6784\u5efa\u5305\u542b\u6b67\u4e49\u53e5\u53ca\u5176\u6d88\u6b67\u5bf9\u7684\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5206\u4e3a3\u5927\u7c7b9\u5c0f\u7c7b\uff0c\u901a\u8fc7\u5b9e\u9a8c\u5206\u6790LLMs\u7684\u8868\u73b0\u3002", "result": "LLMs\u65e0\u6cd5\u53ef\u9760\u533a\u5206\u6b67\u4e49\u6587\u672c\uff0c\u5bf9\u6b67\u4e49\u6587\u672c\u8868\u73b0\u51fa\u8fc7\u5ea6\u81ea\u4fe1\u548c\u8fc7\u5ea6\u601d\u8003\uff0c\u4e0e\u4eba\u7c7b\u884c\u4e3a\u5dee\u5f02\u663e\u8457\u3002", "conclusion": "\u5f53\u524dLLMs\u5728\u8bed\u8a00\u6b67\u4e49\u5904\u7406\u4e0a\u5b58\u5728\u6839\u672c\u6027\u9650\u5236\uff0c\u9700\u6539\u8fdb\u65b9\u6cd5\u4ee5\u5e94\u5bf9\u73b0\u5b9e\u5e94\u7528\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u3002"}}
{"id": "2507.23135", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.23135", "abs": "https://arxiv.org/abs/2507.23135", "authors": ["Ananya Sadana", "Yash Kumar Lal", "Jiawei Zhou"], "title": "ISO-Bench: Benchmarking Multimodal Causal Reasoning in Visual-Language Models through Procedural Plans", "comment": null, "summary": "Understanding causal relationships across modalities is a core challenge for\nmultimodal models operating in real-world environments. We introduce ISO-Bench,\na benchmark for evaluating whether models can infer causal dependencies between\nvisual observations and procedural text. Each example presents an image of a\ntask step and a text snippet from a plan, with the goal of deciding whether the\nvisual step occurs before or after the referenced text step. Evaluation results\non ten frontier vision-language models show underwhelming performance: the best\nzero-shot F1 is only 0.57, and chain-of-thought reasoning yields only modest\ngains (up to 0.62 F1), largely behind humans (0.98 F1). Our analysis further\nhighlights concrete directions for improving causal understanding in multimodal\nmodels.", "AI": {"tldr": "ISO-Bench\u662f\u4e00\u4e2a\u8bc4\u4f30\u591a\u6a21\u6001\u6a21\u578b\u56e0\u679c\u63a8\u7406\u80fd\u529b\u7684\u57fa\u51c6\uff0c\u7ed3\u679c\u663e\u793a\u5f53\u524d\u6a21\u578b\u8868\u73b0\u4e0d\u4f73\uff0c\u8fdc\u4f4e\u4e8e\u4eba\u7c7b\u6c34\u5e73\u3002", "motivation": "\u7406\u89e3\u591a\u6a21\u6001\u95f4\u7684\u56e0\u679c\u5173\u7cfb\u662f\u73b0\u5b9e\u73af\u5883\u4e2d\u591a\u6a21\u6001\u6a21\u578b\u7684\u6838\u5fc3\u6311\u6218\u3002", "method": "\u901a\u8fc7\u56fe\u50cf\u548c\u6587\u672c\u7247\u6bb5\u7684\u4efb\u52a1\u6b65\u9aa4\u5bf9\u6bd4\uff0c\u8bc4\u4f30\u6a21\u578b\u5224\u65ad\u89c6\u89c9\u6b65\u9aa4\u4e0e\u6587\u672c\u6b65\u9aa4\u7684\u65f6\u5e8f\u5173\u7cfb\u3002", "result": "\u5341\u79cd\u524d\u6cbf\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u96f6\u6837\u672cF1\u6700\u9ad8\u4ec50.57\uff0c\u601d\u7ef4\u94fe\u63a8\u7406\u7565\u6709\u63d0\u5347\uff08\u6700\u9ad80.62\uff09\uff0c\u8fdc\u4f4e\u4e8e\u4eba\u7c7b\uff080.98\uff09\u3002", "conclusion": "\u7814\u7a76\u4e3a\u63d0\u5347\u591a\u6a21\u6001\u6a21\u578b\u7684\u56e0\u679c\u7406\u89e3\u80fd\u529b\u63d0\u4f9b\u4e86\u5177\u4f53\u65b9\u5411\u3002"}}
{"id": "2507.23158", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.23158", "abs": "https://arxiv.org/abs/2507.23158", "authors": ["Yuhan Liu", "Michael J. Q. Zhang", "Eunsol Choi"], "title": "User Feedback in Human-LLM Dialogues: A Lens to Understand Users But Noisy as a Learning Signal", "comment": "Earlier version of this paper was presented at 2nd Workshop on Models\n  of Human Feedback for AI Alignment (MoFA), ICML 2025", "summary": "Once language models (LMs) are deployed, they can interact with users\nlong-term, ideally evolving continuously based on their feedback. Asking for\ndirect user feedback can be disruptive; thus, we study harvesting user feedback\nfrom user-LM interaction logs. We study implicit user feedback in two user-LM\ninteraction datasets (WildChat and LMSYS). First, we analyze user feedback in\nthe user-LLM conversation trajectory, providing insights into when and why such\nfeedback occurs. Second, we study harvesting learning signals from such\nimplicit user feedback. We find that the contents of user feedback (e.g., user\nwanted clarification), not just the polarity (e.g., users were unhappy with the\nprevious model response), can improve model performance in short human-designed\nquestions (MTBench) but not on longer and more complex questions (WildBench).\nWe also find that the usefulness of user feedback is largely tied to the\nquality of the user's initial prompt. Together, we provide an in-depth study of\nimplicit user feedback, showing its potential and limitations.", "AI": {"tldr": "\u7814\u7a76\u4ece\u7528\u6237\u4e0e\u8bed\u8a00\u6a21\u578b\uff08LM\uff09\u4ea4\u4e92\u65e5\u5fd7\u4e2d\u63d0\u53d6\u9690\u5f0f\u7528\u6237\u53cd\u9988\uff0c\u5206\u6790\u5176\u5185\u5bb9\u548c\u6781\u6027\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u53cd\u9988\u5185\u5bb9\u5728\u7b80\u5355\u4efb\u52a1\u4e2d\u6709\u6548\uff0c\u4f46\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u6548\u679c\u6709\u9650\u3002", "motivation": "\u63a2\u7d22\u5982\u4f55\u5728\u4e0d\u76f4\u63a5\u6253\u6270\u7528\u6237\u7684\u60c5\u51b5\u4e0b\uff0c\u901a\u8fc7\u9690\u5f0f\u7528\u6237\u53cd\u9988\u6301\u7eed\u4f18\u5316\u8bed\u8a00\u6a21\u578b\u3002", "method": "\u5206\u6790\u4e24\u4e2a\u7528\u6237-LM\u4ea4\u4e92\u6570\u636e\u96c6\uff08WildChat\u548cLMSYS\uff09\uff0c\u7814\u7a76\u53cd\u9988\u5185\u5bb9\u548c\u6781\u6027\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u53cd\u9988\u5185\u5bb9\u5728\u7b80\u5355\u4efb\u52a1\uff08MTBench\uff09\u4e2d\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u4f46\u5728\u590d\u6742\u4efb\u52a1\uff08WildBench\uff09\u4e2d\u65e0\u6548\uff1b\u53cd\u9988\u6548\u679c\u4e0e\u7528\u6237\u521d\u59cb\u63d0\u793a\u8d28\u91cf\u76f8\u5173\u3002", "conclusion": "\u9690\u5f0f\u7528\u6237\u53cd\u9988\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u5176\u6548\u679c\u53d7\u4efb\u52a1\u590d\u6742\u6027\u548c\u7528\u6237\u63d0\u793a\u8d28\u91cf\u9650\u5236\u3002"}}
{"id": "2507.23167", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.23167", "abs": "https://arxiv.org/abs/2507.23167", "authors": ["Jizhou Guo"], "title": "LENS: Learning Ensemble Confidence from Neural States for Multi-LLM Answer Integration", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated impressive performance across\nvarious tasks, with different models excelling in distinct domains and specific\nabilities. Effectively combining the predictions of multiple LLMs is crucial\nfor enhancing system robustness and performance. However, existing ensemble\nmethods often rely on simple techniques like voting or logits ensembling, which\noverlook the varying confidence and reliability of models in different\ncontexts. In this work, we propose LENS (Learning ENsemble confidence from\nNeural States), a novel approach that learns to estimate model confidence by\nanalyzing internal representations. For each LLM, we train a lightweight linear\nconfidence predictor that leverages layer-wise hidden states and normalized\nprobabilities as inputs. This allows for more nuanced weighting of model\npredictions based on their context-dependent reliability. Our method does not\nrequire modifying the model parameters and requires negligible additional\ncomputation. Experimental results on multiple-choice and boolean\nquestion-answering tasks demonstrate that LENS outperforms traditional ensemble\nmethods by a substantial margin. Our findings suggest that internal\nrepresentations provide valuable signals for determining model confidence and\ncan be effectively leveraged for ensemble learning.", "AI": {"tldr": "LENS\u662f\u4e00\u79cd\u901a\u8fc7\u5206\u6790\u5185\u90e8\u8868\u793a\u6765\u5b66\u4e60\u6a21\u578b\u7f6e\u4fe1\u5ea6\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u4f18\u5316\u591aLLM\u7684\u9884\u6d4b\u7ec4\u5408\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u96c6\u6210\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u96c6\u6210\u65b9\u6cd5\uff08\u5982\u6295\u7968\u6216\u5bf9\u6570\u96c6\u6210\uff09\u5ffd\u7565\u4e86\u6a21\u578b\u5728\u4e0d\u540c\u4e0a\u4e0b\u6587\u4e2d\u7684\u7f6e\u4fe1\u5ea6\u548c\u53ef\u9760\u6027\u5dee\u5f02\uff0c\u9700\u8981\u66f4\u7cbe\u7ec6\u7684\u52a0\u6743\u7b56\u7565\u3002", "method": "LENS\u901a\u8fc7\u8bad\u7ec3\u8f7b\u91cf\u7ea7\u7ebf\u6027\u7f6e\u4fe1\u5ea6\u9884\u6d4b\u5668\uff0c\u5229\u7528\u5c42\u95f4\u9690\u85cf\u72b6\u6001\u548c\u5f52\u4e00\u5316\u6982\u7387\u4f5c\u4e3a\u8f93\u5165\uff0c\u52a8\u6001\u8c03\u6574\u6a21\u578b\u9884\u6d4b\u6743\u91cd\u3002", "result": "\u5728\u591a\u9009\u548c\u5e03\u5c14\u95ee\u7b54\u4efb\u52a1\u4e2d\uff0cLENS\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u96c6\u6210\u65b9\u6cd5\u3002", "conclusion": "\u5185\u90e8\u8868\u793a\u4e3a\u6a21\u578b\u7f6e\u4fe1\u5ea6\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u4fe1\u53f7\uff0c\u53ef\u7528\u4e8e\u9ad8\u6548\u96c6\u6210\u5b66\u4e60\u3002"}}
{"id": "2507.23194", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.23194", "abs": "https://arxiv.org/abs/2507.23194", "authors": ["Jianghui Wang", "Vinay Joshi", "Saptarshi Majumder", "Xu Chao", "Bin Ding", "Ziqiong Liu", "Pratik Prabhanjan Brahma", "Dong Li", "Zicheng Liu", "Emad Barsoum"], "title": "Geak: Introducing Triton Kernel AI Agent & Evaluation Benchmarks", "comment": null, "summary": "The demand for AI-generated GPU kernels is rapidly growing, influenced by the\nneed for scalable, hardware-optimized solutions in both industry and academia.\nAs deep learning workloads grow in complexity and diversity, it is imperative\nto automate low-level kernel development to meet performance and productivity\ndemands. Major cloud providers, semiconductor companies, and research\ninstitutions are now investing heavily in AI-driven code generation for GPUs,\naiming to reduce manual optimization efforts while achieving near-expert\nperformance on hardware like AMD MI300X. The Triton language, a Python-based\nDSL for GPU programming, has emerged as a popular target for such AI-generated\nkernels due to its balance of performance and ease-of-coding. In this work, we\npresent an evaluation suite for Triton-based GPU kernels and GEAK (Generating\nEfficient AI-centric GPU Kernels)-a framework that leverages cutting-edge LLMs\nto generate performant Triton code specifically for AMD GPUs, including the AMD\nMI300X and MI250. GEAK leverages inference-time compute scaling to produce\nTriton-based GPU kernels using a reasoning loop adapted from Reflexion-style\nfeedback mechanisms. On two evaluation benchmarks, GEAK significantly\noutperformed the baselines of directly prompting frontier LLMs as well as\nReflexion-based generation pipelines by achieving correctness up to $63$% and\nexecution speed up of up to $2.59$X. These results highlight the promise of\nGEAK-like agentic code generation for accelerating the adoption of diverse\nhardware platforms and democratizing access to expert-level kernel performance.", "AI": {"tldr": "GEAK\u6846\u67b6\u5229\u7528\u524d\u6cbfLLM\u4e3aAMD GPU\u751f\u6210\u9ad8\u6027\u80fdTriton\u4ee3\u7801\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u968f\u7740\u6df1\u5ea6\u5b66\u4e60\u5de5\u4f5c\u8d1f\u8f7d\u7684\u590d\u6742\u6027\u548c\u591a\u6837\u6027\u589e\u52a0\uff0c\u81ea\u52a8\u5316\u4f4e\u5c42\u5185\u6838\u5f00\u53d1\u6210\u4e3a\u5fc5\u8981\uff0c\u4ee5\u6ee1\u8db3\u6027\u80fd\u548c\u751f\u4ea7\u529b\u9700\u6c42\u3002", "method": "GEAK\u91c7\u7528\u63a8\u7406\u65f6\u8ba1\u7b97\u7f29\u653e\u548cReflexion\u5f0f\u53cd\u9988\u673a\u5236\uff0c\u751f\u6210\u9488\u5bf9AMD GPU\u7684Triton\u4ee3\u7801\u3002", "result": "GEAK\u5728\u6b63\u786e\u6027\u4e0a\u63d0\u534763%\uff0c\u6267\u884c\u901f\u5ea6\u63d0\u53472.59\u500d\u3002", "conclusion": "GEAK\u5c55\u793a\u4e86\u4ee3\u7406\u5f0f\u4ee3\u7801\u751f\u6210\u5728\u52a0\u901f\u786c\u4ef6\u5e73\u53f0\u91c7\u7528\u548c\u666e\u53ca\u4e13\u5bb6\u7ea7\u5185\u6838\u6027\u80fd\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.23211", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.23211", "abs": "https://arxiv.org/abs/2507.23211", "authors": ["Yunhao Liang", "Ruixuan Ying", "Takuya Taniguchi", "Zhe Cui"], "title": "Failures Are the Stepping Stones to Success: Enhancing Few-Shot In-Context Learning by Leveraging Negative Samples", "comment": null, "summary": "Large Language Models exhibit powerful few-shot in-context learning (ICL)\ncapabilities, but the performance is highly sensitive to provided examples.\n  Recent research has focused on retrieving corresponding examples for each\ninput query, not only enhancing the efficiency and scalability of the learning\nprocess but also mitigating inherent biases in manual example selection.\n  However, these studies have primarily emphasized leveraging Positive samples\nwhile overlooking the additional information within Negative samples for\ncontextual learning.\n  We propose a novel method that utilizes Negative samples to better select\nPositive sample examples, thereby enhancing the performance of few-shot ICL.\nInitially, we construct Positive and Negative sample corpora based on\nZero-Shot-Cot. Then, during inference, we employ a semantic similarity-based\napproach to select the most similar examples from both the Positive and\nNegative corpora for a given query. Subsequently, we further retrieve Positive\nexamples from the Positive sample corpus based on semantic similarity to the\nNegative examples, then concatenating them with the previously selected\nPositive examples to serve as ICL demonstrations. Experimental results\ndemonstrate that our approach surpasses methods solely relying on the most\nsimilar positive examples for context, validating that the additional\ninformation in negative samples aids in enhancing ICL performance through\nimproved Positive sample selection.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u8d1f\u6837\u672c\u4f18\u5316\u6b63\u6837\u672c\u9009\u62e9\u7684\u65b9\u6cd5\uff0c\u4ee5\u63d0\u5347\u5c11\u6837\u672c\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08ICL\uff09\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u6b63\u6837\u672c\u7684\u5229\u7528\uff0c\u5ffd\u89c6\u4e86\u8d1f\u6837\u672c\u5728\u4e0a\u4e0b\u6587\u5b66\u4e60\u4e2d\u7684\u6f5c\u5728\u4ef7\u503c\u3002", "method": "\u57fa\u4e8eZero-Shot-Cot\u6784\u5efa\u6b63\u8d1f\u6837\u672c\u5e93\uff0c\u901a\u8fc7\u8bed\u4e49\u76f8\u4f3c\u6027\u9009\u62e9\u6b63\u8d1f\u6837\u672c\uff0c\u5e76\u8fdb\u4e00\u6b65\u4f18\u5316\u6b63\u6837\u672c\u9009\u62e9\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u4ec5\u4f9d\u8d56\u6b63\u6837\u672c\u7684\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u8d1f\u6837\u672c\u4fe1\u606f\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8d1f\u6837\u672c\u4fe1\u606f\u6709\u52a9\u4e8e\u4f18\u5316\u6b63\u6837\u672c\u9009\u62e9\uff0c\u4ece\u800c\u63d0\u5347ICL\u6027\u80fd\u3002"}}
{"id": "2507.23220", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.23220", "abs": "https://arxiv.org/abs/2507.23220", "authors": ["Carolina Zheng", "Nicolas Beltran-Velez", "Sweta Karlekar", "Claudia Shi", "Achille Nazaret", "Asif Mallik", "Amir Feder", "David M. Blei"], "title": "Model Directions, Not Words: Mechanistic Topic Models Using Sparse Autoencoders", "comment": null, "summary": "Traditional topic models are effective at uncovering latent themes in large\ntext collections. However, due to their reliance on bag-of-words\nrepresentations, they struggle to capture semantically abstract features. While\nsome neural variants use richer representations, they are similarly constrained\nby expressing topics as word lists, which limits their ability to articulate\ncomplex topics. We introduce Mechanistic Topic Models (MTMs), a class of topic\nmodels that operate on interpretable features learned by sparse autoencoders\n(SAEs). By defining topics over this semantically rich space, MTMs can reveal\ndeeper conceptual themes with expressive feature descriptions. Moreover,\nuniquely among topic models, MTMs enable controllable text generation using\ntopic-based steering vectors. To properly evaluate MTM topics against\nword-list-based approaches, we propose \\textit{topic judge}, an LLM-based\npairwise comparison evaluation framework. Across five datasets, MTMs match or\nexceed traditional and neural baselines on coherence metrics, are consistently\npreferred by topic judge, and enable effective steering of LLM outputs.", "AI": {"tldr": "MTMs\u5229\u7528\u7a00\u758f\u81ea\u7f16\u7801\u5668\u5b66\u4e60\u53ef\u89e3\u91ca\u7279\u5f81\uff0c\u5b9a\u4e49\u4e3b\u9898\u4e8e\u8bed\u4e49\u4e30\u5bcc\u7a7a\u95f4\uff0c\u4f18\u4e8e\u4f20\u7edf\u4e3b\u9898\u6a21\u578b\uff0c\u5e76\u80fd\u63a7\u5236\u6587\u672c\u751f\u6210\u3002", "motivation": "\u4f20\u7edf\u4e3b\u9898\u6a21\u578b\u56e0\u4f9d\u8d56\u8bcd\u888b\u8868\u793a\uff0c\u96be\u4ee5\u6355\u6349\u8bed\u4e49\u62bd\u8c61\u7279\u5f81\uff0c\u800c\u795e\u7ecf\u53d8\u4f53\u540c\u6837\u53d7\u9650\u4e8e\u8bcd\u5217\u8868\u8868\u8fbe\u3002", "method": "\u63d0\u51faMTMs\uff0c\u57fa\u4e8e\u7a00\u758f\u81ea\u7f16\u7801\u5668\u5b66\u4e60\u7279\u5f81\uff0c\u5b9a\u4e49\u4e3b\u9898\u4e8e\u8bed\u4e49\u4e30\u5bcc\u7a7a\u95f4\uff0c\u5e76\u5f15\u5165\u57fa\u4e8eLLM\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "result": "MTMs\u5728\u4e94\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u548c\u795e\u7ecf\u57fa\u7ebf\uff0c\u4e14\u80fd\u6709\u6548\u63a7\u5236LLM\u8f93\u51fa\u3002", "conclusion": "MTMs\u5728\u4e3b\u9898\u8868\u8fbe\u548c\u751f\u6210\u63a7\u5236\u65b9\u9762\u5177\u6709\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2507.23227", "categories": ["cs.CL", "cs.LG", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2507.23227", "abs": "https://arxiv.org/abs/2507.23227", "authors": ["Sophie Kearney", "Shu Yang", "Zixuan Wen", "Bojian Hou", "Duy Duong-Tran", "Tianlong Chen", "Jason Moore", "Marylyn Ritchie", "Li Shen"], "title": "Enabling Few-Shot Alzheimer's Disease Diagnosis on Tabular Biomarker Data with LLMs", "comment": null, "summary": "Early and accurate diagnosis of Alzheimer's disease (AD), a complex\nneurodegenerative disorder, requires analysis of heterogeneous biomarkers\n(e.g., neuroimaging, genetic risk factors, cognitive tests, and cerebrospinal\nfluid proteins) typically represented in a tabular format. With flexible\nfew-shot reasoning, multimodal integration, and natural-language-based\ninterpretability, large language models (LLMs) offer unprecedented\nopportunities for prediction with structured biomedical data. We propose a\nnovel framework called TAP-GPT, Tabular Alzheimer's Prediction GPT, that adapts\nTableGPT2, a multimodal tabular-specialized LLM originally developed for\nbusiness intelligence tasks, for AD diagnosis using structured biomarker data\nwith small sample sizes. Our approach constructs few-shot tabular prompts using\nin-context learning examples from structured biomedical data and finetunes\nTableGPT2 using the parameter-efficient qLoRA adaption for a clinical binary\nclassification task of AD or cognitively normal (CN). The TAP-GPT framework\nharnesses the powerful tabular understanding ability of TableGPT2 and the\nencoded prior knowledge of LLMs to outperform more advanced general-purpose\nLLMs and a tabular foundation model (TFM) developed for prediction tasks. To\nour knowledge, this is the first application of LLMs to the prediction task\nusing tabular biomarker data, paving the way for future LLM-driven multi-agent\nframeworks in biomedical informatics.", "AI": {"tldr": "TAP-GPT\u662f\u4e00\u79cd\u57fa\u4e8eTableGPT2\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u901a\u8fc7\u5c11\u91cf\u6837\u672c\u7684\u8868\u683c\u751f\u7269\u6807\u5fd7\u7269\u6570\u636e\u8bca\u65ad\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\uff0c\u6027\u80fd\u4f18\u4e8e\u901a\u7528LLMs\u548c\u8868\u683c\u57fa\u7840\u6a21\u578b\u3002", "motivation": "\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\uff08AD\uff09\u7684\u65e9\u671f\u51c6\u786e\u8bca\u65ad\u9700\u8981\u5206\u6790\u591a\u79cd\u5f02\u6784\u751f\u7269\u6807\u5fd7\u7269\uff0c\u800c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u7ed3\u6784\u5316\u751f\u7269\u533b\u5b66\u6570\u636e\u9884\u6d4b\u65b9\u9762\u5177\u6709\u6f5c\u529b\u3002", "method": "\u901a\u8fc7\u4e0a\u4e0b\u6587\u5b66\u4e60\u6784\u5efa\u5c11\u91cf\u6837\u672c\u7684\u8868\u683c\u63d0\u793a\uff0c\u5e76\u5229\u7528\u53c2\u6570\u9ad8\u6548\u7684qLoRA\u9002\u914d\u5fae\u8c03TableGPT2\uff0c\u8fdb\u884cAD\u6216\u8ba4\u77e5\u6b63\u5e38\uff08CN\uff09\u7684\u4e8c\u5143\u5206\u7c7b\u3002", "result": "TAP-GPT\u5728\u8868\u683c\u7406\u89e3\u80fd\u529b\u548cLLMs\u5148\u9a8c\u77e5\u8bc6\u7684\u652f\u6301\u4e0b\uff0c\u6027\u80fd\u4f18\u4e8e\u901a\u7528LLMs\u548c\u8868\u683c\u57fa\u7840\u6a21\u578b\u3002", "conclusion": "\u8fd9\u662f\u9996\u6b21\u5c06LLMs\u5e94\u7528\u4e8e\u8868\u683c\u751f\u7269\u6807\u5fd7\u7269\u6570\u636e\u9884\u6d4b\u4efb\u52a1\uff0c\u4e3a\u672a\u6765\u751f\u7269\u533b\u5b66\u4fe1\u606f\u5b66\u4e2d\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2507.23247", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.23247", "abs": "https://arxiv.org/abs/2507.23247", "authors": ["Sneha Oram", "Pushpak Bhattacharyya"], "title": "P-ReMIS: Pragmatic Reasoning in Mental Health and a Social Implication", "comment": null, "summary": "There has been an increase in recent advancements in the explainability and\ndevelopment of personalized chatbots for mental health. However, the reasoning\naspects for explainability and dialogue discourse have not been explored\npreviously for mental health. Hence, we are investigating the pragmatic\nreasoning capability of large language models (LLMs) in this domain. We\nintroduce P-ReMe dataset, and propose a modified definition for the pragmatic\nphenomena of implicature (implied meaning) and presupposition (implicit\nassumption) in mental health. Following the definition, we formulate two tasks\nin implicature and one task in presupposition. To benchmark the dataset and the\npresented tasks, we consider four models - Llama3.1, Mistral, MentaLLaMa, and\nQwen. The results of the experiments suggest that Mistral and Qwen show\nsubstantial reasoning capabilities in the domain. In addition, we also propose\nStiPRompts to study the stigma around mental health with the state-of-the-art\nLLMs, GPT-4o mini, Deepseek-chat, and Claude-3.5-haiku. Our evaluated findings\nshow that Claude-3.5-haiku deals with the stigma more responsibly compared to\nthe other two LLMs.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5fc3\u7406\u5065\u5eb7\u9886\u57df\u4e2d\u7684\u5b9e\u7528\u63a8\u7406\u80fd\u529b\uff0c\u63d0\u51fa\u4e86P-ReMe\u6570\u636e\u96c6\uff0c\u5e76\u6539\u8fdb\u4e86\u9690\u542b\u610f\u4e49\u548c\u9884\u8bbe\u7684\u5b9a\u4e49\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aMistral\u548cQwen\u8868\u73b0\u4f18\u5f02\uff0c\u540c\u65f6\u63d0\u51fa\u4e86StiPRompts\u7814\u7a76\u5fc3\u7406\u5065\u5eb7\u6c61\u540d\u95ee\u9898\uff0cClaude-3.5-haiku\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u63a2\u7d22\u5fc3\u7406\u5065\u5eb7\u9886\u57df\u4e2d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5b9e\u7528\u63a8\u7406\u80fd\u529b\uff0c\u586b\u8865\u73b0\u6709\u7814\u7a76\u5728\u89e3\u91ca\u6027\u548c\u5bf9\u8bdd\u63a8\u7406\u65b9\u9762\u7684\u7a7a\u767d\u3002", "method": "\u5f15\u5165P-ReMe\u6570\u636e\u96c6\uff0c\u6539\u8fdb\u9690\u542b\u610f\u4e49\u548c\u9884\u8bbe\u7684\u5b9a\u4e49\uff0c\u8bbe\u8ba1\u76f8\u5173\u4efb\u52a1\uff0c\u5e76\u8bc4\u4f30\u56db\u79cd\u6a21\u578b\u7684\u6027\u80fd\u3002\u540c\u65f6\u63d0\u51faStiPRompts\u7814\u7a76\u5fc3\u7406\u5065\u5eb7\u6c61\u540d\u95ee\u9898\u3002", "result": "Mistral\u548cQwen\u5728\u5b9e\u7528\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u7a81\u51fa\uff1bClaude-3.5-haiku\u5728\u5904\u7406\u5fc3\u7406\u5065\u5eb7\u6c61\u540d\u95ee\u9898\u65f6\u8868\u73b0\u66f4\u8d1f\u8d23\u4efb\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5fc3\u7406\u5065\u5eb7\u9886\u57df\u7684\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\uff0c\u5e76\u5c55\u793a\u4e86\u6a21\u578b\u5728\u89e3\u51b3\u5fc3\u7406\u5065\u5eb7\u6c61\u540d\u95ee\u9898\u4e0a\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.23248", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.23248", "abs": "https://arxiv.org/abs/2507.23248", "authors": ["Shimanto Bhowmik", "Tawsif Tashwar Dipto", "Md Sazzad Islam", "Sheryl Hsu", "Tahsin Reasat"], "title": "Evaluating LLMs' Multilingual Capabilities for Bengali: Benchmark Creation and Performance Analysis", "comment": null, "summary": "Bengali is an underrepresented language in NLP research. However, it remains\na challenge due to its unique linguistic structure and computational\nconstraints. In this work, we systematically investigate the challenges that\nhinder Bengali NLP performance by focusing on the absence of standardized\nevaluation benchmarks. We then evaluated 10 recent open source Large Language\nModels (LLMs) in 8 of the translated datasets and performed a comprehensive\nerror analysis to pinpoint their primary failure modes. Our findings reveal\nconsistent performance gaps for Bengali compared to English, particularly for\nsmaller models and specific model families like Mistral. We also identified\npromising robustness in certain architectures, such as DeepSeek, that maintain\nmore stable performance across languages. Our analysis reveals an inverse\nrelationship between tokenization efficiency and LLM accuracy where models tend\nto perform worse when inputs are excessively tokenized, whereas more efficient\n\\& concise tokenization results in improved performance. These findings\nhighlight critical areas where current models fall short and underscore the\nneed for improved dataset quality and evaluation methodologies tailored to\nmultilingual contexts. This work will catalyze further research on NLP for\nunderrepresented languages, helping to democratize access to advanced language\ntechnologies worldwide. The code and dataset used in this research is publicly\navailable at https://github.com/BengaliAI/bn-llm-benchmark.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5b5f\u52a0\u62c9\u8bedNLP\u7684\u6311\u6218\uff0c\u8bc4\u4f30\u4e8610\u79cd\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u57288\u4e2a\u7ffb\u8bd1\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u6027\u80fd\u5dee\u8ddd\u4e0e\u5206\u8bcd\u6548\u7387\u76f8\u5173\u3002", "motivation": "\u5b5f\u52a0\u62c9\u8bed\u5728NLP\u7814\u7a76\u4e2d\u4ee3\u8868\u6027\u4e0d\u8db3\uff0c\u7f3a\u4e4f\u6807\u51c6\u5316\u8bc4\u4f30\u57fa\u51c6\uff0c\u963b\u788d\u4e86\u5176\u6027\u80fd\u63d0\u5347\u3002", "method": "\u7cfb\u7edf\u5206\u6790\u6311\u6218\uff0c\u8bc4\u4f3010\u79cd\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u57288\u4e2a\u7ffb\u8bd1\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u8fdb\u884c\u9519\u8bef\u5206\u6790\u3002", "result": "\u53d1\u73b0\u5b5f\u52a0\u62c9\u8bed\u6027\u80fd\u666e\u904d\u4f4e\u4e8e\u82f1\u8bed\uff0c\u5206\u8bcd\u6548\u7387\u4e0e\u6a21\u578b\u51c6\u786e\u6027\u6210\u53cd\u6bd4\uff0c\u67d0\u4e9b\u67b6\u6784\uff08\u5982DeepSeek\uff09\u8868\u73b0\u7a33\u5065\u3002", "conclusion": "\u9700\u6539\u8fdb\u6570\u636e\u96c6\u8d28\u91cf\u548c\u8bc4\u4f30\u65b9\u6cd5\uff0c\u63a8\u52a8\u591a\u8bed\u8a00NLP\u7814\u7a76\uff0c\u4fc3\u8fdb\u8bed\u8a00\u6280\u672f\u666e\u53ca\u3002"}}
{"id": "2507.23279", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.23279", "abs": "https://arxiv.org/abs/2507.23279", "authors": ["Zunhai Su", "Qingyuan Li", "Hao Zhang", "YuLei Qian", "Yuchen Xie", "Kehong Yuan"], "title": "Unveiling Super Experts in Mixture-of-Experts Large Language Models", "comment": null, "summary": "Sparsely activated Mixture-of-Experts (MoE) models have shown promise in\nenhancing the learning capacity of large language models (LLMs). Leveraging the\nintrinsic importance differences among experts, recent research has explored\nexpert-level compression techniques to improve the efficiency of MoE LLMs.\nHowever, existing approaches often rely on empirical criteria to identify\ncritical experts, lacking a deeper exploration and understanding of the\nheterogeneous importance of experts. In this study, we present the first\ndiscovery and investigation of a distinct subset of experts that play a crucial\nrole in the underlying mechanisms during the model's forward inference. These\nexperts are prevalent in open-source MoE LLMs, and despite their limited\nnumber, pruning them leads to a significant decline in model performance (e.g.,\npruning three causes Qwen3-30B-A3B to produce repetitive and uninformative\noutputs). We refer to these experts as Super Experts (SEs). Our comprehensive\nanalysis provides progressively deeper insights into SEs. (i) SEs are\ncharacterized by rare but extreme activation outliers in the output of the\ndown_proj, which give rise to massive activations in the hidden states between\ndecoder layers. Moreover, the distribution of SEs remains model-specific and is\nunaffected by post-training processes. (ii) By pruning SEs, we assess their\nsignificance across a variety of tasks, revealing their considerable impact on\nthe model's overall performance, particularly in mathematical reasoning. (iii)\nWe further enhance our understanding of the influence of SEs compression. Our\nfindings confirm that MoE LLMs rely on SEs to induce attention sinks, which are\ncrucial for the distribution of attention scores but are significantly\ndisrupted by SE pruning. The code is available at\nhttps://github.com/ZunhaiSu/Super-Experts-Profilling.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0MoE\u6a21\u578b\u4e2d\u7684\u201c\u8d85\u7ea7\u4e13\u5bb6\u201d\uff08SEs\uff09\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u8d77\u5173\u952e\u4f5c\u7528\uff0c\u4fee\u526a\u5b83\u4eec\u4f1a\u663e\u8457\u964d\u4f4e\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u63a2\u7d22MoE\u6a21\u578b\u4e2d\u4e13\u5bb6\u7684\u91cd\u8981\u6027\u5dee\u5f02\uff0c\u63ed\u793a\u5173\u952e\u5b50\u96c6\u7684\u4f5c\u7528\u3002", "method": "\u901a\u8fc7\u5206\u6790\u6fc0\u6d3b\u5f02\u5e38\u548c\u4fee\u526a\u5b9e\u9a8c\uff0c\u8bc6\u522b\u5e76\u9a8c\u8bc1SEs\u7684\u91cd\u8981\u6027\u3002", "result": "SEs\u5bf9\u6a21\u578b\u6027\u80fd\uff08\u5c24\u5176\u662f\u6570\u5b66\u63a8\u7406\uff09\u6709\u663e\u8457\u5f71\u54cd\uff0c\u4e14\u5176\u5206\u5e03\u4e0d\u53d7\u540e\u8bad\u7ec3\u5f71\u54cd\u3002", "conclusion": "SEs\u662fMoE\u6a21\u578b\u7684\u5173\u952e\u7ec4\u6210\u90e8\u5206\uff0c\u4fee\u526a\u4f1a\u7834\u574f\u6ce8\u610f\u529b\u5206\u5e03\uff0c\u5f71\u54cd\u6a21\u578b\u8868\u73b0\u3002"}}
{"id": "2507.23334", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.23334", "abs": "https://arxiv.org/abs/2507.23334", "authors": ["Daeyong Kwon", "SeungHeon Doh", "Juhan Nam"], "title": "MUST-RAG: MUSical Text Question Answering with Retrieval Augmented Generation", "comment": "8 pages, 2 figures", "summary": "Recent advancements in Large language models (LLMs) have demonstrated\nremarkable capabilities across diverse domains. While they exhibit strong\nzero-shot performance on various tasks, LLMs' effectiveness in music-related\napplications remains limited due to the relatively small proportion of\nmusic-specific knowledge in their training data. To address this limitation, we\npropose MusT-RAG, a comprehensive framework based on Retrieval Augmented\nGeneration (RAG) to adapt general-purpose LLMs for text-only music question\nanswering (MQA) tasks. RAG is a technique that provides external knowledge to\nLLMs by retrieving relevant context information when generating answers to\nquestions. To optimize RAG for the music domain, we (1) propose MusWikiDB, a\nmusic-specialized vector database for the retrieval stage, and (2) utilizes\ncontext information during both inference and fine-tuning processes to\neffectively transform general-purpose LLMs into music-specific models. Our\nexperiment demonstrates that MusT-RAG significantly outperforms traditional\nfine-tuning approaches in enhancing LLMs' music domain adaptation capabilities,\nshowing consistent improvements across both in-domain and out-of-domain MQA\nbenchmarks. Additionally, our MusWikiDB proves substantially more effective\nthan general Wikipedia corpora, delivering superior performance and\ncomputational efficiency.", "AI": {"tldr": "MusT-RAG\u6846\u67b6\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6280\u672f\uff0c\u7ed3\u5408\u97f3\u4e50\u4e13\u7528\u6570\u636e\u5e93MusWikiDB\uff0c\u663e\u8457\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u97f3\u4e50\u95ee\u7b54\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u97f3\u4e50\u76f8\u5173\u5e94\u7528\u4e2d\u8868\u73b0\u6709\u9650\uff0c\u4e3b\u8981\u56e0\u4e3a\u8bad\u7ec3\u6570\u636e\u4e2d\u97f3\u4e50\u77e5\u8bc6\u8f83\u5c11\u3002", "method": "\u63d0\u51faMusT-RAG\u6846\u67b6\uff0c\u7ed3\u5408MusWikiDB\u97f3\u4e50\u4e13\u7528\u6570\u636e\u5e93\uff0c\u4f18\u5316\u68c0\u7d22\u548c\u751f\u6210\u8fc7\u7a0b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cMusT-RAG\u5728\u97f3\u4e50\u95ee\u7b54\u4efb\u52a1\u4e2d\u4f18\u4e8e\u4f20\u7edf\u5fae\u8c03\u65b9\u6cd5\uff0c\u4e14MusWikiDB\u6bd4\u901a\u7528\u8bed\u6599\u5e93\u66f4\u9ad8\u6548\u3002", "conclusion": "MusT-RAG\u6709\u6548\u89e3\u51b3\u4e86LLMs\u5728\u97f3\u4e50\u9886\u57df\u7684\u9002\u5e94\u6027\u95ee\u9898\uff0c\u4e3a\u97f3\u4e50\u76f8\u5173\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2507.23319", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.23319", "abs": "https://arxiv.org/abs/2507.23319", "authors": ["Alfio Ferrara", "Sergio Picascia", "Laura Pinnavaia", "Vojimir Ranitovic", "Elisabetta Rocchetti", "Alice Tuveri"], "title": "What's Taboo for You? - An Empirical Evaluation of LLMs Behavior Toward Sensitive Content", "comment": null, "summary": "Proprietary Large Language Models (LLMs) have shown tendencies toward\npoliteness, formality, and implicit content moderation. While previous research\nhas primarily focused on explicitly training models to moderate and detoxify\nsensitive content, there has been limited exploration of whether LLMs\nimplicitly sanitize language without explicit instructions. This study\nempirically analyzes the implicit moderation behavior of GPT-4o-mini when\nparaphrasing sensitive content and evaluates the extent of sensitivity shifts.\nOur experiments indicate that GPT-4o-mini systematically moderates content\ntoward less sensitive classes, with substantial reductions in derogatory and\ntaboo language. Also, we evaluate the zero-shot capabilities of LLMs in\nclassifying sentence sensitivity, comparing their performances against\ntraditional methods.", "AI": {"tldr": "\u7814\u7a76\u5206\u6790\u4e86GPT-4o-mini\u5728\u65e0\u660e\u786e\u6307\u4ee4\u4e0b\u5bf9\u654f\u611f\u5185\u5bb9\u7684\u9690\u5f0f\u51c0\u5316\u884c\u4e3a\uff0c\u53d1\u73b0\u5176\u80fd\u663e\u8457\u964d\u4f4e\u654f\u611f\u8bed\u8a00\uff0c\u5e76\u8bc4\u4f30\u4e86\u5176\u5728\u96f6\u6837\u672c\u5206\u7c7b\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u63a2\u7d22LLMs\u662f\u5426\u4f1a\u5728\u65e0\u660e\u786e\u6307\u4ee4\u4e0b\u9690\u5f0f\u51c0\u5316\u8bed\u8a00\uff0c\u586b\u8865\u73b0\u6709\u7814\u7a76\u7684\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u5b9e\u9a8c\u5206\u6790GPT-4o-mini\u5728\u6539\u5199\u654f\u611f\u5185\u5bb9\u65f6\u7684\u9690\u5f0f\u51c0\u5316\u884c\u4e3a\uff0c\u5e76\u8bc4\u4f30\u5176\u96f6\u6837\u672c\u5206\u7c7b\u80fd\u529b\u3002", "result": "GPT-4o-mini\u80fd\u7cfb\u7edf\u6027\u5730\u964d\u4f4e\u654f\u611f\u5185\u5bb9\uff0c\u663e\u8457\u51cf\u5c11\u8d2c\u4e49\u548c\u7981\u5fcc\u8bed\u8a00\uff0c\u4e14\u5728\u96f6\u6837\u672c\u5206\u7c7b\u4e2d\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "conclusion": "LLMs\u5177\u5907\u9690\u5f0f\u51c0\u5316\u8bed\u8a00\u7684\u80fd\u529b\uff0c\u4e14\u5728\u96f6\u6837\u672c\u5206\u7c7b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2507.23358", "categories": ["cs.CL", "cs.AI", "cs.DB", "cs.IR"], "pdf": "https://arxiv.org/pdf/2507.23358", "abs": "https://arxiv.org/abs/2507.23358", "authors": ["Renato Vukovic", "Carel van Niekerk", "Michael Heck", "Benjamin Ruppik", "Hsien-Chin Lin", "Shutong Feng", "Nurul Lubis", "Milica Gasic"], "title": "Text-to-SQL Task-oriented Dialogue Ontology Construction", "comment": null, "summary": "Large language models (LLMs) are widely used as general-purpose knowledge\nsources, but they rely on parametric knowledge, limiting explainability and\ntrustworthiness. In task-oriented dialogue (TOD) systems, this separation is\nexplicit, using an external database structured by an explicit ontology to\nensure explainability and controllability. However, building such ontologies\nrequires manual labels or supervised training. We introduce TeQoDO: a\nText-to-SQL task-oriented Dialogue Ontology construction method. Here, an LLM\nautonomously builds a TOD ontology from scratch without supervision using its\ninherent SQL programming capabilities combined with dialogue theory provided in\nthe prompt. We show that TeQoDO outperforms transfer learning approaches, and\nits constructed ontology is competitive on a downstream dialogue state tracking\ntask. Ablation studies demonstrate the key role of dialogue theory. TeQoDO also\nscales to allow construction of much larger ontologies, which we investigate on\na Wikipedia and ArXiv dataset. We view this as a step towards broader\napplication of ontologies to increase LLM explainability.", "AI": {"tldr": "TeQoDO\u662f\u4e00\u79cd\u65e0\u76d1\u7763\u7684\u6587\u672c\u5230SQL\u4efb\u52a1\u5bfc\u5411\u5bf9\u8bdd\u672c\u4f53\u6784\u5efa\u65b9\u6cd5\uff0c\u5229\u7528LLM\u7684SQL\u7f16\u7a0b\u80fd\u529b\u548c\u5bf9\u8bdd\u7406\u8bba\uff0c\u6784\u5efa\u7684\u5bf9\u8bdd\u672c\u4f53\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u8fc1\u79fb\u5b66\u4e60\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3LLMs\u4f9d\u8d56\u53c2\u6570\u5316\u77e5\u8bc6\u5bfc\u81f4\u7684\u89e3\u91ca\u6027\u548c\u53ef\u4fe1\u5ea6\u95ee\u9898\uff0c\u540c\u65f6\u907f\u514d\u624b\u52a8\u6807\u6ce8\u6216\u76d1\u7763\u8bad\u7ec3\u7684\u9700\u6c42\u3002", "method": "\u7ed3\u5408LLM\u7684SQL\u7f16\u7a0b\u80fd\u529b\u548c\u5bf9\u8bdd\u7406\u8bba\uff0c\u65e0\u76d1\u7763\u5730\u4ece\u96f6\u6784\u5efa\u4efb\u52a1\u5bfc\u5411\u5bf9\u8bdd\u672c\u4f53\u3002", "result": "TeQoDO\u5728\u5bf9\u8bdd\u72b6\u6001\u8ddf\u8e2a\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u8fc1\u79fb\u5b66\u4e60\u65b9\u6cd5\uff0c\u4e14\u80fd\u6269\u5c55\u5230\u6784\u5efa\u66f4\u5927\u89c4\u6a21\u7684\u672c\u4f53\u3002", "conclusion": "TeQoDO\u4e3a\u63d0\u5347LLM\u89e3\u91ca\u6027\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\uff0c\u5c55\u793a\u4e86\u65e0\u76d1\u7763\u672c\u4f53\u6784\u5efa\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.23382", "categories": ["cs.CL", "cs.AI", "cs.CV", "I.2.8; I.2.10"], "pdf": "https://arxiv.org/pdf/2507.23382", "abs": "https://arxiv.org/abs/2507.23382", "authors": ["Yiyan Ji", "Haoran Chen", "Qiguang Chen", "Chengyue Wu", "Libo Qin", "Wanxiang Che"], "title": "MPCC: A Novel Benchmark for Multimodal Planning with Complex Constraints in Multimodal Large Language Models", "comment": "Accepted to ACM Multimedia 2025", "summary": "Multimodal planning capabilities refer to the ability to predict, reason, and\ndesign steps for task execution with multimodal context, which is essential for\ncomplex reasoning and decision-making across multiple steps. However, current\nbenchmarks face two key challenges: (1) they cannot directly assess multimodal\nreal-world planning capabilities, and (2) they lack constraints or implicit\nconstraints across modalities. To address these issues, we introduce Multimodal\nPlanning with Complex Constraints (MPCC), the first benchmark to systematically\nevaluate MLLMs' ability to handle multimodal constraints in planning. To\naddress the first challenge, MPCC focuses on three real-world tasks: Flight\nPlanning, Calendar Planning, and Meeting Planning. To solve the second\nchallenge, we introduce complex constraints (e.g. budget, temporal, and\nspatial) in these tasks, with graded difficulty levels (EASY, MEDIUM, HARD) to\nseparate constraint complexity from search space expansion. Experiments on 13\nadvanced MLLMs reveal significant challenges: closed-source models achieve only\n21.3% feasible plans, while open-source models average below 11%. Additionally,\nwe observe that MLLMs are highly sensitive to constraint complexity and that\ntraditional multimodal prompting strategies fail in multi-constraint scenarios.\nOur work formalizes multimodal constraints in planning, provides a rigorous\nevaluation framework, and highlights the need for advancements in\nconstraint-aware reasoning for real-world MLLM applications.", "AI": {"tldr": "MPCC\u662f\u9996\u4e2a\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u5904\u7406\u591a\u6a21\u6001\u7ea6\u675f\u89c4\u5212\u80fd\u529b\u7684\u57fa\u51c6\uff0c\u901a\u8fc7\u771f\u5b9e\u4efb\u52a1\u548c\u590d\u6742\u7ea6\u675f\u63ed\u793a\u5f53\u524d\u6a21\u578b\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u65e0\u6cd5\u76f4\u63a5\u8bc4\u4f30\u591a\u6a21\u6001\u771f\u5b9e\u4e16\u754c\u89c4\u5212\u80fd\u529b\uff0c\u4e14\u7f3a\u4e4f\u8de8\u6a21\u6001\u7ea6\u675f\u3002", "method": "\u63d0\u51faMPCC\u57fa\u51c6\uff0c\u5305\u542b\u822a\u73ed\u3001\u65e5\u5386\u548c\u4f1a\u8bae\u89c4\u5212\u4efb\u52a1\uff0c\u5f15\u5165\u9884\u7b97\u3001\u65f6\u95f4\u548c\u7a7a\u95f4\u7b49\u590d\u6742\u7ea6\u675f\uff0c\u5e76\u5206\u96be\u5ea6\u7ea7\u522b\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u95ed\u6e90\u6a21\u578b\u4ec5\u751f\u621021.3%\u53ef\u884c\u8ba1\u5212\uff0c\u5f00\u6e90\u6a21\u578b\u4f4e\u4e8e11%\uff0c\u4e14\u6a21\u578b\u5bf9\u7ea6\u675f\u590d\u6742\u5ea6\u654f\u611f\u3002", "conclusion": "MPCC\u4e3a\u591a\u6a21\u6001\u7ea6\u675f\u89c4\u5212\u63d0\u4f9b\u4e25\u683c\u8bc4\u4f30\u6846\u67b6\uff0c\u51f8\u663e\u7ea6\u675f\u611f\u77e5\u63a8\u7406\u5728MLLM\u5e94\u7528\u4e2d\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2507.23386", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23386", "abs": "https://arxiv.org/abs/2507.23386", "authors": ["Ailiang Lin", "Zhuoyun Li", "Kotaro Funakoshi"], "title": "Causal2Vec: Improving Decoder-only LLMs as Versatile Embedding Models", "comment": null, "summary": "Decoder-only large language models (LLMs) are increasingly used to build\nembedding models that effectively encode the semantic information of natural\nlanguage texts into dense vector representations for various embedding tasks.\nHowever, many existing methods primarily focus on removing the causal attention\nmask in LLMs to enable bidirectional attention, potentially undermining the\nmodel's ability to extract semantic information acquired during pretraining.\nAdditionally, leading unidirectional approaches often rely on extra input text\nto overcome the inherent limitations of causal attention, inevitably increasing\ncomputational costs. In this work, we propose Causal2Vec, a general-purpose\nembedding model tailored to enhance the performance of decoder-only LLMs\nwithout altering their original architectures or introducing significant\ncomputational overhead. Specifically, we first employ a lightweight BERT-style\nmodel to pre-encode the input text into a single Contextual token, which is\nthen prepended to the LLM's input sequence, allowing each token to capture\ncontextualized information even without attending to future tokens.\nFurthermore, to mitigate the recency bias introduced by last-token pooling and\nhelp LLMs better leverage the semantic information encoded in the Contextual\ntoken, we concatenate the last hidden states of Contextual and EOS tokens as\nthe final text embedding. In practice, Causal2Vec achieves state-of-the-art\nperformance on the Massive Text Embeddings Benchmark (MTEB) among models\ntrained solely on publicly available retrieval datasets, while reducing the\nrequired sequence length by up to 85% and inference time by up to 82% compared\nto best-performing methods.", "AI": {"tldr": "Causal2Vec\u662f\u4e00\u79cd\u9488\u5bf9\u89e3\u7801\u5668\u4e13\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u5d4c\u5165\u6a21\u578b\uff0c\u901a\u8fc7\u9884\u7f16\u7801\u8f93\u5165\u6587\u672c\u4e3aContextual token\u5e76\u4f18\u5316\u6c60\u5316\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u4e14\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u53bb\u9664\u56e0\u679c\u6ce8\u610f\u529b\u63a9\u7801\u6216\u4f9d\u8d56\u989d\u5916\u8f93\u5165\u65f6\uff0c\u53ef\u80fd\u635f\u5bb3LLM\u7684\u8bed\u4e49\u63d0\u53d6\u80fd\u529b\u6216\u589e\u52a0\u8ba1\u7b97\u5f00\u9500\uff0cCausal2Vec\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u8f7b\u91cf\u7ea7BERT\u6a21\u578b\u9884\u7f16\u7801\u8f93\u5165\u4e3aContextual token\uff0c\u5c06\u5176\u6dfb\u52a0\u5230LLM\u8f93\u5165\u5e8f\u5217\uff0c\u5e76\u4f18\u5316\u6c60\u5316\u7b56\u7565\uff08\u7ed3\u5408Contextual\u548cEOS token\u7684\u9690\u85cf\u72b6\u6001\uff09\u3002", "result": "\u5728MTEB\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u4f18\u6027\u80fd\uff0c\u540c\u65f6\u51cf\u5c11\u5e8f\u5217\u957f\u5ea685%\u548c\u63a8\u7406\u65f6\u95f482%\u3002", "conclusion": "Causal2Vec\u5728\u4e0d\u6539\u53d8LLM\u67b6\u6784\u6216\u663e\u8457\u589e\u52a0\u8ba1\u7b97\u6210\u672c\u7684\u60c5\u51b5\u4e0b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5d4c\u5165\u6a21\u578b\u7684\u6027\u80fd\u3002"}}
{"id": "2507.23465", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23465", "abs": "https://arxiv.org/abs/2507.23465", "authors": ["Saeed Almheiri", "Yerulan Kongrat", "Adrian Santosh", "Ruslan Tasmukhanov", "Josemaria Vera", "Muhammad Dehan Al Kautsar", "Fajri Koto"], "title": "Role-Aware Language Models for Secure and Contextualized Access Control in Organizations", "comment": null, "summary": "As large language models (LLMs) are increasingly deployed in enterprise\nsettings, controlling model behavior based on user roles becomes an essential\nrequirement. Existing safety methods typically assume uniform access and focus\non preventing harmful or toxic outputs, without addressing role-specific access\nconstraints. In this work, we investigate whether LLMs can be fine-tuned to\ngenerate responses that reflect the access privileges associated with different\norganizational roles. We explore three modeling strategies: a BERT-based\nclassifier, an LLM-based classifier, and role-conditioned generation. To\nevaluate these approaches, we construct two complementary datasets. The first\nis adapted from existing instruction-tuning corpora through clustering and role\nlabeling, while the second is synthetically generated to reflect realistic,\nrole-sensitive enterprise scenarios. We assess model performance across varying\norganizational structures and analyze robustness to prompt injection, role\nmismatch, and jailbreak attempts.", "AI": {"tldr": "\u7814\u7a76\u5982\u4f55\u901a\u8fc7\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5b9e\u73b0\u57fa\u4e8e\u7528\u6237\u89d2\u8272\u7684\u884c\u4e3a\u63a7\u5236\uff0c\u63d0\u51fa\u4e09\u79cd\u5efa\u6a21\u7b56\u7565\u5e76\u6784\u5efa\u4e24\u4e2a\u6570\u636e\u96c6\u8fdb\u884c\u8bc4\u4f30\u3002", "motivation": "\u4f01\u4e1a\u73af\u5883\u4e2d\u9700\u8981\u6839\u636e\u7528\u6237\u89d2\u8272\u63a7\u5236LLMs\u7684\u884c\u4e3a\uff0c\u73b0\u6709\u65b9\u6cd5\u672a\u89e3\u51b3\u89d2\u8272\u7279\u5b9a\u8bbf\u95ee\u9650\u5236\u7684\u95ee\u9898\u3002", "method": "\u63a2\u7d22\u4e09\u79cd\u7b56\u7565\uff1a\u57fa\u4e8eBERT\u7684\u5206\u7c7b\u5668\u3001\u57fa\u4e8eLLM\u7684\u5206\u7c7b\u5668\u548c\u89d2\u8272\u6761\u4ef6\u751f\u6210\uff0c\u5e76\u6784\u5efa\u4e24\u4e2a\u6570\u636e\u96c6\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u8bc4\u4f30\u4e86\u6a21\u578b\u5728\u4e0d\u540c\u7ec4\u7ec7\u7ed3\u6784\u548c\u5bf9\u6297\u573a\u666f\uff08\u5982\u63d0\u793a\u6ce8\u5165\u3001\u89d2\u8272\u4e0d\u5339\u914d\u548c\u8d8a\u72f1\u5c1d\u8bd5\uff09\u4e0b\u7684\u6027\u80fd\u3002", "conclusion": "\u7814\u7a76\u8868\u660eLLMs\u53ef\u4ee5\u901a\u8fc7\u5fae\u8c03\u5b9e\u73b0\u89d2\u8272\u7279\u5b9a\u7684\u884c\u4e3a\u63a7\u5236\uff0c\u4e3a\u5b9e\u9645\u4f01\u4e1a\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2507.23740", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.23740", "abs": "https://arxiv.org/abs/2507.23740", "authors": ["Nasim Shirvani-Mahdavi", "Devin Wingfield", "Amin Ghasemi", "Chengkai Li"], "title": "Rule2Text: Natural Language Explanation of Logical Rules in Knowledge Graphs", "comment": null, "summary": "Knowledge graphs (KGs) often contain sufficient information to support the\ninference of new facts. Identifying logical rules not only improves the\ncompleteness of a knowledge graph but also enables the detection of potential\nerrors, reveals subtle data patterns, and enhances the overall capacity for\nreasoning and interpretation. However, the complexity of such rules, combined\nwith the unique labeling conventions of each KG, can make them difficult for\nhumans to understand. In this paper, we explore the potential of large language\nmodels to generate natural language explanations for logical rules.\nSpecifically, we extract logical rules using the AMIE 3.5.1 rule discovery\nalgorithm from the benchmark dataset FB15k-237 and two large-scale datasets,\nFB-CVT-REV and FB+CVT-REV. We examine various prompting strategies, including\nzero- and few-shot prompting, including variable entity types, and\nchain-of-thought reasoning. We conduct a comprehensive human evaluation of the\ngenerated explanations based on correctness, clarity, and hallucination, and\nalso assess the use of large language models as automatic judges. Our results\ndemonstrate promising performance in terms of explanation correctness and\nclarity, although several challenges remain for future research. All scripts\nand data used in this study are publicly available at\nhttps://github.com/idirlab/KGRule2NL}{https://github.com/idirlab/KGRule2NL.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4e3a\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u903b\u8f91\u89c4\u5219\u751f\u6210\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\u7684\u6f5c\u529b\uff0c\u5e76\u8bc4\u4f30\u4e86\u4e0d\u540c\u63d0\u793a\u7b56\u7565\u7684\u6548\u679c\u3002", "motivation": "\u63d0\u5347\u77e5\u8bc6\u56fe\u8c31\u7684\u5b8c\u6574\u6027\u548c\u63a8\u7406\u80fd\u529b\uff0c\u540c\u65f6\u5e2e\u52a9\u4eba\u7c7b\u7406\u89e3\u590d\u6742\u7684\u903b\u8f91\u89c4\u5219\u3002", "method": "\u4f7f\u7528AMIE 3.5.1\u7b97\u6cd5\u4ece\u591a\u4e2a\u6570\u636e\u96c6\u4e2d\u63d0\u53d6\u903b\u8f91\u89c4\u5219\uff0c\u5e76\u6d4b\u8bd5\u96f6\u6837\u672c\u3001\u5c11\u6837\u672c\u63d0\u793a\u53ca\u94fe\u5f0f\u63a8\u7406\u7b56\u7565\u3002", "result": "\u751f\u6210\u7684\u89e3\u91ca\u5728\u6b63\u786e\u6027\u548c\u6e05\u6670\u5ea6\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u4ecd\u5b58\u5728\u6311\u6218\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u89e3\u91ca\u903b\u8f91\u89c4\u5219\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u672a\u6765\u7814\u7a76\u9700\u8fdb\u4e00\u6b65\u4f18\u5316\u3002"}}
{"id": "2507.23399", "categories": ["cs.CL", "cs.CY", "I.2.7; K.4.3"], "pdf": "https://arxiv.org/pdf/2507.23399", "abs": "https://arxiv.org/abs/2507.23399", "authors": ["Peter Sandrini"], "title": "Beyond the Cloud: Assessing the Benefits and Drawbacks of Local LLM Deployment for Translators", "comment": null, "summary": "The rapid proliferation of Large Language Models presents both opportunities\nand challenges for the translation field. While commercial, cloud-based AI\nchatbots have garnered significant attention in translation studies, concerns\nregarding data privacy, security, and equitable access necessitate exploration\nof alternative deployment models. This paper investigates the feasibility and\nperformance of locally deployable, free language models as a viable alternative\nto proprietary, cloud-based AI solutions. This study evaluates three\nopen-source models installed on CPU-based platforms and compared against\ncommercially available online chat-bots. The evaluation focuses on functional\nperformance rather than a comparative analysis of human-machine translation\nquality, an area already subject to extensive research. The platforms assessed\nwere chosen for their accessibility and ease of use across various operating\nsystems. While local deployment introduces its own challenges, the benefits of\nenhanced data control, improved privacy, and reduced dependency on cloud\nservices are compelling. The findings of this study contribute to a growing\nbody of knowledge concerning the democratization of AI technology and inform\nfuture research and development efforts aimed at making LLMs more accessible\nand practical for a wider range of users, specifically focusing on the needs of\nindividual translators and small businesses.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u672c\u5730\u90e8\u7f72\u7684\u514d\u8d39\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u5546\u4e1a\u4e91\u7aefAI\u7ffb\u8bd1\u66ff\u4ee3\u65b9\u6848\u7684\u53ef\u884c\u6027\u548c\u6027\u80fd\uff0c\u5f3a\u8c03\u4e86\u6570\u636e\u9690\u79c1\u548c\u8bbf\u95ee\u5e73\u7b49\u7684\u4f18\u52bf\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u89e3\u51b3\u5546\u4e1a\u4e91\u7aefAI\u7ffb\u8bd1\u5728\u6570\u636e\u9690\u79c1\u3001\u5b89\u5168\u548c\u516c\u5e73\u8bbf\u95ee\u65b9\u9762\u7684\u95ee\u9898\uff0c\u63a2\u7d22\u672c\u5730\u90e8\u7f72\u6a21\u578b\u7684\u6f5c\u529b\u3002", "method": "\u7814\u7a76\u8bc4\u4f30\u4e86\u4e09\u79cd\u5f00\u6e90\u6a21\u578b\u5728CPU\u5e73\u53f0\u4e0a\u7684\u6027\u80fd\uff0c\u5e76\u4e0e\u5546\u4e1a\u5728\u7ebf\u804a\u5929\u673a\u5668\u4eba\u5bf9\u6bd4\uff0c\u91cd\u70b9\u8003\u5bdf\u529f\u80fd\u6027\u80fd\u800c\u975e\u7ffb\u8bd1\u8d28\u91cf\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u672c\u5730\u90e8\u7f72\u6a21\u578b\u5728\u6570\u636e\u63a7\u5236\u3001\u9690\u79c1\u4fdd\u62a4\u548c\u51cf\u5c11\u4e91\u7aef\u4f9d\u8d56\u65b9\u9762\u5177\u6709\u663e\u8457\u4f18\u52bf\u3002", "conclusion": "\u7ed3\u8bba\u6307\u51fa\u672c\u5730\u90e8\u7f72\u6a21\u578b\u4e3aAI\u6280\u672f\u7684\u6c11\u4e3b\u5316\u63d0\u4f9b\u4e86\u53ef\u80fd\uff0c\u5c24\u5176\u9002\u5408\u4e2a\u4f53\u8bd1\u8005\u548c\u5c0f\u578b\u4f01\u4e1a\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2507.23400", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2507.23400", "abs": "https://arxiv.org/abs/2507.23400", "authors": ["Yongbing Zhang", "Fang Nan", "Shengxiang Gao", "Yuxin Huang", "Kaiwen Tan", "Zhengtao Yu"], "title": "MRGSEM-Sum: An Unsupervised Multi-document Summarization Framework based on Multi-Relational Graphs and Structural Entropy Minimization", "comment": null, "summary": "The core challenge faced by multi-document summarization is the complexity of\nrelationships among documents and the presence of information redundancy. Graph\nclustering is an effective paradigm for addressing this issue, as it models the\ncomplex relationships among documents using graph structures and reduces\ninformation redundancy through clustering, achieving significant research\nprogress. However, existing methods often only consider single-relational\ngraphs and require a predefined number of clusters, which hinders their ability\nto fully represent rich relational information and adaptively partition\nsentence groups to reduce redundancy. To overcome these limitations, we propose\nMRGSEM-Sum, an unsupervised multi-document summarization framework based on\nmulti-relational graphs and structural entropy minimization. Specifically, we\nconstruct a multi-relational graph that integrates semantic and discourse\nrelations between sentences, comprehensively modeling the intricate and dynamic\nconnections among sentences across documents. We then apply a two-dimensional\nstructural entropy minimization algorithm for clustering, automatically\ndetermining the optimal number of clusters and effectively organizing sentences\ninto coherent groups. Finally, we introduce a position-aware compression\nmechanism to distill each cluster, generating concise and informative\nsummaries. Extensive experiments on four benchmark datasets (Multi-News,\nDUC-2004, PubMed, and WikiSum) demonstrate that our approach consistently\noutperforms previous unsupervised methods and, in several cases, achieves\nperformance comparable to supervised models and large language models. Human\nevaluation demonstrates that the summaries generated by MRGSEM-Sum exhibit high\nconsistency and coverage, approaching human-level quality.", "AI": {"tldr": "MRGSEM-Sum\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u5173\u7cfb\u56fe\u548c\u7ed3\u6784\u71b5\u6700\u5c0f\u5316\u7684\u65e0\u76d1\u7763\u591a\u6587\u6863\u6458\u8981\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u5173\u7cfb\u5efa\u6a21\u548c\u81ea\u9002\u5e94\u805a\u7c7b\u4e0a\u7684\u4e0d\u8db3\u3002", "motivation": "\u591a\u6587\u6863\u6458\u8981\u7684\u6838\u5fc3\u6311\u6218\u662f\u6587\u6863\u95f4\u5173\u7cfb\u7684\u590d\u6742\u6027\u548c\u4fe1\u606f\u5197\u4f59\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u4ec5\u8003\u8651\u5355\u5173\u7cfb\u56fe\u4e14\u9700\u9884\u5b9a\u4e49\u805a\u7c7b\u6570\u91cf\uff0c\u9650\u5236\u4e86\u5176\u6027\u80fd\u3002", "method": "\u6784\u5efa\u591a\u5173\u7cfb\u56fe\u6574\u5408\u8bed\u4e49\u548c\u8bed\u7bc7\u5173\u7cfb\uff0c\u5e94\u7528\u4e8c\u7ef4\u7ed3\u6784\u71b5\u6700\u5c0f\u5316\u7b97\u6cd5\u81ea\u52a8\u805a\u7c7b\uff0c\u5e76\u901a\u8fc7\u4f4d\u7f6e\u611f\u77e5\u538b\u7f29\u673a\u5236\u751f\u6210\u6458\u8981\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65e0\u76d1\u7763\u65b9\u6cd5\uff0c\u90e8\u5206\u60c5\u51b5\u4e0b\u63a5\u8fd1\u76d1\u7763\u6a21\u578b\u548c\u5927\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u3002", "conclusion": "MRGSEM-Sum\u751f\u6210\u7684\u6458\u8981\u5177\u6709\u9ad8\u4e00\u81f4\u6027\u548c\u8986\u76d6\u6027\uff0c\u63a5\u8fd1\u4eba\u5de5\u6c34\u5e73\u3002"}}
{"id": "2507.23404", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.23404", "abs": "https://arxiv.org/abs/2507.23404", "authors": ["Salah Eddine Bekhouche", "Azeddine Benlamoudi", "Yazid Bounab", "Fadi Dornaika", "Abdenour Hadid"], "title": "Enhanced Arabic Text Retrieval with Attentive Relevance Scoring", "comment": null, "summary": "Arabic poses a particular challenge for natural language processing (NLP) and\ninformation retrieval (IR) due to its complex morphology, optional diacritics\nand the coexistence of Modern Standard Arabic (MSA) and various dialects.\nDespite the growing global significance of Arabic, it is still underrepresented\nin NLP research and benchmark resources. In this paper, we present an enhanced\nDense Passage Retrieval (DPR) framework developed specifically for Arabic. At\nthe core of our approach is a novel Attentive Relevance Scoring (ARS) that\nreplaces standard interaction mechanisms with an adaptive scoring function that\nmore effectively models the semantic relevance between questions and passages.\nOur method integrates pre-trained Arabic language models and architectural\nrefinements to improve retrieval performance and significantly increase ranking\naccuracy when answering Arabic questions. The code is made publicly available\nat \\href{https://github.com/Bekhouche/APR}{GitHub}.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u963f\u62c9\u4f2f\u8bed\u7684\u589e\u5f3a\u578b\u5bc6\u96c6\u6bb5\u843d\u68c0\u7d22\uff08DPR\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u65b0\u9896\u7684\u6ce8\u610f\u529b\u76f8\u5173\u8bc4\u5206\uff08ARS\uff09\u63d0\u5347\u8bed\u4e49\u76f8\u5173\u6027\u5efa\u6a21\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u963f\u62c9\u4f2f\u8bed\u95ee\u7b54\u7684\u68c0\u7d22\u6027\u80fd\u3002", "motivation": "\u963f\u62c9\u4f2f\u8bed\u56e0\u5176\u590d\u6742\u5f62\u6001\u3001\u53ef\u9009\u53d8\u97f3\u7b26\u53f7\u53ca\u73b0\u4ee3\u6807\u51c6\u963f\u62c9\u4f2f\u8bed\u4e0e\u65b9\u8a00\u7684\u5171\u5b58\uff0c\u5bf9NLP\u548cIR\u6784\u6210\u6311\u6218\uff0c\u4e14\u7814\u7a76\u8d44\u6e90\u4e0d\u8db3\u3002", "method": "\u91c7\u7528\u9884\u8bad\u7ec3\u963f\u62c9\u4f2f\u8bed\u6a21\u578b\u548c\u67b6\u6784\u6539\u8fdb\uff0c\u5f15\u5165\u81ea\u9002\u5e94\u8bc4\u5206\u51fd\u6570ARS\u66ff\u4ee3\u6807\u51c6\u4ea4\u4e92\u673a\u5236\u3002", "result": "\u663e\u8457\u63d0\u9ad8\u4e86\u963f\u62c9\u4f2f\u8bed\u95ee\u7b54\u7684\u68c0\u7d22\u6027\u80fd\u548c\u6392\u540d\u51c6\u786e\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u963f\u62c9\u4f2f\u8bed\u5728NLP\u548cIR\u4e2d\u7684\u6311\u6218\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2507.23407", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.23407", "abs": "https://arxiv.org/abs/2507.23407", "authors": ["Ante Wang", "Yujie Lin", "Jingyao Liu", "Suhang Wu", "Hao Liu", "Xinyan Xiao", "Jinsong Su"], "title": "Beyond Passive Critical Thinking: Fostering Proactive Questioning to Enhance Human-AI Collaboration", "comment": null, "summary": "Critical thinking is essential for building robust AI systems, preventing\nthem from blindly accepting flawed data or biased reasoning. However, prior\nwork has primarily focused on passive critical thinking, where models simply\nreject problematic queries without taking constructive steps to address user\nrequests. In this work, we introduce proactive critical thinking, a paradigm\nwhere models actively seek missing or clarifying information from users to\nresolve their queries better. To evaluate this capability, we present GSM-MC\nand GSM-MCE, two novel benchmarks based on GSM8K for assessing mathematical\nreasoning under incomplete or misleading conditions. GSM-MC contains 1,368 math\nproblems with a key variable deliberately removed, requiring models to identify\nand request the missing information. GSM-MCE further increases the difficulty\nby introducing irrelevant details to test robustness against distractions.\nExperiments on Qwen3 and Llama series models show that, while these models\nexcel in traditional reasoning tasks due to extensive post-training and\ninference-time scaling, they struggle with proactive critical thinking,\nespecially smaller ones. However, we demonstrate that reinforcement learning\n(RL) can significantly improve this ability. Using our enhanced RL algorithm,\nwe achieve substantial gains, boosting the Qwen3-1.7B's accuracy from 0.15% to\n73.98% on GSM-MC. We hope this work advances models that collaborate more\neffectively with users in problem-solving through proactive critical thinking.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4e3b\u52a8\u6279\u5224\u6027\u601d\u7ef4\u8303\u5f0f\uff0c\u8981\u6c42AI\u6a21\u578b\u4e3b\u52a8\u5bfb\u6c42\u7f3a\u5931\u6216\u6f84\u6e05\u4fe1\u606f\u4ee5\u89e3\u51b3\u7528\u6237\u67e5\u8be2\uff0c\u5e76\u57fa\u4e8eGSM8K\u8bbe\u8ba1\u4e86\u4e24\u4e2a\u65b0\u57fa\u51c6GSM-MC\u548cGSM-MCE\u8fdb\u884c\u8bc4\u4f30\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u73b0\u6709\u6a21\u578b\u5728\u4e3b\u52a8\u6279\u5224\u6027\u601d\u7ef4\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u4f46\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u53ef\u663e\u8457\u63d0\u5347\u80fd\u529b\u3002", "motivation": "\u73b0\u6709AI\u7cfb\u7edf\u4e3b\u8981\u91c7\u7528\u88ab\u52a8\u6279\u5224\u6027\u601d\u7ef4\uff0c\u4ec5\u62d2\u7edd\u95ee\u9898\u67e5\u8be2\u800c\u4e0d\u4e3b\u52a8\u89e3\u51b3\u7528\u6237\u9700\u6c42\uff0c\u9650\u5236\u4e86\u5176\u534f\u4f5c\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e3b\u52a8\u6279\u5224\u6027\u601d\u7ef4\u8303\u5f0f\uff0c\u8bbe\u8ba1GSM-MC\u548cGSM-MCE\u4e24\u4e2a\u6570\u5b66\u63a8\u7406\u57fa\u51c6\uff0c\u5e76\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u63d0\u5347\u6a21\u578b\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u73b0\u6709\u6a21\u578b\uff08\u5982Qwen3\u548cLlama\u7cfb\u5217\uff09\u5728\u4e3b\u52a8\u6279\u5224\u6027\u601d\u7ef4\u4efb\u52a1\u4e0a\u8868\u73b0\u8f83\u5dee\uff0c\u4f46\u5f3a\u5316\u5b66\u4e60\u663e\u8457\u63d0\u5347\u4e86Qwen3-1.7B\u7684\u51c6\u786e\u7387\uff08\u4ece0.15%\u523073.98%\uff09\u3002", "conclusion": "\u4e3b\u52a8\u6279\u5224\u6027\u601d\u7ef4\u80fd\u6709\u6548\u63d0\u5347AI\u4e0e\u7528\u6237\u7684\u534f\u4f5c\u80fd\u529b\uff0c\u5f3a\u5316\u5b66\u4e60\u662f\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\u7684\u6709\u529b\u5de5\u5177\u3002"}}
{"id": "2507.23486", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.23486", "abs": "https://arxiv.org/abs/2507.23486", "authors": ["Shirui Wang", "Zhihui Tang", "Huaxia Yang", "Qiuhong Gong", "Tiantian Gu", "Hongyang Ma", "Yongxin Wang", "Wubin Sun", "Zeliang Lian", "Kehang Mao", "Yinan Jiang", "Zhicheng Huang", "Lingyun Ma", "Wenjie Shen", "Yajie Ji", "Yunhui Tan", "Chunbo Wang", "Yunlu Gao", "Qianling Ye", "Rui Lin", "Mingyu Chen", "Lijuan Niu", "Zhihao Wang", "Peng Yu", "Mengran Lang", "Yue Liu", "Huimin Zhang", "Haitao Shen", "Long Chen", "Qiguang Zhao", "Si-Xuan Liu", "Lina Zhou", "Hua Gao", "Dongqiang Ye", "Lingmin Meng", "Youtao Yu", "Naixin Liang", "Jianxiong Wu"], "title": "A Novel Evaluation Benchmark for Medical LLMs: Illuminating Safety and Effectiveness in Clinical Domains", "comment": null, "summary": "Large language models (LLMs) hold promise in clinical decision support but\nface major challenges in safety evaluation and effectiveness validation. We\ndeveloped the Clinical Safety-Effectiveness Dual-Track Benchmark (CSEDB), a\nmultidimensional framework built on clinical expert consensus, encompassing 30\ncriteria covering critical areas like critical illness recognition, guideline\nadherence, and medication safety, with weighted consequence measures.\nThirty-two specialist physicians developed and reviewed 2,069 open-ended Q&A\nitems aligned with these criteria, spanning 26 clinical departments to simulate\nreal-world scenarios. Benchmark testing of six LLMs revealed moderate overall\nperformance (average total score 57.2%, safety 54.7%, effectiveness 62.3%),\nwith a significant 13.3% performance drop in high-risk scenarios (p < 0.0001).\nDomain-specific medical LLMs showed consistent performance advantages over\ngeneral-purpose models, with relatively higher top scores in safety (0.912) and\neffectiveness (0.861). The findings of this study not only provide a\nstandardized metric for evaluating the clinical application of medical LLMs,\nfacilitating comparative analyses, risk exposure identification, and\nimprovement directions across different scenarios, but also hold the potential\nto promote safer and more effective deployment of large language models in\nhealthcare environments.", "AI": {"tldr": "CSEDB\u6846\u67b6\u8bc4\u4f30LLMs\u5728\u4e34\u5e8a\u51b3\u7b56\u4e2d\u7684\u5b89\u5168\u6027\u548c\u6709\u6548\u6027\uff0c\u53d1\u73b0\u4e13\u4e1a\u533b\u5b66\u6a21\u578b\u4f18\u4e8e\u901a\u7528\u6a21\u578b\uff0c\u4f46\u9ad8\u98ce\u9669\u573a\u666f\u8868\u73b0\u663e\u8457\u4e0b\u964d\u3002", "motivation": "\u8bc4\u4f30LLMs\u5728\u4e34\u5e8a\u51b3\u7b56\u4e2d\u7684\u5b89\u5168\u6027\u548c\u6709\u6548\u6027\uff0c\u4fc3\u8fdb\u5176\u5728\u533b\u7597\u73af\u5883\u4e2d\u7684\u5b89\u5168\u90e8\u7f72\u3002", "method": "\u5f00\u53d1CSEDB\u6846\u67b6\uff0c\u57fa\u4e8e\u4e13\u5bb6\u5171\u8bc6\u5236\u5b9a30\u9879\u6807\u51c6\uff0c\u6d4b\u8bd56\u79cdLLMs\u57282069\u4e2a\u4e34\u5e8a\u573a\u666f\u4e2d\u7684\u8868\u73b0\u3002", "result": "LLMs\u603b\u4f53\u8868\u73b0\u4e2d\u7b49\uff08\u603b\u520657.2%\uff09\uff0c\u9ad8\u98ce\u9669\u573a\u666f\u4e0b\u964d13.3%\uff0c\u4e13\u4e1a\u533b\u5b66\u6a21\u578b\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "CSEDB\u4e3aLLMs\u4e34\u5e8a\u8bc4\u4f30\u63d0\u4f9b\u6807\u51c6\u5316\u6307\u6807\uff0c\u6709\u52a9\u4e8e\u6539\u8fdb\u548c\u63a8\u5e7f\u5176\u5728\u533b\u7597\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2507.23541", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.23541", "abs": "https://arxiv.org/abs/2507.23541", "authors": ["Keer Lu", "Zheng Liang", "Youquan Li", "Jiejun Tan", "Da Pan", "Shusen Zhang", "Guosheng Dong", "Huang Leng"], "title": "Med-R$^3$: Enhancing Medical Retrieval-Augmented Reasoning of LLMs via Progressive Reinforcement Learning", "comment": null, "summary": "In medical scenarios, effectively retrieving external knowledge and\nleveraging it for rigorous logical reasoning is of significant importance.\nDespite their potential, existing work has predominantly focused on enhancing\neither retrieval or reasoning capabilities of the models in isolation, with\nlittle attention given to their joint optimization, which leads to limited\ncoordination between the two processes. Additionally, current methods rely\nheavily on supervised fine-tuning (SFT), which can cause models to memorize\nexisting problem-solving pathways, thereby restricting their generalization\nability when confronted with novel problem contexts. Furthermore, while some\nstudies have explored to improve retrieval-augmented reasoning in general\ndomains via reinforcement learning, their reward function designs do not\nadequately capture the specific demands of the medical domain. To address these\nchallenges, we introduce **Med-R$^3$**, a **Med**ical **R**etrieval-augmented\n**R**easoning framework driven by progressive **R**einforcement learning. In\nthis framework, we first develop the model's ability to perform logical\nreasoning over medical problems. Subsequently, on the basis of this foundation,\nwe adaptively optimize the retrieval capability to better align with the\ncharacteristics of knowledge corpus and external information utilization\nthroughout the reasoning process. Finally, we conduct joint optimization of the\nmodel's retrieval and reasoning coordination. Extensive experiments indicate\nthat **Med-R$^3$** could achieve state-of-the-art performances, with\nLLaMA3.1-8B-Instruct + Med-R$^3$ surpassing closed-sourced GPT-4o-mini by\n3.93\\% at a comparable parameter scale, while Qwen2.5-14B augmented with\nMed-R$^3$ shows a more substantial gain of 13.53\\%.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMed-R\u00b3\u7684\u533b\u5b66\u68c0\u7d22\u589e\u5f3a\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u6e10\u8fdb\u5f0f\u5f3a\u5316\u5b66\u4e60\u8054\u5408\u4f18\u5316\u68c0\u7d22\u4e0e\u63a8\u7406\u80fd\u529b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5728\u533b\u5b66\u9886\u57df\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u533b\u5b66\u9886\u57df\u4e2d\u5355\u72ec\u4f18\u5316\u68c0\u7d22\u6216\u63a8\u7406\u80fd\u529b\uff0c\u7f3a\u4e4f\u8054\u5408\u4f18\u5316\uff0c\u4e14\u4f9d\u8d56\u76d1\u7763\u5fae\u8c03\u9650\u5236\u4e86\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002\u6b64\u5916\uff0c\u901a\u7528\u9886\u57df\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u672a\u80fd\u6ee1\u8db3\u533b\u5b66\u9886\u57df\u7684\u7279\u5b9a\u9700\u6c42\u3002", "method": "Med-R\u00b3\u6846\u67b6\u9996\u5148\u8bad\u7ec3\u6a21\u578b\u7684\u903b\u8f91\u63a8\u7406\u80fd\u529b\uff0c\u968f\u540e\u81ea\u9002\u5e94\u4f18\u5316\u68c0\u7d22\u80fd\u529b\u4ee5\u5339\u914d\u77e5\u8bc6\u5e93\u7279\u5f81\uff0c\u6700\u540e\u8054\u5408\u4f18\u5316\u68c0\u7d22\u4e0e\u63a8\u7406\u7684\u534f\u8c03\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cMed-R\u00b3\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\uff0cLLaMA3.1-8B-Instruct + Med-R\u00b3\u8d85\u8d8aGPT-4o-mini 3.93%\uff0cQwen2.5-14B + Med-R\u00b3\u63d0\u534713.53%\u3002", "conclusion": "Med-R\u00b3\u901a\u8fc7\u8054\u5408\u4f18\u5316\u68c0\u7d22\u4e0e\u63a8\u7406\uff0c\u89e3\u51b3\u4e86\u533b\u5b66\u9886\u57df\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002"}}
{"id": "2507.23577", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.23577", "abs": "https://arxiv.org/abs/2507.23577", "authors": ["Alva West", "Luodan Zhang", "Liuliu Zhang", "Minjun Zhu", "Yixuan Weng", "Yue Zhang"], "title": "T-Detect: Tail-Aware Statistical Normalization for Robust Detection of Adversarial Machine-Generated Text", "comment": null, "summary": "The proliferation of sophisticated text generation models necessitates the\ndevelopment of robust detection methods capable of identifying\nmachine-generated content, particularly text designed to evade detection\nthrough adversarial perturbations. Existing zero-shot detectors often rely on\nstatistical measures that implicitly assume Gaussian distributions, a premise\nthat falters when confronted with the heavy-tailed statistical artifacts\ncharacteristic of adversarial or non-native English texts. This paper\nintroduces T-Detect, a novel detection method that fundamentally redesigns the\nstatistical core of curvature-based detectors. Our primary innovation is the\nreplacement of standard Gaussian normalization with a heavy-tailed discrepancy\nscore derived from the Student's t-distribution. This approach is theoretically\ngrounded in the empirical observation that adversarial texts exhibit\nsignificant leptokurtosis, rendering traditional statistical assumptions\ninadequate. T-Detect computes a detection score by normalizing the\nlog-likelihood of a passage against the expected moments of a t-distribution,\nproviding superior resilience to statistical outliers. We validate our approach\non the challenging RAID benchmark for adversarial text and the comprehensive\nHART dataset. Experiments show that T-Detect provides a consistent performance\nuplift over strong baselines, improving AUROC by up to 3.9\\% in targeted\ndomains. When integrated into a two-dimensional detection framework (CT), our\nmethod achieves state-of-the-art performance, with an AUROC of 0.926 on the\nBooks domain of RAID. Our contributions are a new, theoretically-justified\nstatistical foundation for text detection, an ablation-validated method that\ndemonstrates superior robustness, and a comprehensive analysis of its\nperformance under adversarial conditions. Ours code are released at\nhttps://github.com/ResearAI/t-detect.", "AI": {"tldr": "T-Detect\u662f\u4e00\u79cd\u65b0\u7684\u6587\u672c\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f7f\u7528t\u5206\u5e03\u66ff\u4ee3\u9ad8\u65af\u5206\u5e03\uff0c\u63d0\u9ad8\u4e86\u5bf9\u5bf9\u6297\u6027\u6587\u672c\u7684\u68c0\u6d4b\u80fd\u529b\uff0c\u5e76\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u968f\u7740\u6587\u672c\u751f\u6210\u6a21\u578b\u7684\u666e\u53ca\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u8bc6\u522b\u673a\u5668\u751f\u6210\u5185\u5bb9\uff08\u5c24\u5176\u662f\u5bf9\u6297\u6027\u6587\u672c\uff09\u7684\u9c81\u68d2\u68c0\u6d4b\u65b9\u6cd5\u3002\u73b0\u6709\u65b9\u6cd5\u57fa\u4e8e\u9ad8\u65af\u5206\u5e03\u7684\u5047\u8bbe\u5728\u5bf9\u6297\u6027\u6587\u672c\u4e2d\u8868\u73b0\u4e0d\u4f73\u3002", "method": "T-Detect\u91c7\u7528t\u5206\u5e03\u7684\u91cd\u5c3e\u5dee\u5f02\u5206\u6570\u66ff\u4ee3\u4f20\u7edf\u7684\u9ad8\u65af\u5f52\u4e00\u5316\uff0c\u901a\u8fc7\u8ba1\u7b97\u6587\u672c\u6bb5\u843d\u7684\u5bf9\u6570\u4f3c\u7136\u4e0et\u5206\u5e03\u671f\u671b\u77e9\u7684\u5f52\u4e00\u5316\u5f97\u5206\uff0c\u63d0\u5347\u5bf9\u7edf\u8ba1\u5f02\u5e38\u503c\u7684\u9c81\u68d2\u6027\u3002", "result": "\u5728RAID\u548cHART\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cT-Detect\u5728\u7279\u5b9a\u9886\u57df\u5c06AUROC\u63d0\u5347\u9ad8\u8fbe3.9%\uff0c\u5e76\u5728Books\u57df\u8fbe\u52300.926\u7684AUROC\u3002", "conclusion": "T-Detect\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u7edf\u8ba1\u57fa\u7840\uff0c\u9a8c\u8bc1\u4e86\u5176\u9c81\u68d2\u6027\uff0c\u5e76\u5728\u5bf9\u6297\u6027\u6761\u4ef6\u4e0b\u8868\u73b0\u51fa\u8272\u3002\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2507.23588", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.23588", "abs": "https://arxiv.org/abs/2507.23588", "authors": ["Alexandre Misrahi", "Nadezhda Chirkova", "Maxime Louis", "Vassilina Nikoulina"], "title": "DiffLoRA: Differential Low-Rank Adapters for Large Language Models", "comment": null, "summary": "Differential Transformer has recently been proposed to improve performance in\nTransformer models by canceling out noise through a denoiser attention\nmechanism. In this work, we introduce DiffLoRA, a parameter-efficient\nadaptation of the differential attention mechanism, with low-rank adapters on\nboth positive and negative attention terms. This approach retains the\nefficiency of LoRA while aiming to benefit from the performance gains of\ndifferential attention. We evaluate DiffLoRA across a broad range of NLP tasks,\nincluding general benchmarks, many-shot in-context learning, RAG, and\nlong-context tests. We observe that, although DiffLoRA falls short of other\nparameter-efficient fine-tuning methods in most evaluation tasks, it shows\ninteresting results in certain domains (+11 pts on LoRA for HumanEval). We\nanalyze the attention patterns post-finetuning to identify the reasons for this\nbehavior.", "AI": {"tldr": "DiffLoRA\u662f\u4e00\u79cd\u53c2\u6570\u9ad8\u6548\u7684\u5dee\u5206\u6ce8\u610f\u529b\u673a\u5236\uff0c\u7ed3\u5408\u4e86LoRA\u7684\u4f4e\u79e9\u9002\u914d\u5668\uff0c\u65e8\u5728\u63d0\u5347\u6027\u80fd\u3002\u5c3d\u7ba1\u5728\u591a\u6570\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u53ca\u5176\u4ed6\u65b9\u6cd5\uff0c\u4f46\u5728\u67d0\u4e9b\u9886\u57df\uff08\u5982HumanEval\uff09\u8868\u73b0\u7a81\u51fa\u3002", "motivation": "\u6539\u8fdbTransformer\u6a21\u578b\u7684\u6027\u80fd\uff0c\u901a\u8fc7\u5dee\u5206\u6ce8\u610f\u529b\u673a\u5236\u6d88\u9664\u566a\u58f0\uff0c\u540c\u65f6\u4fdd\u6301LoRA\u7684\u53c2\u6570\u6548\u7387\u3002", "method": "\u5728\u6b63\u8d1f\u6ce8\u610f\u529b\u9879\u4e0a\u5e94\u7528\u4f4e\u79e9\u9002\u914d\u5668\uff08LoRA\uff09\uff0c\u7ed3\u5408\u5dee\u5206\u6ce8\u610f\u529b\u673a\u5236\u3002", "result": "\u5728\u591a\u6570NLP\u4efb\u52a1\u4e2d\u8868\u73b0\u4e00\u822c\uff0c\u4f46\u5728HumanEval\u4e0a\u6bd4LoRA\u63d0\u534711\u5206\u3002", "conclusion": "DiffLoRA\u5728\u67d0\u4e9b\u9886\u57df\u6709\u6f5c\u529b\uff0c\u4f46\u9700\u8fdb\u4e00\u6b65\u4f18\u5316\u4ee5\u63d0\u5347\u5e7f\u6cdb\u9002\u7528\u6027\u3002"}}
{"id": "2507.23661", "categories": ["cs.CL", "I.2.7"], "pdf": "https://arxiv.org/pdf/2507.23661", "abs": "https://arxiv.org/abs/2507.23661", "authors": ["Salam Thabet Doghmash", "Motaz Saad"], "title": "Arabic Hate Speech Identification and Masking in Social Media using Deep Learning Models and Pre-trained Models Fine-tuning", "comment": "23 pages, 5 figures", "summary": "Hate speech identification in social media has become an increasingly\nimportant issue in recent years. In this research, we address two problems: 1)\nto detect hate speech in Arabic text, 2) to clean a given text from hate\nspeech. The meaning of cleaning here is replacing each bad word with stars\nbased on the number of letters for each word. Regarding the first problem, we\nconduct several experiments using deep learning models and transformers to\ndetermine the best model in terms of the F1 score. Regarding second problem, we\nconsider it as a machine translation task, where the input is a sentence\ncontaining dirty text and the output is the same sentence with masking the\ndirty text. The presented methods achieve the best model in hate speech\ndetection with a 92\\% Macro F1 score and 95\\% accuracy. Regarding the text\ncleaning experiment, the best result in the hate speech masking model reached\n0.3 in BLEU score with 1-gram, which is a good result compared with the state\nof the art machine translation systems.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u548cTransformer\u7684\u963f\u62c9\u4f2f\u8bed\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u4e0e\u6587\u672c\u6e05\u7406\u65b9\u6cd5\uff0c\u68c0\u6d4b\u6a21\u578bF1\u5206\u6570\u8fbe92%\uff0c\u6e05\u7406\u6a21\u578bBLEU\u5206\u6570\u4e3a0.3\u3002", "motivation": "\u89e3\u51b3\u793e\u4ea4\u5a92\u4f53\u4e2d\u963f\u62c9\u4f2f\u8bed\u4ec7\u6068\u8a00\u8bba\u7684\u68c0\u6d4b\u4e0e\u6e05\u7406\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u6df1\u5ea6\u5b66\u4e60\u548cTransformer\u6a21\u578b\u8fdb\u884c\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\uff0c\u5c06\u6587\u672c\u6e05\u7406\u89c6\u4e3a\u673a\u5668\u7ffb\u8bd1\u4efb\u52a1\u3002", "result": "\u68c0\u6d4b\u6a21\u578bF1\u5206\u657092%\uff0c\u51c6\u786e\u738795%\uff1b\u6e05\u7406\u6a21\u578bBLEU\u5206\u65700.3\u3002", "conclusion": "\u65b9\u6cd5\u5728\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u548c\u6e05\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002"}}
{"id": "2507.23776", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.23776", "abs": "https://arxiv.org/abs/2507.23776", "authors": ["Yunxiang Yan", "Tomohiro Sawada", "Kartik Goyal"], "title": "Cascaded Information Disclosure for Generalized Evaluation of Problem Solving Capabilities", "comment": "Under review", "summary": "While question-answering~(QA) benchmark performance is an automatic and\nscalable method to compare LLMs, it is an indirect method of evaluating their\nunderlying problem-solving capabilities. Therefore, we propose a holistic and\ngeneralizable framework based on \\emph{cascaded question disclosure} that\nprovides a more accurate estimate of the models' problem-solving capabilities\nwhile maintaining the scalability and automation. This approach collects model\nresponses in a stagewise manner with each stage revealing partial information\nabout the question designed to elicit generalized reasoning in LLMs. We find\nthat our approach not only provides a better comparison between LLMs, but also\ninduces better intermediate traces in models compared to the standard QA\nparadigm. We empirically verify this behavior on diverse reasoning and\nknowledge-heavy QA datasets by comparing LLMs of varying sizes and families.\nOur approach narrows the performance gap observed in the standard QA evaluation\nsettings, indicating that the prevalent indirect QA paradigm of evaluation\noverestimates the differences in performance between models. We further\nvalidate our findings by extensive ablation studies.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7ea7\u8054\u95ee\u9898\u62ab\u9732\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u66f4\u51c6\u786e\u5730\u8bc4\u4f30LLMs\u7684\u95ee\u9898\u89e3\u51b3\u80fd\u529b\uff0c\u540c\u65f6\u4fdd\u6301\u53ef\u6269\u5c55\u6027\u548c\u81ea\u52a8\u5316\u3002", "motivation": "QA\u57fa\u51c6\u6d4b\u8bd5\u662f\u95f4\u63a5\u8bc4\u4f30LLMs\u95ee\u9898\u89e3\u51b3\u80fd\u529b\u7684\u65b9\u6cd5\uff0c\u9700\u8981\u66f4\u76f4\u63a5\u4e14\u53ef\u6269\u5c55\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u91c7\u7528\u7ea7\u8054\u95ee\u9898\u62ab\u9732\u65b9\u6cd5\uff0c\u5206\u9636\u6bb5\u63ed\u793a\u95ee\u9898\u4fe1\u606f\uff0c\u4ee5\u6fc0\u53d1LLMs\u7684\u5e7f\u4e49\u63a8\u7406\u80fd\u529b\u3002", "result": "\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u6539\u8fdb\u4e86LLMs\u4e4b\u95f4\u7684\u6bd4\u8f83\uff0c\u8fd8\u751f\u6210\u4e86\u66f4\u597d\u7684\u4e2d\u95f4\u63a8\u7406\u75d5\u8ff9\uff0c\u7f29\u5c0f\u4e86\u6807\u51c6QA\u8bc4\u4f30\u4e2d\u7684\u6027\u80fd\u5dee\u8ddd\u3002", "conclusion": "\u7ea7\u8054\u95ee\u9898\u62ab\u9732\u6846\u67b6\u63d0\u4f9b\u4e86\u66f4\u51c6\u786e\u7684\u6a21\u578b\u80fd\u529b\u8bc4\u4f30\uff0c\u8868\u660e\u6807\u51c6QA\u8bc4\u4f30\u53ef\u80fd\u9ad8\u4f30\u4e86\u6a21\u578b\u95f4\u7684\u6027\u80fd\u5dee\u5f02\u3002"}}
