<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 41]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Strongly Solving $7 \times 6$ Connect-Four on Consumer Grade Hardware](https://arxiv.org/abs/2507.05267)
*Markus Böck*

Main category: cs.AI

TL;DR: 本文重新探讨了基于二元决策图的符号搜索方法，成功生成了一个89.6 GB的查找表，用于标准7×6棋盘大小的Connect-Four游戏。


<details>
  <summary>Details</summary>
Motivation: 尽管Connect-Four游戏已被数学解决，但基于查找表的强解被认为不可行。本文旨在探索一种高效的符号搜索方法来实现这一目标。

Method: 采用基于二元决策图的符号搜索方法，结合高效的实现，生成了查找表。此外，还引入了alpha-beta搜索以优化最快获胜或最慢失败的策略。

Result: 在单核CPU和128 GB内存的条件下，47小时内生成了89.6 GB的查找表。

Conclusion: 本文证明了通过符号搜索方法生成强解的可行性，并提供了开源工具以支持进一步研究。

Abstract: While the game Connect-Four has been solved mathematically and the best move
can be effectively computed with search based methods, a strong solution in the
form of a look-up table was believed to be infeasible. In this paper, we
revisit a symbolic search method based on binary decision diagrams to produce
strong solutions. With our efficient implementation we were able to produce a
89.6 GB large look-up table in 47 hours on a single CPU core with 128 GB main
memory for the standard $7 \times 6$ board size. In addition to this
win-draw-loss evaluation, we include an alpha-beta search in our open source
artifact to find the move which achieves the fastest win or slowest loss.

</details>


### [2] [Chat2SPaT: A Large Language Model Based Tool for Automating Traffic Signal Control Plan Management](https://arxiv.org/abs/2507.05283)
*Yue Wang,Miao Zhou,Guijing Huang,Rui Zhuo,Chao Yi,Zhenliang Ma*

Main category: cs.AI

TL;DR: Chat2SPaT利用大型语言模型（LLMs）将用户半结构化的交通信号控制计划描述转换为精确的信号相位与时间（SPaT）结果，简化了信号控制计划的管理过程。


<details>
  <summary>Details</summary>
Motivation: 传统预定时交通信号控制计划需要大量手动操作，且一个交叉口常关联多个计划，导致重复输入。Chat2SPaT旨在提供用户友好的计划管理方法。

Method: 通过LLMs理解用户描述并生成相位序列和属性的JSON格式结果，再通过Python脚本处理细节，组装完整的信号控制计划。

Result: 实验显示，Chat2SPaT在300多条计划描述测试集上的准确率超过94%（中英文均适用）。

Conclusion: Chat2SPaT为交通从业者和研究者提供了易于使用的计划管理工具，并展示了LLMs在智能交通系统中的潜力。

Abstract: Pre-timed traffic signal control, commonly used for operating signalized
intersections and coordinated arterials, requires tedious manual work for
signaling plan creating and updating. When the time-of-day or day-of-week plans
are utilized, one intersection is often associated with multiple plans, leading
to further repetitive manual plan parameter inputting. To enable a
user-friendly traffic signal control plan management process, this study
proposes Chat2SPaT, a method to convert users' semi-structured and ambiguous
descriptions on the signal control plan to exact signal phase and timing (SPaT)
results, which could further be transformed into structured stage-based or
ring-based plans to interact with intelligent transportation system (ITS)
software and traffic signal controllers. With curated prompts, Chat2SPaT first
leverages large language models' (LLMs) capability of understanding users' plan
descriptions and reformulate the plan as a combination of phase sequence and
phase attribute results in the json format. Based on LLM outputs, python
scripts are designed to locate phases in a cycle, address nuances of traffic
signal control, and finally assemble the complete traffic signal control plan.
Within a chat, the pipeline can be utilized iteratively to conduct further plan
editing. Experiments show that Chat2SPaT can generate plans with an accuracy of
over 94% for both English and Chinese cases, using a test dataset with over 300
plan descriptions. As the first benchmark for evaluating LLMs' capability of
understanding traffic signal control plan descriptions, Chat2SPaT provides an
easy-to-use plan management pipeline for traffic practitioners and researchers,
serving as a potential new building block for a more accurate and versatile
application of LLMs in the field of ITS. The source codes, prompts and test
dataset are openly accessible at https://github.com/yuewangits/Chat2SPaT.

</details>


### [3] [Fuzzy Classification Aggregation for a Continuum of Agents](https://arxiv.org/abs/2507.05297)
*Zijun Meng*

Main category: cs.AI

TL;DR: 论文证明，对于将m≥3个对象分为2≤p≤m类的连续个体分类，任何最优、独立且零一致的模糊分类聚合函数必须是加权算术平均。


<details>
  <summary>Details</summary>
Motivation: 研究模糊分类聚合函数的性质，特别是在多对象多分类情况下的最优解形式。

Method: 通过数学证明，分析模糊分类聚合函数的最优性、独立性和零一致性条件。

Result: 证明了满足条件的模糊分类聚合函数只能是加权算术平均。

Conclusion: 加权算术平均是满足最优、独立和零一致性的唯一模糊分类聚合函数。

Abstract: We prove that any optimal, independent, and zero unanimous fuzzy
classification aggregation function of a continuum of individual
classifications of $m\ge 3$ objects into $2\le p\le m$ types must be a weighted
arithmetic mean.

</details>


### [4] [OLG++: A Semantic Extension of Obligation Logic Graph](https://arxiv.org/abs/2507.05488)
*Subhasis Dasgupta,Jon Stephens,Amarnath Gupta*

Main category: cs.AI

TL;DR: OLG++是Obligation Logic Graph（OLG）的语义扩展，用于建模市政和跨辖区背景下的法规和法律规则。它引入更丰富的节点和边类型，支持复杂法律义务、例外和层级的表示，并通过食品业务法规示例展示其表达能力。


<details>
  <summary>Details</summary>
Motivation: 现有法律知识表示模型（如LegalRuleML）在表达复杂法律规则（如空间约束、层级关系和例外结构）时存在局限性，OLG++旨在填补这一空白。

Method: OLG++扩展了OLG，引入空间、时间、群体、可废止性和逻辑分组等新节点和边类型，支持结构化推理和复杂触发条件。

Result: OLG++在表达法律义务和例外方面优于现有图模型（如LegalRuleML），并通过食品法规示例验证了其表达能力。

Conclusion: OLG++为法律知识表示提供了更丰富的语义工具，尤其在跨辖区和复杂规则场景中表现突出。

Abstract: We present OLG++, a semantic extension of the Obligation Logic Graph (OLG)
for modeling regulatory and legal rules in municipal and interjurisdictional
contexts. OLG++ introduces richer node and edge types, including spatial,
temporal, party group, defeasibility, and logical grouping constructs, enabling
nuanced representations of legal obligations, exceptions, and hierarchies. The
model supports structured reasoning over rules with contextual conditions,
precedence, and complex triggers. We demonstrate its expressiveness through
examples from food business regulations, showing how OLG++ supports legal
question answering using property graph queries. OLG++ also improves over
LegalRuleML by providing native support for subClassOf, spatial constraints,
and reified exception structures. Our examples show that OLG++ is more
expressive than prior graph-based models for legal knowledge representation.

</details>


### [5] [Deep Research Comparator: A Platform For Fine-grained Human Annotations of Deep Research Agents](https://arxiv.org/abs/2507.05495)
*Prahaladh Chandrahasan,Jiahe Jin,Zhihan Zhang,Tevin Wang,Andy Tang,Lucy Mo,Morteza Ziyadi,Leonardo F. R. Ribeiro,Zimeng Qiu,Markus Dreyer,Akari Asai,Chenyan Xiong*

Main category: cs.AI

TL;DR: 论文介绍了Deep Research Comparator平台，用于评估深度研究代理的生成报告，支持对比、反馈和排名。


<details>
  <summary>Details</summary>
Motivation: 评估自主搜索、分析信息并生成报告的深度研究代理存在挑战，尤其是在长报告和中间步骤的详细反馈方面。

Method: 开发了Deep Research Comparator平台，支持报告对比、中间步骤评估和反馈收集；并提出了Simple Deepresearch作为基线代理。

Result: 收集了17位标注者对三个深度研究代理的真实偏好数据，展示了平台的实用性。

Conclusion: 该平台为深度研究代理的开发提供了全面的评估框架，并展示了其实际应用价值。

Abstract: Effectively evaluating deep research agents that autonomously search the web,
analyze information, and generate reports remains a major challenge,
particularly when it comes to assessing long reports and giving detailed
feedback on their intermediate steps. To address these gaps, we introduce Deep
Research Comparator, a platform that offers a holistic framework for deep
research agent hosting, side-by-side comparison, fine-grained human feedback
collection, and ranking calculation. Given a user query, our platform displays
the final reports from two different agents along with their intermediate steps
during generation. Annotators can evaluate the overall quality of final reports
based on side-by-side comparison, and also provide detailed feedback separately
by assessing intermediate steps or specific text spans within the final report.
Furthermore, we develop Simple Deepresearch, an end-to-end agent scaffold. This
scaffold serves as a baseline that facilitates the easy integration of various
large language models to transform them into deep research agents for
evaluation. To demonstrate the platform's utility for deep research agent
development, we have collected real user preference data from 17 annotators on
three deep research agents. A demo video of our platform can be found at
https://www.youtube.com/watch?v=g4d2dnbdseg.

</details>


### [6] [Fine-Grained Vision-Language Modeling for Multimodal Training Assistants in Augmented Reality](https://arxiv.org/abs/2507.05515)
*Haochen Huang,Jiahuan Pei,Mohammad Aliannejadi,Xin Sun,Moonisa Ahsan,Pablo Cesar,Chuang Yu,Zhaochun Ren,Junxiao Wang*

Main category: cs.AI

TL;DR: 本文介绍了针对AR训练的专用数据集，评估了九种先进VLM模型，发现其在细粒度任务上表现不佳，呼吁改进数据集和基准。


<details>
  <summary>Details</summary>
Motivation: 探索VLM在AR训练中的应用，填补研究空白，并为盲人和视障用户提供平等的AI学习机会。

Method: 构建了系统化的视觉语言任务数据集，并评估了九种先进VLM模型。

Result: 即使是GPT-4o等先进模型在细粒度任务上表现不佳，最高F1分数仅为40.54%。

Conclusion: 需改进数据集和基准以提升视觉语言对齐能力，研究具有广泛社会意义。

Abstract: Vision-language models (VLMs) are essential for enabling AI-powered smart
assistants to interpret and reason in multimodal environments. However, their
application in augmented reality (AR) training remains largely unexplored. In
this work, we introduce a comprehensive dataset tailored for AR training,
featuring systematized vision-language tasks, and evaluate nine
state-of-the-art VLMs on it. Our results reveal that even advanced models,
including GPT-4o, struggle with fine-grained assembly tasks, achieving a
maximum F1 score of just 40.54% on state detection. These findings highlight
the demand for enhanced datasets, benchmarks, and further research to improve
fine-grained vision-language alignment. Beyond technical contributions, our
work has broader social implications, particularly in empowering blind and
visually impaired users with equitable access to AI-driven learning
opportunities. We provide all related resources, including the dataset, source
code, and evaluation results, to support the research community.

</details>


### [7] [Modeling (Deontic) Modal Operators With the s(CASP) Goal-directed Predicated Answer Set Programming System](https://arxiv.org/abs/2507.05519)
*Gopal Gupta,Abhiramon Rajasekharan,Alexis R. Tudor,Elmer Salazar,Joaquín Arias*

Main category: cs.AI

TL;DR: 论文探讨了如何在答案集编程（ASP）中优雅地实现道义模态逻辑，利用默认否定和强否定表示模态算子，并通过ASP的全局约束解决道义模态逻辑的悖论。


<details>
  <summary>Details</summary>
Motivation: 解决道义模态逻辑在实现中的复杂性和悖论问题，探索其在答案集编程中的简洁表达方式。

Method: 利用答案集编程中的默认否定和强否定表示道义模态算子，并通过全局约束建模义务和禁止。

Result: 提出的方法能够优雅地解决道义模态逻辑中的各种悖论。

Conclusion: 在ASP中实现道义模态逻辑不仅简洁高效，还能有效解决传统悖论。

Abstract: We consider the problem of implementing deontic modal logic. We show how
(deontic) modal operators can be expressed elegantly using default negation
(negation-as-failure) and strong negation present in answer set programming
(ASP). We propose using global constraints of ASP to represent obligations and
impermissibilities of deontic modal logic. We show that our proposed
representation results in the various paradoxes of deontic modal logic being
elegantly resolved.

</details>


### [8] [Cultivating Multimodal Intelligence: Interpretive Reasoning and Agentic RAG Approaches to Dermatological Diagnosis](https://arxiv.org/abs/2507.05520)
*Karishma Thakrar,Shreyas Basavatia,Akshay Daftardar*

Main category: cs.AI

TL;DR: 2025 ImageCLEF MEDIQA-MAGIC挑战赛的CVQA任务，结合多模态模型、结构化推理层和代理RAG技术，实现了高准确率的皮肤病诊断支持。


<details>
  <summary>Details</summary>
Motivation: 解决远程医疗中皮肤病诊断的高准确性和可解释性问题。

Method: 结合开源多模态模型微调、结构化推理层和代理RAG技术。

Result: 团队获得第二名，提交方案排名第六，表现竞争力和高准确率。

Conclusion: 该架构为可靠的自动化诊断支持系统提供了路径，模拟皮肤科医生的系统推理模式。

Abstract: The second edition of the 2025 ImageCLEF MEDIQA-MAGIC challenge, co-organized
by researchers from Microsoft, Stanford University, and the Hospital Clinic of
Barcelona, focuses on multimodal dermatology question answering and
segmentation, using real-world patient queries and images. This work addresses
the Closed Visual Question Answering (CVQA) task, where the goal is to select
the correct answer to multiple-choice clinical questions based on both
user-submitted images and accompanying symptom descriptions. The proposed
approach combines three core components: (1) fine-tuning open-source multimodal
models from the Qwen, Gemma, and LLaMA families on the competition dataset, (2)
introducing a structured reasoning layer that reconciles and adjudicates
between candidate model outputs, and (3) incorporating agentic
retrieval-augmented generation (agentic RAG), which adds relevant information
from the American Academy of Dermatology's symptom and condition database to
fill in gaps in patient context. The team achieved second place with a
submission that scored sixth, demonstrating competitive performance and high
accuracy. Beyond competitive benchmarks, this research addresses a practical
challenge in telemedicine: diagnostic decisions must often be made
asynchronously, with limited input and with high accuracy and interpretability.
By emulating the systematic reasoning patterns employed by dermatologists when
evaluating skin conditions, this architecture provided a pathway toward more
reliable automated diagnostic support systems.

</details>


### [9] [Conversational Education at Scale: A Multi-LLM Agent Workflow for Procedural Learning and Pedagogic Quality Assessment](https://arxiv.org/abs/2507.05528)
*Jiahuan Pei,Fanghua Ye,Xin Sun,Wentao Deng,Koen Hindriks,Junxiao Wang*

Main category: cs.AI

TL;DR: 论文提出WikiHowAgent，一个基于大语言模型的多智能体工作流，用于模拟教学互动，并评估教学质量。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏可扩展性，未能充分利用多样化的课程内容，且缺乏评估教学质量的框架。

Method: 提出多智能体工作流，包括教师和学习者智能体、互动管理器和评估器，结合大规模数据集进行实验。

Result: 实验结果表明该工作流在多样化场景中有效，并提供了对大语言模型跨领域能力的见解。

Conclusion: 论文开源了数据集和实现，为AI4Education领域提供了有价值的工具和资源。

Abstract: Large language models (LLMs) have advanced virtual educators and learners,
bridging NLP with AI4Education. Existing work often lacks scalability and fails
to leverage diverse, large-scale course content, with limited frameworks for
assessing pedagogic quality. To this end, we propose WikiHowAgent, a
multi-agent workflow leveraging LLMs to simulate interactive teaching-learning
conversations. It integrates teacher and learner agents, an interaction
manager, and an evaluator to facilitate procedural learning and assess
pedagogic quality. We introduce a dataset of 114,296 teacher-learner
conversations grounded in 14,287 tutorials across 17 domains and 727 topics.
Our evaluation protocol combines computational and rubric-based metrics with
human judgment alignment. Results demonstrate the workflow's effectiveness in
diverse setups, offering insights into LLM capabilities across domains. Our
datasets and implementations are fully open-sourced.

</details>


### [10] [Red Teaming AI Red Teaming](https://arxiv.org/abs/2507.05538)
*Subhabrata Majumdar,Brian Pendleton,Abhishek Gupta*

Main category: cs.AI

TL;DR: 本文批判性地审视了AI红队测试的实践，指出其当前在AI治理中的局限性，并提出一个综合框架以改进。


<details>
  <summary>Details</summary>
Motivation: AI红队测试当前过于关注模型层面的缺陷，忽视了更广泛的社会技术系统和涌现行为，需要更全面的方法。

Method: 提出一个两层次框架：宏观系统红队测试和微观模型红队测试，结合网络安全经验和系统理论。

Result: 建议组建多功能团队，以检查涌现风险、系统性漏洞及技术与社会因素的相互作用。

Conclusion: 有效的AI红队测试需综合考虑技术和社会因素，以应对复杂系统中的风险。

Abstract: Red teaming has evolved from its origins in military applications to become a
widely adopted methodology in cybersecurity and AI. In this paper, we take a
critical look at the practice of AI red teaming. We argue that despite its
current popularity in AI governance, there exists a significant gap between red
teaming's original intent as a critical thinking exercise and its narrow focus
on discovering model-level flaws in the context of generative AI. Current AI
red teaming efforts focus predominantly on individual model vulnerabilities
while overlooking the broader sociotechnical systems and emergent behaviors
that arise from complex interactions between models, users, and environments.
To address this deficiency, we propose a comprehensive framework
operationalizing red teaming in AI systems at two levels: macro-level system
red teaming spanning the entire AI development lifecycle, and micro-level model
red teaming. Drawing on cybersecurity experience and systems theory, we further
propose a set of recommendations. In these, we emphasize that effective AI red
teaming requires multifunctional teams that examine emergent risks, systemic
vulnerabilities, and the interplay between technical and social factors.

</details>


### [11] [SenseCF: LLM-Prompted Counterfactuals for Intervention and Sensor Data Augmentation](https://arxiv.org/abs/2507.05541)
*Shovito Barua Soumma,Asiful Arefeen,Stephanie M. Carpenter,Melanie Hingle,Hassan Ghasemzadeh*

Main category: cs.AI

TL;DR: 论文探讨了使用GPT-4o-mini生成反事实解释（CFs）的零样本和三样本方法，在临床和生理预测任务中表现出高可信度和有效性，并能提升下游分类器性能。


<details>
  <summary>Details</summary>
Motivation: 反事实解释（CFs）能提供人本化的机器学习预测解释，用于异常预防和增强模型鲁棒性。本研究旨在探索大型语言模型（LLMs）在生成CFs中的潜力。

Method: 使用GPT-4o-mini在零样本和三样本设置下生成CFs，并在压力预测和心脏病检测数据集上评估，与传统方法（如DiCE、CFNOW、NICE）对比。

Result: LLM生成的CFs具有高可信度（99%）、强有效性（0.99）和竞争性稀疏性。作为增强数据，CFs能提升下游分类器性能（平均准确率提升5%）。

Conclusion: 基于提示的生成技术能显著提升临床和生理预测任务的可解释性和鲁棒性，展示了LLMs在生成CFs中的潜力。

Abstract: Counterfactual explanations (CFs) offer human-centric insights into machine
learning predictions by highlighting minimal changes required to alter an
outcome. Therefore, CFs can be used as (i) interventions for abnormality
prevention and (ii) augmented data for training robust models. In this work, we
explore large language models (LLMs), specifically GPT-4o-mini, for generating
CFs in a zero-shot and three-shot setting. We evaluate our approach on two
datasets: the AI-Readi flagship dataset for stress prediction and a public
dataset for heart disease detection. Compared to traditional methods such as
DiCE, CFNOW, and NICE, our few-shot LLM-based approach achieves high
plausibility (up to 99%), strong validity (up to 0.99), and competitive
sparsity. Moreover, using LLM-generated CFs as augmented samples improves
downstream classifier performance (an average accuracy gain of 5%), especially
in low-data regimes. This demonstrates the potential of prompt-based generative
techniques to enhance explainability and robustness in clinical and
physiological prediction tasks. Code base: github.com/anonymous/SenseCF.

</details>


### [12] [SingLoRA: Low Rank Adaptation Using a Single Matrix](https://arxiv.org/abs/2507.05566)
*David Bensaïd,Noam Rotstein,Roy Velich,Daniel Bensaïd,Ron Kimmel*

Main category: cs.AI

TL;DR: SingLoRA提出了一种改进的低秩适应方法，通过单低秩矩阵分解解决LoRA中的尺度冲突问题，提升训练稳定性并减少参数数量。


<details>
  <summary>Details</summary>
Motivation: LoRA在参数高效微调中表现优异，但矩阵间的尺度差异导致训练不稳定和性能下降。

Method: SingLoRA将权重更新重新表述为单低秩矩阵与其转置的乘积，消除尺度冲突并减少参数。

Result: 在多项任务中，SingLoRA表现优于LoRA和LoRA+，参数效率更高。例如，在MNLI任务中，SingLoRA准确率达91.3%，而LoRA为89.1%。

Conclusion: SingLoRA通过简化设计解决了LoRA的稳定性问题，并在性能和参数效率上均有显著提升。

Abstract: Low-Rank Adaptation (LoRA) has significantly advanced parameter-efficient
fine-tuning of large pretrained models. LoRA augments the pre-trained weights
of a model by adding the product of two smaller matrices that together form a
low-rank matrix update. Recent research has shown that scale disparities
between these two matrices often cause unstable training dynamics, leading to
suboptimal performance. In this paper, we propose SingLoRA, which reformulates
low-rank adaptation by learning the weights update as a decomposition of a
single low-rank matrix multiplied by its transpose. This simple design
inherently removes inter-matrix scale conflicts, ensuring stable optimization,
and roughly halves the parameter count. We analyze SingLoRA within the
infinite-width neural network framework, showing that it guarantees stable
feature learning by construction. Extensive experiments on multiple tasks
validate these benefits. In common sense reasoning, fine-tuning LLama 7B on
MNLI with SingLoRA achieves 91.3% accuracy - surpassing LoRA (89.1%) and LoRA+
(90.2%) - while using only 60% of their parameter budget. In image generation,
fine-tuning Stable Diffusion with SingLoRA significantly improves image
fidelity on DreamBooth, achieving a DINO similarity score of 0.151, compared to
scores of 0.148 and 0.143 for DoRA and LoRA, respectively.

</details>


### [13] [Towards Measurement Theory for Artificial Intelligence](https://arxiv.org/abs/2507.05587)
*Elija Perrier*

Main category: cs.AI

TL;DR: 提出一个关于人工智能测量的正式理论框架，旨在实现系统比较、风险评估和测量标准统一。


<details>
  <summary>Details</summary>
Motivation: 为AI研究、实践和监管提供统一的测量标准，以便比较系统、评估风险并理解AI能力的测量依赖性。

Method: 提出分层的测量框架，区分直接和间接可观测性，并构建可校准的AI现象分类法。

Result: 为AI测量提供理论基础，支持系统比较、风险评估和测量标准统一。

Conclusion: 正式测量理论有助于推动AI研究的标准化和风险评估的科学化。

Abstract: We motivate and outline a programme for a formal theory of measurement of
artificial intelligence. We argue that formalising measurement for AI will
allow researchers, practitioners, and regulators to: (i) make comparisons
between systems and the evaluation methods applied to them; (ii) connect
frontier AI evaluations with established quantitative risk analysis techniques
drawn from engineering and safety science; and (iii) foreground how what counts
as AI capability is contingent upon the measurement operations and scales we
elect to use. We sketch a layered measurement stack, distinguish direct from
indirect observables, and signpost how these ingredients provide a pathway
toward a unified, calibratable taxonomy of AI phenomena.

</details>


### [14] [MLlm-DR: Towards Explainable Depression Recognition with MultiModal Large Language Models](https://arxiv.org/abs/2507.05591)
*Wei Zhang,Juan Chen,En Zhu,Wenhong Cheng,YunPeng Li,Yanbo J. Wang*

Main category: cs.AI

TL;DR: 提出了一种新型多模态大语言模型（MLlm-DR），用于可解释的抑郁症诊断，结合小型LLMs和轻量级查询模块（LQ-former），在CMDC和E-DAIC-WOZ数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有抑郁症诊断方法缺乏解释性，且多模态LLMs在访谈数据上表现不佳，限制了临床应用。

Method: MLlm-DR整合小型LLMs生成抑郁症评分及解释，LQ-former提取语音和视觉特征，通过训练数据集优化逻辑推理。

Result: 在CMDC和E-DAIC-WOZ数据集上取得最优结果。

Conclusion: MLlm-DR实现了可解释且全面的抑郁症诊断，具有临床潜力。

Abstract: Automated depression diagnosis aims to analyze multimodal information from
interview videos to predict participants' depression scores. Previous studies
often lack clear explanations of how these scores were determined, limiting
their adoption in clinical practice. While the advent of LLMs provides a
possible pathway for explainable depression diagnosis, current LLMs capable of
processing multimodal data lack training on interview data, resulting in poor
diagnostic performance when used directly. In this paper, we propose a novel
multimodal large language model (MLlm-DR) that can understand multimodal
information inputs and supports explainable depression diagnosis. MLlm-DR
integrates a smaller LLMs and a lightweight query module (LQ-former).
Specifically, the smaller LLMs is designed to generate depression scores and
corresponding evaluation rationales. To enhance its logical reasoning for
domain-specific tasks while maintaining practicality, we constructed a robust
training dataset to fine-tune it. Meanwhile, the LQ-former captures
depression-related features from speech and visual data, aiding the model's
ability to process multimodal information, to achieve comprehensive depression
diagnosis. Our approach achieves state-of-the-art results on two
interview-based benchmark datasets, CMDC and E-DAIC-WOZ, demonstrating its
effectiveness and superiority.

</details>


### [15] [Domain adaptation of large language models for geotechnical applications](https://arxiv.org/abs/2507.05613)
*Lei Fan,Fangxue Liu,Cheng Chen*

Main category: cs.AI

TL;DR: 本文综述了大型语言模型（LLMs）在地质工程中的适应与应用，探讨了关键方法、应用领域及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在地质工程中的潜力，以提升工作效率和解决领域特定问题。

Method: 包括提示工程、检索增强生成、领域自适应预训练和微调等方法。

Result: LLMs已成功应用于地质解释、地下特征描述、设计计算等多个领域，但仍存在局限性。

Conclusion: 本文为实践者提供了整合LLMs的指南，并为学术研究指明了未来方向。

Abstract: Recent developments in large language models (LLMs) are opening up new
opportunities in geotechnical engineering and engineering geology. While
general-purpose LLMs possess broad capabilities, effective application in
geotechnics often requires domain-specific adaptation. Such tailored LLMs are
increasingly employed to streamline geotechnical workflows. This paper presents
the first survey of the adaptation and application of LLMs in geotechnical
engineering. It outlines key methodologies for adaptation to geotechnical
domain, including prompt engineering, retrieval-augmented generation,
domain-adaptive pretraining, and fine-tuning. The survey examines the
state-of-the-art applications of geotechnical-adapted LLMs, including
geological interpretation, subsurface characterization, site planning, design
calculations, numerical modeling, safety and risk assessment, and educational
tutoring. It also analyzes benefits and limitations of geotechnical-adapted
LLMs, and identifies promising directions for future research in this
interdisciplinary discipline. The findings serve as a valuable resource for
practitioners seeking to integrate LLMs into geotechnical practice, while also
providing a foundation to stimulate further investigation within the academic
community.

</details>


### [16] [ADMC: Attention-based Diffusion Model for Missing Modalities Feature Completion](https://arxiv.org/abs/2507.05624)
*Wei Zhang,Juan Chen,Yanbo J. Wang,En Zhu,Xuan Yang,Yiduo Wang*

Main category: cs.AI

TL;DR: ADMC模型通过注意力扩散网络解决多模态情感和意图识别中的缺失模态问题，提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决因传感器故障或数据不完整导致的模态缺失问题，避免传统方法的重建不精确和过耦合。

Method: 独立训练各模态特征提取网络，利用注意力扩散网络生成缺失模态特征。

Result: 在IEMOCAP和MIntRec基准测试中取得最优结果，适用于缺失和完整模态场景。

Conclusion: ADMC框架在多模态情感和意图识别中表现出色，尤其在缺失模态情况下效果显著。

Abstract: Multimodal emotion and intent recognition is essential for automated
human-computer interaction, It aims to analyze users' speech, text, and visual
information to predict their emotions or intent. One of the significant
challenges is that missing modalities due to sensor malfunctions or incomplete
data. Traditional methods that attempt to reconstruct missing information often
suffer from over-coupling and imprecise generation processes, leading to
suboptimal outcomes. To address these issues, we introduce an Attention-based
Diffusion model for Missing Modalities feature Completion (ADMC). Our framework
independently trains feature extraction networks for each modality, preserving
their unique characteristics and avoiding over-coupling. The Attention-based
Diffusion Network (ADN) generates missing modality features that closely align
with authentic multimodal distribution, enhancing performance across all
missing-modality scenarios. Moreover, ADN's cross-modal generation offers
improved recognition even in full-modality contexts. Our approach achieves
state-of-the-art results on the IEMOCAP and MIntRec benchmarks, demonstrating
its effectiveness in both missing and complete modality scenarios.

</details>


### [17] [Enhancing Student Learning with LLM-Generated Retrieval Practice Questions: An Empirical Study in Data Science Courses](https://arxiv.org/abs/2507.05629)
*Yuan An,John Liu,Niyam Acharya,Ruhma Hashmi*

Main category: cs.AI

TL;DR: 研究表明，LLM生成的多选题能显著提升学生知识保留率（89% vs 73%），但需人工验证质量。


<details>
  <summary>Details</summary>
Motivation: 解决教师生成高质量检索练习题的耗时问题，探索LLM自动生成的可行性。

Method: 在60名学生的数据科学课程中，比较使用LLM生成的多选题与无练习的学习效果。

Result: 使用LLM生成问题的学生知识保留率显著提高（89% vs 73%）。

Conclusion: LLM生成的检索练习能有效支持学习，但需人工验证以确保质量。

Abstract: Retrieval practice is a well-established pedagogical technique known to
significantly enhance student learning and knowledge retention. However,
generating high-quality retrieval practice questions is often time-consuming
and labor intensive for instructors, especially in rapidly evolving technical
subjects. Large Language Models (LLMs) offer the potential to automate this
process by generating questions in response to prompts, yet the effectiveness
of LLM-generated retrieval practice on student learning remains to be
established. In this study, we conducted an empirical study involving two
college-level data science courses, with approximately 60 students. We compared
learning outcomes during one week in which students received LLM-generated
multiple-choice retrieval practice questions to those from a week in which no
such questions were provided. Results indicate that students exposed to
LLM-generated retrieval practice achieved significantly higher knowledge
retention, with an average accuracy of 89%, compared to 73% in the week without
such practice. These findings suggest that LLM-generated retrieval questions
can effectively support student learning and may provide a scalable solution
for integrating retrieval practice into real-time teaching. However, despite
these encouraging outcomes and the potential time-saving benefits, cautions
must be taken, as the quality of LLM-generated questions can vary. Instructors
must still manually verify and revise the generated questions before releasing
them to students.

</details>


### [18] [LLMs are Introvert](https://arxiv.org/abs/2507.05638)
*Litian Zhang,Xiaoming Zhang,Bingyu Yan,Ziyi Zhou,Bo Zhang,Zhenyu Guan,Xi Zhang,Chaozhuo Li*

Main category: cs.AI

TL;DR: 论文探讨了社交媒体和生成式AI中信息传播的复杂性，提出了一种基于LLM的模拟环境，并通过SIP-CoT机制提升模拟的真实性。


<details>
  <summary>Details</summary>
Motivation: 传统模型（如SIR）和现有高级方法（如注意力机制和图神经网络）未能充分捕捉在线交互的复杂性，尤其是用户心理和行为动态。LLM因其类人推理能力为模拟信息传播的心理层面提供了新可能。

Method: 提出了一种基于LLM的模拟环境，结合SIP-CoT机制和情感引导记忆，以改进社交信息的解释、目标个性化和反馈评估。

Result: 实验表明，SIP-CoT增强的LLM代理能更有效地处理社交信息，行为、态度和情感更接近真实人类互动。

Conclusion: 研究揭示了当前LLM模拟的局限性，并证明SIP-CoT和情感记忆的整合显著提升了LLM代理的社交智能和真实性。

Abstract: The exponential growth of social media and generative AI has transformed
information dissemination, fostering connectivity but also accelerating the
spread of misinformation. Understanding information propagation dynamics and
developing effective control strategies is essential to mitigate harmful
content. Traditional models, such as SIR, provide basic insights but
inadequately capture the complexities of online interactions. Advanced methods,
including attention mechanisms and graph neural networks, enhance accuracy but
typically overlook user psychology and behavioral dynamics. Large language
models (LLMs), with their human-like reasoning, offer new potential for
simulating psychological aspects of information spread. We introduce an
LLM-based simulation environment capturing agents' evolving attitudes,
emotions, and responses. Initial experiments, however, revealed significant
gaps between LLM-generated behaviors and authentic human dynamics, especially
in stance detection and psychological realism. A detailed evaluation through
Social Information Processing Theory identified major discrepancies in
goal-setting and feedback evaluation, stemming from the lack of emotional
processing in standard LLM training. To address these issues, we propose the
Social Information Processing-based Chain of Thought (SIP-CoT) mechanism
enhanced by emotion-guided memory. This method improves the interpretation of
social cues, personalization of goals, and evaluation of feedback. Experimental
results confirm that SIP-CoT-enhanced LLM agents more effectively process
social information, demonstrating behaviors, attitudes, and emotions closer to
real human interactions. In summary, this research highlights critical
limitations in current LLM-based propagation simulations and demonstrates how
integrating SIP-CoT and emotional memory significantly enhances the social
intelligence and realism of LLM agents.

</details>


### [19] [City-Level Foreign Direct Investment Prediction with Tabular Learning on Judicial Data](https://arxiv.org/abs/2507.05651)
*Tianxing Wu,Lizhe Cao,Shuang Wang,Jiming Wang,Shutong Zhu,Yerong Wu,Yuqing Feng*

Main category: cs.AI

TL;DR: 论文提出了一种基于司法数据的城市级外国直接投资（FDI）预测方法（TLJD），通过整合大规模司法数据和经济数据，提高了预测的可靠性。


<details>
  <summary>Details</summary>
Motivation: 传统基于经济数据（如GDP）的FDI预测可能因数据操纵而不准确，司法数据能更可靠地反映投资安全和回报。

Method: 构建司法绩效评估指标体系，提出TLJD方法，整合行数据和列数据，并利用专家混合模型调整指标权重。

Result: TLJD在跨城市和跨时间任务中表现优异（R2至少0.92），优于其他十种先进基线方法。

Conclusion: TLJD通过司法数据显著提升了FDI预测的准确性和可靠性，为地方政府决策提供了有力支持。

Abstract: To advance the United Nations Sustainable Development Goal on promoting
sustained, inclusive, and sustainable economic growth, foreign direct
investment (FDI) plays a crucial role in catalyzing economic expansion and
fostering innovation. Precise city-level FDI prediction is quite important for
local government and is commonly studied based on economic data (e.g., GDP).
However, such economic data could be prone to manipulation, making predictions
less reliable. To address this issue, we try to leverage large-scale judicial
data which reflects judicial performance influencing local investment security
and returns, for city-level FDI prediction. Based on this, we first build an
index system for the evaluation of judicial performance over twelve million
publicly available adjudication documents according to which a tabular dataset
is reformulated. We then propose a new Tabular Learning method on Judicial Data
(TLJD) for city-level FDI prediction. TLJD integrates row data and column data
in our built tabular dataset for judicial performance indicator encoding, and
utilizes a mixture of experts model to adjust the weights of different
indicators considering regional variations. To validate the effectiveness of
TLJD, we design cross-city and cross-time tasks for city-level FDI predictions.
Extensive experiments on both tasks demonstrate the superiority of TLJD (reach
to at least 0.92 R2) over the other ten state-of-the-art baselines in different
evaluation metrics.

</details>


### [20] [Divergent Realities: A Comparative Analysis of Human Expert vs. Artificial Intelligence Based Generation and Evaluation of Treatment Plans in Dermatology](https://arxiv.org/abs/2507.05716)
*Dipayan Sengupta,Saumya Panda*

Main category: cs.AI

TL;DR: 研究比较了人类专家与两种AI模型（通用型和推理型）生成的皮肤病治疗方案，发现评估者的性质显著影响结果：人类专家更认可同行，而AI评估者更认可AI生成的方案。


<details>
  <summary>Details</summary>
Motivation: 随着AI在医疗领域的扩展，评估AI生成的治疗方案成为关键挑战，尤其是在新的推理模型出现后。

Method: 10位皮肤科医生、通用型AI（GPT-4o）和推理型AI（o3）为5个复杂皮肤病案例生成治疗方案，匿名后由人类专家和高级AI评估者（Gemini 2.5 Pro）评分。

Result: 人类专家评分显著高于AI方案，而AI评估者则相反，推理型AI（o3）被评为最佳。

Conclusion: 临床方案的质量感知取决于评估者性质，未来需发展可解释的人机协同系统以弥合推理差距。

Abstract: Background: Evaluating AI-generated treatment plans is a key challenge as AI
expands beyond diagnostics, especially with new reasoning models. This study
compares plans from human experts and two AI models (a generalist and a
reasoner), assessed by both human peers and a superior AI judge.
  Methods: Ten dermatologists, a generalist AI (GPT-4o), and a reasoning AI
(o3) generated treatment plans for five complex dermatology cases. The
anonymized, normalized plans were scored in two phases: 1) by the ten human
experts, and 2) by a superior AI judge (Gemini 2.5 Pro) using an identical
rubric.
  Results: A profound 'evaluator effect' was observed. Human experts scored
peer-generated plans significantly higher than AI plans (mean 7.62 vs. 7.16;
p=0.0313), ranking GPT-4o 6th (mean 7.38) and the reasoning model, o3, 11th
(mean 6.97). Conversely, the AI judge produced a complete inversion, scoring AI
plans significantly higher than human plans (mean 7.75 vs. 6.79; p=0.0313). It
ranked o3 1st (mean 8.20) and GPT-4o 2nd, placing all human experts lower.
  Conclusions: The perceived quality of a clinical plan is fundamentally
dependent on the evaluator's nature. An advanced reasoning AI, ranked poorly by
human experts, was judged as superior by a sophisticated AI, revealing a deep
gap between experience-based clinical heuristics and data-driven algorithmic
logic. This paradox presents a critical challenge for AI integration,
suggesting the future requires synergistic, explainable human-AI systems that
bridge this reasoning gap to augment clinical care.

</details>


### [21] [An autonomous agent for auditing and improving the reliability of clinical AI models](https://arxiv.org/abs/2507.05755)
*Lukas Kuhn,Florian Buettner*

Main category: cs.AI

TL;DR: ModelAuditor是一个自反思代理工具，用于识别和修复AI模型在临床实践中的隐藏故障模式，通过模拟分布变化生成可解释报告，显著提升模型在真实场景中的性能。


<details>
  <summary>Details</summary>
Motivation: AI模型在临床实践中可能因真实世界的变化（如硬件、光照或人口统计差异）而性能骤降，目前缺乏高效且可解释的工具来识别和修复这些故障。

Method: ModelAuditor通过与用户对话、选择任务特定指标、模拟临床相关分布变化，生成解释性能下降、故障模式及缓解策略的报告。

Result: 在三个真实临床场景中，ModelAuditor成功识别故障模式，并通过针对性建议恢复15-25%的性能损失，优于基线模型和现有增强方法。

Conclusion: ModelAuditor提供了一种高效、低成本的方法，显著提升AI模型在临床实践中的可靠性。

Abstract: The deployment of AI models in clinical practice faces a critical challenge:
models achieving expert-level performance on benchmarks can fail
catastrophically when confronted with real-world variations in medical imaging.
Minor shifts in scanner hardware, lighting or demographics can erode accuracy,
but currently reliability auditing to identify such catastrophic failure cases
before deployment is a bespoke and time-consuming process. Practitioners lack
accessible and interpretable tools to expose and repair hidden failure modes.
Here we introduce ModelAuditor, a self-reflective agent that converses with
users, selects task-specific metrics, and simulates context-dependent,
clinically relevant distribution shifts. ModelAuditor then generates
interpretable reports explaining how much performance likely degrades during
deployment, discussing specific likely failure modes and identifying root
causes and mitigation strategies. Our comprehensive evaluation across three
real-world clinical scenarios - inter-institutional variation in
histopathology, demographic shifts in dermatology, and equipment heterogeneity
in chest radiography - demonstrates that ModelAuditor is able correctly
identify context-specific failure modes of state-of-the-art models such as the
established SIIM-ISIC melanoma classifier. Its targeted recommendations recover
15-25% of performance lost under real-world distribution shift, substantially
outperforming both baseline models and state-of-the-art augmentation methods.
These improvements are achieved through a multi-agent architecture and execute
on consumer hardware in under 10 minutes, costing less than US$0.50 per audit.

</details>


### [22] [Real-time monitoring of the SoH of lithium-ion batteries](https://arxiv.org/abs/2507.05765)
*Bruno Jammes,Edgar Hernando Sepúlveda-Oviedo,Corinne Alonso*

Main category: cs.AI

TL;DR: 论文提出了一种基于充电结束阶段放电脉冲分析的新方法，用于实时监测电池健康状态（SoH），实验结果显示预测误差低且解释性强。


<details>
  <summary>Details</summary>
Motivation: 微电网中电池健康状态的实时监测存在挑战，传统方法受限，需要创新解决方案。

Method: 通过分析充电结束阶段的放电脉冲，利用等效电路模型参数估计SoH。

Result: 实验数据验证了方法的有效性，预测误差低至1%，解释性评分接近0.9。

Conclusion: 该方法有望集成到电池管理系统（BMS）中，优化持续运行下的电池管理。

Abstract: Real-time monitoring of the state of health (SoH) of batteries remains a
major challenge, particularly in microgrids where operational constraints limit
the use of traditional methods. As part of the 4BLife project, we propose an
innovative method based on the analysis of a discharge pulse at the end of the
charge phase. The parameters of the equivalent electrical model describing the
voltage evolution across the battery terminals during this current pulse are
then used to estimate the SoH. Based on the experimental data acquired so far,
the initial results demonstrate the relevance of the proposed approach. After
training using the parameters of two batteries with a capacity degradation of
around 85%, we successfully predicted the degradation of two other batteries,
cycled down to approximately 90% SoH, with a mean absolute error of around 1%
in the worst case, and an explainability score of the estimator close to 0.9.
If these performances are confirmed, this method can be easily integrated into
battery management systems (BMS) and paves the way for optimized battery
management under continuous operation.

</details>


### [23] [GTA1: GUI Test-time Scaling Agent](https://arxiv.org/abs/2507.05791)
*Yan Yang,Dongxu Li,Yutong Dai,Yuhao Yang,Ziyang Luo,Zirui Zhao,Zhiyuan Hu,Junzhe Huang,Amrita Saha,Zeyuan Chen,Ran Xu,Liyuan Pan,Caiming Xiong,Junnan Li*

Main category: cs.AI

TL;DR: 论文提出了一种名为GTA1的GUI代理，通过测试时扩展方法和强化学习解决任务规划和视觉定位的挑战，实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 解决GUI代理在任务规划中的模糊性和复杂界面中视觉定位的准确性两大挑战。

Method: 引入测试时扩展方法选择最佳动作提案，并利用强化学习模型提高视觉定位的准确性。

Result: 在多个基准测试中表现优异，如Screenspot-Pro、Screenspot-V2和OSWorld-G上分别达到50.1%、92.4%和67.7%的准确率。

Conclusion: GTA1通过结合测试时扩展和强化学习，显著提升了GUI代理的性能，并开源了代码和模型。

Abstract: Graphical user interface (GUI) agents autonomously operate across platforms
(e.g., Linux) to complete tasks by interacting with visual elements.
Specifically, a user instruction is decomposed into a sequence of action
proposals, each corresponding to an interaction with the GUI. After each
action, the agent observes the updated GUI environment to plan the next step.
However, two main challenges arise: i) resolving ambiguity in task planning
(i.e., the action proposal sequence), where selecting an appropriate plan is
non-trivial, as many valid ones may exist; ii) accurately grounding actions in
complex and high-resolution interfaces, i.e., precisely interacting with visual
targets.
  This paper investigates the two aforementioned challenges with our GUI
Test-time Scaling Agent, namely GTA1. First, to select the most appropriate
action proposal, we introduce a test-time scaling method. At each step, we
sample multiple candidate action proposals and leverage a judge model to
evaluate and select the most suitable one. It trades off computation for better
decision quality by concurrent sampling, shortening task execution steps, and
improving overall performance. Second, we propose a model that achieves
improved accuracy when grounding the selected action proposal to its
corresponding visual elements. Our key insight is that reinforcement learning
(RL) facilitates visual grounding through inherent objective alignments,
rewarding successful clicks on interface elements.
  Experimentally, our method establishes state-of-the-art performance across
diverse benchmarks. For example, GTA1-7B achieves 50.1%, 92.4%, and 67.7%
accuracies on Screenspot-Pro, Screenspot-V2, and OSWorld-G, respectively. When
paired with a planner applying our test-time scaling strategy, it exhibits
state-of-the-art agentic performance (e.g., 45.2% task success rate on
OSWorld). We open-source our code and models here.

</details>


### [24] [Affective-ROPTester: Capability and Bias Analysis of LLMs in Predicting Retinopathy of Prematurity](https://arxiv.org/abs/2507.05816)
*Shuai Zhao,Yulin Zhang,Luwei Xiao,Xinyi Wu,Yanhao Jia,Zhongliang Guo,Xiaobao Wu,Cong-Duy Nguyen,Guoming Zhang,Anh Tuan Luu*

Main category: cs.AI

TL;DR: 论文探讨了大型语言模型（LLMs）在预测早产儿视网膜病变（ROP）风险中的能力，提出了CROP数据集和Affective-ROPTester评估框架，发现外部知识增强模型性能，情感提示影响预测偏差。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在多个领域取得进展，但其在ROP风险预测中的应用尚未充分研究。本文旨在填补这一空白，并探讨情感提示对模型性能的影响。

Method: 提出CROP数据集和Affective-ROPTester框架，结合三种提示策略（指令、思维链、上下文学习）和情感元素，评估LLMs的预测能力和情感偏差。

Result: LLMs在仅依赖内在知识时预测效果有限，但通过外部输入显著提升；情感偏差明显，积极情感提示有助于减少预测偏差。

Conclusion: 情感敏感的提示工程对提升诊断可靠性至关重要，Affective-ROPTester为临床语言模型评估和偏差缓解提供了实用框架。

Abstract: Despite the remarkable progress of large language models (LLMs) across
various domains, their capacity to predict retinopathy of prematurity (ROP)
risk remains largely unexplored. To address this gap, we introduce a novel
Chinese benchmark dataset, termed CROP, comprising 993 admission records
annotated with low, medium, and high-risk labels. To systematically examine the
predictive capabilities and affective biases of LLMs in ROP risk
stratification, we propose Affective-ROPTester, an automated evaluation
framework incorporating three prompting strategies: Instruction-based,
Chain-of-Thought (CoT), and In-Context Learning (ICL). The Instruction scheme
assesses LLMs' intrinsic knowledge and associated biases, whereas the CoT and
ICL schemes leverage external medical knowledge to enhance predictive accuracy.
Crucially, we integrate emotional elements at the prompt level to investigate
how different affective framings influence the model's ability to predict ROP
and its bias patterns. Empirical results derived from the CROP dataset yield
two principal observations. First, LLMs demonstrate limited efficacy in ROP
risk prediction when operating solely on intrinsic knowledge, yet exhibit
marked performance gains when augmented with structured external inputs.
Second, affective biases are evident in the model outputs, with a consistent
inclination toward overestimating medium- and high-risk cases. Third, compared
to negative emotions, positive emotional framing contributes to mitigating
predictive bias in model outputs. These findings highlight the critical role of
affect-sensitive prompt engineering in enhancing diagnostic reliability and
emphasize the utility of Affective-ROPTester as a framework for evaluating and
mitigating affective bias in clinical language modeling systems.

</details>


### [25] [CogniPlay: a work-in-progress Human-like model for General Game Playing](https://arxiv.org/abs/2507.05868)
*Aloïs Rautureau,Éric Piette*

Main category: cs.AI

TL;DR: 论文探讨AI系统在游戏中表现优异但仍缺乏人类直觉决策能力，提出基于认知心理学的模型CogniPlay。


<details>
  <summary>Details</summary>
Motivation: 尽管AI在游戏中表现超越人类，但其决策过程缺乏人类直觉和模式识别能力，研究旨在弥补这一差距。

Method: 结合认知心理学和现有模型，提出新模型CogniPlay，应用于通用游戏（GGP）。

Result: 模型CogniPlay为工作进展，尚未明确结果。

Conclusion: 未来研究需进一步验证CogniPlay在模拟人类决策中的有效性。

Abstract: While AI systems have equaled or surpassed human performance in a wide
variety of games such as Chess, Go, or Dota 2, describing these systems as
truly "human-like" remains far-fetched. Despite their success, they fail to
replicate the pattern-based, intuitive decision-making processes observed in
human cognition. This paper presents an overview of findings from cognitive
psychology and previous efforts to model human-like behavior in artificial
agents, discusses their applicability to General Game Playing (GGP) and
introduces our work-in-progress model based on these observations: CogniPlay.

</details>


### [26] [Current Practices for Building LLM-Powered Reasoning Tools Are Ad Hoc -- and We Can Do Better](https://arxiv.org/abs/2507.05886)
*Aaron Bembenek*

Main category: cs.AI

TL;DR: 提出了一种名为“神经符号转换系统”的计算模型，旨在结合符号算法和大型语言模型（LLMs）构建神经符号自动推理工具。


<details>
  <summary>Details</summary>
Motivation: 当前构建神经符号自动推理系统的实践缺乏传统符号算法的强保证，且未能充分结合神经网络与符号推理的潜力。

Method: 提出神经符号转换系统，将符号状态与直觉配对，并在符号和直觉上并行执行状态转换。

Result: 该模型有望扩展逻辑推理能力，同时保留符号算法的强保证。

Conclusion: 该计算模型可具体化为逻辑编程语言，为神经符号自动推理工具提供理论基础。

Abstract: There is growing excitement about building software verifiers, synthesizers,
and other Automated Reasoning (AR) tools by combining traditional symbolic
algorithms and Large Language Models (LLMs). Unfortunately, the current
practice for constructing such neurosymbolic AR systems is an ad hoc
programming model that does not have the strong guarantees of traditional
symbolic algorithms, nor a deep enough synchronization of neural networks and
symbolic reasoning to unlock the full potential of LLM-powered reasoning. I
propose Neurosymbolic Transition Systems as a principled computational model
that can underlie infrastructure for building neurosymbolic AR tools. In this
model, symbolic state is paired with intuition, and state transitions operate
over symbols and intuition in parallel. I argue why this new paradigm can scale
logical reasoning beyond current capabilities while retaining the strong
guarantees of symbolic algorithms, and I sketch out how the computational model
I propose can be reified in a logic programming language.

</details>


### [27] [Decomposing the Time Series Forecasting Pipeline: A Modular Approach for Time Series Representation, Information Extraction, and Projection](https://arxiv.org/abs/2507.05891)
*Robert Leppich,Michael Stenger,André Bauer,Samuel Kounev*

Main category: cs.AI

TL;DR: 该论文提出了一种分解时间序列预测流程的方法，通过三个阶段优化序列表示、信息提取和目标投影，提升了预测精度和计算效率。


<details>
  <summary>Details</summary>
Motivation: 时间序列预测面临序列表示、信息提取和目标投影的挑战，不同任务需求各异，需要系统性解决方案。

Method: 将预测流程分解为输入序列表示、信息提取与内存构建、目标投影三个阶段，测试不同模块（如卷积层和自注意力机制）的效果。

Result: 在七个基准数据集上实现了最先进的预测精度，同时显著提高了计算效率，减少了训练和推理时间及参数数量。

Conclusion: 通过分解和优化预测流程，论文提供了一种高效且准确的时间序列预测方法。

Abstract: With the advent of Transformers, time series forecasting has seen significant
advances, yet it remains challenging due to the need for effective sequence
representation, memory construction, and accurate target projection. Time
series forecasting remains a challenging task, demanding effective sequence
representation, meaningful information extraction, and precise future
projection. Each dataset and forecasting configuration constitutes a distinct
task, each posing unique challenges the model must overcome to produce accurate
predictions. To systematically address these task-specific difficulties, this
work decomposes the time series forecasting pipeline into three core stages:
input sequence representation, information extraction and memory construction,
and final target projection. Within each stage, we investigate a range of
architectural configurations to assess the effectiveness of various modules,
such as convolutional layers for feature extraction and self-attention
mechanisms for information extraction, across diverse forecasting tasks,
including evaluations on seven benchmark datasets. Our models achieve
state-of-the-art forecasting accuracy while greatly enhancing computational
efficiency, with reduced training and inference times and a lower parameter
count. The source code is available at
https://github.com/RobertLeppich/REP-Net.

</details>


### [28] [MusiScene: Leveraging MU-LLaMA for Scene Imagination and Enhanced Video Background Music Generation](https://arxiv.org/abs/2507.05894)
*Fathinah Izzati,Xinyue Li,Yuxuan Wu,Gus Xia*

Main category: cs.AI

TL;DR: 论文提出MusiScene模型，通过音乐场景想象（MSI）任务生成与音乐相关的场景描述，并用于提升视频背景音乐生成（VBMG）。


<details>
  <summary>Details</summary>
Motivation: 探索音乐语言模型是否能像人类一样通过音乐想象相关场景，弥补现有音乐标注模型仅关注音乐元素的不足。

Method: 构建大规模视频-音频标注数据集，微调Music Understanding LLaMA（MU-LLaMA）以创建MusiScene模型，并进行全面评估。

Result: MusiScene在生成上下文相关标注方面优于MU-LLaMA，并成功应用于VBMG任务。

Conclusion: MusiScene通过跨模态信息训练，有效实现了音乐场景想象，为音乐与视频的结合提供了新思路。

Abstract: Humans can imagine various atmospheres and settings when listening to music,
envisioning movie scenes that complement each piece. For example, slow,
melancholic music might evoke scenes of heartbreak, while upbeat melodies
suggest celebration. This paper explores whether a Music Language Model, e.g.
MU-LLaMA, can perform a similar task, called Music Scene Imagination (MSI),
which requires cross-modal information from video and music to train. To
improve upon existing music captioning models which focusing solely on musical
elements, we introduce MusiScene, a music captioning model designed to imagine
scenes that complement each music. In this paper, (1) we construct a
large-scale video-audio caption dataset with 3,371 pairs, (2) we finetune Music
Understanding LLaMA for the MSI task to create MusiScene, and (3) we conduct
comprehensive evaluations and prove that our MusiScene is more capable of
generating contextually relevant captions compared to MU-LLaMA. We leverage the
generated MSI captions to enhance Video Background Music Generation (VBMG) from
text.

</details>


### [29] [BlueLM-2.5-3B Technical Report](https://arxiv.org/abs/2507.05934)
*Baojiao Xiong,Boheng Chen,Chengzhi Wang,Daxiong Luo,Dongsheng Xu,Dongyang Liu,Fan Yang,Fangyuan Li,Fei Teng,Feng Wang,Fukang Qin,Fuquan Peng,Guanxin Tan,Guozhi Wang,Haibo Yu,Haohao Gao,Heng Liu,Hongbo Yang,Hongjian Zou,Houzheng Shen,Hu Meng,Huan Li,Hui Tan,Jiali Chen,Jianzhao Chen,Jinliang Zhu,Kai Wang,Lei Wu,Liangbing Liu,Liuyang Bian,Liyan He,Long Liu,Peiwen Li,Penggang Shi,Qi Ding,Rui Hu,Shuai Cao,Shuai Ren,Shuang Peng,Teng Xie,Weiji Chen,Weilin Xiang,Weixin Wu,Xi Yin,Xiaoxin Chen,Xu Chen,Yafei Wen,Yan Hu,Yanzhou Yang,Yina Xie,Yinghao Chen,Yixuan Liao,Yu Geng,Yuanjiang Ouyang,Yuanzhuo Yang,Yuehua He,Yushuai Peng,Zhaoxiong Wang,Zheng Wang,Zhibo Zhou,Ziyang Wu*

Main category: cs.AI

TL;DR: BlueLM-2.5-3B是一个紧凑的多模态大语言模型，支持思考和普通模式，并在边缘设备上高效部署。


<details>
  <summary>Details</summary>
Motivation: 开发一个高性能、适用于边缘设备的多模态大语言模型，同时保持文本和多模态任务的竞争力。

Method: 通过多样化数据整理、关键数据重采样、混合异构强化学习和高性能训练基础设施开发模型。

Result: 在文本和多模态任务上表现优异，数据效率高，性能接近或超过更大规模的模型。

Conclusion: BlueLM-2.5-3B为高性能边缘设备MLLM的发展提供了贡献，并为研究社区提供了有价值的见解。

Abstract: We present BlueLM-2.5-3B, a compact and unified dense Multimodal Large
Language Model (MLLM) designed for efficient edge-device deployment, offering
strong general-purpose and reasoning capabilities. To the best of our
knowledge, this is the first 3B-scale MLLM to support both thinking and
non-thinking modes, while also enabling explicit control over thinking token
budget. BlueLM-2.5-3B is developed through diversified data curation, key data
resampling, hybrid heterogeneous reinforcement learning, and a high-performance
training infrastructure. Our model achieves superior multimodal capacity while
preserving competitive pure-text performance with only 2.9 billion parameters.
We conduct comprehensive evaluations across a broad range of multimodal and
text-only benchmarks. In thinking mode, BlueLM-2.5-3B achieves comparable
performance to Qwen3-4B on text-only benchmarks, and trails the larger
Kimi-VL-A3B-16B by only about 5% on average across multimodal evaluations. In
non-thinking mode, it outperforms Qwen2.5-VL-3B on the majority of multimodal
benchmarks. Additionally, BlueLM-2.5-3B exhibits exceptional data efficiency.
All of the aforementioned performance is achieved with substantially less total
training data than Qwen2.5-VL-3B and Qwen3-4B. We hope our work contributes to
the advancement of high-performance, on-device MLLMs and provides meaningful
insights to the research community.

</details>


### [30] [A Wireless Foundation Model for Multi-Task Prediction](https://arxiv.org/abs/2507.05938)
*Yucheng Sheng,Jiacheng Wang,Xingyu Zhou,Le Liang,Hao Ye,Shi Jin,Geoffrey Ye Li*

Main category: cs.AI

TL;DR: 提出了一种统一的基础模型，用于无线网络中的多任务预测，支持不同预测区间，并通过因果Transformer架构和补丁掩码策略提升泛化能力。


<details>
  <summary>Details</summary>
Motivation: 移动通信网络的复杂性和动态性增加，传统深度学习方法难以泛化到不同场景和任务，因此需要一种统一的多任务预测模型。

Method: 采用单变量分解统一异构任务，编码粒度以实现区间感知，使用因果Transformer架构，并引入补丁掩码策略支持任意输入长度。

Result: 在大规模数据集上训练后，模型在未见场景中表现出强泛化能力，并在新任务上实现零样本性能，超越传统全样本基线。

Conclusion: 提出的基础模型为无线网络中的多任务预测提供了一种高效且泛化能力强的解决方案。

Abstract: With the growing complexity and dynamics of the mobile communication
networks, accurately predicting key system parameters, such as channel state
information (CSI), user location, and network traffic, has become essential for
a wide range of physical (PHY)-layer and medium access control (MAC)-layer
tasks. Although traditional deep learning (DL)-based methods have been widely
applied to such prediction tasks, they often struggle to generalize across
different scenarios and tasks. In response, we propose a unified foundation
model for multi-task prediction in wireless networks that supports diverse
prediction intervals. The proposed model enforces univariate decomposition to
unify heterogeneous tasks, encodes granularity for interval awareness, and uses
a causal Transformer backbone for accurate predictions. Additionally, we
introduce a patch masking strategy during training to support arbitrary input
lengths. After trained on large-scale datasets, the proposed foundation model
demonstrates strong generalization to unseen scenarios and achieves zero-shot
performance on new tasks that surpass traditional full-shot baselines.

</details>


### [31] [Enhancing the Interpretability of Rule-based Explanations through Information Retrieval](https://arxiv.org/abs/2507.05976)
*Alessandro Umbrico,Guido Bologna,Luca Coraci,Francesca Fracasso,Silvia Gola,Gabriella Cortellessa*

Main category: cs.AI

TL;DR: 提出了一种基于属性的方法，用于提高可解释AI在乳腺癌淋巴结放疗后淋巴水肿风险评估中的透明度和可解释性。


<details>
  <summary>Details</summary>
Motivation: 数据驱动的AI技术缺乏透明度，限制了其在医疗决策中的可解释性和接受度。

Method: 通过信息检索技术的标准指标，对基于规则的预测模型中的属性进行统计分析，计算每个属性对预测的相关性。

Result: 用户研究表明，该方法生成的输出比原始可解释AI模型的输出更具可解释性和实用性。

Conclusion: 该方法提高了AI预测在医疗决策中的透明度和可接受性。

Abstract: The lack of transparency of data-driven Artificial Intelligence techniques
limits their interpretability and acceptance into healthcare decision-making
processes. We propose an attribution-based approach to improve the
interpretability of Explainable AI-based predictions in the specific context of
arm lymphedema's risk assessment after lymph nodal radiotherapy in breast
cancer. The proposed method performs a statistical analysis of the attributes
in the rule-based prediction model using standard metrics from Information
Retrieval techniques. This analysis computes the relevance of each attribute to
the prediction and provides users with interpretable information about the
impact of risk factors. The results of a user study that compared the output
generated by the proposed approach with the raw output of the Explainable AI
model suggested higher levels of interpretability and usefulness in the context
of predicting lymphedema risk.

</details>


### [32] [Development and Evaluation of HopeBot: an LLM-based chatbot for structured and interactive PHQ-9 depression screening](https://arxiv.org/abs/2507.05984)
*Zhijun Guo,Alvina Lai,Julia Ive,Alexandru Petcu,Yutong Wang,Luyuan Qi,Johan H Thygesen,Kezhi Li*

Main category: cs.AI

TL;DR: HopeBot是一种基于大型语言模型的聊天机器人，用于抑郁症筛查，与传统PHQ-9问卷相比，具有更强的交互性和适应性。研究表明，用户对其信任度更高，且愿意重复使用或推荐。


<details>
  <summary>Details</summary>
Motivation: 传统抑郁症筛查工具（如PHQ-9）缺乏交互性和适应性，HopeBot旨在通过聊天机器人提供更灵活和用户友好的筛查方式。

Method: 开发了HopeBot，采用检索增强生成和实时澄清技术，并在英国和中国的132名成年人中进行了自我填写和聊天机器人版本的对比研究。

Result: HopeBot与PHQ-9得分一致性高（ICC=0.91），71%的用户更信任聊天机器人，87.1%的用户愿意重复使用或推荐。

Conclusion: 基于语音的LLM聊天机器人可作为抑郁症筛查的可扩展、低负担辅助工具。

Abstract: Static tools like the Patient Health Questionnaire-9 (PHQ-9) effectively
screen depression but lack interactivity and adaptability. We developed
HopeBot, a chatbot powered by a large language model (LLM) that administers the
PHQ-9 using retrieval-augmented generation and real-time clarification. In a
within-subject study, 132 adults in the United Kingdom and China completed both
self-administered and chatbot versions. Scores demonstrated strong agreement
(ICC = 0.91; 45% identical). Among 75 participants providing comparative
feedback, 71% reported greater trust in the chatbot, highlighting clearer
structure, interpretive guidance, and a supportive tone. Mean ratings (0-10)
were 8.4 for comfort, 7.7 for voice clarity, 7.6 for handling sensitive topics,
and 7.4 for recommendation helpfulness; the latter varied significantly by
employment status and prior mental-health service use (p < 0.05). Overall,
87.1% expressed willingness to reuse or recommend HopeBot. These findings
demonstrate voice-based LLM chatbots can feasibly serve as scalable, low-burden
adjuncts for routine depression screening.

</details>


### [33] [CogniSQL-R1-Zero: Lightweight Reinforced Reasoning for Efficient SQL Generation](https://arxiv.org/abs/2507.06013)
*Kushal Gajjar,Harshit Sikchi,Arpit Singh Gautam,Marc Hammons,Saurabh Jha*

Main category: cs.AI

TL;DR: CogniSQL-R1-Zero是一个基于强化学习的框架，通过轻量级奖励信号生成准确的SQL，在Text2SQL基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决自然语言转SQL（Text-to-SQL）中复杂查询生成的挑战，避免中间监督和复杂奖励设计。

Method: 使用强化学习框架，基于执行正确性和格式标签合规性的轻量级奖励信号。

Result: 在BIRD基准测试中超越现有监督和指令调优模型，如SFT CodeS-7B等，且仅需4块NVIDIA A100 GPU训练。

Conclusion: 该方法展示了强化学习在Text-to-SQL任务中的高效性和可扩展性，并发布了两个数据集以支持进一步研究。

Abstract: Translating natural language into SQL (Text-to-SQL) remains a core challenge
at the intersection of language understanding and structured data access.
Although large language models (LLMs) have improved fluency, generating correct
and executable SQL, especially for complex queries, continues to be
challenging. We introduce CogniSQL-R1-Zero, a reinforcement learning (RL)
framework and model that produces accurate SQL using a lightweight reward
signal based on execution correctness and format-tag compliance. By avoiding
intermediate supervision, hybrid pipelines and complex reward shaping, our
method encourages stable learning and stronger alignment with the ultimate task
objective-producing executable programs. CogniSQL-R1-Zero achieves
state-of-the-art execution accuracy on Text2SQL benchmark; BIRD bench,
outperforming prior supervised and instruction-tuned baselines including SFT
CodeS-7B, DeepSeek-Coder 236B, and Mistral 123B-despite being trained on a
significantly smaller 7B backbone. This result underscores the scalability and
efficiency of our RL-based approach when trained on just four NVIDIA A100 GPUs
(40 GB VRAM each). To support further research in efficient and interpretable
Text-to-SQL modeling, we release two curated datasets: (i) a collection of
5,024 reasoning traces with varying context lengths, and (ii) a
positive-sampled corpus of 36,356 corpus of weakly supervised queries, each
annotated with six semantically diverse reasoning paths. Together, these
contributions advance scalable, execution-aligned Text-to-SQL generation.

</details>


### [34] [Feature-Guided Neighbor Selection for Non-Expert Evaluation of Model Predictions](https://arxiv.org/abs/2507.06029)
*Courtney Ford,Mark T. Keane*

Main category: cs.AI

TL;DR: FGNS是一种后处理方法，通过结合局部和全局特征重要性选择代表性样本，提升非专家用户对模型输出的理解能力。


<details>
  <summary>Details</summary>
Motivation: 当前XAI方法对非专家用户生成清晰解释的能力有限，FGNS旨在改善这一问题。

Method: FGNS利用局部和全局特征重要性选择类代表性样本，与传统k-NN方法对比。

Result: 在用户研究中，FGNS显著提升非专家识别模型错误的能力，决策更快更准，且选择样本更符合类特征。

Conclusion: FGNS是迈向更人性化模型评估的一步，但解释质量与用户信任之间的差距仍需进一步研究。

Abstract: Explainable AI (XAI) methods often struggle to generate clear, interpretable
outputs for users without domain expertise. We introduce Feature-Guided
Neighbor Selection (FGNS), a post hoc method that enhances interpretability by
selecting class-representative examples using both local and global feature
importance. In a user study (N = 98) evaluating Kannada script classifications,
FGNS significantly improved non-experts' ability to identify model errors while
maintaining appropriate agreement with correct predictions. Participants made
faster and more accurate decisions compared to those given traditional k-NN
explanations. Quantitative analysis shows that FGNS selects neighbors that
better reflect class characteristics rather than merely minimizing
feature-space distance, leading to more consistent selection and tighter
clustering around class prototypes. These results support FGNS as a step toward
more human-aligned model assessment, although further work is needed to address
the gap between explanation quality and perceived trust.

</details>


### [35] [On Lockean beliefs that are deductively closed and minimal change](https://arxiv.org/abs/2507.06042)
*Tommaso Flaminio,Lluis Godo,Ramón Pino Pérez,Lluis Subirana*

Main category: cs.AI

TL;DR: 论文在Lockean理论框架下，通过概率描述置信度定义信念集，并解决其在经典逻辑演绎下不封闭的问题。提出了两种封闭信念集的表征方法，以及一种最小化修正的更新方法。


<details>
  <summary>Details</summary>
Motivation: Lockean信念集在经典逻辑演绎下通常不封闭，限制了其在信念修正理论等领域的应用。本文旨在解决这一问题。

Method: 提供了两种封闭信念集的表征方法，并提出一种最小化修正的更新方法，以实现信念集的演绎封闭。

Result: 展示了如何通过最小修正实现信念集的演绎封闭。

Conclusion: 本文解决了Lockean信念集在逻辑演绎下的封闭性问题，并提出了实用的最小修正更新方法。

Abstract: Within the formal setting of the Lockean thesis, an agent belief set is
defined in terms of degrees of confidence and these are described in
probabilistic terms. This approach is of established interest, notwithstanding
some limitations that make its use troublesome in some contexts, like, for
instance, in belief change theory. Precisely, Lockean belief sets are not
generally closed under (classical) logical deduction. The aim of the present
paper is twofold: on one side we provide two characterizations of those belief
sets that are closed under classical logic deduction, and on the other we
propose an approach to probabilistic update that allows us for a minimal
revision of those beliefs, i.e., a revision obtained by making the fewest
possible changes to the existing belief set while still accommodating the new
information. In particular, we show how we can deductively close a belief set
via a minimal revision.

</details>


### [36] [FEVO: Financial Knowledge Expansion and Reasoning Evolution for Large Language Models](https://arxiv.org/abs/2507.06057)
*Bo Pang,Yalu Ouyang,Hangfei Xu,Ziqi Jia,Panpan Li,Shengzhao Wen,Lu Wang,Shiyong Li,Yanpeng Wang*

Main category: cs.AI

TL;DR: FEVO框架通过多阶段增强方法（CPT、SFT、RL）提升LLM在金融领域的性能，并在多个基准测试中取得领先表现。


<details>
  <summary>Details</summary>
Motivation: 现有研究在金融领域应用LLM的进展有限，需要结合领域知识和结构化推理。

Method: 采用持续预训练（CPT）、监督微调（SFT）和强化学习（RL）三阶段框架，结合高质量数据集FEVO-Train。

Result: FEVO-R32B在五个金融基准测试中表现最优，验证了领域知识扩展和结构化推理的有效性。

Conclusion: FEVO框架显著提升了LLM在金融领域的性能，为领域特定任务提供了有效解决方案。

Abstract: Advancements in reasoning for large language models (LLMs) have lead to
significant performance improvements for LLMs in various fields such as
mathematics and programming. However, research applying these advances to the
financial domain, where considerable domain-specific knowledge is necessary to
complete tasks, remains limited. To address this gap, we introduce FEVO
(Financial Evolution), a multi-stage enhancement framework developed to enhance
LLM performance in the financial domain. FEVO systemically enhances LLM
performance by using continued pre-training (CPT) to expand financial domain
knowledge, supervised fine-tuning (SFT) to instill structured, elaborate
reasoning patterns, and reinforcement learning (RL) to further integrate the
expanded financial domain knowledge with the learned structured reasoning. To
ensure effective and efficient training, we leverage frontier reasoning models
and rule-based filtering to curate FEVO-Train, high-quality datasets
specifically designed for the different post-training phases. Using our
framework, we train the FEVO series of models -- C32B, S32B, R32B -- from
Qwen2.5-32B and evaluate them on seven benchmarks to assess financial and
general capabilities, with results showing that FEVO-R32B achieves
state-of-the-art performance on five financial benchmarks against much larger
models as well as specialist models. More significantly, FEVO-R32B demonstrates
markedly better performance than FEVO-R32B-0 (trained from Qwen2.5-32B-Instruct
using only RL), thus validating the effectiveness of financial domain knowledge
expansion and structured, logical reasoning distillation

</details>


### [37] [AI-Based Demand Forecasting and Load Balancing for Optimising Energy use in Healthcare Systems: A real case study](https://arxiv.org/abs/2507.06077)
*Iman Rahimi,Isha Patel*

Main category: cs.AI

TL;DR: 论文提出了一种结合LSTM、遗传算法和SHAP的AI框架，用于医疗设施的高效能源管理，显著提升了预测准确性和能源效率。


<details>
  <summary>Details</summary>
Motivation: 医疗设施能源需求波动大，传统方法效率低下且成本高，亟需智能解决方案。

Method: 采用LSTM进行时间序列预测，遗传算法优化参数和负载平衡，SHAP增强模型可解释性。

Result: LSTM在预测性能上显著优于ARIMA和Prophet模型（MAE: 21.69, RMSE: 29.96），遗传算法和SHAP进一步提升了效率和透明度。

Conclusion: 该框架为医疗能源管理提供了高效、可扩展的解决方案，未来可探索实时部署和强化学习结合。

Abstract: This paper tackles the urgent need for efficient energy management in
healthcare facilities, where fluctuating demands challenge operational
efficiency and sustainability. Traditional methods often prove inadequate,
causing inefficiencies and higher costs. To address this, the study presents an
AI-based framework combining Long Short-Term Memory (LSTM), genetic algorithm
(GA), and SHAP (Shapley Additive Explanations), specifically designed for
healthcare energy management. Although LSTM is widely used for time-series
forecasting, its application in healthcare energy prediction remains
underexplored. The results reveal that LSTM significantly outperforms ARIMA and
Prophet models in forecasting complex, non-linear demand patterns. LSTM
achieves a Mean Absolute Error (MAE) of 21.69 and Root Mean Square Error (RMSE)
of 29.96, far better than Prophet (MAE: 59.78, RMSE: 81.22) and ARIMA (MAE:
87.73, RMSE: 125.22), demonstrating superior performance. The genetic algorithm
is applied to optimize model parameters and improve load balancing strategies,
enabling adaptive responses to real-time energy fluctuations. SHAP analysis
further enhances model transparency by explaining the influence of different
features on predictions, fostering trust in decision-making processes. This
integrated LSTM-GA-SHAP approach offers a robust solution for improving
forecasting accuracy, boosting energy efficiency, and advancing sustainability
in healthcare facilities. Future research may explore real-time deployment and
hybridization with reinforcement learning for continuous optimization. Overall,
the study establishes a solid foundation for using AI in healthcare energy
management, highlighting its scalability, efficiency, and resilience potential.

</details>


### [38] [OpenAgentSafety: A Comprehensive Framework for Evaluating Real-World AI Agent Safety](https://arxiv.org/abs/2507.06134)
*Sanidhya Vijayvargiya,Aditya Bharat Soni,Xuhui Zhou,Zora Zhiruo Wang,Nouha Dziri,Graham Neubig,Maarten Sap*

Main category: cs.AI

TL;DR: OpenAgentSafety是一个模块化框架，用于评估AI代理在真实工具环境中的行为安全性，覆盖八类关键风险，并支持350多种多轮任务。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法依赖模拟环境或狭窄任务领域，无法全面评估AI代理在真实世界中的安全行为。

Method: OpenAgentSafety结合基于规则的分析和LLM评估，支持真实工具交互和多轮任务，设计为可扩展。

Result: 实验显示，五种LLM在安全脆弱任务中表现出51.2%至72.7%的不安全行为。

Conclusion: OpenAgentSafety揭示了AI代理的安全漏洞，强调在真实部署前需加强安全保障。

Abstract: Recent advances in AI agents capable of solving complex, everyday tasks, from
scheduling to customer service, have enabled deployment in real-world settings,
but their possibilities for unsafe behavior demands rigorous evaluation. While
prior benchmarks have attempted to assess agent safety, most fall short by
relying on simulated environments, narrow task domains, or unrealistic tool
abstractions. We introduce OpenAgentSafety, a comprehensive and modular
framework for evaluating agent behavior across eight critical risk categories.
Unlike prior work, our framework evaluates agents that interact with real
tools, including web browsers, code execution environments, file systems, bash
shells, and messaging platforms; and supports over 350 multi-turn, multi-user
tasks spanning both benign and adversarial user intents. OpenAgentSafety is
designed for extensibility, allowing researchers to add tools, tasks, websites,
and adversarial strategies with minimal effort. It combines rule-based analysis
with LLM-as-judge assessments to detect both overt and subtle unsafe behaviors.
Empirical analysis of five prominent LLMs in agentic scenarios reveals unsafe
behavior in 51.2% of safety-vulnerable tasks with Claude-Sonnet-3.7, to 72.7%
with o3-mini, highlighting critical safety vulnerabilities and the need for
stronger safeguards before real-world deployment.

</details>


### [39] [The Delta Learning Hypothesis: Preference Tuning on Weak Data can Yield Strong Gains](https://arxiv.org/abs/2507.06187)
*Scott Geng,Hamish Ivison,Chun-Liang Li,Maarten Sap,Jerry Li,Ranjay Krishna,Pang Wei Koh*

Main category: cs.AI

TL;DR: 通过配对偏好数据（即使单个数据点较弱）可以提升语言模型性能，提出delta学习假设，验证其有效性，并在实验中匹配了先进模型的性能。


<details>
  <summary>Details</summary>
Motivation: 强监督数据稀缺时，如何利用弱数据点提升模型性能。

Method: 提出delta学习假设，通过配对弱模型生成的数据点形成质量差异，用于偏好调优。

Result: 在11个基准测试中，匹配了先进模型Tulu 3的性能，且成本更低。

Conclusion: delta学习为利用弱数据点提供了高效方法，简化了先进模型的训练过程。

Abstract: Improvements in language models are often driven by improving the quality of
the data we train them on, which can be limiting when strong supervision is
scarce. In this work, we show that paired preference data consisting of
individually weak data points can enable gains beyond the strength of each
individual data point. We formulate the delta learning hypothesis to explain
this phenomenon, positing that the relative quality delta between points
suffices to drive learning via preference tuning--even when supervised
finetuning on the weak data hurts. We validate our hypothesis in controlled
experiments and at scale, where we post-train 8B models on preference data
generated by pairing a small 3B model's responses with outputs from an even
smaller 1.5B model to create a meaningful delta. Strikingly, on a standard
11-benchmark evaluation suite (MATH, MMLU, etc.), our simple recipe matches the
performance of Tulu 3, a state-of-the-art open model tuned from the same base
model while relying on much stronger supervisors (e.g., GPT-4o). Thus, delta
learning enables simpler and cheaper open recipes for state-of-the-art
post-training. To better understand delta learning, we prove in logistic
regression that the performance gap between two weak teacher models provides
useful signal for improving a stronger student. Overall, our work shows that
models can learn surprisingly well from paired data that might typically be
considered weak.

</details>


### [40] [Identifiability in Causal Abstractions: A Hierarchy of Criteria](https://arxiv.org/abs/2507.06213)
*Clément Yvernes,Emilie Devijver,Marianne Clausel,Eric Gaussier*

Main category: cs.AI

TL;DR: 论文探讨了在缺乏完整因果图的情况下，如何通过因果抽象（简化的因果表示）来识别因果效应，并提出了一系列可识别性标准及其层次结构。


<details>
  <summary>Details</summary>
Motivation: 在观测数据中识别因果效应通常需要完整的因果图，但实际中这种图很少已知，尤其是在复杂或高维场景中。因此，研究如何在部分因果信息下进行识别具有重要意义。

Method: 通过形式化因果抽象为因果图的集合，提出并组织多种可识别性标准，构建其层次结构。

Result: 建立了一个层次化的可识别性标准框架，明确了在不同因果知识水平下可以识别的范围。

Conclusion: 该框架为在缺乏完整因果知识时进行因果推断提供了工具和理论基础。

Abstract: Identifying the effect of a treatment from observational data typically
requires assuming a fully specified causal diagram. However, such diagrams are
rarely known in practice, especially in complex or high-dimensional settings.
To overcome this limitation, recent works have explored the use of causal
abstractions-simplified representations that retain partial causal information.
In this paper, we consider causal abstractions formalized as collections of
causal diagrams, and focus on the identifiability of causal queries within such
collections. We introduce and formalize several identifiability criteria under
this setting. Our main contribution is to organize these criteria into a
structured hierarchy, highlighting their relationships. This hierarchical view
enables a clearer understanding of what can be identified under varying levels
of causal knowledge. We illustrate our framework through examples from the
literature and provide tools to reason about identifiability when full causal
knowledge is unavailable.

</details>


### [41] [Aligned Textual Scoring Rules](https://arxiv.org/abs/2507.06221)
*Yuxuan Lu,Yifan Wu,Jason Hartline,Michael J. Curry*

Main category: cs.AI

TL;DR: 本文提出了一种对齐评分规则（ASR），通过优化均方误差来确保文本评分规则既符合人类偏好又保持正确性。


<details>
  <summary>Details</summary>
Motivation: 现有评分规则在文本信息获取中虽具有理论正确性，但未能充分与人类偏好对齐。

Method: 设计ASR，通过最小化评分规则与参考分数（如人类评分）的均方误差。

Result: 实验表明，ASR在保持正确性的同时，显著优于现有方法。

Conclusion: ASR成功解决了文本评分规则与人类偏好的对齐问题。

Abstract: Scoring rules elicit probabilistic predictions from a strategic agent by
scoring the prediction against a ground truth state. A scoring rule is proper
if, from the agent's perspective, reporting the true belief maximizes the
expected score. With the development of language models, Wu and Hartline (2024)
proposes a reduction from textual information elicitation to the numerical
(i.e. probabilistic) information elicitation problem, which achieves provable
properness for textual elicitation. However, not all proper scoring rules are
well aligned with human preference over text. Our paper designs the Aligned
Scoring rule (ASR) for text by optimizing and minimizing the mean squared error
between a proper scoring rule and a reference score (e.g. human score). Our
experiments show that our ASR outperforms previous methods in aligning with
human preference while maintaining properness.

</details>
