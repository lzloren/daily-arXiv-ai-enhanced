<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 17]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [SEEA-R1: Tree-Structured Reinforcement Fine-Tuning for Self-Evolving Embodied Agents](https://arxiv.org/abs/2506.21669)
*Wanxin Tian,Shijie Zhang,Kevin Zhang,Xiaowei Chi,Yulin Luo,Junyu Lu,Chunkai Fan,Qiang Zhou,Yiming Zhao,Ning Liu Siyu Lin,Zhiyuan Qin,Xiaozhu Ju,Shanghang Zhang,Jian Tang*

Main category: cs.AI

TL;DR: SEEA-R1是一个基于强化微调的框架，旨在提升具身智能体的自我进化能力，通过Tree-GRPO和MGRM解决多步推理任务中的奖励稀疏性和泛化问题。


<details>
  <summary>Details</summary>
Motivation: 当前强化微调在具身智能领域的潜力尚未充分挖掘，尤其是在多模态交互和长时任务中。

Method: 提出了Tree-GRPO（基于蒙特卡洛树搜索的组相对策略优化）和MGRM（多模态生成奖励模型），以解决奖励稀疏性和任务泛化问题。

Result: 在ALFWorld基准测试中，SEEA-R1在文本和多模态任务中分别达到85.07%和36.19%的得分，优于GPT-4o等模型。

Conclusion: SEEA-R1展示了在可扩展具身智能研究中的潜力，为未来研究提供了新方向。

Abstract: Self-evolution, the ability of agents to autonomously improve their reasoning
and behavior, is essential for the embodied domain with long-horizon,
real-world tasks. Despite current advancements in reinforcement fine-tuning
(RFT) showing strong performance in enhancing reasoning in LLMs, its potential
to enable self-evolving embodied intelligence with multi-modal interactions
remains largely unexplored. Specifically, reinforcement fine-tuning faces two
fundamental obstacles in embodied settings: (i) the lack of accessible
intermediate rewards in multi-step reasoning tasks limits effective learning
signals, and (ii) reliance on hand-crafted reward functions restricts
generalization to novel tasks and environments. To address these challenges, we
present Self-Evolving Embodied Agents-R1, SEEA-R1, the first RFT framework
designed for enabling the self-evolving capabilities of embodied agents.
Specifically, to convert sparse delayed rewards into denser intermediate
signals that improve multi-step reasoning, we propose Tree-based group relative
policy optimization (Tree-GRPO), which integrates Monte Carlo Tree Search into
GRPO. To generalize reward estimation across tasks and scenes, supporting
autonomous adaptation and reward-driven self-evolution, we further introduce
Multi-modal Generative Reward Model (MGRM). To holistically evaluate the
effectiveness of SEEA-R1, we evaluate on the ALFWorld benchmark, surpassing
state-of-the-art methods with scores of 85.07% (textual) and 36.19%
(multi-modal), outperforming prior models including GPT-4o. SEEA-R1 also
achieves scores of 80.3% without environmental reward, surpassing all
open-source baselines and highlighting its scalability as a self-evolving
embodied agent. Additional experiments and qualitative analysis further support
the potential of SEEA-R1 for future research in scalable embodied intelligence.

</details>


### [2] [Hierarchical Reasoning Model](https://arxiv.org/abs/2506.21734)
*Guan Wang,Jin Li,Yuhao Sun,Xing Chen,Changling Liu,Yue Wu,Meng Lu,Sen Song,Yasin Abbasi Yadkori*

Main category: cs.AI

TL;DR: HRM是一种新型循环架构，通过分层处理实现高效推理，无需预训练或大量数据，性能优于现有大模型。


<details>
  <summary>Details</summary>
Motivation: 解决当前大语言模型在推理任务中的脆弱性、高数据需求和延迟问题。

Method: 提出HRM，包含高低级循环模块，分别负责抽象规划和细节计算，单次前向传播完成推理。

Result: 仅用27M参数和1000样本，在复杂推理任务中表现优异，超越更大模型。

Conclusion: HRM是通用计算和推理系统的潜在突破性进展。

Abstract: Reasoning, the process of devising and executing complex goal-oriented action
sequences, remains a critical challenge in AI. Current large language models
(LLMs) primarily employ Chain-of-Thought (CoT) techniques, which suffer from
brittle task decomposition, extensive data requirements, and high latency.
Inspired by the hierarchical and multi-timescale processing in the human brain,
we propose the Hierarchical Reasoning Model (HRM), a novel recurrent
architecture that attains significant computational depth while maintaining
both training stability and efficiency. HRM executes sequential reasoning tasks
in a single forward pass without explicit supervision of the intermediate
process, through two interdependent recurrent modules: a high-level module
responsible for slow, abstract planning, and a low-level module handling rapid,
detailed computations. With only 27 million parameters, HRM achieves
exceptional performance on complex reasoning tasks using only 1000 training
samples. The model operates without pre-training or CoT data, yet achieves
nearly perfect performance on challenging tasks including complex Sudoku
puzzles and optimal path finding in large mazes. Furthermore, HRM outperforms
much larger models with significantly longer context windows on the Abstraction
and Reasoning Corpus (ARC), a key benchmark for measuring artificial general
intelligence capabilities. These results underscore HRM's potential as a
transformative advancement toward universal computation and general-purpose
reasoning systems.

</details>


### [3] [THE-Tree: Can Tracing Historical Evolution Enhance Scientific Verification and Reasoning?](https://arxiv.org/abs/2506.21763)
*Xin Wang,Jiyao Liu,Yulong Xiao,Junzhi Ning,Lihao Liu,Junjun He,Botian Shi,Kaicheng Yu*

Main category: cs.AI

TL;DR: THE-Tree框架通过结构化科学文献构建技术演化树，提升科学发展的验证和预测能力。


<details>
  <summary>Details</summary>
Motivation: 解决现有验证方法（如LLM和传统引用网络）在科学命题验证中的不足，如幻觉、领域知识缺乏和非结构化问题。

Method: 提出THE-Tree框架，结合LLM的“Think-Verbalize-Cite-Verify”流程和自然语言推理机制，验证演化链接的逻辑性和证据支持。

Result: 在88个领域的实验中，THE-Tree显著提升了图完成和科学发展的预测性能，并增强了重要论文的评估效果。

Conclusion: THE-Tree为科学演化提供了结构化、可验证的框架，显著提升了验证和预测能力。

Abstract: Large Language Models (LLMs) are accelerating scientific idea generation, but
rigorously evaluating these numerous, often superficial, AI-generated
propositions for novelty and factual accuracy is a critical bottleneck; manual
verification is too slow.Existing validation methods are inadequate: LLMs as
standalone verifiers may hallucinate and lack domain knowledge (our findings
show ~60\% unawareness of relevant papers in specific domains), while
traditional citation networks lack explicit causality and narrative surveys are
unstructured.This underscores a core challenge: the absence of structured,
verifiable, and causally-linked historical data of scientific evolution.To
address this,we introduce \textbf{THE-Tree} (\textbf{T}echnology
\textbf{H}istory \textbf{E}volution Tree), a computational framework that
constructs such domain-specific evolution trees from scientific
literature.THE-Tree employs a search algorithm to explore evolutionary paths.
During its node expansion, it utilizes a novel "Think-Verbalize-Cite-Verify"
process: an LLM proposes potential advancements and cites supporting
literature. Critically, each proposed evolutionary link is then validated for
logical coherence and evidential support by a recovered natural language
inference mechanism that interrogates the cited literature, ensuring that each
step is grounded.We construct and validate 88 THE-Trees across diverse domains
and release a benchmark dataset including up to 71k fact verifications covering
27k papers to foster further research.Experiments demonstrate that i) in graph
completion, our THE-Tree improves hit@1 by 8\% to 14\% across multiple models
compared to traditional citation networks; ii) for predicting future scientific
developments, it improves hit@1 metric by nearly 10\%; and iii) when combined
with other methods, it boosts the performance of evaluating important
scientific papers by almost 100\%.

</details>


### [4] [MobiVerse: Scaling Urban Mobility Simulation with Hybrid Lightweight Domain-Specific Generator and Large Language Models](https://arxiv.org/abs/2506.21784)
*Yifan Liu,Xishun Liao,Haoxuan Ma,Jonathan Liu,Rohan Jadhav,Jiaqi Ma*

Main category: cs.AI

TL;DR: MobiVerse是一个混合框架，结合轻量级领域特定生成器和LLMs，用于高效生成和动态调整人类移动模式，解决了传统方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 解决现有移动模拟平台在算法开发、政策实施和大规模评估方面的不足，传统方法数据需求高且适应性差。

Method: 提出MobiVerse混合框架，结合轻量级生成器生成基础活动链，利用LLMs进行上下文感知调整。

Result: 在西洛杉矶Westwood的案例研究中，成功为5.3万代理生成动态调整的日程，响应环境反馈（如道路封闭、大型活动）。

Conclusion: MobiVerse在计算效率和行为真实性之间取得平衡，为移动系统规划和算法测试提供了可定制平台。

Abstract: Understanding and modeling human mobility patterns is crucial for effective
transportation planning and urban development. Despite significant advances in
mobility research, there remains a critical gap in simulation platforms that
allow for algorithm development, policy implementation, and comprehensive
evaluation at scale. Traditional activity-based models require extensive data
collection and manual calibration, machine learning approaches struggle with
adaptation to dynamic conditions, and treding agent-based Large Language Models
(LLMs) implementations face computational constraints with large-scale
simulations. To address these challenges, we propose MobiVerse, a hybrid
framework leverages the efficiency of lightweight domain-specific generator for
generating base activity chains with the adaptability of LLMs for context-aware
modifications. A case study was conducted in Westwood, Los Angeles, where we
efficiently generated and dynamically adjusted schedules for the whole
population of approximately 53,000 agents on a standard PC. Our experiments
demonstrate that MobiVerse successfully enables agents to respond to
environmental feedback, including road closures, large gathering events like
football games, and congestion, through our hybrid framework. Its modular
design facilitates testing various mobility algorithms at both transportation
system and agent levels. Results show our approach maintains computational
efficiency while enhancing behavioral realism. MobiVerse bridges the gap in
mobility simulation by providing a customizable platform for mobility systems
planning and operations with benchmark algorithms. Code and videos are
available at https://github.com/ucla-mobility/MobiVerse.

</details>


### [5] [CitySim: Modeling Urban Behaviors and City Dynamics with Large-Scale LLM-Driven Agent Simulation](https://arxiv.org/abs/2506.21805)
*Nicolas Bougie,Narimasa Watanabe*

Main category: cs.AI

TL;DR: CitySim利用大语言模型模拟人类行为，通过递归价值驱动方法生成真实日程，支持长期模拟，比现有方法更贴近现实。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖固定规则，难以模拟复杂行为和意图，CitySim旨在解决这一问题。

Method: 采用递归价值驱动方法，结合信念、长期目标和空间记忆，模拟个体和集体行为。

Result: CitySim在微观和宏观层面均表现出与真实人类行为的高度一致性，并能模拟大规模场景。

Conclusion: CitySim是一个可扩展、灵活的测试平台，适用于理解和预测城市现象。

Abstract: Modeling human behavior in urban environments is fundamental for social
science, behavioral studies, and urban planning. Prior work often rely on
rigid, hand-crafted rules, limiting their ability to simulate nuanced
intentions, plans, and adaptive behaviors. Addressing these challenges, we
envision an urban simulator (CitySim), capitalizing on breakthroughs in
human-level intelligence exhibited by large language models. In CitySim, agents
generate realistic daily schedules using a recursive value-driven approach that
balances mandatory activities, personal habits, and situational factors. To
enable long-term, lifelike simulations, we endow agents with beliefs, long-term
goals, and spatial memory for navigation. CitySim exhibits closer alignment
with real humans than prior work, both at micro and macro levels. Additionally,
we conduct insightful experiments by modeling tens of thousands of agents and
evaluating their collective behaviors under various real-world scenarios,
including estimating crowd density, predicting place popularity, and assessing
well-being. Our results highlight CitySim as a scalable, flexible testbed for
understanding and forecasting urban phenomena.

</details>


### [6] [Interactive Multi-Objective Probabilistic Preference Learning with Soft and Hard Bounds](https://arxiv.org/abs/2506.21887)
*Edward Chen,Sang T. Truong,Natalie Dullerud,Sanmi Koyejo,Carlos Guestrin*

Main category: cs.AI

TL;DR: Active-MoSH是一个交互式框架，用于在高风险决策中平衡多目标优化，结合软硬约束和偏好学习，提升决策者信任和效率。


<details>
  <summary>Details</summary>
Motivation: 解决多目标决策中资源密集、认知负担重的问题，同时确保决策者对最终选择的信任。

Method: 结合局部（软硬约束与偏好学习）和全局（多目标敏感性分析）组件，通过主动采样优化探索与利用。

Result: 在合成和实际应用中表现优异，用户研究证实其能加速收敛、增强信任并提供灵活偏好表达。

Conclusion: Active-MoSH为高风险决策提供高效、可信的交互式解决方案。

Abstract: High-stakes decision-making involves navigating multiple competing objectives
with expensive evaluations. For instance, in brachytherapy, clinicians must
balance maximizing tumor coverage (e.g., an aspirational target or soft bound
of >95% coverage) against strict organ dose limits (e.g., a non-negotiable hard
bound of <601 cGy to the bladder), with each plan evaluation being
resource-intensive. Selecting Pareto-optimal solutions that match implicit
preferences is challenging, as exhaustive Pareto frontier exploration is
computationally and cognitively prohibitive, necessitating interactive
frameworks to guide users. While decision-makers (DMs) often possess domain
knowledge to narrow the search via such soft-hard bounds, current methods often
lack systematic approaches to iteratively refine these multi-faceted preference
structures. Critically, DMs must trust their final decision, confident they
haven't missed superior alternatives; this trust is paramount in
high-consequence scenarios. We present Active-MoSH, an interactive local-global
framework designed for this process. Its local component integrates soft-hard
bounds with probabilistic preference learning, maintaining distributions over
DM preferences and bounds for adaptive Pareto subset refinement. This is guided
by an active sampling strategy optimizing exploration-exploitation while
minimizing cognitive burden. To build DM trust, Active-MoSH's global component,
T-MoSH, leverages multi-objective sensitivity analysis to identify potentially
overlooked, high-value points beyond immediate feedback. We demonstrate
Active-MoSH's performance benefits through diverse synthetic and real-world
applications. A user study on AI-generated image selection further validates
our hypotheses regarding the framework's ability to improve convergence,
enhance DM trust, and provide expressive preference articulation, enabling more
effective DMs.

</details>


### [7] [AlphaBeta is not as good as you think: a new probabilistic model to better analyze deterministic game-solving algorithms](https://arxiv.org/abs/2506.21996)
*Raphaël Boige,Amine Boumaza,Bruno Scherrer*

Main category: cs.AI

TL;DR: 论文提出了一种新的概率模型，通过引入祖先依赖关系生成更具挑战性的游戏树，分析了AlphaBeta和Scout等算法的平均复杂度，揭示了实际性能差异。


<details>
  <summary>Details</summary>
Motivation: 传统模型因独立性假设简化了游戏结构，导致算法分析结果不具实际意义。新模型旨在更真实地模拟游戏复杂性。

Method: 引入基于层级条件分布的概率模型，强制祖先依赖关系，生成可调难度的游戏树，并推导算法的递归复杂度公式。

Result: 新模型下，算法在深度有限树中表现出显著性能差异，AlphaBeta的常数乘因子明显大于Scout。

Conclusion: 新框架为经典游戏求解算法提供了更现实的分析工具，揭示了实际性能差异，推动了算法理解的进步。

Abstract: Deterministic game-solving algorithms are conventionally analyzed in the
light of their average-case complexity against a distribution of random
game-trees, where leaf values are independently sampled from a fixed
distribution. This simplified model enables uncluttered mathematical analysis,
revealing two key properties: root value distributions asymptotically collapse
to a single fixed value for finite-valued trees, and all reasonable algorithms
achieve global optimality. However, these findings are artifacts of the model's
design-its long criticized independence assumption strips games of structural
complexity, producing trivial instances where no algorithm faces meaningful
challenges. To address this limitation, we introduce a new probabilistic model
that incrementally constructs game-trees using a fixed level-wise conditional
distribution. By enforcing ancestor dependency, a critical structural feature
of real-world games, our framework generates problems with adjustable
difficulty while retaining some form of analytical tractability. For several
algorithms, including AlphaBeta and Scout, we derive recursive formulas
characterizing their average-case complexities under this model. These allow us
to rigorously compare algorithms on deep game-trees, where Monte-Carlo
simulations are no longer feasible. While asymptotically, all algorithms seem
to converge to identical branching factor (a result analogous to those of
independence-based models), deep finite trees reveal stark differences:
AlphaBeta incurs a significantly larger constant multiplicative factor compared
to algorithms like Scout, leading to a substantial practical slowdown. Our
framework sheds new light on classical game-solving algorithms, offering
rigorous evidence and analytical tools to advance the understanding of these
methods under a more realistic, challenging, and yet tractable model.

</details>


### [8] [LeanConjecturer: Automatic Generation of Mathematical Conjectures for Theorem Proving](https://arxiv.org/abs/2506.22005)
*Naoto Onda,Kazumi Kasaura,Yuta Oriike,Masaya Taniguchi,Akiyoshi Sannai,Sho Sonoda*

Main category: cs.AI

TL;DR: LeanConjecturer是一个基于LLM的自动生成数学猜想的管道，结合规则提取与LLM生成，解决了形式化定理证明中的数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 解决形式化定理证明中训练数据不足的挑战，提升定理证明系统的能力。

Method: 混合方法：规则提取上下文 + LLM生成定理陈述，通过迭代生成与评估筛选有效猜想。

Result: 从40个Mathlib种子文件生成12,289个猜想，3,776个非平凡且语法有效；展示了在拓扑学中的非平凡定理验证能力。

Conclusion: LeanConjecturer为定理证明系统提供了可扩展的训练数据生成方案，展示了数学发现的潜力。

Abstract: We introduce LeanConjecturer, a pipeline for automatically generating
university-level mathematical conjectures in Lean 4 using Large Language Models
(LLMs). Our hybrid approach combines rule-based context extraction with
LLM-based theorem statement generation, addressing the data scarcity challenge
in formal theorem proving. Through iterative generation and evaluation,
LeanConjecturer produced 12,289 conjectures from 40 Mathlib seed files, with
3,776 identified as syntactically valid and non-trivial, that is, cannot be
proven by \texttt{aesop} tactic. We demonstrate the utility of these generated
conjectures for reinforcement learning through Group Relative Policy
Optimization (GRPO), showing that targeted training on domain-specific
conjectures can enhance theorem proving capabilities. Our approach generates
103.25 novel conjectures per seed file on average, providing a scalable
solution for creating training data for theorem proving systems. Our system
successfully verified several non-trivial theorems in topology, including
properties of semi-open, alpha-open, and pre-open sets, demonstrating its
potential for mathematical discovery beyond simple variations of existing
results.

</details>


### [9] [Universal Retrieval for Multimodal Trajectory Modeling](https://arxiv.org/abs/2506.22056)
*Xuan Zhang,Ziyan Jiang,Rui Meng,Yifei Leng,Zhenbang Xiao,Zora Zhiruo Wang,Yanyi Shang,Dehan Kong*

Main category: cs.AI

TL;DR: 提出了一种多模态轨迹检索方法GAE-Retriever，通过构建数据集UATD和基准GAE-Bench，结合视觉语言模型和对比学习优化，显著提升了检索性能。


<details>
  <summary>Details</summary>
Motivation: 轨迹数据对提升AI代理能力有巨大潜力，但如何建模轨迹级数据尚未系统解决。

Method: 构建UATD数据集和GAE-Bench基准，提出GAE-Retriever框架，结合视觉语言模型和优化对比学习。

Result: GAE-Retriever在多个数据集上检索召回率显著优于基线方法。

Conclusion: GAE-Retriever有效推动了多模态轨迹检索的发展。

Abstract: Trajectory data, capturing human actions and environmental states across
various modalities, holds significant potential for enhancing AI agent
capabilities, particularly in GUI environments. However, how to model the
representation of trajectory-level data presents a significant challenge that
has not been systematically addressed amid explosive trajectory data growth. In
this work, we introduce Multimodal Trajectory Retrieval, bridging the gap
between universal retrieval and agent-centric trajectory modeling. We construct
the Unified Agent Trajectory Dataset (UATD) from annotated demonstrations and
states across diverse real-world scenarios. Based on this, we present
GAE-Bench, a benchmark containing a large number of trajectory-based retrieval
pairs. In addition, we propose GAE-Retriever, a multimodal retrieval framework
that adopts vision-language models and incorporates optimized contrastive
learning through a token selection and the GradCache mechanism. Comprehensive
evaluations across multiple datasets show that GAE-Retriever consistently
outperforms strong baselines in retrieval recall, highlighting its
effectiveness in advancing multimodal trajectory retrieval.

</details>


### [10] [Query as Test: An Intelligent Driving Test and Data Storage Method for Integrated Cockpit-Vehicle-Road Scenarios](https://arxiv.org/abs/2506.22068)
*Shengyue Yao,Runqing Guo,Yangyang Qin,Miangbing Meng,Jipeng Cao,Yilun Lin,Yisheng Lv,Fei-Yue Wang*

Main category: cs.AI

TL;DR: 论文提出了一种名为“查询即测试”（QaT）的新方法，通过逻辑查询统一表示多模态数据，解决了智能交通领域数据碎片化和测试不灵活的问题。


<details>
  <summary>Details</summary>
Motivation: 智能交通领域的数据生态系统日益碎片化，现有测试方法依赖数据堆叠且无法覆盖所有边缘情况，缺乏灵活性。

Method: 提出“可扩展场景表示法”（ESN），基于答案集编程（ASP）统一表示多模态数据，并通过逻辑查询实现测试。

Result: ESN支持复杂语义查询、提供决策过程可解释性，并实现细粒度隐私保护。QaT显著提升了测试的表达能力和形式严谨性。

Conclusion: 论文还提出“验证驱动开发”（VDD），建议在大型语言模型时代通过逻辑验证而非定量测试指导开发，加速迭代过程。

Abstract: With the deep penetration of Artificial Intelligence (AI) in the
transportation sector, intelligent cockpits, autonomous driving, and
intelligent road networks are developing at an unprecedented pace. However, the
data ecosystems of these three key areas are increasingly fragmented and
incompatible. Especially, existing testing methods rely on data stacking, fail
to cover all edge cases, and lack flexibility. To address this issue, this
paper introduces the concept of "Query as Test" (QaT). This concept shifts the
focus from rigid, prescripted test cases to flexible, on-demand logical queries
against a unified data representation. Specifically, we identify the need for a
fundamental improvement in data storage and representation, leading to our
proposal of "Extensible Scenarios Notations" (ESN). ESN is a novel declarative
data framework based on Answer Set Programming (ASP), which uniformly
represents heterogeneous multimodal data from the cockpit, vehicle, and road as
a collection of logical facts and rules. This approach not only achieves deep
semantic fusion of data, but also brings three core advantages: (1) supports
complex and flexible semantic querying through logical reasoning; (2) provides
natural interpretability for decision-making processes; (3) allows for
on-demand data abstraction through logical rules, enabling fine-grained privacy
protection. We further elaborate on the QaT paradigm, transforming the
functional validation and safety compliance checks of autonomous driving
systems into logical queries against the ESN database, significantly enhancing
the expressiveness and formal rigor of the testing. Finally, we introduce the
concept of "Validation-Driven Development" (VDD), which suggests to guide
developments by logical validation rather than quantitative testing in the era
of Large Language Models, in order to accelerating the iteration and
development process.

</details>


### [11] [A Different Approach to AI Safety: Proceedings from the Columbia Convening on Openness in Artificial Intelligence and AI Safety](https://arxiv.org/abs/2506.22183)
*Camille François,Ludovic Péran,Ayah Bdeir,Nouha Dziri,Will Hawkins,Yacine Jernite,Sayash Kapoor,Juliet Shen,Heidy Khlaaf,Kevin Klyman,Nik Marda,Marie Pellat,Deb Raji,Divya Siddarth,Aviya Skowron,Joseph Spisak,Madhulika Srikumar,Victor Storchan,Audrey Tang,Jen Weedon*

Main category: cs.AI

TL;DR: 论文探讨了开源基础模型对AI安全的影响，提出了研究议程、技术干预和安全工具，并指出了当前存在的安全缺口。


<details>
  <summary>Details</summary>
Motivation: 随着开源AI模型的快速发展，如何确保其安全性成为迫切需求。

Method: 通过哥伦比亚AI开放与安全会议的参与式解决方案，形成了研究议程、技术干预和安全工具。

Result: 研究发现开放性可增强安全性，但仍存在多模态和多语言基准不足等问题。

Conclusion: 提出了五项优先研究方向，为开放、多元和负责任的AI安全学科奠定基础。

Abstract: The rapid rise of open-weight and open-source foundation models is
intensifying the obligation and reshaping the opportunity to make AI systems
safe. This paper reports outcomes from the Columbia Convening on AI Openness
and Safety (San Francisco, 19 Nov 2024) and its six-week preparatory programme
involving more than forty-five researchers, engineers, and policy leaders from
academia, industry, civil society, and government. Using a participatory,
solutions-oriented process, the working groups produced (i) a research agenda
at the intersection of safety and open source AI; (ii) a mapping of existing
and needed technical interventions and open source tools to safely and
responsibly deploy open foundation models across the AI development workflow;
and (iii) a mapping of the content safety filter ecosystem with a proposed
roadmap for future research and development. We find that openness --
understood as transparent weights, interoperable tooling, and public governance
-- can enhance safety by enabling independent scrutiny, decentralized
mitigation, and culturally plural oversight. However, significant gaps persist:
scarce multimodal and multilingual benchmarks, limited defenses against
prompt-injection and compositional attacks in agentic systems, and insufficient
participatory mechanisms for communities most affected by AI harms. The paper
concludes with a roadmap of five priority research directions, emphasizing
participatory inputs, future-proof content filters, ecosystem-wide safety
infrastructure, rigorous agentic safeguards, and expanded harm taxonomies.
These recommendations informed the February 2025 French AI Action Summit and
lay groundwork for an open, plural, and accountable AI safety discipline.

</details>


### [12] [Breaking Rank Bottlenecks in Knowledge Graph Completion](https://arxiv.org/abs/2506.22271)
*Samy Badreddine,Emile van Krieken,Luciano Serafini*

Main category: cs.AI

TL;DR: 论文研究了知识图谱补全（KGC）模型中的秩瓶颈问题，并提出了一种基于混合的输出层（KGE-MoS）来提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有KGC模型在实体数量远大于嵌入维度时，线性输出层会形成秩瓶颈，限制了模型的表达能力和预测准确性。

Method: 通过理论和实证分析秩瓶颈的影响，并提出KGE-MoS方法，利用混合输出层打破秩瓶颈。

Result: 在四个数据集上的实验表明，KGE-MoS以较低参数成本提升了KGC模型的性能和概率拟合度。

Conclusion: KGE-MoS有效解决了秩瓶颈问题，为KGC模型提供了更高的表达能力和准确性。

Abstract: Many Knowledge Graph Completion (KGC) models, despite using powerful
encoders, rely on a simple vector-matrix multiplication to score queries
against candidate object entities. When the number of entities is larger than
the model's embedding dimension, which in practical scenarios is often by
several orders of magnitude, we have a linear output layer with a rank
bottleneck. Such bottlenecked layers limit model expressivity. We investigate
both theoretically and empirically how rank bottlenecks affect KGC models. We
find that, by limiting the set of feasible predictions, rank bottlenecks hurt
ranking accuracy and the distribution fidelity of scores. Inspired by the
language modelling literature, we propose KGE-MoS, a mixture-based output layer
to break rank bottlenecks in many KGC models. Our experiments on four datasets
show that KGE-MoS improves performance and probabilistic fit of KGC models for
a low parameter cost.

</details>


### [13] [Artificial Intelligent Disobedience: Rethinking the Agency of Our Artificial Teammates](https://arxiv.org/abs/2506.22276)
*Reuth Mirsky*

Main category: cs.AI

TL;DR: 论文主张赋予AI队友"智能不服从"能力，使其在人类-AI团队中能自主决策，并探讨了不同自主级别下智能不服从的表现。


<details>
  <summary>Details</summary>
Motivation: 当前大多数协作AI系统过于服从人类指令，可能导致低效或不安全，因此需要研究AI的自主性。

Method: 提出AI自主性级别量表，并通过代表性案例说明智能不服从的重要性。

Result: 强调了将AI自主性作为独立研究焦点的必要性，并探讨了智能不服从的表现形式。

Conclusion: 提出了研究AI不服从能力的初步边界和考虑因素，作为未来研究的起点。

Abstract: Artificial intelligence has made remarkable strides in recent years,
achieving superhuman performance across a wide range of tasks. Yet despite
these advances, most cooperative AI systems remain rigidly obedient, designed
to follow human instructions without question and conform to user expectations,
even when doing so may be counterproductive or unsafe. This paper argues for
expanding the agency of AI teammates to include \textit{intelligent
disobedience}, empowering them to make meaningful and autonomous contributions
within human-AI teams. It introduces a scale of AI agency levels and uses
representative examples to highlight the importance and growing necessity of
treating AI autonomy as an independent research focus in cooperative settings.
The paper then explores how intelligent disobedience manifests across different
autonomy levels and concludes by proposing initial boundaries and
considerations for studying disobedience as a core capability of artificial
agents.

</details>


### [14] [Conceptual Topic Aggregation](https://arxiv.org/abs/2506.22309)
*Klara M. Gutekunst,Dominik Dürrschnabel,Johannes Hirth,Gerd Stumme*

Main category: cs.AI

TL;DR: 提出了一种基于形式概念分析（FCA）的FAT-CAT方法，用于改进主题建模的可解释性和可视化效果。


<details>
  <summary>Details</summary>
Motivation: 传统主题建模方法难以提供可解释的表示，限制了数据探索的深度。

Method: 利用FCA构建概念格，实现主题的分层结构化表示，支持多样化的主题和文件类型。

Result: 在ETYNTKE数据集上的实验表明，FAT-CAT比现有方法提供更直观和有意义的数据洞察。

Conclusion: FCA为基础的主题聚合方法在提升主题建模的可解释性方面具有潜力。

Abstract: The vast growth of data has rendered traditional manual inspection
infeasible, necessitating the adoption of computational methods for efficient
data exploration. Topic modeling has emerged as a powerful tool for analyzing
large-scale textual datasets, enabling the extraction of latent semantic
structures. However, existing methods for topic modeling often struggle to
provide interpretable representations that facilitate deeper insights into data
structure and content. In this paper, we propose FAT-CAT, an approach based on
Formal Concept Analysis (FCA) to enhance meaningful topic aggregation and
visualization of discovered topics. Our approach can handle diverse topics and
file types -- grouped by directories -- to construct a concept lattice that
offers a structured, hierarchical representation of their topic distribution.
In a case study on the ETYNTKE dataset, we evaluate the effectiveness of our
approach against other representation methods to demonstrate that FCA-based
aggregation provides more meaningful and interpretable insights into dataset
composition than existing topic modeling techniques.

</details>


### [15] [Embodied AI Agents: Modeling the World](https://arxiv.org/abs/2506.22355)
*Pascale Fung,Yoram Bachrach,Asli Celikyilmaz,Kamalika Chaudhuri,Delong Chen,Willy Chung,Emmanuel Dupoux,Hervé Jégou,Alessandro Lazaric,Arjun Majumdar,Andrea Madotto,Franziska Meier,Florian Metze,Théo Moutakanni,Juan Pino,Basile Terver,Joseph Tighe,Jitendra Malik*

Main category: cs.AI

TL;DR: 研究探讨了具身AI代理在视觉、虚拟或物理形式中的交互能力，强调世界模型对其推理和规划的核心作用。


<details>
  <summary>Details</summary>
Motivation: 提升AI代理与环境和用户的交互能力，使其更接近人类的学习与互动方式。

Method: 提出通过多模态感知、推理规划和记忆构建世界模型，并学习用户的心理世界模型。

Result: 具身AI代理能更好地理解和预测环境，增强自主执行复杂任务的能力。

Conclusion: 世界模型是具身AI代理实现高效交互和协作的关键。

Abstract: This paper describes our research on AI agents embodied in visual, virtual or
physical forms, enabling them to interact with both users and their
environments. These agents, which include virtual avatars, wearable devices,
and robots, are designed to perceive, learn and act within their surroundings,
which makes them more similar to how humans learn and interact with the
environments as compared to disembodied agents. We propose that the development
of world models is central to reasoning and planning of embodied AI agents,
allowing these agents to understand and predict their environment, to
understand user intentions and social contexts, thereby enhancing their ability
to perform complex tasks autonomously. World modeling encompasses the
integration of multimodal perception, planning through reasoning for action and
control, and memory to create a comprehensive understanding of the physical
world. Beyond the physical world, we also propose to learn the mental world
model of users to enable better human-agent collaboration.

</details>


### [16] [AI Model Passport: Data and System Traceability Framework for Transparent AI in Health](https://arxiv.org/abs/2506.22358)
*Varvara Kalokyri,Nikolaos S. Tachos,Charalampos N. Kalantzopoulos,Stelios Sfakianakis,Haridimos Kondylakis,Dimitrios I. Zaridis,Sara Colantonio,Daniele Regge,Nikolaos Papanikolaou,The ProCAncer-I consortium,Konstantinos Marias,Dimitrios I. Fotiadis,Manolis Tsiknakis*

Main category: cs.AI

TL;DR: 论文提出AI Model Passport框架，为AI模型提供标准化数字身份和验证工具，提升透明度和可追溯性，并通过AIPassport工具实现自动化元数据收集。


<details>
  <summary>Details</summary>
Motivation: 现有AI框架依赖人工文档，缺乏可扩展性和机器可读性，难以确保模型身份和真实性，限制了可重复性和信任。

Method: 引入AI Model Passport框架，标准化记录模型元数据，开发AIPassport工具自动化收集和管理元数据。

Result: 通过医学影像案例验证，AIPassport提升了透明度、可重复性和合规性，减少人工操作。

Conclusion: AI Model Passport为AI医疗解决方案设定了信任和问责新标准，有望成为跨领域透明合规AI系统的基础。

Abstract: The increasing integration of Artificial Intelligence (AI) into health and
biomedical systems necessitates robust frameworks for transparency,
accountability, and ethical compliance. Existing frameworks often rely on
human-readable, manual documentation which limits scalability, comparability,
and machine interpretability across projects and platforms. They also fail to
provide a unique, verifiable identity for AI models to ensure their provenance
and authenticity across systems and use cases, limiting reproducibility and
stakeholder trust. This paper introduces the concept of the AI Model Passport,
a structured and standardized documentation framework that acts as a digital
identity and verification tool for AI models. It captures essential metadata to
uniquely identify, verify, trace and monitor AI models across their lifecycle -
from data acquisition and preprocessing to model design, development and
deployment. In addition, an implementation of this framework is presented
through AIPassport, an MLOps tool developed within the ProCAncer-I EU project
for medical imaging applications. AIPassport automates metadata collection,
ensures proper versioning, decouples results from source scripts, and
integrates with various development environments. Its effectiveness is
showcased through a lesion segmentation use case using data from the
ProCAncer-I dataset, illustrating how the AI Model Passport enhances
transparency, reproducibility, and regulatory readiness while reducing manual
effort. This approach aims to set a new standard for fostering trust and
accountability in AI-driven healthcare solutions, aspiring to serve as the
basis for developing transparent and regulation compliant AI systems across
domains.

</details>


### [17] [The Automated LLM Speedrunning Benchmark: Reproducing NanoGPT Improvements](https://arxiv.org/abs/2506.22419)
*Bingchen Zhao,Despoina Magka,Minqi Jiang,Xian Li,Roberta Raileanu,Tatiana Shavrina,Jean-Christophe Gagnon-Audet,Kelvin Niu,Shagun Sodhani,Michael Shvartsman,Andrei Lupu,Alisia Lupidi,Edan Toledo,Karen Hambardzumyan,Martin Josifoski,Thomas Foster,Lucia Cipolina-Kun,Abhishek Charnalia,Derek Dunfield,Alexander H. Miller,Oisin Mac Aodha,Jakob Foerster,Yoram Bachrach*

Main category: cs.AI

TL;DR: 论文提出了一个自动化LLM速度跑分基准，用于评估AI代理在科学复现中的能力，发现即使提供详细提示，现有LLM仍难以复现已知创新。


<details>
  <summary>Details</summary>
Motivation: 评估AI代理在科学复现中的能力，以推动LLM在科学进步中的应用。

Method: 引入自动化LLM速度跑分基准，基于NanoGPT速度跑任务，提供不同格式的提示，测试LLM复现能力。

Result: 现有LLM即使结合先进框架，仍难以复现已知创新。

Conclusion: 该基准为衡量LLM自动化科学复现能力提供了简单且未饱和的指标，是自主研究代理的必要技能之一。

Abstract: Rapid advancements in large language models (LLMs) have the potential to
assist in scientific progress. A critical capability toward this endeavor is
the ability to reproduce existing work. To evaluate the ability of AI agents to
reproduce results in an active research area, we introduce the Automated LLM
Speedrunning Benchmark, leveraging the research community contributions on the
NanoGPT speedrun, a competition to train a GPT-2 model in the shortest time.
Each of the 19 speedrun tasks provides the agent with the previous records
training script, optionally paired with one of three hint formats, ranging from
pseudocode to paper-like descriptions of the new records improvements. Records
execute quickly by design and speedrun improvements encompass diverse
code-level changes, ranging from high-level algorithmic advancements to
hardware-aware optimizations. These features make the benchmark both accessible
and realistic for the frontier problem of improving LLM training. We find that
recent reasoning LLMs combined with SoTA scaffolds struggle to reimplement
already-known innovations in our benchmark, even when given detailed hints. Our
benchmark thus provides a simple, non-saturated measure of an LLMs ability to
automate scientific reproduction, a necessary (but not sufficient) skill for an
autonomous research agent.

</details>
